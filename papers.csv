author,publisher,title,url,year,abstract,session,pdf_url,openreview_url
"['Ching Fang', 'Kimberly Stachenfeld']",ICLR,Predictive auxiliary objectives in deep RL mimic learning in the brain,https://iclr.cc/virtual/2024/oral/19748,2024," The ability to predict upcoming events has been hypothesized to comprise a key aspect of natural and machine cognition. This is supported by trends in deep reinforcement learning (RL), where self-supervised auxiliary objectives such as prediction are widely used to support representation learning and improve task performance. Here, we study the effects predictive auxiliary objectives have on representation learning across different modules of an RL system and how these mimic representational changes observed in the brain. We find that predictive objectives improve and stabilize learning particularly in resource-limited architectures, and we identify settings where longer predictive horizons better support representational transfer. Furthermore, we find that representational changes in this RL system bear a striking resemblance to changes in neural activity observed in the brain across various experiments. Specifically, we draw a connection between the auxiliary predictive model of the RL system and hippocampus, an area thought to learn a predictive model to support memory-guided behavior. We also connect the encoder network and the value learning network of the RL system to visual cortex and striatum in the brain, respectively. This work demonstrates how representation learning in deep RL systems can provide an interpretable framework for modeling multi-region interactions in the brain. The deep RL perspective taken here also suggests an additional role of the hippocampus in the brain-- that of an auxiliary learning system that benefits representation learning in other regions.",Oral 1A,https://openreview.net/pdf?id=agPpmEgf8C,https://openreview.net/forum?id=agPpmEgf8C
"['HAOYUE DAI', 'Ignavier Ng', 'Gongxu Luo', 'Peter Spirtes', 'Petar Stojanov', 'Kun Zhang']",ICLR,Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View,https://iclr.cc/virtual/2024/oral/19739,2024," Gene regulatory network inference (GRNI) is a challenging problem, particularly owing to the presence of zeros in single-cell RNA sequencing data: some are biological zeros representing no gene expression, while some others are technical zeros arising from the sequencing procedure (aka dropouts), which may bias GRNI by distorting the joint distribution of the measured gene expressions. Existing approaches typically handle dropout error via imputation, which may introduce spurious relations as the true joint distribution is generally unidentifiable. To tackle this issue, we introduce a causal graphical model to characterize the dropout mechanism, namely, Causal Dropout Model. We provide a simple yet effective theoretical result: interestingly, the conditional independence (CI) relations in the data with dropouts, after deleting the samples with zero values (regardless if technical or not) for the conditioned variables, are asymptotically identical to the CI relations in the original data without dropouts. This particular test-wise deletion procedure, in which we perform CI tests on the samples without zeros for the conditioned variables, can be seamlessly integrated with existing structure learning approaches including constraint-based and greedy score-based methods, thus giving rise to a principled framework for GRNI in the presence of dropouts. We further show that the causal dropout model can be validated from data, and many existing statistical models to handle dropouts fit into our model as specific parametric instances. Empirical evaluation on synthetic, curated, and real-world experimental transcriptomic data comprehensively demonstrate the efficacy of our method.",Oral 1D,https://openreview.net/pdf?id=gFR4QwK53h,https://openreview.net/forum?id=gFR4QwK53h
"['Izzeddin Gur', 'Hiroki Furuta', 'Austin Huang', 'Mustafa Safdari', 'Yutaka Matsuo', 'Douglas Eck', 'Aleksandra Faust']",ICLR,"A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",https://iclr.cc/virtual/2024/oral/19785,2024," Pre-trained large language models (LLMs) have recently achieved better generalization and sample efficiency in autonomous web automation.However, the performance on real-world websites has still suffered from (1) open domainness, (2) limited context length, and (3) lack of inductive bias on HTML.We introduce WebAgent, an LLM-driven agent that learns from self-experience to complete tasks on real websites following natural language instructions.WebAgent plans ahead by decomposing instructions into canonical sub-instructions, summarizes long HTML documents into task-relevant snippets, and acts on websites via Python programs generated from those.We design WebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, new pre-trained LLMs for long HTML documents using local and global attention mechanisms and a mixture of long-span denoising objectives, for planning and summarization.We empirically demonstrate that our modular recipe improves the success on real websites by over 50%, and that HTML-T5 is the best model to solve various HTML understanding tasks; achieving 18.7% higher success rate than the prior method on MiniWoB web automation benchmark, and SoTA performance on Mind2Web, an offline task planning evaluation.",Oral 1B,https://openreview.net/pdf?id=9JQtrumvg8,https://openreview.net/forum?id=9JQtrumvg8
"['Yukang Chen', 'Shengju Qian', 'Haotian Tang', 'Xin Lai', 'Zhijian Liu', 'Song Han', 'Jiaya Jia']",ICLR,LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models,https://iclr.cc/virtual/2024/oral/19790,2024," We present LongLoRA, an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs), with limited computation cost.Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. For example, training on the context length of 8192 needs 16x computational costs in self-attention layers as that of 2048. In this paper, we speed up the context extension of LLMs in two aspects. On the one hand, although dense global attention is needed during inference, fine-tuning the model can be effectively and efficiently done by sparse local attention. The proposed shifted sparse attention effectively enables context extension, leading to non-trivial computation saving with similar performance to fine-tuning with vanilla attention. Particularly, it can be implemented with only two lines of code in training, while being optional in inference. On the other hand, we revisit the parameter-efficient fine-tuning regime for context expansion. Notably, we find that LoRA for context extension works well under the premise of trainable embedding and normalization. LongLoRA combines this improved LoRA with S^2-Attn. LongLoRA demonstrates strong empirical results on various tasks on Llama2 models from 7B/13B to 70B. LongLoRA extends Llama2 7B from 4k context to 100k, or Llama2 70B to 32k on a single 8x A100 machine. LongLoRA extends models' context while retaining their original architectures, and is compatible with most existing techniques, like Flash-Attention2. In addition, we further conduct supervised fine-tuning with LongLoRA and our long instruction-following LongAlpaca dataset. All our code, models, dataset, and demo are available at https://github.com/dvlab-research/LongLoRA.",Oral 1C,https://openreview.net/pdf?id=6PmJoRfdaK,https://openreview.net/forum?id=6PmJoRfdaK
"['Sirui Hong', 'Mingchen Zhuge', 'Jonathan Chen', 'Xiawu Zheng', 'Yuheng Cheng', 'Jinlin Wang', 'Ceyao Zhang', 'zili wang', 'Steven Yau', 'Zijuan Lin', 'Liyang Zhou', 'Chenyu Ran', 'Lingfeng Xiao', 'Chenglin Wu', 'Jürgen Schmidhuber']",ICLR,MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework,https://iclr.cc/virtual/2024/oral/19756,2024," Recently, remarkable progress has been made on automated problem solving through societies of agents based on large language models (LLMs). Previous LLM-based multi-agent systems can already solve simple dialogue tasks. More complex tasks, however, face challenges through logic inconsistencies due to cascading hallucinations caused by naively chaining LLMs. Here we introduce MetaGPT, an innovative meta-programming framework incorporating efficient human workflows into LLM-based multi-agent collaborations. MetaGPT encodes Standardized Operating Procedures (SOPs) into prompt sequences for more streamlined workflows, thus allowing agents with human-like domain expertise to verify intermediate results and reduce errors.  MetaGPT utilizes an assembly line paradigm to assign diverse roles to various agents, efficiently breaking down complex tasks into subtasks involving many agents working together.  On collaborative software engineering benchmarks, MetaGPT generates more coherent solutions than previous chat-based multi-agent systems.",Oral 2A,https://openreview.net/pdf?id=VtmBAGCN7o,https://openreview.net/forum?id=VtmBAGCN7o
"['Timothée Darcet', 'Maxime Oquab', 'Julien Mairal', 'Piotr Bojanowski']",ICLR,Vision Transformers Need Registers,https://iclr.cc/virtual/2024/oral/19794,2024," Transformers have recently emerged as a powerful tool for learning visual representations. In this paper, we identify and characterize artifacts in feature maps of both supervised and self-supervised ViT networks. The artifacts correspond to high-norm tokens appearing during inference primarily in low-informative background areas of images, that are repurposed for internal computations. We propose a simple yet effective solution based on providing additional tokens to the input sequence of the Vision Transformer to fill that role. We show that this solution fixes that problem entirely for both supervised and self-supervised models, sets a new state of the art for self-supervised visual models on dense visual prediction tasks, enables object discovery methods with larger models, and most importantly leads to smoother feature maps and attention maps for downstream visual processing.",Oral 2B,https://openreview.net/pdf?id=2dnO3LLiJ1,https://openreview.net/forum?id=2dnO3LLiJ1
"['Zhantao Yang', 'Ruili Feng', 'Han Zhang', 'Yujun Shen', 'Kai Zhu', 'Lianghua Huang', 'Yifei Zhang', 'Yu Liu', 'Deli Zhao', 'Jingren Zhou', 'Fan Cheng']",ICLR,Lipschitz Singularities in Diffusion Models,https://iclr.cc/virtual/2024/oral/19755,2024," Diffusion models, which employ stochastic differential equations to sample images through integrals, have emerged as a dominant class of generative models. However, the rationality of the diffusion process itself receives limited attention, leaving the question of whether the problem is well-posed and well-conditioned. In this paper, we uncover a vexing propensity of diffusion models: they frequently exhibit the infinite Lipschitz near the zero point of timesteps. We provide theoretical proofs to illustrate the presence of infinite Lipschitz constants and empirical results to confirm it. The Lipschitz singularities pose a threat to the stability and accuracy during both the training and inference processes of diffusion models. Therefore, the mitigation of Lipschitz singularities holds great potential for enhancing the performance of diffusion models. To address this challenge, we propose a novel approach, dubbed E-TSDM, which alleviates the Lipschitz singularities of the diffusion model near the zero point. Remarkably, our technique yields a substantial improvement in performance. Moreover, as a byproduct of our method, we achieve a dramatic reduction in the Fréchet Inception Distance of acceleration methods relying on network Lipschitz, including DDIM and DPM-Solver, by over 33\%. Extensive experiments on diverse datasets validate our theory and method. Our work may advance the understanding of the general diffusion process, and also provide insights for the design of diffusion models.",Oral 2C,https://openreview.net/pdf?id=WNkW0cOwiz,https://openreview.net/forum?id=WNkW0cOwiz
"['Bohang Zhang', 'Jingchu Gai', 'Yiheng Du', 'Qiwei Ye', 'Di He', 'Liwei Wang']",ICLR,Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness,https://iclr.cc/virtual/2024/oral/19773,2024," Designing expressive Graph Neural Networks (GNNs) is a fundamental topic in the graph learning community. So far, GNN expressiveness has been primarily assessed via the Weisfeiler-Lehman (WL) hierarchy. However, such an expressivity measure has notable limitations: it is inherently coarse, qualitative, and may not well reflect practical requirements (e.g., the ability to encode substructures). In this paper, we introduce a novel framework for quantitatively studying the expressiveness of GNN architectures, addressing all the above limitations. Specifically, we identify a fundamental expressivity measure termed homomorphism expressivity, which quantifies the ability of GNN models to count graphs under homomorphism. Homomorphism expressivity offers a complete and practical assessment tool: the completeness enables direct expressivity comparisons between GNN models, while the practicality allows for understanding concrete GNN abilities such as subgraph counting. By examining four classes of prominent GNNs as case studies, we derive simple, unified, and elegant descriptions of their homomorphism expressivity for both invariant and equivariant settings. Our results provide novel insights into a series of previous work, unify the landscape of different subareas in the community, and settle several open questions. Empirically, extensive experiments on both synthetic and real-world tasks verify our theory, showing that the practical performance of GNN models aligns well with the proposed metric.",Oral 2D,https://openreview.net/pdf?id=HSKaGOi7Ar,https://openreview.net/forum?id=HSKaGOi7Ar
"['Yixiao Li', 'Yifan Yu', 'Chen Liang', 'Nikos Karampatziakis', 'Pengcheng He', 'Weizhu Chen', 'Tuo Zhao']",ICLR,LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models,https://iclr.cc/virtual/2024/oral/19765,2024," Quantization is an indispensable technique for serving Large Language Models (LLMs) and has recently found its way into LoRA fine-tuning (Dettmers et al., 2023). In this work we focus on the scenario where quantization and LoRA fine- tuning are applied together on a pre-trained model. In such cases it is common to observe a consistent gap in the performance on downstream tasks between full fine-tuning and quantization plus LoRA fine-tuning approach. In response, we propose LoftQ (LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that simultaneously quantizes an LLM and finds a proper low-rank initialization for LoRA fine-tuning. Such an initialization alleviates the discrep- ancy between the quantized and full-precision model and significantly improves the generalization in downstream tasks. We evaluate our method on natural lan- guage understanding, question answering, summarization, and natural language generation tasks. Experiments show that our method is highly effective and out- performs existing quantization methods, especially in the challenging 2-bit and 2/4-bit mixed precision regimes. We will release our code.",Oral 3A,https://openreview.net/pdf?id=LzPWWPAdY4,https://openreview.net/forum?id=LzPWWPAdY4
"['Yuxuan Song', 'Jingjing Gong', 'Hao Zhou', 'Mingyue Zheng', 'Jingjing Liu', 'Wei-Ying Ma']",ICLR,Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks,https://iclr.cc/virtual/2024/oral/19764,2024," Advanced generative model (\textit{e.g.}, diffusion model) derived from simplified continuity assumptions of data distribution, though showing promising progress, has been difficult to apply directly to geometry generation applications due to the \textit{multi-modality} and \textit{noise-sensitive} nature of molecule geometry. This work introduces Geometric Bayesian Flow Networks (GeoBFN), which naturally fits molecule geometry by modeling diverse modalities in the differentiable parameter space of distributions. GeoBFN maintains the SE-(3) invariant density modeling property by incorporating equivariant inter-dependency modeling on parameters of distributions and unifying the probabilistic modeling of different modalities. Through optimized training and sampling techniques, we demonstrate that GeoBFN achieves state-of-the-art performance on multiple 3D molecule generation benchmarks in terms of generation quality (90.87\% molecule stability in QM9 and 85.6\% atom stability in GEOM-DRUG\footnote{The scores are reported at 1k sampling steps for fair comparison, and our scores could be further improved if sampling sufficiently longer steps.}). GeoBFN can also conduct sampling with any number of steps to reach an optimal trade-off between efficiency and quality (\textit{e.g.}, 20$\times$ speedup without sacrificing performance).",Oral 3B,https://openreview.net/pdf?id=NSVtmmzeRB,https://openreview.net/forum?id=NSVtmmzeRB
"['Bo Zhao', 'Robert M. Gower', 'Robin Walters', 'Rose Yu']",ICLR,Improving Convergence and Generalization Using Parameter Symmetries,https://iclr.cc/virtual/2024/oral/19767,2024," In many neural networks, different values of the parameters may result in the same loss value. Parameter space symmetries are loss-invariant transformations that change the model parameters. Teleportation applies such transformations to accelerate optimization. However, the exact mechanism behind this algorithm's success is not well understood. In this paper, we show that teleportation not only speeds up optimization in the short-term, but gives overall faster time to convergence. Additionally, teleporting to minima with different curvatures improves generalization, which suggests a connection between the curvature of the minimum and generalization ability. Finally, we show that integrating teleportation into a wide range of optimization algorithms and optimization-based meta-learning improves convergence. Our results showcase the versatility of teleportation and demonstrate the potential of incorporating symmetry in optimization.",Oral 3C,https://openreview.net/pdf?id=L0r0GphlIL,https://openreview.net/forum?id=L0r0GphlIL
"['Wenxuan Li', 'Alan Yuille', 'Zongwei Zhou']",ICLR,How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?,https://iclr.cc/virtual/2024/oral/19781,2024," The pre-training and fine-tuning paradigm has become prominent in transfer learning. For example, if the model is pre-trained on ImageNet and then fine-tuned to PASCAL, it can significantly outperform that trained on PASCAL from scratch. While ImageNet pre-training has shown enormous success, it is formed in 2D, and the learned features are for classification tasks; when transferring to more diverse tasks, like 3D image segmentation, its performance is inevitably compromised due to the deviation from the original ImageNet context. A significant challenge lies in the lack of large, annotated 3D datasets rivaling the scale of ImageNet for model pre-training. To overcome this challenge, we make two contributions. Firstly, we construct AbdomenAtlas 1.1 that comprises 9,262 three-dimensional computed tomography (CT) volumes with high-quality, per-voxel annotations of 25 anatomical structures and pseudo annotations of seven tumor types. Secondly, we develop a suite of models that are pre-trained on our AbdomenAtlas 1.1 for transfer learning. Our preliminary analyses indicate that the model trained only with 21 CT volumes, 672 masks, and 40 GPU hours has a transfer learning ability similar to the model trained with 5,050 (unlabeled) CT volumes and 1,152 GPU hours. More importantly, the transfer learning ability of supervised models can further scale up with larger annotated datasets, achieving significantly better performance than preexisting pre-trained models, irrespective of their pre-training methodologies or data sources. We hope this study can facilitate collective efforts in constructing larger 3D medical datasets and more releases of supervised pre-trained models.",Oral 3D,https://openreview.net/pdf?id=AhizIPytk4,https://openreview.net/forum?id=AhizIPytk4
"['Ismail Akhalwaya', 'Shashanka Ubaru', 'Kenneth Clarkson', 'Mark Squillante', 'Vishnu Jejjala', 'Yang-Hui He', 'Kugendran Naidoo', 'Vasileios Kalantzis', 'Lior Horesh']",ICLR,Topological data analysis on noisy quantum computers,https://iclr.cc/virtual/2024/oral/19742,2024," Topological data analysis (TDA) is a powerful technique for extracting complex and valuable shape-related summaries of high-dimensional data. However, the computational demands of classical algorithms for computing TDA are exorbitant, and quickly become impractical for high-order characteristics. Quantum computers offer the potential of achieving significant speedup for certain computational problems. Indeed, TDA has been purported to be one such problem, yet, quantum computing algorithms proposed for the problem, such as the original Quantum TDA (QTDA) formulation by Lloyd, Garnerone and Zanardi, require fault-tolerance qualifications that are currently unavailable. In this study, we present NISQ-TDA, a fully implemented end-to-end quantum machine learning algorithm needing only a short circuit-depth, that is applicable to high-dimensional classical data, and with provable asymptotic speedup for certain classes of problems. The algorithm neither suffers from the data-loading problem nor does it need to store the input data on the quantum computer explicitly. The algorithm was successfully executed on quantum computing devices, as well as on noisy quantum simulators, applied to small datasets. Preliminary empirical results suggest that the algorithm is robust to noise.",Oral 4B,https://openreview.net/pdf?id=dLrhRIMVmB,https://openreview.net/forum?id=dLrhRIMVmB
"['Carlos E Jimenez', 'John Yang', 'Alexander Wettig', 'Shunyu Yao', 'Kexin Pei', 'Ofir Press', 'Karthik Narasimhan']",ICLR,SWE-bench: Can Language Models Resolve Real-world Github Issues?,https://iclr.cc/virtual/2024/oral/19757,2024," Language models have outpaced our ability to evaluate them effectively, but for their future development it is essential to study the frontier of their capabilities. We find real-world software engineering to be a rich, sustainable, and challenging testbed for evaluating the next generation of language models. To this end, we introduce SWE-bench, an evaluation framework consisting of 2,294 software engineering problems drawn from real GitHub issues and corresponding pull requests across 12 popular Python repositories. Given a codebase along with a description of an issue to be resolved, a language model is tasked with editing the codebase to address the issue. Resolving issues in SWE-bench frequently requires understanding and coordinating changes across multiple functions, classes, and even files simultaneously, calling for models to interact with execution environments, process extremely long contexts and perform complex reasoning that goes far beyond traditional code generation tasks. Our evaluations show that both state-of-the-art proprietary models and our fine-tuned model SWE-Llama can resolve only the simplest issues. The best-performing model, Claude 2, is able to solve a mere 1.96% of the issues. Advances on SWE-bench represent steps towards LMs that are more practical, intelligent, and autonomous.",Oral 4A,https://openreview.net/pdf?id=VTF8yNQM66,https://openreview.net/forum?id=VTF8yNQM66
"['Hyungho Na', 'Yunkyeong Seo', 'Il-chul Moon']",ICLR,Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning,https://iclr.cc/virtual/2024/oral/19766,2024," In cooperative multi-agent reinforcement learning (MARL), agents aim to achieve a common goal, such as defeating enemies or scoring a goal. Existing MARL algorithms are effective but still require significant learning time and often get trapped in local optima by complex tasks, subsequently failing to discover a goal-reaching policy. To address this, we introduce Efficient episodic Memory Utilization (EMU) for MARL, with two primary objectives: (a) accelerating reinforcement learning by leveraging semantically coherent memory from an episodic buffer and (b) selectively promoting desirable transitions to prevent local convergence. To achieve (a), EMU incorporates a trainable encoder/decoder structure alongside MARL, creating coherent memory embeddings that facilitate exploratory memory recall. To achieve (b), EMU introduces a novel reward structure called episodic incentive based on the desirability of states. This reward improves the TD target in Q-learning and acts as an additional incentive for desirable transitions. We provide theoretical support for the proposed incentive and demonstrate the effectiveness of EMU compared to conventional episodic control. The proposed method is evaluated in StarCraft II and Google Research Football, and empirical results indicate further performance improvement over state-of-the-art methods.",Oral 4C,https://openreview.net/pdf?id=LjivA1SLZ6,https://openreview.net/forum?id=LjivA1SLZ6
"['Edward Hu', 'Moksh Jain', 'Eric Elmoznino', 'Younesse Kaddar', 'Guillaume Lajoie', 'Yoshua Bengio', 'Nikolay Malkin']",ICLR,Amortizing intractable inference in large language models,https://iclr.cc/virtual/2024/oral/19763,2024," Autoregressive large language models (LLMs) compress knowledge from their training data through next-token conditional distributions. This limits tractable querying of this knowledge to start-to-end autoregressive sampling. However, many tasks of interest---including sequence continuation, infilling, and other forms of constrained generation---involve sampling from intractable posterior distributions. We address this limitation by using amortized Bayesian inference to sample from these intractable posteriors. Such amortization is algorithmically achieved by fine-tuning LLMs via diversity-seeking reinforcement learning algorithms: generative flow networks (GFlowNets). We empirically demonstrate that this distribution-matching paradigm of LLM fine-tuning can serve as an effective alternative to maximum-likelihood training and reward-maximizing policy optimization. As an important application, we interpret chain-of-thought reasoning as a latent variable modeling problem and demonstrate that our approach enables data-efficient adaptation of LLMs to tasks that require multi-step rationalization and tool use.",Oral 4D,https://openreview.net/pdf?id=Ouj6p4ca60,https://openreview.net/forum?id=Ouj6p4ca60
"['Zahra Kadkhodaie', 'Florentin Guth', 'Eero Simoncelli', 'Stéphane Mallat']",ICLR,Generalization in diffusion models arises from geometry-adaptive harmonic representations,https://iclr.cc/virtual/2024/oral/19783,2024," Deep neural networks (DNNs) trained for image denoising are able to generate high-quality samples with score-based reverse diffusion algorithms. These impressive capabilities seem to imply an escape from the curse of dimensionality, but recent reports of memorization of the training set raise the question of whether these networks are learning the ""true"" continuous density of the data. Here, we show that two DNNs trained on non-overlapping subsets of a dataset learn nearly the same score function, and thus the same density, when the number of training images is large enough.  In this regime of strong generalization, diffusion-generated images are distinct from the training set, and are of high visual quality, suggesting that the inductive biases of the DNNs are well-aligned with the data density. We analyze the learned denoising functions and show that the inductive biases give rise to a shrinkage operation in a basis adapted to the underlying image. Examination of these bases reveals oscillating harmonic structures along contours and in homogeneous regions. We demonstrate that trained denoisers are inductively biased towards these geometry-adaptive harmonic bases since they arise not only when the network is trained on photographic images, but also when it is trained on image classes supported on low-dimensional manifolds for which the harmonic basis is suboptimal. Finally, we show that when trained on regular image classes for which the optimal basis is known to be geometry-adaptive and harmonic, the denoising performance of the networks is near-optimal.",Oral 5A,https://openreview.net/pdf?id=ANvmVS2Yr0,https://openreview.net/forum?id=ANvmVS2Yr0
"['Xiangyu Qi', 'Yi Zeng', 'Tinghao Xie', 'Pin-Yu Chen', 'Ruoxi Jia', 'Prateek Mittal', 'Peter Henderson']",ICLR,"Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!",https://iclr.cc/virtual/2024/oral/19735,2024," Optimizing large language models (LLMs) for downstream use cases often involves the customization of pre-trained LLMs through further fine-tuning. Meta's open-source release of Llama models and OpenAI's APIs for fine-tuning GPT-3.5 Turbo on customized datasets accelerate this trend. But, what are the safety costs associated with such customized fine-tuning? While existing safety alignment techniques restrict harmful behaviors of LLMs at inference time, they do not cover safety risks when fine-tuning privileges are extended to end-users. Our red teaming studies find that the safety alignment of LLMs can be compromised by fine-tuning with only a few adversarially designed training examples. For instance, we jailbreak GPT-3.5 Turbo's safety guardrails by fine-tuning it on only 10 such examples at a cost of less than $0.20 via OpenAI's APIs, making the model responsive to nearly any harmful instructions. Disconcertingly, our research also reveals that, even without malicious intent, simply fine-tuning with benign and commonly used datasets can also inadvertently degrade the safety alignment of LLMs, though to a lesser extent. These findings suggest that fine-tuning aligned LLMs introduces new safety risks that current safety infrastructures fall short of addressing --- even if a model's initial safety alignment is impeccable, how can it be maintained after customized fine-tuning? We outline and critically analyze potential mitigations and advocate for further research efforts toward reinforcing safety protocols for the customized fine-tuning of aligned LLMs.  (This paper contains red-teaming data and model-generated content that can be offensive in nature.)",Oral 5B,https://openreview.net/pdf?id=hTEGyKf0dZ,https://openreview.net/forum?id=hTEGyKf0dZ
"['Panagiotis Eustratiadis', 'Łukasz Dudziak', 'Da Li', 'Timothy Hospedales']",ICLR,Neural Fine-Tuning Search for Few-Shot Learning,https://iclr.cc/virtual/2024/oral/19760,2024," In few-shot recognition, a classifier that has been trained on one set of classes is required to rapidly adapt and generalize to a disjoint, novel set of classes. To that end, recent studies have shown the efficacy of fine-tuning with carefully-crafted adaptation architectures. However this raises the question of: How can one design the optimal adaptation strategy? In this paper, we study this question through the lens of neural architecture search (NAS). Given a pre-trained neural network, our algorithm discovers the optimal arrangement of adapters, which layers to keep frozen, and which to fine-tune. We demonstrate the generality of our NAS method by applying it to both residual networks and vision transformers and report state-of-the-art performance on Meta-Dataset and Meta-Album.",Oral 5C,https://openreview.net/pdf?id=T7YV5UZKBc,https://openreview.net/forum?id=T7YV5UZKBc
"['Yossi Gandelsman', 'Alexei Efros', 'Jacob Steinhardt']",ICLR,Interpreting CLIP's Image Representation via Text-Based Decomposition,https://iclr.cc/virtual/2024/oral/19791,2024," We investigate the CLIP image encoder by analyzing how individual model components affect the final representation. We decompose the image representation as a sum across individual image patches, model layers, and attention heads, and use CLIP's text representation to interpret the summands. Interpreting the attention heads, we characterize each head's role by automatically finding text representations that span its output space, which reveals property-specific roles for many heads (e.g. location or shape). Next, interpreting the image patches, we uncover an emergent spatial localization within CLIP. Finally, we use this understanding to remove spurious features from CLIP and to create a strong zero-shot image segmenter. Our results indicate that scalable understanding of transformer models is attainable and can be used to repair and improve models.",Oral 5D,https://openreview.net/pdf?id=5Ca9sSzuDp,https://openreview.net/forum?id=5Ca9sSzuDp
"['Giorgio Mariani', 'Irene Tallini', 'Emilian Postolache', 'Michele Mancusi', 'Luca Cosmo', 'Emanuele Rodolà']",ICLR,Multi-Source Diffusion Models for Simultaneous Music Generation and Separation,https://iclr.cc/virtual/2024/oral/19737,2024," In this work, we define a diffusion-based generative model capable of both music generation and source separation by learning the score of the joint probability density of sources sharing a context. Alongside the classic total inference tasks (i.e., generating a mixture, separating the sources), we also introduce and experiment on the partial generation task of source imputation, where we generate a subset of the sources given the others (e.g., play a piano track that goes well with the drums). Additionally, we introduce a novel inference method for the separation task based on Dirac likelihood functions. We train our model on Slakh2100, a standard dataset for musical source separation, provide qualitative results in the generation settings, and showcase competitive quantitative results in the source separation setting. Our method is the first example of a single model that can handle both generation and separation tasks, thus representing a step toward general audio models.",Oral 6A,https://openreview.net/pdf?id=h922Qhkmx1,https://openreview.net/forum?id=h922Qhkmx1
"['Shuo He', 'Chaojie Wang', 'Guowu Yang', 'Lei Feng']",ICLR,Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning,https://iclr.cc/virtual/2024/oral/19776,2024," Partial-label learning (PLL) allows each training example to be equipped with a set of candidate labels. Existing deep PLL research focuses on a \emph{learning-centric} perspective to design various training strategies for label disambiguation i.e., identifying the concealed true label from the candidate label set, for model training. However, when the size of the candidate label set becomes excessively large, these learning-centric strategies would be unable to find the true label for model training, thereby causing performance degradation. This motivates us to think from a \emph{data-centric} perspective and pioneer a new PLL-related task called candidate label set pruning (CLSP) that aims to filter out certain potential false candidate labels in a training-free manner. To this end, we propose the first CLSP method based on the inconsistency between the representation space and the candidate label space. Specifically, for each candidate label of a training instance, if it is not a candidate label of the instance's nearest neighbors in the representation space, then it has a high probability of being a false label. Based on this intuition, we employ a per-example pruning scheme that filters out a specific proportion of high-probability false candidate labels. Theoretically, we prove an upper bound of the pruning error rate and analyze how the quality of representations affects our proposed method. Empirically, extensive experiments on both benchmark-simulated and real-world PLL datasets validate the great value of CLSP to significantly improve many state-of-the-art deep PLL methods.",Oral 6C,https://openreview.net/pdf?id=Fk5IzauJ7F,https://openreview.net/forum?id=Fk5IzauJ7F
"['Zaishuo Xia', 'Han Yang', 'Binghui Wang', 'Jinyuan Jia']",ICLR,GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations,https://iclr.cc/virtual/2024/oral/19771,2024," Graph classification, which aims to predict a label for a graph, has many real-world applications such as malware detection, fraud detection, and healthcare. However, many studies show an attacker could carefully perturb the structure and/or node features in a graph such that a graph classifier misclassifies the perturbed graph. Such vulnerability impedes the deployment of graph classification in security/safety-critical applications. Existing empirical defenses lack formal robustness guarantees and could be broken by adaptive or unknown attacks. Existing provable defenses have the following limitations: 1)  they achieve sub-optimal robustness guarantees for graph structure perturbation, 2) they cannot provide robustness guarantees for arbitrarily node feature perturbations, 3) their robustness guarantees are probabilistic, meaning they could be incorrect with a non-zero probability, and 4) they incur large computation costs. We aim to address those limitations in this work. We propose GNNCert, a certified defense against both graph structure and node feature perturbations for graph classification. Our GNNCert provably predicts the same label for a graph when the number of perturbed edges and the number of nodes with perturbed features are bounded. Our results on 8 benchmark datasets show that GNNCert outperforms three state-of-the-art methods.",Oral 6B,https://openreview.net/pdf?id=IGzaH538fz,https://openreview.net/forum?id=IGzaH538fz
"['Yijie Lin', 'Jie Zhang', 'Zhenyu Huang', 'Jia Liu', 'zujie wen', 'Xi Peng']",ICLR,Multi-granularity Correspondence Learning from Long-term Noisy Videos,https://iclr.cc/virtual/2024/oral/19786,2024," Existing video-language studies mainly focus on learning short video clips, leaving long-term temporal dependencies rarely explored due to over-high computational cost of modeling long videos. To address this issue, one feasible solution is learning the correspondence between video clips and captions, which however inevitably encounters the multi-granularity noisy correspondence (MNC) problem. To be specific, MNC refers to the clip-caption misalignment (coarse-grained) and frame-word misalignment (fine-grained), hindering temporal learning and video understanding. In this paper, we propose NOise Robust Temporal Optimal traNsport (Norton) that addresses MNC in a unified optimal transport (OT) framework. In brief, Norton employs video-paragraph and clip-caption contrastive losses to capture long-term dependencies based on OT. To address coarse-grained misalignment in video-paragraph contrast, Norton filters out the irrelevant clips and captions through an alignable prompt bucket and realigns asynchronous clip-caption pairs based on transport distance. To address the fine-grained misalignment, Norton incorporates a soft-maximum operator to identify crucial words and key frames. Additionally, Norton exploits the potential faulty negative samples in clip-caption contrast by rectifying the alignment target with OT assignment to ensure precise temporal modeling. Extensive experiments on video retrieval, videoQA, and action segmentation verify the effectiveness of our method. Code is available at https://lin-yijie.github.io/projects/Norton.",Oral 6D,https://openreview.net/pdf?id=9Cu8MRmhq2,https://openreview.net/forum?id=9Cu8MRmhq2
"['Galen Andrew', 'Peter Kairouz', 'Sewoong Oh', 'Alina Oprea', 'H. Brendan McMahan', 'Vinith Suriyakumar']",ICLR,One-shot Empirical Privacy Estimation for Federated Learning,https://iclr.cc/virtual/2024/oral/19797,2024," Privacy estimation techniques for differentially private (DP) algorithms are useful for comparing against analytical bounds, or to empirically measure privacy loss in settings where known analytical bounds are not tight. However, existing privacy auditing techniques usually make strong assumptions on the adversary (e.g., knowledge of intermediate model iterates or the training data distribution), are tailored to specific tasks, model architectures, or DP algorithm, and/or require retraining the model many times (typically on the order of thousands). These shortcomings make deploying such techniques at scale difficult in practice, especially in federated settings where model training can take days or weeks. In this work, we present a novel “one-shot” approach that can systematically address these challenges, allowing efficient auditing or estimation of the privacy loss of a model during the same, single training run used to fit model parameters, and without requiring any a priori knowledge about the model architecture, task, or DP algorithm. We show that our method provides provably correct estimates for the privacy loss under the Gaussian mechanism, and we demonstrate its performance on a well-established FL benchmark dataset under several adversarial threat models.",Oral 7D,https://openreview.net/pdf?id=0BqyZSWfzo,https://openreview.net/forum?id=0BqyZSWfzo
"['Mitchell Wortsman', 'Peter Liu', 'Lechao Xiao', 'Katie Everett', 'Alexander Alemi', 'Ben Adlam', 'John Co-Reyes', 'Izzeddin Gur', 'Abhishek Kumar', 'Roman Novak', 'Jeffrey Pennington', 'Jascha Sohl-Dickstein', 'Kelvin Xu', 'Jaehoon Lee', 'Justin Gilmer', 'Simon Kornblith']",ICLR,Small-scale proxies for large-scale Transformer training instabilities,https://iclr.cc/virtual/2024/oral/19743,2024," Teams that have trained large Transformer-based models have reported training instabilities at large scale that did not appear when training with the same hyperparameters at smaller scales. Although the causes of such instabilities are of scientific interest, the amount of resources required to reproduce them has made investigation difficult. In this work, we seek ways to reproduce and study training instability at smaller scales. First, we focus on two sources of training instability described in previous work: the growth of logits in attention layers (Dehghani et al., 2023) and divergence of the output logits from the log probabilities (Chowdhery et al., 2022). By measuring the relationship between learning rate and loss across scales, we show that these instabilities also appear in small models when training at high learning rates, and that mitigations previously employed at large scales are equally effective in this regime. This prompts us to investigate the extent to which other known optimizer and model interventions influence the sensitivity of the final loss to changes in the learning rate. To this end, we study methods such as warm-up, weight decay, and the MuParam (Yang et al., 2022), and combine techniques to train small models that achieve similar losses across orders of magnitude of learning rate variation. Finally, to conclude our exploration we study two cases where instabilities can be predicted before they emerge by examining the scaling behavior of model characteristics such as activation and gradient norms.",Oral 7A,https://openreview.net/pdf?id=d8w0pmvXbZ,https://openreview.net/forum?id=d8w0pmvXbZ
"['Jiaxiang Tang', 'Jiawei Ren', 'Hang Zhou', 'Ziwei Liu', 'Gang Zeng']",ICLR,DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation,https://iclr.cc/virtual/2024/oral/19758,2024," Recent advances in 3D content creation mostly leverage optimization-based 3D generation via score distillation sampling (SDS).Though promising results have been exhibited, these methods often suffer from slow per-sample optimization, limiting their practical usage. In this paper, we propose DreamGaussian, a novel 3D content generation framework that achieves both efficiency and quality simultaneously. Our key insight is to design a generative 3D Gaussian Splatting model with companioned mesh extraction and texture refinement in UV space.In contrast to the occupancy pruning used in Neural Radiance Fields, we demonstrate that the progressive densification of 3D Gaussians converges significantly faster for 3D generative tasks.To further enhance the texture quality and facilitate downstream applications, we introduce an efficient algorithm to convert 3D Gaussians into textured meshes and apply a fine-tuning stage to refine the details.Extensive experiments demonstrate the superior efficiency and competitive generation quality of our proposed approach.Notably, DreamGaussian produces high-quality textured meshes in just 2 minutes from a single-view image, achieving approximately 10 times acceleration compared to existing methods.",Oral 7B,https://openreview.net/pdf?id=UyNXMqnN3c,https://openreview.net/forum?id=UyNXMqnN3c
"['Ruoyu Chen', 'Hua Zhang', 'Siyuan Liang', 'Jingzhi Li', 'Xiaochun Cao']",ICLR,Less is More: Fewer Interpretable Region via Submodular Subset Selection,https://iclr.cc/virtual/2024/oral/19733,2024," Image attribution algorithms aim to identify important regions that are highly relevant to model decisions. Although existing attribution solutions can effectively assign importance to target elements, they still face the following challenges: 1) existing attribution methods generate inaccurate small regions thus misleading the direction of correct attribution, and 2) the model cannot produce good attribution results for samples with wrong predictions. To address the above challenges, this paper re-models the above image attribution problem as a submodular subset selection problem, aiming to enhance model interpretability using fewer regions. To address the lack of attention to local regions, we construct a novel submodular function to discover more accurate small interpretation regions. To enhance the attribution effect for all samples, we also impose four different constraints on the selection of sub-regions, i.e., confidence, effectiveness, consistency, and collaboration scores, to assess the importance of various subsets. Moreover, our theoretical analysis substantiates that the proposed function is in fact submodular. Extensive experiments show that the proposed method outperforms SOTA methods on two face datasets (Celeb-A and VGG-Face2) and one fine-grained dataset (CUB-200-2011). For correctly predicted samples, the proposed method improves the Deletion and Insertion scores with an average of 4.9\% and 2.5\% gain relative to HSIC-Attribution. For incorrectly predicted samples, our method achieves gains of 81.0\% and 18.4\% compared to the HSIC-Attribution algorithm in the average highest confidence and Insertion score respectively. The code is released at https://github.com/RuoyuChen10/SMDL-Attribution.",Oral 7C,https://openreview.net/pdf?id=jKTUlxo5zy,https://openreview.net/forum?id=jKTUlxo5zy
"['Xian Li', 'Ping Yu', 'Chunting Zhou', 'Timo Schick', 'Omer Levy', 'Luke Zettlemoyer', 'Jason E Weston', 'Mike Lewis']",ICLR,Self-Alignment with Instruction Backtranslation,https://iclr.cc/virtual/2024/oral/19796,2024," We present a scalable method to build a high quality instruction following language model by automatically labelling human-written text with corresponding instructions. Our approach, named instruction backtranslation, starts with a language model finetuned on a small amount of seed data, and a given web corpus. The seed model is used to construct training examples by generating instruction prompts for web documents (self-augmentation), and then  selecting high quality examples from among these candidates (self-curation).  This data is then used to finetune a stronger model.  Finetuning LLaMa on two iterations of our approach yields a model that outperforms all other LLaMa-based models on the Alpaca leaderboard not relying on distillation data, demonstrating highly effective self-alignment.",Oral 8A,https://openreview.net/pdf?id=1oijHJBRsT,https://openreview.net/forum?id=1oijHJBRsT
"['Jie Hu', 'Vishwaraj Doshi', 'Do Young Eun']",ICLR,Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks,https://iclr.cc/virtual/2024/oral/19780,2024," We study a family of distributed stochastic optimization algorithms where gradients are sampled by a token traversing a network of agents in random-walk fashion. Typically, these random-walks are chosen to be Markov chains that asymptotically sample from a desired target distribution, and play a critical role in the convergence of the optimization iterates. In this paper, we take a novel approach by replacing the standard *linear* Markovian token by one which follows a *non-linear* Markov chain - namely the Self-Repellent Radom Walk (SRRW). Defined for any given 'base' Markov chain, the SRRW, parameterized by a positive scalar $\\alpha$, is less likely to transition to states that were highly visited in the past, thus the name. In the context of MCMC sampling on a graph, a recent breakthrough in Doshi et al. (2023) shows that the SRRW achieves $O(1/\\alpha)$ decrease in the asymptotic variance for sampling. We propose the use of a `generalized' version of the SRRW to drive token algorithms for distributed stochastic optimization in the form of stochastic approximation, termed SA-SRRW. We prove that the optimization iterate errors of the resulting SA-SRRW converge to zero almost surely and prove a central limit theorem, deriving the explicit form of the resulting asymptotic covariance matrix corresponding to iterate errors. This asymptotic covariance is always smaller than that of an algorithm driven by the base Markov chain and decreases at rate $O(1/\\alpha^2)$ - the performance benefit of using SRRW thereby *amplified* in the stochastic optimization context. Empirical results support our theoretical findings.",Oral 8B,https://openreview.net/pdf?id=BV1PHbTJzd,https://openreview.net/forum?id=BV1PHbTJzd
"['Mohammad Reza Samsami', 'Artem Zholus', 'Janarthanan Rajendran', 'Sarath Chandar']",ICLR,Mastering Memory Tasks with World Models,https://iclr.cc/virtual/2024/oral/19795,2024," Current model-based reinforcement learning (MBRL) agents struggle with long-term dependencies. This limits their ability to effectively solve tasks involving extended time gaps between actions and outcomes, or tasks demanding the recalling of distant observations to inform current actions. To improve temporal coherence, we integrate a new family of state space models (SSMs) in world models of MBRL agents to present a new method, Recall to Imagine (R2I). This integration aims to enhance both long-term memory and long-horizon credit assignment. Through a diverse set of illustrative tasks, we systematically demonstrate that R2I not only establishes a new state-of-the-art for challenging memory and credit assignment RL tasks, such as BSuite and POPGym, but also showcases superhuman performance in the complex memory domain of Memory Maze. At the same time, it upholds comparable performance in classic RL tasks, such as Atari and DMC, suggesting the generality of our method. We also show that R2I is faster than the state-of-the-art MBRL method, DreamerV3, resulting in faster wall-time convergence.",Oral 8C,https://openreview.net/pdf?id=1vDArHJ68h,https://openreview.net/forum?id=1vDArHJ68h
"['Thaddäus Wiedemer', 'Jack Brady', 'Alexander Panfilov', 'Attila Juhos', 'Matthias Bethge', 'Wieland Brendel']",ICLR,Provable Compositional Generalization for Object-Centric Learning,https://iclr.cc/virtual/2024/oral/19788,2024," Learning representations that generalize to novel compositions of known concepts is crucial for bridging the gap between human and machine perception. One prominent effort is learning object-centric representations, which are widely conjectured to enable compositional generalization. Yet, it remains unclear when this conjecture will be true, as a principled theoretical or empirical understanding of compositional generalization is lacking. In this work, we investigate when compositional generalization is guaranteed for object-centric representations through the lens of identifiability theory. We show that autoencoders that satisfy structural assumptions on the decoder and enforce encoder-decoder consistency will learn object-centric representations that provably generalize compositionally. We validate our theoretical result and highlight the practical relevance of our assumptions through experiments on synthetic image data.",Oral 8D,https://openreview.net/pdf?id=7VPTUWkiDQ,https://openreview.net/forum?id=7VPTUWkiDQ
"['Yogesh Verma', 'Markus Heinonen', 'Vikas Garg']",ICLR,ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs,https://iclr.cc/virtual/2024/oral/19715,2024," Climate and weather prediction traditionally relies on complex numerical simulations of atmospheric physics. Deep learning approaches, such as transformers, have recently challenged the simulation paradigm with complex network forecasts. However, they often act as data-driven black-box models that neglect the underlying physics and lack uncertainty quantification. We address these limitations with ClimODE, a  spatiotemporal continuous-time process that implements a key principle of advection from statistical mechanics, namely, weather changes due to a spatial movement of quantities over time. ClimODE models precise weather evolution with value-conserving dynamics, learning global weather transport as a neural flow, which also enables estimating the uncertainty in predictions. Our approach outperforms existing data-driven methods in global and regional forecasting with an order of magnitude smaller parameterization, establishing a new state of the art.",Oral 1A,https://openreview.net/pdf?id=xuY33XhEGR,https://openreview.net/forum?id=xuY33XhEGR
"['Jonathan Richens', 'Tom Everitt']",ICLR,Robust agents learn causal world models,https://iclr.cc/virtual/2024/oral/19724,2024," It has long been hypothesised that causal reasoning plays a fundamental role in robust and general intelligence. However, it is not known if agents must learn causal models in order to generalise to new domains, or if other inductive biases are sufficient. We answer this question, showing that any agent capable of satisfying a regret bound for a large set of distributional shifts must have learned an approximate causal model of the data generating process, which converges to the true causal model for optimal agents. We discuss the implications of this result for several research areas including transfer learning and causal inference.",Oral 1D,https://openreview.net/pdf?id=pOoKI3ouv1,https://openreview.net/forum?id=pOoKI3ouv1
"['Marius Memmel', 'Andrew Wagenmaker', 'Chuning Zhu', 'Dieter Fox', 'Abhishek Gupta']",ICLR,ASID: Active Exploration for System Identification in Robotic Manipulation,https://iclr.cc/virtual/2024/oral/19732,2024," Model-free control strategies such as reinforcement learning have shown the ability to learn control strategies without requiring an accurate model or simulator of the world. While this is appealing due to the lack of modeling requirements, such methods can be sample inefficient, making them impractical in many real-world domains. On the other hand, model-based control techniques leveraging accurate simulators can circumvent these challenges and use a large amount of cheap simulation data to learn controllers that can effectively transfer to the real world. The challenge with such model-based techniques is the requirement for an extremely accurate simulation, requiring both the specification of appropriate simulation assets and physical parameters. This requires considerable human effort to design for every environment being considered. In this work, we propose a learning system that can leverage a small amount of real-world data to autonomously refine a simulation model and then plan an accurate control strategy that can be deployed in the real world. Our approach critically relies on utilizing an initial (possibly inaccurate) simulator to design effective exploration policies that, when deployed in the real world, collect high-quality data. We demonstrate the efficacy of this paradigm in identifying articulation, mass, and other physical parameters in several challenging robotic manipulation tasks, and illustrate that only a small amount of real-world data can allow for effective sim-to-real transfer.",Oral 1B,https://openreview.net/pdf?id=jNR6s6OSBT,https://openreview.net/forum?id=jNR6s6OSBT
"['Pan Lu', 'Hritik Bansal', 'Tony Xia', 'Jiacheng Liu', 'Chunyuan Li', 'Hannaneh Hajishirzi', 'Hao Cheng', 'Kai-Wei Chang', 'Michel Galley', 'Jianfeng Gao']",ICLR,MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts,https://iclr.cc/virtual/2024/oral/19768,2024," Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive problem-solving skills in many tasks and domains, but their ability in mathematical reasoning in visual contexts has not been systematically studied. To bridge this gap, we present MathVista, a benchmark designed to combine challenges from diverse mathematical and visual tasks. It consists of 6,141 examples, derived from 28 existing multimodal datasets involving mathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and PaperQA). Completing these tasks requires fine-grained, deep visual understanding and compositional reasoning, which all state-of-the-art foundation models find challenging. With MathVista, we have conducted a comprehensive, quantitative evaluation of 12 prominent foundation models. The best-performing GPT-4V model achieves an overall accuracy of 49.9%, substantially outperforming Bard, the second-best performer, by 15.1%. Our in-depth analysis reveals that the superiority of GPT-4V is mainly attributed to its enhanced visual perception and mathematical reasoning. However, GPT-4V still falls short of human performance by 10.4%, as it often struggles to understand complex figures and perform rigorous reasoning. This significant gap underscores the critical role that MathVista will play in the development of general-purpose AI agents capable of tackling mathematically intensive and visually rich real-world tasks. We further explore the new ability of self-verification, the application of self-consistency, and the interactive chatbot capabilities of GPT-4V, highlighting its promising potential for future research. The project is available at https://mathvista.github.io/.",Oral 1C,https://openreview.net/pdf?id=KUNzEQMWU7,https://openreview.net/forum?id=KUNzEQMWU7
"['Zhen Liu', 'Yao Feng', 'Yuliang Xiu', 'Weiyang Liu', 'Liam Paull', 'Michael J Black', 'Bernhard Schoelkopf']",ICLR,Ghost on the Shell: An Expressive Representation of General 3D Shapes,https://iclr.cc/virtual/2024/oral/19782,2024," The creation of photorealistic virtual worlds requires the accurate modeling of 3D surface geometry for a wide range of objects. For this, meshes are appealing since they enable 1) fast physics-based rendering with realistic material and lighting, 2) physical simulation, and 3) are memory-efficient for modern graphics pipelines. Recent work on reconstructing and statistically modeling 3D shape, however, has critiqued meshes as being topologically inflexible. To capture a wide range of object shapes, any 3D representation must be able to model solid, watertight, shapes as well as thin, open, surfaces. Recent work has focused on the former, and methods for reconstructing open surfaces do not support fast reconstruction with material and lighting or unconditional generative modelling. Inspired by the observation that open surfaces can be seen as islands floating on watertight surfaces, we parametrize open surfaces by defining a manifold signed distance field on watertight templates. With this parametrization, we further develop a grid-based and differentiable representation that parametrizes both watertight and non-watertight meshes of arbitrary topology. Our new representation, called Ghost-on-the-Shell (G-Shell), enables two important applications:  differentiable rasterization-based reconstruction from multiview images and generative modelling of non-watertight meshes. We empirically demonstrate that G-Shell achieves state-of-the-art performance on non-watertight mesh reconstruction and generation tasks, while also performing effectively for watertight meshes.",Oral 2B,https://openreview.net/pdf?id=Ad87VjRqUw,https://openreview.net/forum?id=Ad87VjRqUw
"['Satwik Bhattamishra', 'Arkil Patel', 'Phil Blunsom', 'Varun Kanade']",ICLR,Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions,https://iclr.cc/virtual/2024/oral/19741,2024," In order to understand the in-context learning phenomenon, recent works have adopted a stylized experimental framework and demonstrated that Transformers can match the performance of gradient-based learning algorithms for various classes of real-valued functions. However, the limitations of Transformers in implementing learning algorithms, and their ability to learn other forms of algorithms are not well understood. Additionally, the degree to which these capabilities are confined to attention-based models is unclear. Furthermore, it remains to be seen whether the insights derived from these stylized settings can be extrapolated to pretrained Large Language Models (LLMs). In this work, we take a step towards answering these questions by demonstrating the following: (a) On a test-bed with a variety of Boolean function classes, we find that Transformers can nearly match the optimal learning algorithm for 'simpler' tasks, while their performance deteriorates on more 'complex' tasks. Additionally, we find that certain attention-free models perform (almost) identically to Transformers on a range of tasks. (b) When provided a teaching sequence , i.e. a set of examples that uniquely identifies a function in a class, we show that Transformers learn more sample-efficiently. Interestingly, our results show that Transformers can learn to implement two distinct algorithms to solve a single task, and can adaptively select the more sample-efficient algorithm depending on the sequence of in-context examples. (c) Lastly, we show that extant LLMs, e.g. LLaMA-2, GPT-4, can compete with nearest-neighbor baselines on prediction tasks that are guaranteed to not be in their training set.",Oral 2A,https://openreview.net/pdf?id=ekeyCgeRfC,https://openreview.net/forum?id=ekeyCgeRfC
"['Yang Song', 'Prafulla Dhariwal']",ICLR,Improved Techniques for Training Consistency Models,https://iclr.cc/virtual/2024/oral/19754,2024," Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training. Current consistency models achieve optimal sample quality by distilling from pre-trained diffusion models and employing learned metrics such as LPIPS. However, distillation limits the quality of consistency models to that of the pre-trained diffusion model, and LPIPS causes undesirable bias in evaluation. To tackle these challenges, we present improved techniques for consistency training, where consistency models learn directly from data without distillation. We delve into the theory behind consistency training and identify a previously overlooked flaw, which we address by eliminating Exponential Moving Average from the teacher consistency model. To replace learned metrics like LPIPS, we adopt Pseudo-Huber losses from robust statistics. Additionally, we introduce a lognormal noise schedule for the consistency training objective, and propose to double total discretization steps every set number of training iterations. Combined with better hyperparameter tuning, these modifications enable consistency models to achieve FID scores of 2.51 and 3.25 on CIFAR-10 and ImageNet $64\times 64$ respectively in a single sampling step. These scores mark a 3.5$\times$ and 4$\times$ improvement compared to prior consistency training approaches. Through two-step sampling, we further reduce FID scores to 2.24 and 2.77 on these two datasets, surpassing those obtained via distillation in both one-step and two-step settings, while narrowing the gap between consistency models and other state-of-the-art generative models.",Oral 2C,https://openreview.net/pdf?id=WNzy9bRDvG,https://openreview.net/forum?id=WNzy9bRDvG
['Gautam Reddy Nallamala'],ICLR,The mechanistic basis of data dependence and abrupt learning in an in-context classification task,https://iclr.cc/virtual/2024/oral/19749,2024," Transformer models exhibit in-context learning: the ability to accurately predict the response to a novel query based on illustrative examples in the input sequence, which contrasts with traditional in-weights learning of query-output relationships. What aspects of the training data distribution and architecture favor in-context vs in-weights learning? Recent work has shown that specific distributional properties inherent in language, such as burstiness, large dictionaries and skewed rank-frequency distributions, control the trade-off or simultaneous appearance of these two forms of learning. We first show that these results are recapitulated in a minimal attention-only network trained on a simplified dataset. In-context learning (ICL) is driven by the abrupt emergence of an induction head, which subsequently competes with in-weights learning. By identifying progress measures that precede in-context learning and targeted experiments, we construct a two-parameter model of an induction head which emulates the full data distributional dependencies displayed by the attention-based network. A phenomenological model of induction head formation traces its abrupt emergence to the sequential learning of three nested logits enabled by an intrinsic curriculum. We propose that the sharp transitions in attention-based networks arise due to a specific chain of multi-layer operations necessary to achieve ICL, which is implemented by nested nonlinearities sequentially learned during training.",Oral 2D,https://openreview.net/pdf?id=aN4Jf6Cx69,https://openreview.net/forum?id=aN4Jf6Cx69
"['Linlu Qiu', 'Liwei Jiang', 'Ximing Lu', 'Melanie Sclar', 'Valentina Pyatkin', 'Chandra Bhagavatula', 'Bailin Wang', 'Yoon Kim', 'Yejin Choi', 'Nouha Dziri', 'Xiang Ren']",ICLR,Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement,https://iclr.cc/virtual/2024/oral/19747,2024," The ability to derive underlying principles from a handful of observations and then generalize to novel situations---known as inductive reasoning---is central to human intelligence. Prior work suggests that language models (LMs) often fall short on inductive reasoning, despite achieving impressive success on research benchmarks. In this work, we conduct a systematic study of the inductive reasoning capabilities of LMs through $\textit{iterative hypothesis refinement}$, a technique that more closely mirrors the human inductive process than standard input-output prompting. Iterative hypothesis refinement employs a three-step process: proposing, selecting, and refining hypotheses in the form of textual rules. By examining the intermediate rules, we observe that LMs are phenomenal $\textit{hypothesis proposers}$ (i.e., generating candidate rules), and when coupled with a (task-specific) symbolic interpreter that is able to systematically filter the proposed set of rules, this hybrid approach achieves strong results across inductive reasoning benchmarks that require inducing causal relations, language-like instructions, and symbolic concepts. However, they also behave as puzzling $\textit{inductive reasoners}$, showing notable performance gaps between rule induction (i.e., identifying plausible rules) and rule application (i.e., applying proposed rules to instances), suggesting that LMs are proposing hypotheses without being able to actually apply the rules. Through empirical and human analyses, we further reveal several discrepancies between the inductive reasoning processes of LMs and humans, shedding light on both the potentials and limitations of using LMs in inductive reasoning tasks.",Oral 3A,https://openreview.net/pdf?id=bNt7oajl2a,https://openreview.net/forum?id=bNt7oajl2a
"['Hyosoon Jang', 'Minsu Kim', 'Sungsoo Ahn']",ICLR,Learning Energy Decompositions for Partial Inference in GFlowNets,https://iclr.cc/virtual/2024/oral/19762,2024," This paper studies generative flow networks (GFlowNets) to sample objects from the Boltzmann energy distribution via a sequence of actions. In particular, we focus on improving GFlowNet with partial inference: training flow functions with the evaluation of the intermediate states or transitions. To this end, the recently developed forward-looking GFlowNet reparameterizes the flow functions based on evaluating the energy of intermediate states. However, such an evaluation of intermediate energies may (i) be too expensive or impossible to evaluate and (ii) even provide misleading training signals under large energy fluctuations along the sequence of actions. To resolve this issue, we propose learning energy decompositions for GFlowNets (LED-GFN). Our main idea is to (i) decompose the energy of an object into learnable potential functions defined on state transitions and (ii) reparameterize the flow functions using the potential functions. In particular, to produce informative local credits, we propose to regularize the potential to change smoothly over the sequence of actions. It is also noteworthy that training GFlowNet with our learned potential can preserve the optimal policy. We empirically verify the superiority of LED-GFN in five problems including the generation of unstructured and maximum independent sets, molecular graphs, and RNA sequences.",Oral 3B,https://openreview.net/pdf?id=P15CHILQlg,https://openreview.net/forum?id=P15CHILQlg
"['Yichen Wu', 'Long-Kai Huang', 'Renzhen Wang', 'Deyu Meng', 'Ying Wei']",ICLR,Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction,https://iclr.cc/virtual/2024/oral/19759,2024," Regularization-based methods have so far been among the de facto choices for continual learning. Recent theoretical studies have revealed that these methods all boil down to relying on the Hessian matrix approximation of model weights. However, these methods suffer from suboptimal trade-offs between knowledge transfer and forgetting due to fixed and unchanging Hessian estimations during training.Another seemingly parallel strand of Meta-Continual Learning (Meta-CL) algorithms enforces alignment between gradients of previous tasks and that of the current task. In this work we revisit Meta-CL and for the first time bridge it with regularization-based methods. Concretely, Meta-CL implicitly approximates Hessian in an online manner, which enjoys the benefits of timely adaptation but meantime suffers from high variance induced by random memory buffer sampling. We are thus highly motivated to combine the best of both worlds, through the proposal of Variance Reduced Meta-CL (VR-MCL) to achieve both timely and accurate Hessian approximation.Through comprehensive experiments across three datasets and various settings, we consistently observe that VR-MCL outperforms other SOTA methods, which further validates the effectiveness of VR-MCL.",Oral 3C,https://openreview.net/pdf?id=TpD2aG1h0D,https://openreview.net/forum?id=TpD2aG1h0D
"['Kim-Celine Kahl', 'Carsten Lüth', 'Maximilian Zenk', 'Klaus Maier-Hein', 'Paul F. Jaeger']",ICLR,ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation,https://iclr.cc/virtual/2024/oral/19714,2024," Uncertainty estimation is an essential and heavily-studied component for the reliable application of semantic segmentation methods. While various studies exist claiming methodological advances on the one hand, and successful application on the other hand, the field is currently hampered by a gap between theory and practice leaving fundamental questions unanswered: Can data-related and model-related uncertainty really be separated in practice? Which components of an uncertainty method are essential for real-world performance? Which uncertainty method works well for which application? In this work, we link this research gap to a lack of systematic and comprehensive evaluation of uncertainty methods. Specifically, we identify three key pitfalls in current literature and present an evaluation framework that bridges the research gap by providing 1) a controlled environment for studying data ambiguities as well as distribution shifts, 2) systematic ablations of relevant method components, and 3) test-beds for the five predominant uncertainty applications: OoD-detection, active learning, failure detection, calibration, and ambiguity modeling. Empirical results on simulated as well as real-world data demonstrate how the proposed framework is able to answer the predominant questions in the field revealing for instance that 1) separation of uncertainty types works on simulated data but does not necessarily translate to real-world data, 2) aggregation of scores is a crucial but currently neglected component of uncertainty methods, 3) While ensembles are performing most robustly across the different downstream tasks and settings, test-time augmentation often constitutes a light-weight alternative. Code is at: https://github.com/IML-DKFZ/values",Oral 3D,https://openreview.net/pdf?id=yV6fD7LYkF,https://openreview.net/forum?id=yV6fD7LYkF
"['Ricky T. Q. Chen', 'Yaron Lipman']",ICLR,Flow Matching on General Geometries,https://iclr.cc/virtual/2024/oral/19740,2024," We propose Riemannian Flow Matching (RFM), a simple yet powerful framework for training continuous normalizing flows on manifolds. Existing methods for generative modeling on manifolds either require expensive simulation, are inherently unable to scale to high dimensions, or use approximations for limiting quantities that result in biased training objectives. Riemannian Flow Matching bypasses these limitations and offers several advantages over previous approaches: it is simulation-free on simple geometries, does not require divergence computation, and computes its target vector field in closed-form. The key ingredient behind RFM is the construction of a relatively simple premetric for defining target vector fields, which encompasses the existing Euclidean case. To extend to general geometries, we rely on the use of spectral decompositions to efficiently compute premetrics on the fly. Our method achieves state-of-the-art performance on real-world non-Euclidean datasets, and we demonstrate tractable training on general geometries, including triangular meshes with highly non-trivial curvature and boundaries.",Oral 4B,https://openreview.net/pdf?id=g7ohDlTITL,https://openreview.net/forum?id=g7ohDlTITL
"['Seohong Park', 'Oleh Rybkin', 'Sergey Levine']",ICLR,METRA: Scalable Unsupervised RL with Metric-Aware Abstraction,https://iclr.cc/virtual/2024/oral/19745,2024," Unsupervised pre-training strategies have proven to be highly effective in natural language processing and computer vision. Likewise, unsupervised reinforcement learning (RL) holds the promise of discovering a variety of potentially useful behaviors that can accelerate the learning of a wide array of downstream tasks. Previous unsupervised RL approaches have mainly focused on pure exploration and mutual information skill learning. However, despite the previous attempts, making unsupervised RL truly scalable still remains a major open challenge: pure exploration approaches might struggle in complex environments with large state spaces, where covering every possible transition is infeasible, and mutual information skill learning approaches might completely fail to explore the environment due to the lack of incentives. To make unsupervised RL scalable to complex, high-dimensional environments, we propose a novel unsupervised RL objective, which we call Metric-Aware Abstraction (METRA). Our main idea is, instead of directly covering the entire state space, to only cover a compact latent space $\mathcal{Z}$ that is metrically connected to the state space $\mathcal{S}$ by temporal distances. By learning to move in every direction in the latent space, METRA obtains a tractable set of diverse behaviors that approximately cover the state space, being scalable to high-dimensional environments. Through our experiments in five locomotion and manipulation environments, we demonstrate that METRA can discover a variety of useful behaviors even in complex, pixel-based environments, being the first unsupervised RL method that discovers diverse locomotion behaviors in pixel-based Quadruped and Humanoid. Our code and videos are available at https://seohong.me/projects/metra/",Oral 4C,https://openreview.net/pdf?id=c5pwL0Soay,https://openreview.net/forum?id=c5pwL0Soay
"['Gabriel Cardoso', 'Yazid Janati el idrissi', 'Sylvain Le Corff', 'Eric Moulines']",ICLR,Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems.,https://iclr.cc/virtual/2024/oral/19729,2024," Ill-posed linear inverse problems arise frequently in various applications, from computational photography to medical imaging.A recent line of research exploits Bayesian inference with informative priors to handle the ill-posedness of such problems.Amongst such priors, score-based generative models (SGM) have recently been successfully applied to several different inverse problems.In this study, we exploit the particular structure of the prior defined by the SGM to define a sequence of intermediate linear inverse problems. As the noise level decreases, the posteriors of these inverse problems get closer to the target posterior of the original inverse problem. To sample from this sequence of posteriors, we propose the use of Sequential Monte Carlo (SMC) methods.The proposed algorithm, \algo, is shown to be theoretically grounded and we provide numerical simulations showing that it outperforms competing baselines when dealing with ill-posed inverse problems in a Bayesian setting.",Oral 4D,https://openreview.net/pdf?id=nHESwXvxWK,https://openreview.net/forum?id=nHESwXvxWK
"['Yeming Wen', 'Swarat Chaudhuri']",ICLR,Batched Low-Rank Adaptation of Foundation Models,https://iclr.cc/virtual/2024/oral/19716,2024," Low-Rank Adaptation (LoRA) has recently gained attention for fine-tuning foundation models by incorporating trainable low-rank matrices, thereby reducing the number of trainable parameters. While \lora/ offers numerous advantages, its applicability for real-time serving to a diverse and global user base is constrained by its incapability to handle multiple task-specific adapters efficiently. This imposes a performance bottleneck in scenarios requiring personalized, task-specific adaptations for each incoming request.To address this, we introduce FLoRA (Fast LoRA), a framework in which each input example in a minibatch can be associated with its unique low-rank adaptation weights, allowing for efficient batching of heterogeneous requests. We empirically demonstrate that \flora/ retains the performance merits of \lora/, showcasing competitive results on the MultiPL-E code generation benchmark spanning over 8 languages and a multilingual speech recognition task across 6 languages.",Oral 4A,https://openreview.net/pdf?id=w4abltTZ2f,https://openreview.net/forum?id=w4abltTZ2f
"['Xudong Shen', 'Chao Du', 'Tianyu Pang', 'Min Lin', 'Yongkang Wong', 'Mohan Kankanhalli']",ICLR,Finetuning Text-to-Image Diffusion Models for Fairness,https://iclr.cc/virtual/2024/oral/19734,2024," The rapid adoption of text-to-image diffusion models in society underscores an urgent need to address their biases. Without interventions, these biases could propagate a skewed worldview and restrict opportunities for minority groups. In this work, we frame fairness as a distributional alignment problem. Our solution consists of two main technical contributions: (1) a distributional alignment loss that steers specific characteristics of the generated images towards a user-defined target distribution, and (2) adjusted direct finetuning of diffusion model's sampling process (adjusted DFT), which leverages an adjusted gradient to directly optimize losses defined on the generated images. Empirically, our method markedly reduces gender, racial, and their intersectional biases for occupational prompts. Gender bias is significantly reduced even when finetuning just five soft tokens. Crucially, our method supports diverse perspectives of fairness beyond absolute equality, which is demonstrated by controlling age to a 75% young and 25% old distribution while simultaneously debiasing gender and race. Finally, our method is scalable: it can debias multiple concepts at once by simply including these prompts in the finetuning data. We share code and various fair diffusion model adaptors at https://sail-sg.github.io/finetune-fair-diffusion/.",Oral 5B,https://openreview.net/pdf?id=hnrB5YHoYu,https://openreview.net/forum?id=hnrB5YHoYu
"['Jisu Nam', 'Gyuseong Lee', 'Seonwoo Kim', 'Inès Hyeonsu Kim', 'Hyoungwon Cho', 'Seyeon Kim', 'Seungryong Kim']",ICLR,Diffusion Model for Dense Matching,https://iclr.cc/virtual/2024/oral/19751,2024," The objective for establishing dense correspondence between paired images con- sists of two terms: a data term and a prior term. While conventional techniques focused on defining hand-designed prior terms, which are difficult to formulate, re- cent approaches have focused on learning the data term with deep neural networks without explicitly modeling the prior, assuming that the model itself has the capacity to learn an optimal prior from a large-scale dataset. The performance improvement was obvious, however, they often fail to address inherent ambiguities of matching, such as textureless regions, repetitive patterns, large displacements, or noises. To address this, we propose DiffMatch, a novel conditional diffusion-based framework designed to explicitly model both the data and prior terms for dense matching. This is accomplished by leveraging a conditional denoising diffusion model that explic- itly takes matching cost and injects the prior within generative process. However, limited input resolution of the diffusion model is a major hindrance. We address this with a cascaded pipeline, starting with a low-resolution model, followed by a super-resolution model that successively upsamples and incorporates finer details to the matching field. Our experimental results demonstrate significant performance improvements of our method over existing approaches, and the ablation studies validate our design choices along with the effectiveness of each component. Code and pretrained weights are available at https://ku-cvlab.github.io/DiffMatch.",Oral 5A,https://openreview.net/pdf?id=Zsfiqpft6K,https://openreview.net/forum?id=Zsfiqpft6K
"['Qiuhao Zeng', 'Changjian Shui', 'Long-Kai Huang', 'Peng Liu', 'Xi Chen', 'Charles Ling', 'Boyu Wang']",ICLR,Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time,https://iclr.cc/virtual/2024/oral/19746,2024," Distribution shifts over time are common in real-world machine-learning applications. This scenario is formulated as Evolving Domain Generalization (EDG), where models aim to generalize well to unseen target domains in a time-varying system by learning and leveraging the underlying evolving pattern of the distribution shifts across domains. However, existing methods encounter challenges due to the limited number of timestamps (every domain corresponds to a timestamp) in EDG datasets, leading to difficulties in capturing evolving dynamics and risking overfitting to the sparse timestamps, which hampers their generalization and adaptability to new tasks. To address this limitation, we propose a novel approach SDE-EDG that collects the Infinitely Fined-Grid Evolving Trajectory (IFGET) of the data distribution with continuous-interpolated samples to bridge temporal gaps (intervals between two successive timestamps). Furthermore, by leveraging the inherent capacity of Stochastic Differential Equations (SDEs) to capture continuous trajectories, we propose their use to align SDE-modeled trajectories with IFGET across domains, thus enabling the capture of evolving distribution trends. We evaluate our approach on several benchmark datasets and demonstrate that it can achieve superior performance compared to existing state-of-the-art methods.",Oral 5C,https://openreview.net/pdf?id=bTMMNT7IdW,https://openreview.net/forum?id=bTMMNT7IdW
"['Shashank Venkataramanan', 'Mamshad Nayeem Rizve', 'Joao Carreira', 'Yuki Asano', 'Yannis Avrithis']",ICLR,Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video,https://iclr.cc/virtual/2024/oral/19752,2024," Self-supervised learning has unlocked the potential of scaling up pretraining to billions of images, since annotation is unnecessary. But are we making the best use of data? How more economical can we be? In this work, we attempt to answer this question by making two contributions. First, we investigate first-person videos and introduce a Walking Tours'' dataset. These videos are high-resolution, hours-long, captured in a single uninterrupted take, depicting a large number of objects and actions with natural scene transitions. They are unlabeled and uncurated, thus realistic for self-supervision and comparable with human learning. Second, we introduce a novel self-supervised image pretraining method tailored for learning from continuous videos. Existing methods typically adapt image-based pretraining approaches to incorporate more frames. Instead, we advocate a tracking to learn to recognize'' approach. Our method called DoRA, leads to attention maps that D isc O ver and t RA ck objects over time in an end-to-end manner, using transformer cross-attention. We derive multiple views from the tracks and use them in a classical self-supervised distillation loss. Using our novel approach, a single Walking Tours video remarkably becomes a strong competitor to ImageNet for several image and video downstream tasks.",Oral 5D,https://openreview.net/pdf?id=Yen1lGns2o,https://openreview.net/forum?id=Yen1lGns2o
"['Kensen Shi', 'Joey Hong', 'Yinlin Deng', 'Pengcheng Yin', 'Manzil Zaheer', 'Charles Sutton']",ICLR,ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis,https://iclr.cc/virtual/2024/oral/19726,2024," When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks. While it is difficult to measure whether neural program synthesis methods have similar capabilities, we can measure whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks. In this paper, we characterize several different forms of compositional generalization that are desirable in program synthesis, forming a meta-benchmark which we use to create generalization tasks for two popular datasets, RobustFill and DeepCoder. We then propose ExeDec, a novel decomposition-based synthesis strategy that predicts execution subgoals to solve problems step-by-step informed by program execution at each step. When used with Transformer models trained from scratch, ExeDec has better synthesis performance and greatly improved compositional generalization ability compared to baselines. Finally, we use our benchmarks to demonstrate that LLMs struggle to compositionally generalize when asked to do programming-by-example in a few-shot setting, but an ExeDec-style prompting approach can improve the generalization ability and overall performance.",Oral 6A,https://openreview.net/pdf?id=oTRwljRgiv,https://openreview.net/forum?id=oTRwljRgiv
"['Germain Kolossov', 'Andrea Montanari', 'Pulkit Tandon']",ICLR,Towards a statistical theory of data selection under weak supervision,https://iclr.cc/virtual/2024/oral/19772,2024," Given a sample of size N, it is often useful to select a subsample of smaller size n < N to be used for statistical estimation or learning. Such a data selection step is useful to reduce the requirements of data labeling and the computational complexity of learning. We assume to be given N unlabeled samples $x_{i}$, and to be given access to a 'surrogate model' that can predict labels $y_i$ better than random guessing. Our goal is to select a subset of the samples, to be denoted by {$x_{i}$}$_{i\in G}$, of size $|G|=n < N$. We then acquire labels for this set and we use them to train a model via regularized empirical risk minimization. By using a mixture of numerical experiments on real and synthetic data, and mathematical derivations under low- and high- dimensional asymptotics, we show that: (i) Data selection can be very effective, in particular beating training on the full sample in some cases; (ii) Certain popular choices in data selection methods (e.g. unbiased reweighted subsampling, or influence function-based subsampling) can be substantially suboptimal.",Oral 6C,https://openreview.net/pdf?id=HhfcNgQn6p,https://openreview.net/forum?id=HhfcNgQn6p
"['Yonatan Oren', 'Nicole Meister', 'Niladri Chatterji', 'Faisal Ladhak', 'Tatsunori Hashimoto']",ICLR,Proving Test Set Contamination in Black-Box Language Models,https://iclr.cc/virtual/2024/oral/19769,2024," Large language models are trained on vast amounts of internet data, prompting concerns that they have memorized public benchmarks. Detecting this type of contamination is challenging because the pretraining data used by proprietary models are often not publicly accessible.We propose a procedure for detecting test set contamination of language models with exact false positive guarantees and without access to pretraining data or model weights. Our approach leverages the fact that when there is no data contamination, all orderings of an exchangeable benchmark should be equally likely. In contrast, the tendency for language models to memorize example order means that a contaminated language model will find certain canonical orderings to be much more likely than others. Our test flags potential contamination whenever the likelihood of a canonically ordered benchmark dataset is significantly higher than the likelihood after shuffling the examples.We demonstrate that our procedure is sensitive enough to reliably detect contamination in challenging situations, including models as small as 1.4 billion parameters, on small test sets only 1000 examples, and datasets that appear only a few times in the pretraining corpus. Finally, we evaluate LLaMA-2 to apply our test in a realistic setting and find our results to be consistent with existing contamination evaluations.",Oral 6B,https://openreview.net/pdf?id=KS8mIvetg2,https://openreview.net/forum?id=KS8mIvetg2
"['Zengwei Yao', 'Liyong Guo', 'Xiaoyu Yang', 'Wei Kang', 'Fangjun Kuang', 'Yifan Yang', 'Zengrui Jin', 'Long Lin', 'Daniel Povey']",ICLR,Zipformer: A faster and better encoder for automatic speech recognition,https://iclr.cc/virtual/2024/oral/19784,2024," The Conformer has become the most popular encoder model for automatic speech recognition (ASR).  It adds convolution modules to a transformer to learn both local and global dependencies. In this work we describe a faster, more memory-efficient, and better-performing transformer, called Zipformer.  Modeling changes include: 1) a U-Net-like encoder structure where middle stacks operate at lower frame rates; 2) reorganized block structure with more modules, within which we re-use attention weights for efficiency; 3) a modified form of LayerNorm called BiasNorm allows us to retain some length information; 4)  new activation functions SwooshR and SwooshL work better than Swish.  We also propose a new optimizer, called ScaledAdam, which scales the update by each tensor's current scale to keep the relative change about the same, and also explictly learns the parameter scale. It achieves faster converge and better performance than Adam. Extensive experiments on LibriSpeech, Aishell-1, and WenetSpeech datasets demonstrate the effectiveness of our proposed Zipformer over other state-of-the-art ASR models. Our code is publicly available at https://github.com/k2-fsa/icefall.",Oral 6D,https://openreview.net/pdf?id=9WD9KwssyT,https://openreview.net/forum?id=9WD9KwssyT
"['Jen-tse Huang', 'Wenxuan Wang', 'Eric John Li', 'Man Ho LAM', 'Shujie Ren', 'Youliang Yuan', 'Wenxiang Jiao', 'Zhaopeng Tu', 'Michael Lyu']",ICLR,On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs,https://iclr.cc/virtual/2024/oral/19775,2024," Large Language Models (LLMs) have recently showcased their remarkable capacities, not only in natural language processing tasks but also across diverse domains such as clinical medicine, legal consultation, and education. LLMs become more than mere applications, evolving into assistants capable of addressing diverse user requests. This narrows the distinction between human beings and artificial intelligence agents, raising intriguing questions regarding the potential manifestation of personalities, temperaments, and emotions within LLMs. In this paper, we propose a framework, PsychoBench, for evaluating diverse psychological aspects of LLMs. Comprising thirteen scales commonly used in clinical psychology, PsychoBench further classifies these scales into four distinct categories: personality traits, interpersonal relationships, motivational tests, and emotional abilities. Our study examines five popular models, namely text-davinci-003, ChatGPT, GPT-4, LLaMA-2-7b, and LLaMA-2-13b. Additionally, we employ a jailbreak approach to bypass the safety alignment protocols and test the intrinsic natures of LLMs. We have made PsychoBench openly accessible via https://github.com/CUHK-ARISE/PsychoBench.",Oral 7D,https://openreview.net/pdf?id=H3UayAQWoE,https://openreview.net/forum?id=H3UayAQWoE
"['Sergei Solonets', 'Daniil Sinitsyn', 'Lukas Von Stumberg', 'Nikita Araslanov', 'Daniel Cremers']",ICLR,An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment,https://iclr.cc/virtual/2024/oral/19730,2024," Direct image alignment is a widely used technique for relative 6DoF pose estimation between two images, but its accuracy strongly depends on pose initialization.Therefore, recent end-to-end frameworks increase the convergence basin of the learned feature descriptors with special training objectives, such as the Gauss-Newton loss.However, the training data may exhibit bias toward a specific type of motion and pose initialization,thus limiting the generalization of these methods.In this work, we derive a closed-form solution to the expected optimum of the Gauss-Newton loss. The solution is agnostic to the underlying feature representation and allows us to dynamically adjust the basin of convergence according to our assumptions about the uncertainty in the current estimates. These properties allow for effective control over the convergence in the alignment process.Despite using self-supervised feature embeddings, our solution achieves compelling accuracy w.r.t. the state-of-the-art direct image alignment methods trained end-to-end with pose supervision, and demonstrates improved robustness to pose initialization.Our analytical solution exposes some inherent limitations of end-to-end learning with the Gauss-Newton loss, and establishes an intriguing connection between direct image alignment and feature-matching approaches.",Oral 7A,https://openreview.net/pdf?id=mE52zURNGc,https://openreview.net/forum?id=mE52zURNGc
"['Yiding Jiang', 'Christina Baek', 'J Kolter']",ICLR,"On the Joint Interaction of Models, Data, and Features",https://iclr.cc/virtual/2024/oral/19712,2024," Learning features from data is one of the defining characteristics of deep learning,but the theoretical understanding of the role features play in deep learning is still inearly development. To address this gap, we introduce a new tool, the interactiontensor, for empirically analyzing the interaction between data and model throughfeatures. With the interaction tensor, we make several key observations abouthow features are distributed in data and how models with different random seedslearn different features. Based on these observations, we propose a conceptualframework for feature learning. Under this framework, the expected accuracy for asingle hypothesis and agreement for a pair of hypotheses can both be derived inclosed form. We demonstrate that the proposed framework can explain empiricallyobserved phenomena, including the recently discovered Generalization Disagreement Equality (GDE) that allows for estimating the generalization error with onlyunlabeled data. Further, our theory also provides explicit construction of naturaldata distributions that break the GDE. Thus, we believe this work provides valuablenew insight into our understanding of feature learning.",Oral 7C,https://openreview.net/pdf?id=ze7DOLi394,https://openreview.net/forum?id=ze7DOLi394
"['Anshuman Chhabra', 'Peizhao Li', 'Prasant Mohapatra', 'Hongfu Liu']",ICLR,"""What Data Benefits My Classifier?"" Enhancing Model Performance and Interpretability through Influence-Based Data Selection",https://iclr.cc/virtual/2024/oral/19774,2024," Classification models are ubiquitously deployed in society and necessitate high utility, fairness, and robustness performance. Current research efforts mainly focus on improving model architectures and learning algorithms on fixed datasets to achieve this goal. In contrast, in this paper, we address an orthogonal yet crucial problem: given a fixed convex learning model (or a convex surrogate for a non-convex model) and a function of interest, we assess what data benefits the model by interpreting the feature space, and then aim to improve performance as measured by this function. To this end, we propose the use of influence estimation models for interpreting the classifier's performance from the perspective of the data feature space. Additionally, we propose data selection approaches based on influence that enhance model utility, fairness, and robustness. Through extensive experiments on synthetic and real-world datasets, we validate and demonstrate the effectiveness of our approaches not only for conventional classification scenarios, but also under more challenging scenarios such as distribution shifts, fairness poisoning attacks, utility evasion attacks, online learning, and active learning.",Oral 7B,https://openreview.net/pdf?id=HE9eUQlAvo,https://openreview.net/forum?id=HE9eUQlAvo
"['Hengrui Zhang', 'Jiani Zhang', 'Zhengyuan Shen', 'Balasubramaniam Srinivasan', 'Xiao Qin', 'Christos Faloutsos', 'Huzefa Rangwala', 'George Karypis']",ICLR,Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space,https://iclr.cc/virtual/2024/oral/19792,2024," Recent advances in tabular data generation have greatly enhanced synthetic data quality. However, extending diffusion models to tabular data is challenging due to the intricately varied distributions and a blend of data types of tabular data. This paper introduces TabSyn, a methodology that synthesizes tabular data by leveraging a diffusion model within a variational autoencoder (VAE) crafted latent space. The key advantages of the proposed Tabsyn include (1) Generality: the ability to handle a broad spectrum of data types by converting them into a single unified space and explicitly capturing inter-column relations; (2) Quality: optimizing the distribution of latent embeddings to enhance the subsequent training of diffusion models, which helps generate high-quality synthetic data; (3) Speed: much fewer number of reverse steps and faster synthesis speed than existing diffusion-based methods. Extensive experiments on six datasets with five metrics demonstrate that Tabsyn outperforms existing methods. Specifically, it reduces the error rates by 86% and 67% for column-wise distribution and pair-wise column correlation estimations compared with the most competitive baselines. The code has been made available at https://github.com/amazon-science/tabsyn.",Oral 8A,https://openreview.net/pdf?id=4Ay23yeuz0,https://openreview.net/forum?id=4Ay23yeuz0
"['Ziheng Qin', 'Kai Wang', 'Zangwei Zheng', 'Jianyang Gu', 'Xiangyu Peng', 'Zhaopan Xu', 'Zhou Daquan', 'Lei Shang', 'Baigui Sun', 'Xuansong Xie', 'Yang You']",ICLR,InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning,https://iclr.cc/virtual/2024/oral/19779,2024," Data pruning aims to obtain lossless performances with less overall cost. A common approach is to filter out samples that make less contribution to the training. This could lead to gradient expectation bias compared to the original data. To solve this problem, we propose InfoBatch, a novel framework aiming to achieve lossless training acceleration by unbiased dynamic data pruning. Specifically, InfoBatchrandomly prunes a portion of less informative samples based on the loss distribution and rescales the gradients of the remaining samples to approximate the original gradient. As a plug-and-play and architecture-agnostic framework, InfoBatch consistently obtains lossless training results on classification, semantic segmentation, vision pertaining, and instruction fine-tuning tasks. On CIFAR10/100, ImageNet-1K, and ADE20K, InfoBatch losslessly saves 40% overall cost. For pertaining MAE and diffusion model, InfoBatch can respectively save 24.8% and 27% cost. For LLaMA instruction fine-tuning, combining InfoBatch and the recent coreset selection method (DQ) can achieve 10 times acceleration. Our results encourage more exploration on the data efficiency aspect of large model training. Code is publicly available at NUS-HPC-AI-Lab/InfoBatch.",Oral 8B,https://openreview.net/pdf?id=C61sk5LsK6,https://openreview.net/forum?id=C61sk5LsK6
"['Haiming Wang', 'Huajian Xin', 'Chuanyang Zheng', 'Zhengying Liu', 'Qingxing Cao', 'Yinya Huang', 'Jing Xiong', 'Han Shi', 'Enze Xie', 'Jian Yin', 'Zhenguo Li', 'Xiaodan Liang']",ICLR,LEGO-Prover: Neural Theorem Proving with Growing Libraries,https://iclr.cc/virtual/2024/oral/19793,2024," Despite the success of large language models (LLMs), the task of theorem proving still remains one of the hardest reasoning tasks that is far from being fully solved. Prior methods using language models have demonstrated promising results, but they still struggle to prove even middle school level theorems. One common limitation of these methods is that they assume a fixed theorem library during the whole theorem proving process. However, as we all know, creating new useful theorems or even new theories is not only helpful but crucial and necessary for advancing mathematics and proving harder and deeper results. In this work, we present LEGO-Prover, which employs a growing skill library containing verified lemmas as skills to augment the capability of LLMs used in theorem proving. By constructing the proof modularly, LEGO-Prover enables LLMs to utilize existing skills retrieved from the library and to create new skills during the proving process. These skills are further evolved (by prompting an LLM) to enrich the library on another scale. Modular and reusable skills are constantly added to the library to enable tackling increasingly intricate mathematical problems. Moreover, the learned library further bridges the gap between human proofs and formal proofs by making it easier to impute missing steps. LEGO-Prover advances the state-of-the-art pass rate on miniF2F-valid (48.0\% to 57.0\%) and miniF2F-test (45.5\% to 50.0\%). During the proving process, LEGO-Prover also generates over 20,000 skills (theorems/lemmas) and adds them to the growing library. Our ablation study indicates that these newly added skills are indeed helpful for proving theorems, resulting in a 4.9\% improvement in success rate",Oral 8C,https://openreview.net/pdf?id=3f5PALef5B,https://openreview.net/forum?id=3f5PALef5B
"['Yang He', 'Lingao Xiao', 'Joey Tianyi Zhou', 'Ivor Tsang']",ICLR,Multisize Dataset Condensation,https://iclr.cc/virtual/2024/oral/19777,2024," While dataset condensation effectively enhances training efficiency, its application in on-device scenarios brings unique challenges. 1) Due to the fluctuating computational resources of these devices, there's a demand for a flexible dataset size that diverges from a predefined size. 2) The limited computational power on devices often prevents additional condensation operations. These two challenges connect to the ""subset degradation problem"" in traditional dataset condensation: a subset from a larger condensed dataset is often unrepresentative compared to directly condensing the whole dataset to that smaller size. In this paper, we propose Multisize Dataset Condensation (MDC) by **compressing $N$ condensation processes into a single condensation process to obtain datasets with multiple sizes.** Specifically, we introduce an ""adaptive subset loss"" on top of the basic condensation loss to mitigate the ""subset degradation problem"". Our MDC method offers several benefits: 1) No additional condensation process is required; 2) reduced storage requirement by reusing condensed images. Experiments validate our findings on networks including ConvNet, ResNet and DenseNet, and datasets including SVHN,  CIFAR-10, CIFAR-100 and ImageNet. For example, we achieved 5.22%-6.40% average accuracy gains on condensing CIFAR-10 to ten images per class. Code is available at: [https://github.com/he-y/Multisize-Dataset-Condensation](https://github.com/he-y/Multisize-Dataset-Condensation).",Oral 8D,https://openreview.net/pdf?id=FVhmnvqnsI,https://openreview.net/forum?id=FVhmnvqnsI
"['Nathan Frey', 'Dan Berenberg', 'Karina Zadorozhny', 'Joseph Kleinhenz', 'Julien Lafrance-Vanasse', 'Isidro Hotzel', 'Yan Wu', 'Stephen Ra', 'Richard Bonneau', 'Kyunghyun Cho', 'Andreas Loukas', 'Vladimir Gligorijevic', 'Saeed Saremi']",ICLR,Protein Discovery with Discrete Walk-Jump Sampling,https://iclr.cc/virtual/2024/oral/19713,2024," We resolve difficulties in training and sampling from a discrete generative model by learning a smoothed energy function, sampling from the smoothed data manifold with Langevin Markov chain Monte Carlo (MCMC), and projecting back to the true data manifold with one-step denoising. Our $\textit{Discrete Walk-Jump Sampling}$ formalism combines the contrastive divergence training of an energy-based model and improved sample quality of a score-based model, while simplifying training and sampling by requiring only a single noise level. We evaluate the robustness of our approach on generative modeling of antibody proteins and introduce the $\textit{distributional conformity score}$ to benchmark protein generative models. By optimizing and sampling from our models for the proposed distributional conformity score, 97-100\% of generated samples are successfully expressed and purified and 70\% of functional designs show equal or improved binding affinity compared to known functional antibodies on the first attempt in a single round of laboratory experiments. We also report the first demonstration of long-run fast-mixing MCMC chains where diverse antibody protein classes are visited in a single MCMC chain.",Oral 1A,https://openreview.net/pdf?id=zMPHKOmQNb,https://openreview.net/forum?id=zMPHKOmQNb
"['Sherry Yang', 'Yilun Du', 'Seyed Ghasemipour', 'Jonathan Tompson', 'Leslie Kaelbling', 'Dale Schuurmans', 'Pieter Abbeel']",ICLR,Learning Interactive Real-World Simulators,https://iclr.cc/virtual/2024/oral/19722,2024," Generative models trained on internet data have revolutionized how text, image, and video content can be created. Perhaps the next milestone for generative models is to simulate realistic experience in response to actions taken by humans, robots, and other interactive agents. Applications of a real-world simulator range from controllable content creation in games and movies, to training embodied agents purely in simulation that can be directly deployed in the real world. We explore the possibility of learning a universal simulator (UniSim) of real-world interaction through generative modeling. We first make the important observation that natural datasets available for learning a real-world simulator are often rich along different axes (e.g., abundant objects in image data, densely sampled actions in robotics data, and diverse movements in navigation data). With careful orchestration of diverse datasets, each providing a different aspect of the overall experience, UniSim can emulate how humans and agents interact with the world by simulating the visual outcome of both high-level instructions such as “open the drawer” and low-level controls such as “move by x,y” from otherwise static scenes and objects. There are numerous use cases for such a real-world simulator. As an example, we use UniSim to train both high-level vision-language planners and low-level reinforcement learning policies, each of which exhibit zero-shot real-world transfer after training purely in a learned real-world simulator. We also show that other types of intelligence such as video captioning models can benefit from training with simulated experience in UniSim, opening up even wider applications.",Oral 1B,https://openreview.net/pdf?id=sFyTZEqmUY,https://openreview.net/forum?id=sFyTZEqmUY
"['Suyu Ge', 'Yunan Zhang', 'Liyuan Liu', 'Minjia Zhang', 'Jiawei Han', 'Jianfeng Gao']",ICLR,Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs,https://iclr.cc/virtual/2024/oral/19718,2024," In this study, we introduce adaptive KV cache compression, a plug-and-play method that reduces the memory footprint of generative inference for Large Language Models (LLMs). Different from the conventional KV cache that retains key and value vectors for all context tokens, we conduct targeted profiling to discern the intrinsic structure of attention modules. Based on the recognized structure, we then construct the KV cache in an adaptive manner: evicting long-range contexts on attention heads emphasizing local contexts, discarding non-special tokens on attention heads centered on special tokens, and only employing the standard KV cache for attention heads that broadly attend to all tokens. Moreover, with the lightweight attention profiling used to guide the construction of the adaptive KV cache, FastGen can be deployed without resource-intensive fine-tuning or re-training. In our experiments across various asks, FastGen demonstrates substantial reduction on GPU memory consumption with negligible generation quality loss. We will release our code and the compatible CUDA kernel for reproducibility.",Oral 1C,https://openreview.net/pdf?id=uNrFpDPMyo,https://openreview.net/forum?id=uNrFpDPMyo
"['Yicong Hong', 'Kai Zhang', 'Jiuxiang Gu', 'Sai Bi', 'Yang Zhou', 'Difan Liu', 'Feng Liu', 'Kalyan Sunkavalli', 'Trung Bui', 'Hao Tan']",ICLR,LRM: Large Reconstruction Model for Single Image to 3D,https://iclr.cc/virtual/2024/oral/19721,2024," We propose the first Large Reconstruction Model (LRM) that predicts the 3D model of an object from a single input image within just 5 seconds. In contrast to many previous methods that are trained on small-scale datasets such as ShapeNet in a category-specific fashion, LRM adopts a highly scalable transformer-based architecture with 500 million learnable parameters to directly predict a neural radiance field (NeRF) from the input image. We train our model in an end-to-end manner on massive multi-view data containing around 1 million objects, including both synthetic renderings from Objaverse and real captures from MVImgNet. This combination of a high-capacity model and large-scale training data empowers our model to be highly generalizable and produce high-quality 3D reconstructions from various testing inputs, including real-world in-the-wild captures and images created by generative models. Video demos and interactable 3D meshes can be found on our LRM project webpage: https://yiconghong.me/LRM.",Oral 2B,https://openreview.net/pdf?id=sllU8vvsFF,https://openreview.net/forum?id=sllU8vvsFF
"['Akari Asai', 'Zeqiu Wu', 'Yizhong Wang', 'Avi Sil', 'Hannaneh Hajishirzi']",ICLR,"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection",https://iclr.cc/virtual/2024/oral/19736,2024," Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the parametric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues. However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation. We introduce a new framework called Self-Reflective Retrieval-Augmented Generation (Self-RAG) that enhances an LM's quality and factuality through retrieval and self-reflection. Our framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its generations using special tokens, called {\it reflection} tokens. Generating reflection tokens makes the LM controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements. Experiments show that Self-RAG (7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks. Specifically, Self-RAG outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA, reasoning, and fact verification tasks, and it shows significant gains in improving factuality and citation accuracy for long-form generations relative to these models. Our code and trained models are available at https://selfrag.github.io/",Oral 2A,https://openreview.net/pdf?id=hSyW5go0v8,https://openreview.net/forum?id=hSyW5go0v8
"['Iman Mirzadeh', 'Keivan Alizadeh-Vahid', 'Sachin Mehta', 'Carlo C del Mundo', 'Oncel Tuzel', 'Golnoosh Samei', 'Mohammad Rastegari', 'Mehrdad Farajtabar']",ICLR,ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models,https://iclr.cc/virtual/2024/oral/19725,2024," Large Language Models (LLMs) with billions of parameters have drastically transformed AI applications. However, their demanding computation during inference has raised significant challenges for deployment on resource-constrained devices. Despite recent trends favoring alternative activation functions such as GELU or SiLU, known for increased computation, this study strongly advocates for reinstating ReLU activation in LLMs. We demonstrate that using the ReLU activation function has a negligible impact on convergence and performance while significantly reducing computation and weight transfer. This reduction is particularly valuable during the memory-bound inference step, where efficiency is paramount. Exploring sparsity patterns in ReLU-based LLMs, we unveil the reutilization of activated neurons for generating new tokens and leveraging these insights, we propose practical strategies to substantially reduce LLM inference computation up to three times, using ReLU activations with minimal performance trade-offs.",Oral 3A,https://openreview.net/pdf?id=osoWxY8q2E,https://openreview.net/forum?id=osoWxY8q2E
"['Pablo Pernías', 'Dominic Rampas', 'Mats L. Richter', 'Christopher Pal', 'Marc Aubreville']",ICLR,Würstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models,https://iclr.cc/virtual/2024/oral/19738,2024," We introduce Würstchen, a novel architecture for text-to-image synthesis that combines competitive performance with unprecedented cost-effectiveness for large-scale text-to-image diffusion models.A key contribution of our work is to develop a latent diffusion technique in which we learn a detailed but extremely compact semantic image representation used to guide the diffusion process. This highly compressed representation of an image provides much more detailed guidance compared to latent representations of language and this significantly reduces the computational requirements to achieve state-of-the-art results. Our approach also improves the quality of text-conditioned image generation based on our user preference study.The training requirements of our approach consists of 24,602 A100-GPU hours - compared to Stable Diffusion 2.1's 200,000 GPU hours.  Our approach also requires less training data to achieve these results. Furthermore, our compact latent representations allows us to perform inference over twice as fast, slashing the usual costs and carbon footprint of a state-of-the-art (SOTA) diffusion model significantly, without compromising the end performance. In a broader comparison against SOTA models our approach is substantially more efficient and compares favourably in terms of image quality.We believe that this work motivates more emphasis on the prioritization of both performance and computational accessibility.",Oral 2C,https://openreview.net/pdf?id=gU58d5QeGv,https://openreview.net/forum?id=gU58d5QeGv
"['Jason Zhang', 'Amy Lin', 'Moneish Kumar', 'Tzu-Hsuan Yang', 'Deva Ramanan', 'Shubham Tulsiani']",ICLR,Cameras as Rays: Pose Estimation via Ray Diffusion,https://iclr.cc/virtual/2024/oral/19778,2024," Estimating camera poses is a fundamental task for 3D reconstruction and remains challenging given sparsely sampled views (<10). In contrast to existing approaches that pursue top-down prediction of global parametrizations of camera extrinsics, we propose a distributed representation of camera pose that treats a camera as a bundle of rays. This representation allows for a tight coupling with spatial image features improving pose precision. We observe that this representation is naturally suited for set-level transformers and develop a regression-based approach that maps image patches to corresponding rays. To capture the inherent uncertainties in sparse-view pose inference, we adapt this approach to learn a denoising diffusion model which allows us to sample plausible modes while improving performance. Our proposed methods, both regression- and diffusion-based, demonstrate state-of-the-art performance on camera pose estimation on CO3D while generalizing to unseen object categories and in-the-wild captures.",Oral 3B,https://openreview.net/pdf?id=EanCFCwAjM,https://openreview.net/forum?id=EanCFCwAjM
"['Miltiadis (Miltos) Kofinas', 'Boris Knyazev', 'Yan Zhang', 'Yunlu Chen', 'Gertjan J Burghouts', 'Efstratios Gavves', 'Cees G Snoek', 'David Zhang']",ICLR,Graph Neural Networks for Learning Equivariant Representations of Neural Networks,https://iclr.cc/virtual/2024/oral/19727,2024," Neural networks that process the parameters of other neural networks find applications in domains as diverse as classifying implicit neural representations, generating neural network weights, and predicting generalization errors. However, existing approaches either overlook the inherent permutation symmetry in the neural network or rely on intricate weight-sharing patterns to achieve equivariance, while ignoring the impact of the network architecture itself. In this work, we propose to represent neural networks as computational graphs of parameters, which allows us to harness powerful graph neural networks and transformers that preserve permutation symmetry. Consequently, our approach enables a single model to encode neural computational graphs with diverse architectures. We showcase the effectiveness of our method on a wide range of tasks, including classification and editing of implicit neural representations, predicting generalization performance, and learning to optimize, while consistently outperforming state-of-the-art methods. The source code is open-sourced at https://github.com/mkofinas/neural-graphs.",Oral 4B,https://openreview.net/pdf?id=oO6FsMyDBt,https://openreview.net/forum?id=oO6FsMyDBt
"['Ian Gemp', 'Luke Marris', 'Georgios Piliouras']",ICLR,Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization,https://iclr.cc/virtual/2024/oral/19744,2024," We propose the first loss function for approximate Nash equilibria of normal-form games that is amenable to unbiased Monte Carlo estimation. This construction allows us to deploy standard non-convex stochastic optimization techniques for approximating Nash equilibria, resulting in novel algorithms  with provable guarantees. We complement our theoretical analysis with experiments demonstrating that stochastic gradient descent can outperform previous state-of-the-art approaches.",Oral 3C,https://openreview.net/pdf?id=cc8h3I3V4E,https://openreview.net/forum?id=cc8h3I3V4E
"['Haoqi Yuan', 'Zhancun Mu', 'Feiyang Xie', 'Zongqing Lu']",ICLR,Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning,https://iclr.cc/virtual/2024/oral/19728,2024," Pre-training on task-agnostic large datasets is a promising approach for enhancing the sample efficiency of reinforcement learning (RL) in solving complex tasks. We present PTGM, a novel method that pre-trains goal-based models to augment RL by providing temporal abstractions and behavior regularization. PTGM involves pre-training a low-level, goal-conditioned policy and training a high-level policy to generate goals for subsequent RL tasks. To address the challenges posed by the high-dimensional goal space, while simultaneously maintaining the agent's capability to accomplish various skills, we propose clustering goals in the dataset to form a discrete high-level action space. Additionally, we introduce a pre-trained goal prior model to regularize the behavior of the high-level policy in RL, enhancing sample efficiency and learning stability. Experimental results in a robotic simulation environment and the challenging open-world environment of Minecraft demonstrate PTGM’s superiority in sample efficiency and task performance compared to baselines. Moreover, PTGM exemplifies enhanced interpretability and generalization of the acquired low-level skills.",Oral 4C,https://openreview.net/pdf?id=o2IEmeLL9r,https://openreview.net/forum?id=o2IEmeLL9r
"['André F. Cruz', 'Moritz Hardt']",ICLR,Unprocessing Seven Years of Algorithmic Fairness,https://iclr.cc/virtual/2024/oral/19731,2024," Seven years ago, researchers proposed a postprocessing method to equalize the error rates of a model across different demographic groups. The work launched hundreds of papers purporting to improve over the postprocessing baseline. We empirically evaluate these claims through thousands of model evaluations on several tabular datasets. We find that the fairness-accuracy Pareto frontier achieved by postprocessing contains all other methods we were feasibly able to evaluate. In doing so, we address two common methodological errors that have confounded previous observations. One relates to the comparison of methods with different unconstrained base models. The other concerns methods achieving different levels of constraint relaxation. At the heart of our study is a simple idea we call unprocessing that roughly corresponds to the inverse of postprocessing. Unprocessing allows for a direct comparison of methods using different underlying models and levels of relaxation.",Oral 5B,https://openreview.net/pdf?id=jr03SfWsBS,https://openreview.net/forum?id=jr03SfWsBS
"['Tianrong Chen', 'Jiatao Gu', 'Laurent Dinh', 'Evangelos Theodorou', 'Joshua Susskind', 'Shuangfei Zhai']",ICLR,Generative Modeling with Phase Stochastic Bridge,https://iclr.cc/virtual/2024/oral/19720,2024," Diffusion models (DMs) represent state-of-the-art generative models for continuous inputs. DMs work by constructing a Stochastic Differential Equation (SDE) in the input space (ie, position space), and using a neural network to reverse it. In this work, we introduce a novel generative modeling framework grounded in \textbf{phase space dynamics}, where a phase space is defined as {an augmented space encompassing both position and velocity.} Leveraging insights from Stochastic Optimal Control, we construct a path measure in the phase space that enables efficient sampling. {In contrast to DMs, our framework demonstrates the capability to generate realistic data points at an early stage of dynamics propagation.} This early prediction sets the stage for efficient data generation by leveraging additional velocity information along the trajectory. On standard image generation benchmarks, our model yields favorable performance over baselines in the regime of small Number of Function Evaluations (NFEs). Furthermore, our approach rivals the performance of diffusion models equipped with efficient sampling techniques, underscoring its potential as a new tool generative modeling.",Oral 5A,https://openreview.net/pdf?id=tUtGjQEDd4,https://openreview.net/forum?id=tUtGjQEDd4
"['Sebastian Pineda Arango', 'Fabio Ferreira', 'Arlind Kadra', 'Frank Hutter', 'Josif Grabocka']",ICLR,Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How,https://iclr.cc/virtual/2024/oral/19719,2024," With the ever-increasing number of pretrained models, machine learning practitioners are continuously faced with which pretrained model to use, and how to finetune it for a new dataset. In this paper, we propose a methodology that jointly searches for the optimal pretrained model and the hyperparameters for finetuning it. Our method transfers knowledge about the performance of many pretrained models with multiple hyperparameter configurations on a series of datasets. To this aim, we evaluated over 20k hyperparameter configurations for finetuning 24 pretrained image classification models on 87 datasets to generate a large-scale meta-dataset. We meta-learn a gray-box performance predictor on the learning curves of this meta-dataset and use it for fast hyperparameter optimization on new datasets. We empirically demonstrate that our resulting approach can quickly select an accurate pretrained model for a new dataset together with its optimal hyperparameters.",Oral 5C,https://openreview.net/pdf?id=tqh1zdXIra,https://openreview.net/forum?id=tqh1zdXIra
"['Pascal Chang', 'Jingwei Tang', 'Markus Gross', 'Vinicius Da Costa De Azevedo']",ICLR,How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models,https://iclr.cc/virtual/2024/oral/19723,2024," Video editing and generation methods often rely on pre-trained image-based diffusion models. During the diffusion process, however, the reliance on rudimentary noise sampling techniques that do not preserve correlations present in subsequent frames of a video is detrimental to the quality of the results. This either produces high-frequency flickering, or texture-sticking artifacts that are not amenable to post-processing. With this in mind, we propose a novel method for preserving temporal correlations in a sequence of noise samples. This approach is materialized by a novel noise representation, dubbed $\int$-noise (integral noise), that reinterprets individual noise samples as a continuously integrated noise field: pixel values do not represent discrete values, but are rather the integral of an underlying infinite-resolution noise over the pixel area. Additionally, we propose a carefully tailored transport method that uses $\int$-noise to accurately advect noise samples over a sequence of frames, maximizing the correlation between different frames while also preserving the noise properties. Our results demonstrate that the proposed $\int$-noise can be used for a variety of tasks, such as video restoration, surrogate rendering, and conditional video generation.",Oral 6A,https://openreview.net/pdf?id=pzElnMrgSD,https://openreview.net/forum?id=pzElnMrgSD
"['Ido Amos', 'Jonathan Berant', 'Ankit Gupta']",ICLR,Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors,https://iclr.cc/virtual/2024/oral/19761,2024," Modeling long-range dependencies across sequences is a longstanding goal in machine learning and has led to architectures, such as state space models, that dramatically outperform Transformers on long sequences. However, these impressive empirical gains have been by and large demonstrated on benchmarks (e.g. Long Range Arena), where models are randomly initialized and trained to predict a target label from an input sequence. In this work, we show that random initialization leads to gross overestimation of the differences between architectures and that pretraining with standard denoising objectives, using only the downstream task data , leads to dramatic gains across multiple architectures and to very small gaps between Transformers and state space models (SSMs). In stark contrast to prior works, we find vanilla Transformers to match the performance of S4 on Long Range Arena when properly pretrained, and we improve the best reported results of SSMs on the PathX-256 task by 20 absolute points. Subsequently, we analyze the utility of previously-proposed structured parameterizations for SSMs and show they become mostly redundant in the presence of data-driven initialization obtained through pretraining. Our work shows that, when evaluating different architectures on supervised tasks, incorporation of data-driven priors via pretraining is essential for reliable performance estimation, and can be done efficiently.",Oral 6C,https://openreview.net/pdf?id=PdaPky8MUn,https://openreview.net/forum?id=PdaPky8MUn
"['Ahmad Faiz', 'Sotaro Kaneda', 'Ruhan Wang', 'Rita Osi', 'Prateek Sharma', 'Fan Chen', 'Lei Jiang']",ICLR,LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models,https://iclr.cc/virtual/2024/oral/19750,2024," The carbon footprint associated with large language models (LLMs) is a significant concern, encompassing emissions from their training, inference, experimentation, and storage processes, including operational and embodied carbon emissions. An essential aspect is accurately estimating the carbon impact of emerging LLMs even before their training, which heavily relies on GPU usage. Existing studies have reported the carbon footprint of LLM training, but only one tool, mlco2, can predict the carbon footprint of new neural networks prior to physical training. However, mlco2 has several serious limitations. It cannot extend its estimation to dense or mixture-of-experts (MoE) LLMs, disregards critical architectural parameters, focuses solely on GPUs, and cannot model embodied carbon footprints. Addressing these gaps, we introduce \textit{\carb}, an end-to-end carbon footprint projection model designed for both dense and MoE LLMs. Compared to mlco2, \carb~significantly enhances the accuracy of carbon footprint estimations for various LLMs. The source code is released at \url{https://github.com/SotaroKaneda/MLCarbon}.",Oral 6B,https://openreview.net/pdf?id=aIok3ZD9to,https://openreview.net/forum?id=aIok3ZD9to
"['Shangbin Feng', 'Weijia Shi', 'Yuyang Bai', 'Vidhisha Balachandran', 'Tianxing He', 'Yulia Tsvetkov']",ICLR,Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models,https://iclr.cc/virtual/2024/oral/19753,2024," By design, large language models (LLMs) are static general-purpose models, expensive to retrain or update frequently. As they are increasingly adopted for knowledge-intensive tasks, it becomes evident that these design choices lead to failures to generate factual, relevant, and up-to-date knowledge. To this end, we propose Knowledge Card, a modular framework to plug in new factual and relevant knowledge into general-purpose LLMs. We first introduce knowledge cards---specialized language models trained on corpora from specific domains and sources. Knowledge cards serve as parametric repositories that are selected at inference time to generate background knowledge for the base LLM. We then propose three content selectors to dynamically select and retain information in documents generated by knowledge cards, specifically controlling for relevance, brevity, and factuality of outputs. Finally, we propose two complementary integration approaches to augment the base LLM with the (relevant, factual) knowledge curated from the specialized LMs. Through extensive experiments, we demonstrate that Knowledge Card achieves state-of-the-art performance on six benchmark datasets. Ultimately, Knowledge Card framework enables dynamic synthesis and updates of knowledge from diverse domains. Its modularity will ensure that relevant knowledge can be continuously updated through the collective efforts of the research community.",Oral 7B,https://openreview.net/pdf?id=WbWtOYIzIK,https://openreview.net/forum?id=WbWtOYIzIK
"['Yubo Zhuang', 'Xiaohui Chen', 'Yun Yang', 'Richard Zhang']",ICLR,Statistically Optimal $K$-means Clustering via Nonnegative Low-rank Semidefinite Programming,https://iclr.cc/virtual/2024/oral/19717,2024," $K$-means clustering is a widely used machine learning method for identifying patterns in large datasets. Recently, semidefinite programming (SDP) relaxations have been proposed for solving the $K$-means optimization problem, which enjoy strong statistical optimality guarantees. However, the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. In contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm widely used by machine learning practitioners, but it lacks a solid statistical underpinning and theoretical guarantees. In this paper, we consider an NMF-like algorithm that solves a nonnegative low-rank restriction of the SDP-relaxed $K$-means formulation using a nonconvex Burer--Monteiro factorization approach. The resulting algorithm is as simple and scalable as state-of-the-art NMF algorithms while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments, we observe that our algorithm achieves significantly smaller mis-clustering errors compared to the existing state-of-the-art while maintaining scalability.",Oral 7A,https://openreview.net/pdf?id=v7ZPwoHU1j,https://openreview.net/forum?id=v7ZPwoHU1j
"['Yapei Chang', 'Kyle Lo', 'Tanya Goyal', 'Mohit Iyyer']",ICLR,BooookScore: A systematic exploration of book-length summarization in the era of LLMs,https://iclr.cc/virtual/2024/oral/19789,2024," Summarizing book-length documents ($>$100K tokens)  that exceed the context window size of large language models (LLMs) requires first breaking the input document into smaller chunks and then prompting an LLM to merge, update, and compress chunk-level summaries. Despite the complexity and importance of this task, it has yet to be meaningfully studied due to the challenges of evaluation: existing book-length summarization datasets (e.g., BookSum) are in the pretraining data of most public LLMs, and existing evaluation methods struggle to capture errors made by modern LLM summarizers. In this paper, we present the first study of the coherence of LLM-based book-length summarizers implemented via two prompting workflows: (1) hierarchically merging chunk-level summaries, and (2) incrementally updating a running summary. We obtain 1193 fine-grained human annotations on GPT-4 generated summaries of 100 recently-published books and identify eight common types of coherence errors made by LLMs. Because human evaluation is expensive and time-consuming, we develop an automatic metric, BooookScore, that measures the proportion of sentences in a summary that do not contain any of the identified error types. BooookScore has high agreement with human annotations and allows us to systematically evaluate the impact of many other critical parameters (e.g., chunk size, base LLM) while saving \$15K USD and 500 hours in human evaluation costs. We find that closed-source LLMs such as GPT-4 and Claude 2 produce summaries with higher BooookScore than those generated by open-source models. While LLaMA 2 falls behind other models, Mixtral achieves performance on par with GPT-3.5-Turbo. Incremental updating yields lower BooookScore but higher level of detail than hierarchical merging, a trade-off sometimes preferred by annotators. We release code and annotations to spur more principled research on book-length summarization.",Oral 8D,https://openreview.net/pdf?id=7Ttk3RzDeu,https://openreview.net/forum?id=7Ttk3RzDeu
"['Yuxin Wen', 'Yuchen Liu', 'Chen Chen', 'Lingjuan Lyu']",ICLR,"Detecting, Explaining, and Mitigating Memorization in Diffusion Models",https://iclr.cc/virtual/2024/oral/19787,2024," Recent breakthroughs in diffusion models have exhibited exceptional image-generation capabilities. However, studies show that some outputs are merely replications of training data. Such replications present potential legal challenges for model owners, especially when the generated content contains proprietary information. In this work, we introduce a straightforward yet effective method for detecting memorized prompts by inspecting the magnitude of text-conditional predictions. Our proposed method seamlessly integrates without disrupting sampling algorithms, and delivers high accuracy even at the first generation step, with a single generation per prompt. Building on our detection strategy, we unveil an explainable approach that shows the contribution of individual words or tokens to memorization. This offers an interactive medium for users to adjust their prompts. Moreover, we propose two strategies i.e., to mitigate memorization by leveraging the magnitude of text-conditional predictions, either through minimization during inference or filtering during training. These proposed strategies effectively counteract memorization while maintaining high-generation quality. Code is available at https://github.com/YuxinWenRick/diffusion_memorization.",Oral 8A,https://openreview.net/pdf?id=84n3UwkH7b,https://openreview.net/forum?id=84n3UwkH7b
"['Atsushi Shimizu', 'Xiaoou Cheng', 'Christopher Musco', 'Jonathan Weare']",ICLR,Improved Active Learning via Dependent Leverage Score Sampling,https://iclr.cc/virtual/2024/oral/19770,2024," We show how to obtain improved active learning methods in the agnostic (adversarial noise) setting by combining marginal leverage score sampling with non-independent sampling strategies that promote spatial coverage. In particular, we propose an easily implemented method based on the \emph{pivotal sampling algorithm}, which we test on problems motivated by learning-based methods for parametric PDEs and uncertainty quantification. In comparison to independent sampling, our method reduces the number of samples needed to reach a given target accuracy by up to $50\%$.We support our findings with two theoretical results. First, we show that any non-independent leverage score sampling method that obeys a weak \emph{one-sided $\ell_{\infty}$ independence condition} (which includes pivotal sampling) can actively learn $d$ dimensional linear functions with $O(d\log d)$ samples, matching independent sampling. This result extends recent work on matrix Chernoff bounds under $\ell_{\infty}$ independence, and may be of interest for analyzing other sampling strategies beyond pivotal sampling. Second, we show that, for the important case of polynomial regression, our pivotal method obtains an improved bound of $O(d)$ samples.",Oral 8B,https://openreview.net/pdf?id=IYxDy2jDFL,https://openreview.net/forum?id=IYxDy2jDFL
"['HAOYUE DAI', 'Ignavier Ng', 'Gongxu Luo', 'Peter Spirtes', 'Petar Stojanov', 'Kun Zhang']",ICLR,Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View,https://iclr.cc/virtual/2024/oral/19739,2024," Gene regulatory network inference (GRNI) is a challenging problem, particularly owing to the presence of zeros in single-cell RNA sequencing data: some are biological zeros representing no gene expression, while some others are technical zeros arising from the sequencing procedure (aka dropouts), which may bias GRNI by distorting the joint distribution of the measured gene expressions. Existing approaches typically handle dropout error via imputation, which may introduce spurious relations as the true joint distribution is generally unidentifiable. To tackle this issue, we introduce a causal graphical model to characterize the dropout mechanism, namely, Causal Dropout Model. We provide a simple yet effective theoretical result: interestingly, the conditional independence (CI) relations in the data with dropouts, after deleting the samples with zero values (regardless if technical or not) for the conditioned variables, are asymptotically identical to the CI relations in the original data without dropouts. This particular test-wise deletion procedure, in which we perform CI tests on the samples without zeros for the conditioned variables, can be seamlessly integrated with existing structure learning approaches including constraint-based and greedy score-based methods, thus giving rise to a principled framework for GRNI in the presence of dropouts. We further show that the causal dropout model can be validated from data, and many existing statistical models to handle dropouts fit into our model as specific parametric instances. Empirical evaluation on synthetic, curated, and real-world experimental transcriptomic data comprehensively demonstrate the efficacy of our method.",Oral 1D,https://openreview.net/pdf?id=gFR4QwK53h,https://openreview.net/forum?id=gFR4QwK53h
"['Ching Fang', 'Kimberly Stachenfeld']",ICLR,Predictive auxiliary objectives in deep RL mimic learning in the brain,https://iclr.cc/virtual/2024/oral/19748,2024," The ability to predict upcoming events has been hypothesized to comprise a key aspect of natural and machine cognition. This is supported by trends in deep reinforcement learning (RL), where self-supervised auxiliary objectives such as prediction are widely used to support representation learning and improve task performance. Here, we study the effects predictive auxiliary objectives have on representation learning across different modules of an RL system and how these mimic representational changes observed in the brain. We find that predictive objectives improve and stabilize learning particularly in resource-limited architectures, and we identify settings where longer predictive horizons better support representational transfer. Furthermore, we find that representational changes in this RL system bear a striking resemblance to changes in neural activity observed in the brain across various experiments. Specifically, we draw a connection between the auxiliary predictive model of the RL system and hippocampus, an area thought to learn a predictive model to support memory-guided behavior. We also connect the encoder network and the value learning network of the RL system to visual cortex and striatum in the brain, respectively. This work demonstrates how representation learning in deep RL systems can provide an interpretable framework for modeling multi-region interactions in the brain. The deep RL perspective taken here also suggests an additional role of the hippocampus in the brain-- that of an auxiliary learning system that benefits representation learning in other regions.",Oral 1A,https://openreview.net/pdf?id=agPpmEgf8C,https://openreview.net/forum?id=agPpmEgf8C
"['Yukang Chen', 'Shengju Qian', 'Haotian Tang', 'Xin Lai', 'Zhijian Liu', 'Song Han', 'Jiaya Jia']",ICLR,LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models,https://iclr.cc/virtual/2024/oral/19790,2024," We present LongLoRA, an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs), with limited computation cost.Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. For example, training on the context length of 8192 needs 16x computational costs in self-attention layers as that of 2048. In this paper, we speed up the context extension of LLMs in two aspects. On the one hand, although dense global attention is needed during inference, fine-tuning the model can be effectively and efficiently done by sparse local attention. The proposed shifted sparse attention effectively enables context extension, leading to non-trivial computation saving with similar performance to fine-tuning with vanilla attention. Particularly, it can be implemented with only two lines of code in training, while being optional in inference. On the other hand, we revisit the parameter-efficient fine-tuning regime for context expansion. Notably, we find that LoRA for context extension works well under the premise of trainable embedding and normalization. LongLoRA combines this improved LoRA with S^2-Attn. LongLoRA demonstrates strong empirical results on various tasks on Llama2 models from 7B/13B to 70B. LongLoRA extends Llama2 7B from 4k context to 100k, or Llama2 70B to 32k on a single 8x A100 machine. LongLoRA extends models' context while retaining their original architectures, and is compatible with most existing techniques, like Flash-Attention2. In addition, we further conduct supervised fine-tuning with LongLoRA and our long instruction-following LongAlpaca dataset. All our code, models, dataset, and demo are available at https://github.com/dvlab-research/LongLoRA.",Oral 1C,https://openreview.net/pdf?id=6PmJoRfdaK,https://openreview.net/forum?id=6PmJoRfdaK
"['Izzeddin Gur', 'Hiroki Furuta', 'Austin Huang', 'Mustafa Safdari', 'Yutaka Matsuo', 'Douglas Eck', 'Aleksandra Faust']",ICLR,"A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",https://iclr.cc/virtual/2024/oral/19785,2024," Pre-trained large language models (LLMs) have recently achieved better generalization and sample efficiency in autonomous web automation.However, the performance on real-world websites has still suffered from (1) open domainness, (2) limited context length, and (3) lack of inductive bias on HTML.We introduce WebAgent, an LLM-driven agent that learns from self-experience to complete tasks on real websites following natural language instructions.WebAgent plans ahead by decomposing instructions into canonical sub-instructions, summarizes long HTML documents into task-relevant snippets, and acts on websites via Python programs generated from those.We design WebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, new pre-trained LLMs for long HTML documents using local and global attention mechanisms and a mixture of long-span denoising objectives, for planning and summarization.We empirically demonstrate that our modular recipe improves the success on real websites by over 50%, and that HTML-T5 is the best model to solve various HTML understanding tasks; achieving 18.7% higher success rate than the prior method on MiniWoB web automation benchmark, and SoTA performance on Mind2Web, an offline task planning evaluation.",Oral 1B,https://openreview.net/pdf?id=9JQtrumvg8,https://openreview.net/forum?id=9JQtrumvg8
"['Sirui Hong', 'Mingchen Zhuge', 'Jonathan Chen', 'Xiawu Zheng', 'Yuheng Cheng', 'Jinlin Wang', 'Ceyao Zhang', 'zili wang', 'Steven Yau', 'Zijuan Lin', 'Liyang Zhou', 'Chenyu Ran', 'Lingfeng Xiao', 'Chenglin Wu', 'Jürgen Schmidhuber']",ICLR,MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework,https://iclr.cc/virtual/2024/oral/19756,2024," Recently, remarkable progress has been made on automated problem solving through societies of agents based on large language models (LLMs). Previous LLM-based multi-agent systems can already solve simple dialogue tasks. More complex tasks, however, face challenges through logic inconsistencies due to cascading hallucinations caused by naively chaining LLMs. Here we introduce MetaGPT, an innovative meta-programming framework incorporating efficient human workflows into LLM-based multi-agent collaborations. MetaGPT encodes Standardized Operating Procedures (SOPs) into prompt sequences for more streamlined workflows, thus allowing agents with human-like domain expertise to verify intermediate results and reduce errors.  MetaGPT utilizes an assembly line paradigm to assign diverse roles to various agents, efficiently breaking down complex tasks into subtasks involving many agents working together.  On collaborative software engineering benchmarks, MetaGPT generates more coherent solutions than previous chat-based multi-agent systems.",Oral 2A,https://openreview.net/pdf?id=VtmBAGCN7o,https://openreview.net/forum?id=VtmBAGCN7o
"['Timothée Darcet', 'Maxime Oquab', 'Julien Mairal', 'Piotr Bojanowski']",ICLR,Vision Transformers Need Registers,https://iclr.cc/virtual/2024/oral/19794,2024," Transformers have recently emerged as a powerful tool for learning visual representations. In this paper, we identify and characterize artifacts in feature maps of both supervised and self-supervised ViT networks. The artifacts correspond to high-norm tokens appearing during inference primarily in low-informative background areas of images, that are repurposed for internal computations. We propose a simple yet effective solution based on providing additional tokens to the input sequence of the Vision Transformer to fill that role. We show that this solution fixes that problem entirely for both supervised and self-supervised models, sets a new state of the art for self-supervised visual models on dense visual prediction tasks, enables object discovery methods with larger models, and most importantly leads to smoother feature maps and attention maps for downstream visual processing.",Oral 2B,https://openreview.net/pdf?id=2dnO3LLiJ1,https://openreview.net/forum?id=2dnO3LLiJ1
"['Zhantao Yang', 'Ruili Feng', 'Han Zhang', 'Yujun Shen', 'Kai Zhu', 'Lianghua Huang', 'Yifei Zhang', 'Yu Liu', 'Deli Zhao', 'Jingren Zhou', 'Fan Cheng']",ICLR,Lipschitz Singularities in Diffusion Models,https://iclr.cc/virtual/2024/oral/19755,2024," Diffusion models, which employ stochastic differential equations to sample images through integrals, have emerged as a dominant class of generative models. However, the rationality of the diffusion process itself receives limited attention, leaving the question of whether the problem is well-posed and well-conditioned. In this paper, we uncover a vexing propensity of diffusion models: they frequently exhibit the infinite Lipschitz near the zero point of timesteps. We provide theoretical proofs to illustrate the presence of infinite Lipschitz constants and empirical results to confirm it. The Lipschitz singularities pose a threat to the stability and accuracy during both the training and inference processes of diffusion models. Therefore, the mitigation of Lipschitz singularities holds great potential for enhancing the performance of diffusion models. To address this challenge, we propose a novel approach, dubbed E-TSDM, which alleviates the Lipschitz singularities of the diffusion model near the zero point. Remarkably, our technique yields a substantial improvement in performance. Moreover, as a byproduct of our method, we achieve a dramatic reduction in the Fréchet Inception Distance of acceleration methods relying on network Lipschitz, including DDIM and DPM-Solver, by over 33\%. Extensive experiments on diverse datasets validate our theory and method. Our work may advance the understanding of the general diffusion process, and also provide insights for the design of diffusion models.",Oral 2C,https://openreview.net/pdf?id=WNkW0cOwiz,https://openreview.net/forum?id=WNkW0cOwiz
"['Bohang Zhang', 'Jingchu Gai', 'Yiheng Du', 'Qiwei Ye', 'Di He', 'Liwei Wang']",ICLR,Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness,https://iclr.cc/virtual/2024/oral/19773,2024," Designing expressive Graph Neural Networks (GNNs) is a fundamental topic in the graph learning community. So far, GNN expressiveness has been primarily assessed via the Weisfeiler-Lehman (WL) hierarchy. However, such an expressivity measure has notable limitations: it is inherently coarse, qualitative, and may not well reflect practical requirements (e.g., the ability to encode substructures). In this paper, we introduce a novel framework for quantitatively studying the expressiveness of GNN architectures, addressing all the above limitations. Specifically, we identify a fundamental expressivity measure termed homomorphism expressivity, which quantifies the ability of GNN models to count graphs under homomorphism. Homomorphism expressivity offers a complete and practical assessment tool: the completeness enables direct expressivity comparisons between GNN models, while the practicality allows for understanding concrete GNN abilities such as subgraph counting. By examining four classes of prominent GNNs as case studies, we derive simple, unified, and elegant descriptions of their homomorphism expressivity for both invariant and equivariant settings. Our results provide novel insights into a series of previous work, unify the landscape of different subareas in the community, and settle several open questions. Empirically, extensive experiments on both synthetic and real-world tasks verify our theory, showing that the practical performance of GNN models aligns well with the proposed metric.",Oral 2D,https://openreview.net/pdf?id=HSKaGOi7Ar,https://openreview.net/forum?id=HSKaGOi7Ar
"['Yixiao Li', 'Yifan Yu', 'Chen Liang', 'Nikos Karampatziakis', 'Pengcheng He', 'Weizhu Chen', 'Tuo Zhao']",ICLR,LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models,https://iclr.cc/virtual/2024/oral/19765,2024," Quantization is an indispensable technique for serving Large Language Models (LLMs) and has recently found its way into LoRA fine-tuning (Dettmers et al., 2023). In this work we focus on the scenario where quantization and LoRA fine- tuning are applied together on a pre-trained model. In such cases it is common to observe a consistent gap in the performance on downstream tasks between full fine-tuning and quantization plus LoRA fine-tuning approach. In response, we propose LoftQ (LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that simultaneously quantizes an LLM and finds a proper low-rank initialization for LoRA fine-tuning. Such an initialization alleviates the discrep- ancy between the quantized and full-precision model and significantly improves the generalization in downstream tasks. We evaluate our method on natural lan- guage understanding, question answering, summarization, and natural language generation tasks. Experiments show that our method is highly effective and out- performs existing quantization methods, especially in the challenging 2-bit and 2/4-bit mixed precision regimes. We will release our code.",Oral 3A,https://openreview.net/pdf?id=LzPWWPAdY4,https://openreview.net/forum?id=LzPWWPAdY4
"['Yuxuan Song', 'Jingjing Gong', 'Hao Zhou', 'Mingyue Zheng', 'Jingjing Liu', 'Wei-Ying Ma']",ICLR,Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks,https://iclr.cc/virtual/2024/oral/19764,2024," Advanced generative model (\textit{e.g.}, diffusion model) derived from simplified continuity assumptions of data distribution, though showing promising progress, has been difficult to apply directly to geometry generation applications due to the \textit{multi-modality} and \textit{noise-sensitive} nature of molecule geometry. This work introduces Geometric Bayesian Flow Networks (GeoBFN), which naturally fits molecule geometry by modeling diverse modalities in the differentiable parameter space of distributions. GeoBFN maintains the SE-(3) invariant density modeling property by incorporating equivariant inter-dependency modeling on parameters of distributions and unifying the probabilistic modeling of different modalities. Through optimized training and sampling techniques, we demonstrate that GeoBFN achieves state-of-the-art performance on multiple 3D molecule generation benchmarks in terms of generation quality (90.87\% molecule stability in QM9 and 85.6\% atom stability in GEOM-DRUG\footnote{The scores are reported at 1k sampling steps for fair comparison, and our scores could be further improved if sampling sufficiently longer steps.}). GeoBFN can also conduct sampling with any number of steps to reach an optimal trade-off between efficiency and quality (\textit{e.g.}, 20$\times$ speedup without sacrificing performance).",Oral 3B,https://openreview.net/pdf?id=NSVtmmzeRB,https://openreview.net/forum?id=NSVtmmzeRB
"['Bo Zhao', 'Robert M. Gower', 'Robin Walters', 'Rose Yu']",ICLR,Improving Convergence and Generalization Using Parameter Symmetries,https://iclr.cc/virtual/2024/oral/19767,2024," In many neural networks, different values of the parameters may result in the same loss value. Parameter space symmetries are loss-invariant transformations that change the model parameters. Teleportation applies such transformations to accelerate optimization. However, the exact mechanism behind this algorithm's success is not well understood. In this paper, we show that teleportation not only speeds up optimization in the short-term, but gives overall faster time to convergence. Additionally, teleporting to minima with different curvatures improves generalization, which suggests a connection between the curvature of the minimum and generalization ability. Finally, we show that integrating teleportation into a wide range of optimization algorithms and optimization-based meta-learning improves convergence. Our results showcase the versatility of teleportation and demonstrate the potential of incorporating symmetry in optimization.",Oral 3C,https://openreview.net/pdf?id=L0r0GphlIL,https://openreview.net/forum?id=L0r0GphlIL
"['Wenxuan Li', 'Alan Yuille', 'Zongwei Zhou']",ICLR,How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?,https://iclr.cc/virtual/2024/oral/19781,2024," The pre-training and fine-tuning paradigm has become prominent in transfer learning. For example, if the model is pre-trained on ImageNet and then fine-tuned to PASCAL, it can significantly outperform that trained on PASCAL from scratch. While ImageNet pre-training has shown enormous success, it is formed in 2D, and the learned features are for classification tasks; when transferring to more diverse tasks, like 3D image segmentation, its performance is inevitably compromised due to the deviation from the original ImageNet context. A significant challenge lies in the lack of large, annotated 3D datasets rivaling the scale of ImageNet for model pre-training. To overcome this challenge, we make two contributions. Firstly, we construct AbdomenAtlas 1.1 that comprises 9,262 three-dimensional computed tomography (CT) volumes with high-quality, per-voxel annotations of 25 anatomical structures and pseudo annotations of seven tumor types. Secondly, we develop a suite of models that are pre-trained on our AbdomenAtlas 1.1 for transfer learning. Our preliminary analyses indicate that the model trained only with 21 CT volumes, 672 masks, and 40 GPU hours has a transfer learning ability similar to the model trained with 5,050 (unlabeled) CT volumes and 1,152 GPU hours. More importantly, the transfer learning ability of supervised models can further scale up with larger annotated datasets, achieving significantly better performance than preexisting pre-trained models, irrespective of their pre-training methodologies or data sources. We hope this study can facilitate collective efforts in constructing larger 3D medical datasets and more releases of supervised pre-trained models.",Oral 3D,https://openreview.net/pdf?id=AhizIPytk4,https://openreview.net/forum?id=AhizIPytk4
"['Carlos E Jimenez', 'John Yang', 'Alexander Wettig', 'Shunyu Yao', 'Kexin Pei', 'Ofir Press', 'Karthik Narasimhan']",ICLR,SWE-bench: Can Language Models Resolve Real-world Github Issues?,https://iclr.cc/virtual/2024/oral/19757,2024," Language models have outpaced our ability to evaluate them effectively, but for their future development it is essential to study the frontier of their capabilities. We find real-world software engineering to be a rich, sustainable, and challenging testbed for evaluating the next generation of language models. To this end, we introduce SWE-bench, an evaluation framework consisting of 2,294 software engineering problems drawn from real GitHub issues and corresponding pull requests across 12 popular Python repositories. Given a codebase along with a description of an issue to be resolved, a language model is tasked with editing the codebase to address the issue. Resolving issues in SWE-bench frequently requires understanding and coordinating changes across multiple functions, classes, and even files simultaneously, calling for models to interact with execution environments, process extremely long contexts and perform complex reasoning that goes far beyond traditional code generation tasks. Our evaluations show that both state-of-the-art proprietary models and our fine-tuned model SWE-Llama can resolve only the simplest issues. The best-performing model, Claude 2, is able to solve a mere 1.96% of the issues. Advances on SWE-bench represent steps towards LMs that are more practical, intelligent, and autonomous.",Oral 4A,https://openreview.net/pdf?id=VTF8yNQM66,https://openreview.net/forum?id=VTF8yNQM66
"['Ismail Akhalwaya', 'Shashanka Ubaru', 'Kenneth Clarkson', 'Mark Squillante', 'Vishnu Jejjala', 'Yang-Hui He', 'Kugendran Naidoo', 'Vasileios Kalantzis', 'Lior Horesh']",ICLR,Topological data analysis on noisy quantum computers,https://iclr.cc/virtual/2024/oral/19742,2024," Topological data analysis (TDA) is a powerful technique for extracting complex and valuable shape-related summaries of high-dimensional data. However, the computational demands of classical algorithms for computing TDA are exorbitant, and quickly become impractical for high-order characteristics. Quantum computers offer the potential of achieving significant speedup for certain computational problems. Indeed, TDA has been purported to be one such problem, yet, quantum computing algorithms proposed for the problem, such as the original Quantum TDA (QTDA) formulation by Lloyd, Garnerone and Zanardi, require fault-tolerance qualifications that are currently unavailable. In this study, we present NISQ-TDA, a fully implemented end-to-end quantum machine learning algorithm needing only a short circuit-depth, that is applicable to high-dimensional classical data, and with provable asymptotic speedup for certain classes of problems. The algorithm neither suffers from the data-loading problem nor does it need to store the input data on the quantum computer explicitly. The algorithm was successfully executed on quantum computing devices, as well as on noisy quantum simulators, applied to small datasets. Preliminary empirical results suggest that the algorithm is robust to noise.",Oral 4B,https://openreview.net/pdf?id=dLrhRIMVmB,https://openreview.net/forum?id=dLrhRIMVmB
"['Hyungho Na', 'Yunkyeong Seo', 'Il-chul Moon']",ICLR,Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning,https://iclr.cc/virtual/2024/oral/19766,2024," In cooperative multi-agent reinforcement learning (MARL), agents aim to achieve a common goal, such as defeating enemies or scoring a goal. Existing MARL algorithms are effective but still require significant learning time and often get trapped in local optima by complex tasks, subsequently failing to discover a goal-reaching policy. To address this, we introduce Efficient episodic Memory Utilization (EMU) for MARL, with two primary objectives: (a) accelerating reinforcement learning by leveraging semantically coherent memory from an episodic buffer and (b) selectively promoting desirable transitions to prevent local convergence. To achieve (a), EMU incorporates a trainable encoder/decoder structure alongside MARL, creating coherent memory embeddings that facilitate exploratory memory recall. To achieve (b), EMU introduces a novel reward structure called episodic incentive based on the desirability of states. This reward improves the TD target in Q-learning and acts as an additional incentive for desirable transitions. We provide theoretical support for the proposed incentive and demonstrate the effectiveness of EMU compared to conventional episodic control. The proposed method is evaluated in StarCraft II and Google Research Football, and empirical results indicate further performance improvement over state-of-the-art methods.",Oral 4C,https://openreview.net/pdf?id=LjivA1SLZ6,https://openreview.net/forum?id=LjivA1SLZ6
"['Edward Hu', 'Moksh Jain', 'Eric Elmoznino', 'Younesse Kaddar', 'Guillaume Lajoie', 'Yoshua Bengio', 'Nikolay Malkin']",ICLR,Amortizing intractable inference in large language models,https://iclr.cc/virtual/2024/oral/19763,2024," Autoregressive large language models (LLMs) compress knowledge from their training data through next-token conditional distributions. This limits tractable querying of this knowledge to start-to-end autoregressive sampling. However, many tasks of interest---including sequence continuation, infilling, and other forms of constrained generation---involve sampling from intractable posterior distributions. We address this limitation by using amortized Bayesian inference to sample from these intractable posteriors. Such amortization is algorithmically achieved by fine-tuning LLMs via diversity-seeking reinforcement learning algorithms: generative flow networks (GFlowNets). We empirically demonstrate that this distribution-matching paradigm of LLM fine-tuning can serve as an effective alternative to maximum-likelihood training and reward-maximizing policy optimization. As an important application, we interpret chain-of-thought reasoning as a latent variable modeling problem and demonstrate that our approach enables data-efficient adaptation of LLMs to tasks that require multi-step rationalization and tool use.",Oral 4D,https://openreview.net/pdf?id=Ouj6p4ca60,https://openreview.net/forum?id=Ouj6p4ca60
"['Zahra Kadkhodaie', 'Florentin Guth', 'Eero Simoncelli', 'Stéphane Mallat']",ICLR,Generalization in diffusion models arises from geometry-adaptive harmonic representations,https://iclr.cc/virtual/2024/oral/19783,2024," Deep neural networks (DNNs) trained for image denoising are able to generate high-quality samples with score-based reverse diffusion algorithms. These impressive capabilities seem to imply an escape from the curse of dimensionality, but recent reports of memorization of the training set raise the question of whether these networks are learning the ""true"" continuous density of the data. Here, we show that two DNNs trained on non-overlapping subsets of a dataset learn nearly the same score function, and thus the same density, when the number of training images is large enough.  In this regime of strong generalization, diffusion-generated images are distinct from the training set, and are of high visual quality, suggesting that the inductive biases of the DNNs are well-aligned with the data density. We analyze the learned denoising functions and show that the inductive biases give rise to a shrinkage operation in a basis adapted to the underlying image. Examination of these bases reveals oscillating harmonic structures along contours and in homogeneous regions. We demonstrate that trained denoisers are inductively biased towards these geometry-adaptive harmonic bases since they arise not only when the network is trained on photographic images, but also when it is trained on image classes supported on low-dimensional manifolds for which the harmonic basis is suboptimal. Finally, we show that when trained on regular image classes for which the optimal basis is known to be geometry-adaptive and harmonic, the denoising performance of the networks is near-optimal.",Oral 5A,https://openreview.net/pdf?id=ANvmVS2Yr0,https://openreview.net/forum?id=ANvmVS2Yr0
"['Xiangyu Qi', 'Yi Zeng', 'Tinghao Xie', 'Pin-Yu Chen', 'Ruoxi Jia', 'Prateek Mittal', 'Peter Henderson']",ICLR,"Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!",https://iclr.cc/virtual/2024/oral/19735,2024," Optimizing large language models (LLMs) for downstream use cases often involves the customization of pre-trained LLMs through further fine-tuning. Meta's open-source release of Llama models and OpenAI's APIs for fine-tuning GPT-3.5 Turbo on customized datasets accelerate this trend. But, what are the safety costs associated with such customized fine-tuning? While existing safety alignment techniques restrict harmful behaviors of LLMs at inference time, they do not cover safety risks when fine-tuning privileges are extended to end-users. Our red teaming studies find that the safety alignment of LLMs can be compromised by fine-tuning with only a few adversarially designed training examples. For instance, we jailbreak GPT-3.5 Turbo's safety guardrails by fine-tuning it on only 10 such examples at a cost of less than $0.20 via OpenAI's APIs, making the model responsive to nearly any harmful instructions. Disconcertingly, our research also reveals that, even without malicious intent, simply fine-tuning with benign and commonly used datasets can also inadvertently degrade the safety alignment of LLMs, though to a lesser extent. These findings suggest that fine-tuning aligned LLMs introduces new safety risks that current safety infrastructures fall short of addressing --- even if a model's initial safety alignment is impeccable, how can it be maintained after customized fine-tuning? We outline and critically analyze potential mitigations and advocate for further research efforts toward reinforcing safety protocols for the customized fine-tuning of aligned LLMs.  (This paper contains red-teaming data and model-generated content that can be offensive in nature.)",Oral 5B,https://openreview.net/pdf?id=hTEGyKf0dZ,https://openreview.net/forum?id=hTEGyKf0dZ
"['Panagiotis Eustratiadis', 'Łukasz Dudziak', 'Da Li', 'Timothy Hospedales']",ICLR,Neural Fine-Tuning Search for Few-Shot Learning,https://iclr.cc/virtual/2024/oral/19760,2024," In few-shot recognition, a classifier that has been trained on one set of classes is required to rapidly adapt and generalize to a disjoint, novel set of classes. To that end, recent studies have shown the efficacy of fine-tuning with carefully-crafted adaptation architectures. However this raises the question of: How can one design the optimal adaptation strategy? In this paper, we study this question through the lens of neural architecture search (NAS). Given a pre-trained neural network, our algorithm discovers the optimal arrangement of adapters, which layers to keep frozen, and which to fine-tune. We demonstrate the generality of our NAS method by applying it to both residual networks and vision transformers and report state-of-the-art performance on Meta-Dataset and Meta-Album.",Oral 5C,https://openreview.net/pdf?id=T7YV5UZKBc,https://openreview.net/forum?id=T7YV5UZKBc
"['Yossi Gandelsman', 'Alexei Efros', 'Jacob Steinhardt']",ICLR,Interpreting CLIP's Image Representation via Text-Based Decomposition,https://iclr.cc/virtual/2024/oral/19791,2024," We investigate the CLIP image encoder by analyzing how individual model components affect the final representation. We decompose the image representation as a sum across individual image patches, model layers, and attention heads, and use CLIP's text representation to interpret the summands. Interpreting the attention heads, we characterize each head's role by automatically finding text representations that span its output space, which reveals property-specific roles for many heads (e.g. location or shape). Next, interpreting the image patches, we uncover an emergent spatial localization within CLIP. Finally, we use this understanding to remove spurious features from CLIP and to create a strong zero-shot image segmenter. Our results indicate that scalable understanding of transformer models is attainable and can be used to repair and improve models.",Oral 5D,https://openreview.net/pdf?id=5Ca9sSzuDp,https://openreview.net/forum?id=5Ca9sSzuDp
"['Zaishuo Xia', 'Han Yang', 'Binghui Wang', 'Jinyuan Jia']",ICLR,GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations,https://iclr.cc/virtual/2024/oral/19771,2024," Graph classification, which aims to predict a label for a graph, has many real-world applications such as malware detection, fraud detection, and healthcare. However, many studies show an attacker could carefully perturb the structure and/or node features in a graph such that a graph classifier misclassifies the perturbed graph. Such vulnerability impedes the deployment of graph classification in security/safety-critical applications. Existing empirical defenses lack formal robustness guarantees and could be broken by adaptive or unknown attacks. Existing provable defenses have the following limitations: 1)  they achieve sub-optimal robustness guarantees for graph structure perturbation, 2) they cannot provide robustness guarantees for arbitrarily node feature perturbations, 3) their robustness guarantees are probabilistic, meaning they could be incorrect with a non-zero probability, and 4) they incur large computation costs. We aim to address those limitations in this work. We propose GNNCert, a certified defense against both graph structure and node feature perturbations for graph classification. Our GNNCert provably predicts the same label for a graph when the number of perturbed edges and the number of nodes with perturbed features are bounded. Our results on 8 benchmark datasets show that GNNCert outperforms three state-of-the-art methods.",Oral 6B,https://openreview.net/pdf?id=IGzaH538fz,https://openreview.net/forum?id=IGzaH538fz
"['Shuo He', 'Chaojie Wang', 'Guowu Yang', 'Lei Feng']",ICLR,Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning,https://iclr.cc/virtual/2024/oral/19776,2024," Partial-label learning (PLL) allows each training example to be equipped with a set of candidate labels. Existing deep PLL research focuses on a \emph{learning-centric} perspective to design various training strategies for label disambiguation i.e., identifying the concealed true label from the candidate label set, for model training. However, when the size of the candidate label set becomes excessively large, these learning-centric strategies would be unable to find the true label for model training, thereby causing performance degradation. This motivates us to think from a \emph{data-centric} perspective and pioneer a new PLL-related task called candidate label set pruning (CLSP) that aims to filter out certain potential false candidate labels in a training-free manner. To this end, we propose the first CLSP method based on the inconsistency between the representation space and the candidate label space. Specifically, for each candidate label of a training instance, if it is not a candidate label of the instance's nearest neighbors in the representation space, then it has a high probability of being a false label. Based on this intuition, we employ a per-example pruning scheme that filters out a specific proportion of high-probability false candidate labels. Theoretically, we prove an upper bound of the pruning error rate and analyze how the quality of representations affects our proposed method. Empirically, extensive experiments on both benchmark-simulated and real-world PLL datasets validate the great value of CLSP to significantly improve many state-of-the-art deep PLL methods.",Oral 6C,https://openreview.net/pdf?id=Fk5IzauJ7F,https://openreview.net/forum?id=Fk5IzauJ7F
"['Giorgio Mariani', 'Irene Tallini', 'Emilian Postolache', 'Michele Mancusi', 'Luca Cosmo', 'Emanuele Rodolà']",ICLR,Multi-Source Diffusion Models for Simultaneous Music Generation and Separation,https://iclr.cc/virtual/2024/oral/19737,2024," In this work, we define a diffusion-based generative model capable of both music generation and source separation by learning the score of the joint probability density of sources sharing a context. Alongside the classic total inference tasks (i.e., generating a mixture, separating the sources), we also introduce and experiment on the partial generation task of source imputation, where we generate a subset of the sources given the others (e.g., play a piano track that goes well with the drums). Additionally, we introduce a novel inference method for the separation task based on Dirac likelihood functions. We train our model on Slakh2100, a standard dataset for musical source separation, provide qualitative results in the generation settings, and showcase competitive quantitative results in the source separation setting. Our method is the first example of a single model that can handle both generation and separation tasks, thus representing a step toward general audio models.",Oral 6A,https://openreview.net/pdf?id=h922Qhkmx1,https://openreview.net/forum?id=h922Qhkmx1
"['Mitchell Wortsman', 'Peter Liu', 'Lechao Xiao', 'Katie Everett', 'Alexander Alemi', 'Ben Adlam', 'John Co-Reyes', 'Izzeddin Gur', 'Abhishek Kumar', 'Roman Novak', 'Jeffrey Pennington', 'Jascha Sohl-Dickstein', 'Kelvin Xu', 'Jaehoon Lee', 'Justin Gilmer', 'Simon Kornblith']",ICLR,Small-scale proxies for large-scale Transformer training instabilities,https://iclr.cc/virtual/2024/oral/19743,2024," Teams that have trained large Transformer-based models have reported training instabilities at large scale that did not appear when training with the same hyperparameters at smaller scales. Although the causes of such instabilities are of scientific interest, the amount of resources required to reproduce them has made investigation difficult. In this work, we seek ways to reproduce and study training instability at smaller scales. First, we focus on two sources of training instability described in previous work: the growth of logits in attention layers (Dehghani et al., 2023) and divergence of the output logits from the log probabilities (Chowdhery et al., 2022). By measuring the relationship between learning rate and loss across scales, we show that these instabilities also appear in small models when training at high learning rates, and that mitigations previously employed at large scales are equally effective in this regime. This prompts us to investigate the extent to which other known optimizer and model interventions influence the sensitivity of the final loss to changes in the learning rate. To this end, we study methods such as warm-up, weight decay, and the MuParam (Yang et al., 2022), and combine techniques to train small models that achieve similar losses across orders of magnitude of learning rate variation. Finally, to conclude our exploration we study two cases where instabilities can be predicted before they emerge by examining the scaling behavior of model characteristics such as activation and gradient norms.",Oral 7A,https://openreview.net/pdf?id=d8w0pmvXbZ,https://openreview.net/forum?id=d8w0pmvXbZ
"['Yijie Lin', 'Jie Zhang', 'Zhenyu Huang', 'Jia Liu', 'zujie wen', 'Xi Peng']",ICLR,Multi-granularity Correspondence Learning from Long-term Noisy Videos,https://iclr.cc/virtual/2024/oral/19786,2024," Existing video-language studies mainly focus on learning short video clips, leaving long-term temporal dependencies rarely explored due to over-high computational cost of modeling long videos. To address this issue, one feasible solution is learning the correspondence between video clips and captions, which however inevitably encounters the multi-granularity noisy correspondence (MNC) problem. To be specific, MNC refers to the clip-caption misalignment (coarse-grained) and frame-word misalignment (fine-grained), hindering temporal learning and video understanding. In this paper, we propose NOise Robust Temporal Optimal traNsport (Norton) that addresses MNC in a unified optimal transport (OT) framework. In brief, Norton employs video-paragraph and clip-caption contrastive losses to capture long-term dependencies based on OT. To address coarse-grained misalignment in video-paragraph contrast, Norton filters out the irrelevant clips and captions through an alignable prompt bucket and realigns asynchronous clip-caption pairs based on transport distance. To address the fine-grained misalignment, Norton incorporates a soft-maximum operator to identify crucial words and key frames. Additionally, Norton exploits the potential faulty negative samples in clip-caption contrast by rectifying the alignment target with OT assignment to ensure precise temporal modeling. Extensive experiments on video retrieval, videoQA, and action segmentation verify the effectiveness of our method. Code is available at https://lin-yijie.github.io/projects/Norton.",Oral 6D,https://openreview.net/pdf?id=9Cu8MRmhq2,https://openreview.net/forum?id=9Cu8MRmhq2
"['Jiaxiang Tang', 'Jiawei Ren', 'Hang Zhou', 'Ziwei Liu', 'Gang Zeng']",ICLR,DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation,https://iclr.cc/virtual/2024/oral/19758,2024," Recent advances in 3D content creation mostly leverage optimization-based 3D generation via score distillation sampling (SDS).Though promising results have been exhibited, these methods often suffer from slow per-sample optimization, limiting their practical usage. In this paper, we propose DreamGaussian, a novel 3D content generation framework that achieves both efficiency and quality simultaneously. Our key insight is to design a generative 3D Gaussian Splatting model with companioned mesh extraction and texture refinement in UV space.In contrast to the occupancy pruning used in Neural Radiance Fields, we demonstrate that the progressive densification of 3D Gaussians converges significantly faster for 3D generative tasks.To further enhance the texture quality and facilitate downstream applications, we introduce an efficient algorithm to convert 3D Gaussians into textured meshes and apply a fine-tuning stage to refine the details.Extensive experiments demonstrate the superior efficiency and competitive generation quality of our proposed approach.Notably, DreamGaussian produces high-quality textured meshes in just 2 minutes from a single-view image, achieving approximately 10 times acceleration compared to existing methods.",Oral 7B,https://openreview.net/pdf?id=UyNXMqnN3c,https://openreview.net/forum?id=UyNXMqnN3c
"['Galen Andrew', 'Peter Kairouz', 'Sewoong Oh', 'Alina Oprea', 'H. Brendan McMahan', 'Vinith Suriyakumar']",ICLR,One-shot Empirical Privacy Estimation for Federated Learning,https://iclr.cc/virtual/2024/oral/19797,2024," Privacy estimation techniques for differentially private (DP) algorithms are useful for comparing against analytical bounds, or to empirically measure privacy loss in settings where known analytical bounds are not tight. However, existing privacy auditing techniques usually make strong assumptions on the adversary (e.g., knowledge of intermediate model iterates or the training data distribution), are tailored to specific tasks, model architectures, or DP algorithm, and/or require retraining the model many times (typically on the order of thousands). These shortcomings make deploying such techniques at scale difficult in practice, especially in federated settings where model training can take days or weeks. In this work, we present a novel “one-shot” approach that can systematically address these challenges, allowing efficient auditing or estimation of the privacy loss of a model during the same, single training run used to fit model parameters, and without requiring any a priori knowledge about the model architecture, task, or DP algorithm. We show that our method provides provably correct estimates for the privacy loss under the Gaussian mechanism, and we demonstrate its performance on a well-established FL benchmark dataset under several adversarial threat models.",Oral 7D,https://openreview.net/pdf?id=0BqyZSWfzo,https://openreview.net/forum?id=0BqyZSWfzo
"['Ruoyu Chen', 'Hua Zhang', 'Siyuan Liang', 'Jingzhi Li', 'Xiaochun Cao']",ICLR,Less is More: Fewer Interpretable Region via Submodular Subset Selection,https://iclr.cc/virtual/2024/oral/19733,2024," Image attribution algorithms aim to identify important regions that are highly relevant to model decisions. Although existing attribution solutions can effectively assign importance to target elements, they still face the following challenges: 1) existing attribution methods generate inaccurate small regions thus misleading the direction of correct attribution, and 2) the model cannot produce good attribution results for samples with wrong predictions. To address the above challenges, this paper re-models the above image attribution problem as a submodular subset selection problem, aiming to enhance model interpretability using fewer regions. To address the lack of attention to local regions, we construct a novel submodular function to discover more accurate small interpretation regions. To enhance the attribution effect for all samples, we also impose four different constraints on the selection of sub-regions, i.e., confidence, effectiveness, consistency, and collaboration scores, to assess the importance of various subsets. Moreover, our theoretical analysis substantiates that the proposed function is in fact submodular. Extensive experiments show that the proposed method outperforms SOTA methods on two face datasets (Celeb-A and VGG-Face2) and one fine-grained dataset (CUB-200-2011). For correctly predicted samples, the proposed method improves the Deletion and Insertion scores with an average of 4.9\% and 2.5\% gain relative to HSIC-Attribution. For incorrectly predicted samples, our method achieves gains of 81.0\% and 18.4\% compared to the HSIC-Attribution algorithm in the average highest confidence and Insertion score respectively. The code is released at https://github.com/RuoyuChen10/SMDL-Attribution.",Oral 7C,https://openreview.net/pdf?id=jKTUlxo5zy,https://openreview.net/forum?id=jKTUlxo5zy
"['Mohammad Reza Samsami', 'Artem Zholus', 'Janarthanan Rajendran', 'Sarath Chandar']",ICLR,Mastering Memory Tasks with World Models,https://iclr.cc/virtual/2024/oral/19795,2024," Current model-based reinforcement learning (MBRL) agents struggle with long-term dependencies. This limits their ability to effectively solve tasks involving extended time gaps between actions and outcomes, or tasks demanding the recalling of distant observations to inform current actions. To improve temporal coherence, we integrate a new family of state space models (SSMs) in world models of MBRL agents to present a new method, Recall to Imagine (R2I). This integration aims to enhance both long-term memory and long-horizon credit assignment. Through a diverse set of illustrative tasks, we systematically demonstrate that R2I not only establishes a new state-of-the-art for challenging memory and credit assignment RL tasks, such as BSuite and POPGym, but also showcases superhuman performance in the complex memory domain of Memory Maze. At the same time, it upholds comparable performance in classic RL tasks, such as Atari and DMC, suggesting the generality of our method. We also show that R2I is faster than the state-of-the-art MBRL method, DreamerV3, resulting in faster wall-time convergence.",Oral 8C,https://openreview.net/pdf?id=1vDArHJ68h,https://openreview.net/forum?id=1vDArHJ68h
"['Xian Li', 'Ping Yu', 'Chunting Zhou', 'Timo Schick', 'Omer Levy', 'Luke Zettlemoyer', 'Jason E Weston', 'Mike Lewis']",ICLR,Self-Alignment with Instruction Backtranslation,https://iclr.cc/virtual/2024/oral/19796,2024," We present a scalable method to build a high quality instruction following language model by automatically labelling human-written text with corresponding instructions. Our approach, named instruction backtranslation, starts with a language model finetuned on a small amount of seed data, and a given web corpus. The seed model is used to construct training examples by generating instruction prompts for web documents (self-augmentation), and then  selecting high quality examples from among these candidates (self-curation).  This data is then used to finetune a stronger model.  Finetuning LLaMa on two iterations of our approach yields a model that outperforms all other LLaMa-based models on the Alpaca leaderboard not relying on distillation data, demonstrating highly effective self-alignment.",Oral 8A,https://openreview.net/pdf?id=1oijHJBRsT,https://openreview.net/forum?id=1oijHJBRsT
"['Jie Hu', 'Vishwaraj Doshi', 'Do Young Eun']",ICLR,Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks,https://iclr.cc/virtual/2024/oral/19780,2024," We study a family of distributed stochastic optimization algorithms where gradients are sampled by a token traversing a network of agents in random-walk fashion. Typically, these random-walks are chosen to be Markov chains that asymptotically sample from a desired target distribution, and play a critical role in the convergence of the optimization iterates. In this paper, we take a novel approach by replacing the standard *linear* Markovian token by one which follows a *non-linear* Markov chain - namely the Self-Repellent Radom Walk (SRRW). Defined for any given 'base' Markov chain, the SRRW, parameterized by a positive scalar $\\alpha$, is less likely to transition to states that were highly visited in the past, thus the name. In the context of MCMC sampling on a graph, a recent breakthrough in Doshi et al. (2023) shows that the SRRW achieves $O(1/\\alpha)$ decrease in the asymptotic variance for sampling. We propose the use of a `generalized' version of the SRRW to drive token algorithms for distributed stochastic optimization in the form of stochastic approximation, termed SA-SRRW. We prove that the optimization iterate errors of the resulting SA-SRRW converge to zero almost surely and prove a central limit theorem, deriving the explicit form of the resulting asymptotic covariance matrix corresponding to iterate errors. This asymptotic covariance is always smaller than that of an algorithm driven by the base Markov chain and decreases at rate $O(1/\\alpha^2)$ - the performance benefit of using SRRW thereby *amplified* in the stochastic optimization context. Empirical results support our theoretical findings.",Oral 8B,https://openreview.net/pdf?id=BV1PHbTJzd,https://openreview.net/forum?id=BV1PHbTJzd
"['Jonathan Richens', 'Tom Everitt']",ICLR,Robust agents learn causal world models,https://iclr.cc/virtual/2024/oral/19724,2024," It has long been hypothesised that causal reasoning plays a fundamental role in robust and general intelligence. However, it is not known if agents must learn causal models in order to generalise to new domains, or if other inductive biases are sufficient. We answer this question, showing that any agent capable of satisfying a regret bound for a large set of distributional shifts must have learned an approximate causal model of the data generating process, which converges to the true causal model for optimal agents. We discuss the implications of this result for several research areas including transfer learning and causal inference.",Oral 1D,https://openreview.net/pdf?id=pOoKI3ouv1,https://openreview.net/forum?id=pOoKI3ouv1
"['Yogesh Verma', 'Markus Heinonen', 'Vikas Garg']",ICLR,ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs,https://iclr.cc/virtual/2024/oral/19715,2024," Climate and weather prediction traditionally relies on complex numerical simulations of atmospheric physics. Deep learning approaches, such as transformers, have recently challenged the simulation paradigm with complex network forecasts. However, they often act as data-driven black-box models that neglect the underlying physics and lack uncertainty quantification. We address these limitations with ClimODE, a  spatiotemporal continuous-time process that implements a key principle of advection from statistical mechanics, namely, weather changes due to a spatial movement of quantities over time. ClimODE models precise weather evolution with value-conserving dynamics, learning global weather transport as a neural flow, which also enables estimating the uncertainty in predictions. Our approach outperforms existing data-driven methods in global and regional forecasting with an order of magnitude smaller parameterization, establishing a new state of the art.",Oral 1A,https://openreview.net/pdf?id=xuY33XhEGR,https://openreview.net/forum?id=xuY33XhEGR
"['Thaddäus Wiedemer', 'Jack Brady', 'Alexander Panfilov', 'Attila Juhos', 'Matthias Bethge', 'Wieland Brendel']",ICLR,Provable Compositional Generalization for Object-Centric Learning,https://iclr.cc/virtual/2024/oral/19788,2024," Learning representations that generalize to novel compositions of known concepts is crucial for bridging the gap between human and machine perception. One prominent effort is learning object-centric representations, which are widely conjectured to enable compositional generalization. Yet, it remains unclear when this conjecture will be true, as a principled theoretical or empirical understanding of compositional generalization is lacking. In this work, we investigate when compositional generalization is guaranteed for object-centric representations through the lens of identifiability theory. We show that autoencoders that satisfy structural assumptions on the decoder and enforce encoder-decoder consistency will learn object-centric representations that provably generalize compositionally. We validate our theoretical result and highlight the practical relevance of our assumptions through experiments on synthetic image data.",Oral 8D,https://openreview.net/pdf?id=7VPTUWkiDQ,https://openreview.net/forum?id=7VPTUWkiDQ
"['Pan Lu', 'Hritik Bansal', 'Tony Xia', 'Jiacheng Liu', 'Chunyuan Li', 'Hannaneh Hajishirzi', 'Hao Cheng', 'Kai-Wei Chang', 'Michel Galley', 'Jianfeng Gao']",ICLR,MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts,https://iclr.cc/virtual/2024/oral/19768,2024," Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive problem-solving skills in many tasks and domains, but their ability in mathematical reasoning in visual contexts has not been systematically studied. To bridge this gap, we present MathVista, a benchmark designed to combine challenges from diverse mathematical and visual tasks. It consists of 6,141 examples, derived from 28 existing multimodal datasets involving mathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and PaperQA). Completing these tasks requires fine-grained, deep visual understanding and compositional reasoning, which all state-of-the-art foundation models find challenging. With MathVista, we have conducted a comprehensive, quantitative evaluation of 12 prominent foundation models. The best-performing GPT-4V model achieves an overall accuracy of 49.9%, substantially outperforming Bard, the second-best performer, by 15.1%. Our in-depth analysis reveals that the superiority of GPT-4V is mainly attributed to its enhanced visual perception and mathematical reasoning. However, GPT-4V still falls short of human performance by 10.4%, as it often struggles to understand complex figures and perform rigorous reasoning. This significant gap underscores the critical role that MathVista will play in the development of general-purpose AI agents capable of tackling mathematically intensive and visually rich real-world tasks. We further explore the new ability of self-verification, the application of self-consistency, and the interactive chatbot capabilities of GPT-4V, highlighting its promising potential for future research. The project is available at https://mathvista.github.io/.",Oral 1C,https://openreview.net/pdf?id=KUNzEQMWU7,https://openreview.net/forum?id=KUNzEQMWU7
"['Marius Memmel', 'Andrew Wagenmaker', 'Chuning Zhu', 'Dieter Fox', 'Abhishek Gupta']",ICLR,ASID: Active Exploration for System Identification in Robotic Manipulation,https://iclr.cc/virtual/2024/oral/19732,2024," Model-free control strategies such as reinforcement learning have shown the ability to learn control strategies without requiring an accurate model or simulator of the world. While this is appealing due to the lack of modeling requirements, such methods can be sample inefficient, making them impractical in many real-world domains. On the other hand, model-based control techniques leveraging accurate simulators can circumvent these challenges and use a large amount of cheap simulation data to learn controllers that can effectively transfer to the real world. The challenge with such model-based techniques is the requirement for an extremely accurate simulation, requiring both the specification of appropriate simulation assets and physical parameters. This requires considerable human effort to design for every environment being considered. In this work, we propose a learning system that can leverage a small amount of real-world data to autonomously refine a simulation model and then plan an accurate control strategy that can be deployed in the real world. Our approach critically relies on utilizing an initial (possibly inaccurate) simulator to design effective exploration policies that, when deployed in the real world, collect high-quality data. We demonstrate the efficacy of this paradigm in identifying articulation, mass, and other physical parameters in several challenging robotic manipulation tasks, and illustrate that only a small amount of real-world data can allow for effective sim-to-real transfer.",Oral 1B,https://openreview.net/pdf?id=jNR6s6OSBT,https://openreview.net/forum?id=jNR6s6OSBT
"['Satwik Bhattamishra', 'Arkil Patel', 'Phil Blunsom', 'Varun Kanade']",ICLR,Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions,https://iclr.cc/virtual/2024/oral/19741,2024," In order to understand the in-context learning phenomenon, recent works have adopted a stylized experimental framework and demonstrated that Transformers can match the performance of gradient-based learning algorithms for various classes of real-valued functions. However, the limitations of Transformers in implementing learning algorithms, and their ability to learn other forms of algorithms are not well understood. Additionally, the degree to which these capabilities are confined to attention-based models is unclear. Furthermore, it remains to be seen whether the insights derived from these stylized settings can be extrapolated to pretrained Large Language Models (LLMs). In this work, we take a step towards answering these questions by demonstrating the following: (a) On a test-bed with a variety of Boolean function classes, we find that Transformers can nearly match the optimal learning algorithm for 'simpler' tasks, while their performance deteriorates on more 'complex' tasks. Additionally, we find that certain attention-free models perform (almost) identically to Transformers on a range of tasks. (b) When provided a teaching sequence , i.e. a set of examples that uniquely identifies a function in a class, we show that Transformers learn more sample-efficiently. Interestingly, our results show that Transformers can learn to implement two distinct algorithms to solve a single task, and can adaptively select the more sample-efficient algorithm depending on the sequence of in-context examples. (c) Lastly, we show that extant LLMs, e.g. LLaMA-2, GPT-4, can compete with nearest-neighbor baselines on prediction tasks that are guaranteed to not be in their training set.",Oral 2A,https://openreview.net/pdf?id=ekeyCgeRfC,https://openreview.net/forum?id=ekeyCgeRfC
"['Zhen Liu', 'Yao Feng', 'Yuliang Xiu', 'Weiyang Liu', 'Liam Paull', 'Michael J Black', 'Bernhard Schoelkopf']",ICLR,Ghost on the Shell: An Expressive Representation of General 3D Shapes,https://iclr.cc/virtual/2024/oral/19782,2024," The creation of photorealistic virtual worlds requires the accurate modeling of 3D surface geometry for a wide range of objects. For this, meshes are appealing since they enable 1) fast physics-based rendering with realistic material and lighting, 2) physical simulation, and 3) are memory-efficient for modern graphics pipelines. Recent work on reconstructing and statistically modeling 3D shape, however, has critiqued meshes as being topologically inflexible. To capture a wide range of object shapes, any 3D representation must be able to model solid, watertight, shapes as well as thin, open, surfaces. Recent work has focused on the former, and methods for reconstructing open surfaces do not support fast reconstruction with material and lighting or unconditional generative modelling. Inspired by the observation that open surfaces can be seen as islands floating on watertight surfaces, we parametrize open surfaces by defining a manifold signed distance field on watertight templates. With this parametrization, we further develop a grid-based and differentiable representation that parametrizes both watertight and non-watertight meshes of arbitrary topology. Our new representation, called Ghost-on-the-Shell (G-Shell), enables two important applications:  differentiable rasterization-based reconstruction from multiview images and generative modelling of non-watertight meshes. We empirically demonstrate that G-Shell achieves state-of-the-art performance on non-watertight mesh reconstruction and generation tasks, while also performing effectively for watertight meshes.",Oral 2B,https://openreview.net/pdf?id=Ad87VjRqUw,https://openreview.net/forum?id=Ad87VjRqUw
"['Yang Song', 'Prafulla Dhariwal']",ICLR,Improved Techniques for Training Consistency Models,https://iclr.cc/virtual/2024/oral/19754,2024," Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training. Current consistency models achieve optimal sample quality by distilling from pre-trained diffusion models and employing learned metrics such as LPIPS. However, distillation limits the quality of consistency models to that of the pre-trained diffusion model, and LPIPS causes undesirable bias in evaluation. To tackle these challenges, we present improved techniques for consistency training, where consistency models learn directly from data without distillation. We delve into the theory behind consistency training and identify a previously overlooked flaw, which we address by eliminating Exponential Moving Average from the teacher consistency model. To replace learned metrics like LPIPS, we adopt Pseudo-Huber losses from robust statistics. Additionally, we introduce a lognormal noise schedule for the consistency training objective, and propose to double total discretization steps every set number of training iterations. Combined with better hyperparameter tuning, these modifications enable consistency models to achieve FID scores of 2.51 and 3.25 on CIFAR-10 and ImageNet $64\times 64$ respectively in a single sampling step. These scores mark a 3.5$\times$ and 4$\times$ improvement compared to prior consistency training approaches. Through two-step sampling, we further reduce FID scores to 2.24 and 2.77 on these two datasets, surpassing those obtained via distillation in both one-step and two-step settings, while narrowing the gap between consistency models and other state-of-the-art generative models.",Oral 2C,https://openreview.net/pdf?id=WNzy9bRDvG,https://openreview.net/forum?id=WNzy9bRDvG
['Gautam Reddy Nallamala'],ICLR,The mechanistic basis of data dependence and abrupt learning in an in-context classification task,https://iclr.cc/virtual/2024/oral/19749,2024," Transformer models exhibit in-context learning: the ability to accurately predict the response to a novel query based on illustrative examples in the input sequence, which contrasts with traditional in-weights learning of query-output relationships. What aspects of the training data distribution and architecture favor in-context vs in-weights learning? Recent work has shown that specific distributional properties inherent in language, such as burstiness, large dictionaries and skewed rank-frequency distributions, control the trade-off or simultaneous appearance of these two forms of learning. We first show that these results are recapitulated in a minimal attention-only network trained on a simplified dataset. In-context learning (ICL) is driven by the abrupt emergence of an induction head, which subsequently competes with in-weights learning. By identifying progress measures that precede in-context learning and targeted experiments, we construct a two-parameter model of an induction head which emulates the full data distributional dependencies displayed by the attention-based network. A phenomenological model of induction head formation traces its abrupt emergence to the sequential learning of three nested logits enabled by an intrinsic curriculum. We propose that the sharp transitions in attention-based networks arise due to a specific chain of multi-layer operations necessary to achieve ICL, which is implemented by nested nonlinearities sequentially learned during training.",Oral 2D,https://openreview.net/pdf?id=aN4Jf6Cx69,https://openreview.net/forum?id=aN4Jf6Cx69
"['Linlu Qiu', 'Liwei Jiang', 'Ximing Lu', 'Melanie Sclar', 'Valentina Pyatkin', 'Chandra Bhagavatula', 'Bailin Wang', 'Yoon Kim', 'Yejin Choi', 'Nouha Dziri', 'Xiang Ren']",ICLR,Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement,https://iclr.cc/virtual/2024/oral/19747,2024," The ability to derive underlying principles from a handful of observations and then generalize to novel situations---known as inductive reasoning---is central to human intelligence. Prior work suggests that language models (LMs) often fall short on inductive reasoning, despite achieving impressive success on research benchmarks. In this work, we conduct a systematic study of the inductive reasoning capabilities of LMs through $\textit{iterative hypothesis refinement}$, a technique that more closely mirrors the human inductive process than standard input-output prompting. Iterative hypothesis refinement employs a three-step process: proposing, selecting, and refining hypotheses in the form of textual rules. By examining the intermediate rules, we observe that LMs are phenomenal $\textit{hypothesis proposers}$ (i.e., generating candidate rules), and when coupled with a (task-specific) symbolic interpreter that is able to systematically filter the proposed set of rules, this hybrid approach achieves strong results across inductive reasoning benchmarks that require inducing causal relations, language-like instructions, and symbolic concepts. However, they also behave as puzzling $\textit{inductive reasoners}$, showing notable performance gaps between rule induction (i.e., identifying plausible rules) and rule application (i.e., applying proposed rules to instances), suggesting that LMs are proposing hypotheses without being able to actually apply the rules. Through empirical and human analyses, we further reveal several discrepancies between the inductive reasoning processes of LMs and humans, shedding light on both the potentials and limitations of using LMs in inductive reasoning tasks.",Oral 3A,https://openreview.net/pdf?id=bNt7oajl2a,https://openreview.net/forum?id=bNt7oajl2a
"['Hyosoon Jang', 'Minsu Kim', 'Sungsoo Ahn']",ICLR,Learning Energy Decompositions for Partial Inference in GFlowNets,https://iclr.cc/virtual/2024/oral/19762,2024," This paper studies generative flow networks (GFlowNets) to sample objects from the Boltzmann energy distribution via a sequence of actions. In particular, we focus on improving GFlowNet with partial inference: training flow functions with the evaluation of the intermediate states or transitions. To this end, the recently developed forward-looking GFlowNet reparameterizes the flow functions based on evaluating the energy of intermediate states. However, such an evaluation of intermediate energies may (i) be too expensive or impossible to evaluate and (ii) even provide misleading training signals under large energy fluctuations along the sequence of actions. To resolve this issue, we propose learning energy decompositions for GFlowNets (LED-GFN). Our main idea is to (i) decompose the energy of an object into learnable potential functions defined on state transitions and (ii) reparameterize the flow functions using the potential functions. In particular, to produce informative local credits, we propose to regularize the potential to change smoothly over the sequence of actions. It is also noteworthy that training GFlowNet with our learned potential can preserve the optimal policy. We empirically verify the superiority of LED-GFN in five problems including the generation of unstructured and maximum independent sets, molecular graphs, and RNA sequences.",Oral 3B,https://openreview.net/pdf?id=P15CHILQlg,https://openreview.net/forum?id=P15CHILQlg
"['Yichen Wu', 'Long-Kai Huang', 'Renzhen Wang', 'Deyu Meng', 'Ying Wei']",ICLR,Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction,https://iclr.cc/virtual/2024/oral/19759,2024," Regularization-based methods have so far been among the de facto choices for continual learning. Recent theoretical studies have revealed that these methods all boil down to relying on the Hessian matrix approximation of model weights. However, these methods suffer from suboptimal trade-offs between knowledge transfer and forgetting due to fixed and unchanging Hessian estimations during training.Another seemingly parallel strand of Meta-Continual Learning (Meta-CL) algorithms enforces alignment between gradients of previous tasks and that of the current task. In this work we revisit Meta-CL and for the first time bridge it with regularization-based methods. Concretely, Meta-CL implicitly approximates Hessian in an online manner, which enjoys the benefits of timely adaptation but meantime suffers from high variance induced by random memory buffer sampling. We are thus highly motivated to combine the best of both worlds, through the proposal of Variance Reduced Meta-CL (VR-MCL) to achieve both timely and accurate Hessian approximation.Through comprehensive experiments across three datasets and various settings, we consistently observe that VR-MCL outperforms other SOTA methods, which further validates the effectiveness of VR-MCL.",Oral 3C,https://openreview.net/pdf?id=TpD2aG1h0D,https://openreview.net/forum?id=TpD2aG1h0D
"['Kim-Celine Kahl', 'Carsten Lüth', 'Maximilian Zenk', 'Klaus Maier-Hein', 'Paul F. Jaeger']",ICLR,ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation,https://iclr.cc/virtual/2024/oral/19714,2024," Uncertainty estimation is an essential and heavily-studied component for the reliable application of semantic segmentation methods. While various studies exist claiming methodological advances on the one hand, and successful application on the other hand, the field is currently hampered by a gap between theory and practice leaving fundamental questions unanswered: Can data-related and model-related uncertainty really be separated in practice? Which components of an uncertainty method are essential for real-world performance? Which uncertainty method works well for which application? In this work, we link this research gap to a lack of systematic and comprehensive evaluation of uncertainty methods. Specifically, we identify three key pitfalls in current literature and present an evaluation framework that bridges the research gap by providing 1) a controlled environment for studying data ambiguities as well as distribution shifts, 2) systematic ablations of relevant method components, and 3) test-beds for the five predominant uncertainty applications: OoD-detection, active learning, failure detection, calibration, and ambiguity modeling. Empirical results on simulated as well as real-world data demonstrate how the proposed framework is able to answer the predominant questions in the field revealing for instance that 1) separation of uncertainty types works on simulated data but does not necessarily translate to real-world data, 2) aggregation of scores is a crucial but currently neglected component of uncertainty methods, 3) While ensembles are performing most robustly across the different downstream tasks and settings, test-time augmentation often constitutes a light-weight alternative. Code is at: https://github.com/IML-DKFZ/values",Oral 3D,https://openreview.net/pdf?id=yV6fD7LYkF,https://openreview.net/forum?id=yV6fD7LYkF
"['Yeming Wen', 'Swarat Chaudhuri']",ICLR,Batched Low-Rank Adaptation of Foundation Models,https://iclr.cc/virtual/2024/oral/19716,2024," Low-Rank Adaptation (LoRA) has recently gained attention for fine-tuning foundation models by incorporating trainable low-rank matrices, thereby reducing the number of trainable parameters. While \lora/ offers numerous advantages, its applicability for real-time serving to a diverse and global user base is constrained by its incapability to handle multiple task-specific adapters efficiently. This imposes a performance bottleneck in scenarios requiring personalized, task-specific adaptations for each incoming request.To address this, we introduce FLoRA (Fast LoRA), a framework in which each input example in a minibatch can be associated with its unique low-rank adaptation weights, allowing for efficient batching of heterogeneous requests. We empirically demonstrate that \flora/ retains the performance merits of \lora/, showcasing competitive results on the MultiPL-E code generation benchmark spanning over 8 languages and a multilingual speech recognition task across 6 languages.",Oral 4A,https://openreview.net/pdf?id=w4abltTZ2f,https://openreview.net/forum?id=w4abltTZ2f
"['Ricky T. Q. Chen', 'Yaron Lipman']",ICLR,Flow Matching on General Geometries,https://iclr.cc/virtual/2024/oral/19740,2024," We propose Riemannian Flow Matching (RFM), a simple yet powerful framework for training continuous normalizing flows on manifolds. Existing methods for generative modeling on manifolds either require expensive simulation, are inherently unable to scale to high dimensions, or use approximations for limiting quantities that result in biased training objectives. Riemannian Flow Matching bypasses these limitations and offers several advantages over previous approaches: it is simulation-free on simple geometries, does not require divergence computation, and computes its target vector field in closed-form. The key ingredient behind RFM is the construction of a relatively simple premetric for defining target vector fields, which encompasses the existing Euclidean case. To extend to general geometries, we rely on the use of spectral decompositions to efficiently compute premetrics on the fly. Our method achieves state-of-the-art performance on real-world non-Euclidean datasets, and we demonstrate tractable training on general geometries, including triangular meshes with highly non-trivial curvature and boundaries.",Oral 4B,https://openreview.net/pdf?id=g7ohDlTITL,https://openreview.net/forum?id=g7ohDlTITL
"['Seohong Park', 'Oleh Rybkin', 'Sergey Levine']",ICLR,METRA: Scalable Unsupervised RL with Metric-Aware Abstraction,https://iclr.cc/virtual/2024/oral/19745,2024," Unsupervised pre-training strategies have proven to be highly effective in natural language processing and computer vision. Likewise, unsupervised reinforcement learning (RL) holds the promise of discovering a variety of potentially useful behaviors that can accelerate the learning of a wide array of downstream tasks. Previous unsupervised RL approaches have mainly focused on pure exploration and mutual information skill learning. However, despite the previous attempts, making unsupervised RL truly scalable still remains a major open challenge: pure exploration approaches might struggle in complex environments with large state spaces, where covering every possible transition is infeasible, and mutual information skill learning approaches might completely fail to explore the environment due to the lack of incentives. To make unsupervised RL scalable to complex, high-dimensional environments, we propose a novel unsupervised RL objective, which we call Metric-Aware Abstraction (METRA). Our main idea is, instead of directly covering the entire state space, to only cover a compact latent space $\mathcal{Z}$ that is metrically connected to the state space $\mathcal{S}$ by temporal distances. By learning to move in every direction in the latent space, METRA obtains a tractable set of diverse behaviors that approximately cover the state space, being scalable to high-dimensional environments. Through our experiments in five locomotion and manipulation environments, we demonstrate that METRA can discover a variety of useful behaviors even in complex, pixel-based environments, being the first unsupervised RL method that discovers diverse locomotion behaviors in pixel-based Quadruped and Humanoid. Our code and videos are available at https://seohong.me/projects/metra/",Oral 4C,https://openreview.net/pdf?id=c5pwL0Soay,https://openreview.net/forum?id=c5pwL0Soay
"['Gabriel Cardoso', 'Yazid Janati el idrissi', 'Sylvain Le Corff', 'Eric Moulines']",ICLR,Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems.,https://iclr.cc/virtual/2024/oral/19729,2024," Ill-posed linear inverse problems arise frequently in various applications, from computational photography to medical imaging.A recent line of research exploits Bayesian inference with informative priors to handle the ill-posedness of such problems.Amongst such priors, score-based generative models (SGM) have recently been successfully applied to several different inverse problems.In this study, we exploit the particular structure of the prior defined by the SGM to define a sequence of intermediate linear inverse problems. As the noise level decreases, the posteriors of these inverse problems get closer to the target posterior of the original inverse problem. To sample from this sequence of posteriors, we propose the use of Sequential Monte Carlo (SMC) methods.The proposed algorithm, \algo, is shown to be theoretically grounded and we provide numerical simulations showing that it outperforms competing baselines when dealing with ill-posed inverse problems in a Bayesian setting.",Oral 4D,https://openreview.net/pdf?id=nHESwXvxWK,https://openreview.net/forum?id=nHESwXvxWK
"['Jisu Nam', 'Gyuseong Lee', 'Seonwoo Kim', 'Inès Hyeonsu Kim', 'Hyoungwon Cho', 'Seyeon Kim', 'Seungryong Kim']",ICLR,Diffusion Model for Dense Matching,https://iclr.cc/virtual/2024/oral/19751,2024," The objective for establishing dense correspondence between paired images con- sists of two terms: a data term and a prior term. While conventional techniques focused on defining hand-designed prior terms, which are difficult to formulate, re- cent approaches have focused on learning the data term with deep neural networks without explicitly modeling the prior, assuming that the model itself has the capacity to learn an optimal prior from a large-scale dataset. The performance improvement was obvious, however, they often fail to address inherent ambiguities of matching, such as textureless regions, repetitive patterns, large displacements, or noises. To address this, we propose DiffMatch, a novel conditional diffusion-based framework designed to explicitly model both the data and prior terms for dense matching. This is accomplished by leveraging a conditional denoising diffusion model that explic- itly takes matching cost and injects the prior within generative process. However, limited input resolution of the diffusion model is a major hindrance. We address this with a cascaded pipeline, starting with a low-resolution model, followed by a super-resolution model that successively upsamples and incorporates finer details to the matching field. Our experimental results demonstrate significant performance improvements of our method over existing approaches, and the ablation studies validate our design choices along with the effectiveness of each component. Code and pretrained weights are available at https://ku-cvlab.github.io/DiffMatch.",Oral 5A,https://openreview.net/pdf?id=Zsfiqpft6K,https://openreview.net/forum?id=Zsfiqpft6K
"['Xudong Shen', 'Chao Du', 'Tianyu Pang', 'Min Lin', 'Yongkang Wong', 'Mohan Kankanhalli']",ICLR,Finetuning Text-to-Image Diffusion Models for Fairness,https://iclr.cc/virtual/2024/oral/19734,2024," The rapid adoption of text-to-image diffusion models in society underscores an urgent need to address their biases. Without interventions, these biases could propagate a skewed worldview and restrict opportunities for minority groups. In this work, we frame fairness as a distributional alignment problem. Our solution consists of two main technical contributions: (1) a distributional alignment loss that steers specific characteristics of the generated images towards a user-defined target distribution, and (2) adjusted direct finetuning of diffusion model's sampling process (adjusted DFT), which leverages an adjusted gradient to directly optimize losses defined on the generated images. Empirically, our method markedly reduces gender, racial, and their intersectional biases for occupational prompts. Gender bias is significantly reduced even when finetuning just five soft tokens. Crucially, our method supports diverse perspectives of fairness beyond absolute equality, which is demonstrated by controlling age to a 75% young and 25% old distribution while simultaneously debiasing gender and race. Finally, our method is scalable: it can debias multiple concepts at once by simply including these prompts in the finetuning data. We share code and various fair diffusion model adaptors at https://sail-sg.github.io/finetune-fair-diffusion/.",Oral 5B,https://openreview.net/pdf?id=hnrB5YHoYu,https://openreview.net/forum?id=hnrB5YHoYu
"['Qiuhao Zeng', 'Changjian Shui', 'Long-Kai Huang', 'Peng Liu', 'Xi Chen', 'Charles Ling', 'Boyu Wang']",ICLR,Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time,https://iclr.cc/virtual/2024/oral/19746,2024," Distribution shifts over time are common in real-world machine-learning applications. This scenario is formulated as Evolving Domain Generalization (EDG), where models aim to generalize well to unseen target domains in a time-varying system by learning and leveraging the underlying evolving pattern of the distribution shifts across domains. However, existing methods encounter challenges due to the limited number of timestamps (every domain corresponds to a timestamp) in EDG datasets, leading to difficulties in capturing evolving dynamics and risking overfitting to the sparse timestamps, which hampers their generalization and adaptability to new tasks. To address this limitation, we propose a novel approach SDE-EDG that collects the Infinitely Fined-Grid Evolving Trajectory (IFGET) of the data distribution with continuous-interpolated samples to bridge temporal gaps (intervals between two successive timestamps). Furthermore, by leveraging the inherent capacity of Stochastic Differential Equations (SDEs) to capture continuous trajectories, we propose their use to align SDE-modeled trajectories with IFGET across domains, thus enabling the capture of evolving distribution trends. We evaluate our approach on several benchmark datasets and demonstrate that it can achieve superior performance compared to existing state-of-the-art methods.",Oral 5C,https://openreview.net/pdf?id=bTMMNT7IdW,https://openreview.net/forum?id=bTMMNT7IdW
"['Shashank Venkataramanan', 'Mamshad Nayeem Rizve', 'Joao Carreira', 'Yuki Asano', 'Yannis Avrithis']",ICLR,Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video,https://iclr.cc/virtual/2024/oral/19752,2024," Self-supervised learning has unlocked the potential of scaling up pretraining to billions of images, since annotation is unnecessary. But are we making the best use of data? How more economical can we be? In this work, we attempt to answer this question by making two contributions. First, we investigate first-person videos and introduce a Walking Tours'' dataset. These videos are high-resolution, hours-long, captured in a single uninterrupted take, depicting a large number of objects and actions with natural scene transitions. They are unlabeled and uncurated, thus realistic for self-supervision and comparable with human learning. Second, we introduce a novel self-supervised image pretraining method tailored for learning from continuous videos. Existing methods typically adapt image-based pretraining approaches to incorporate more frames. Instead, we advocate a tracking to learn to recognize'' approach. Our method called DoRA, leads to attention maps that D isc O ver and t RA ck objects over time in an end-to-end manner, using transformer cross-attention. We derive multiple views from the tracks and use them in a classical self-supervised distillation loss. Using our novel approach, a single Walking Tours video remarkably becomes a strong competitor to ImageNet for several image and video downstream tasks.",Oral 5D,https://openreview.net/pdf?id=Yen1lGns2o,https://openreview.net/forum?id=Yen1lGns2o
"['Yonatan Oren', 'Nicole Meister', 'Niladri Chatterji', 'Faisal Ladhak', 'Tatsunori Hashimoto']",ICLR,Proving Test Set Contamination in Black-Box Language Models,https://iclr.cc/virtual/2024/oral/19769,2024," Large language models are trained on vast amounts of internet data, prompting concerns that they have memorized public benchmarks. Detecting this type of contamination is challenging because the pretraining data used by proprietary models are often not publicly accessible.We propose a procedure for detecting test set contamination of language models with exact false positive guarantees and without access to pretraining data or model weights. Our approach leverages the fact that when there is no data contamination, all orderings of an exchangeable benchmark should be equally likely. In contrast, the tendency for language models to memorize example order means that a contaminated language model will find certain canonical orderings to be much more likely than others. Our test flags potential contamination whenever the likelihood of a canonically ordered benchmark dataset is significantly higher than the likelihood after shuffling the examples.We demonstrate that our procedure is sensitive enough to reliably detect contamination in challenging situations, including models as small as 1.4 billion parameters, on small test sets only 1000 examples, and datasets that appear only a few times in the pretraining corpus. Finally, we evaluate LLaMA-2 to apply our test in a realistic setting and find our results to be consistent with existing contamination evaluations.",Oral 6B,https://openreview.net/pdf?id=KS8mIvetg2,https://openreview.net/forum?id=KS8mIvetg2
"['Germain Kolossov', 'Andrea Montanari', 'Pulkit Tandon']",ICLR,Towards a statistical theory of data selection under weak supervision,https://iclr.cc/virtual/2024/oral/19772,2024," Given a sample of size N, it is often useful to select a subsample of smaller size n < N to be used for statistical estimation or learning. Such a data selection step is useful to reduce the requirements of data labeling and the computational complexity of learning. We assume to be given N unlabeled samples $x_{i}$, and to be given access to a 'surrogate model' that can predict labels $y_i$ better than random guessing. Our goal is to select a subset of the samples, to be denoted by {$x_{i}$}$_{i\in G}$, of size $|G|=n < N$. We then acquire labels for this set and we use them to train a model via regularized empirical risk minimization. By using a mixture of numerical experiments on real and synthetic data, and mathematical derivations under low- and high- dimensional asymptotics, we show that: (i) Data selection can be very effective, in particular beating training on the full sample in some cases; (ii) Certain popular choices in data selection methods (e.g. unbiased reweighted subsampling, or influence function-based subsampling) can be substantially suboptimal.",Oral 6C,https://openreview.net/pdf?id=HhfcNgQn6p,https://openreview.net/forum?id=HhfcNgQn6p
"['Kensen Shi', 'Joey Hong', 'Yinlin Deng', 'Pengcheng Yin', 'Manzil Zaheer', 'Charles Sutton']",ICLR,ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis,https://iclr.cc/virtual/2024/oral/19726,2024," When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks. While it is difficult to measure whether neural program synthesis methods have similar capabilities, we can measure whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks. In this paper, we characterize several different forms of compositional generalization that are desirable in program synthesis, forming a meta-benchmark which we use to create generalization tasks for two popular datasets, RobustFill and DeepCoder. We then propose ExeDec, a novel decomposition-based synthesis strategy that predicts execution subgoals to solve problems step-by-step informed by program execution at each step. When used with Transformer models trained from scratch, ExeDec has better synthesis performance and greatly improved compositional generalization ability compared to baselines. Finally, we use our benchmarks to demonstrate that LLMs struggle to compositionally generalize when asked to do programming-by-example in a few-shot setting, but an ExeDec-style prompting approach can improve the generalization ability and overall performance.",Oral 6A,https://openreview.net/pdf?id=oTRwljRgiv,https://openreview.net/forum?id=oTRwljRgiv
"['Sergei Solonets', 'Daniil Sinitsyn', 'Lukas Von Stumberg', 'Nikita Araslanov', 'Daniel Cremers']",ICLR,An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment,https://iclr.cc/virtual/2024/oral/19730,2024," Direct image alignment is a widely used technique for relative 6DoF pose estimation between two images, but its accuracy strongly depends on pose initialization.Therefore, recent end-to-end frameworks increase the convergence basin of the learned feature descriptors with special training objectives, such as the Gauss-Newton loss.However, the training data may exhibit bias toward a specific type of motion and pose initialization,thus limiting the generalization of these methods.In this work, we derive a closed-form solution to the expected optimum of the Gauss-Newton loss. The solution is agnostic to the underlying feature representation and allows us to dynamically adjust the basin of convergence according to our assumptions about the uncertainty in the current estimates. These properties allow for effective control over the convergence in the alignment process.Despite using self-supervised feature embeddings, our solution achieves compelling accuracy w.r.t. the state-of-the-art direct image alignment methods trained end-to-end with pose supervision, and demonstrates improved robustness to pose initialization.Our analytical solution exposes some inherent limitations of end-to-end learning with the Gauss-Newton loss, and establishes an intriguing connection between direct image alignment and feature-matching approaches.",Oral 7A,https://openreview.net/pdf?id=mE52zURNGc,https://openreview.net/forum?id=mE52zURNGc
"['Zengwei Yao', 'Liyong Guo', 'Xiaoyu Yang', 'Wei Kang', 'Fangjun Kuang', 'Yifan Yang', 'Zengrui Jin', 'Long Lin', 'Daniel Povey']",ICLR,Zipformer: A faster and better encoder for automatic speech recognition,https://iclr.cc/virtual/2024/oral/19784,2024," The Conformer has become the most popular encoder model for automatic speech recognition (ASR).  It adds convolution modules to a transformer to learn both local and global dependencies. In this work we describe a faster, more memory-efficient, and better-performing transformer, called Zipformer.  Modeling changes include: 1) a U-Net-like encoder structure where middle stacks operate at lower frame rates; 2) reorganized block structure with more modules, within which we re-use attention weights for efficiency; 3) a modified form of LayerNorm called BiasNorm allows us to retain some length information; 4)  new activation functions SwooshR and SwooshL work better than Swish.  We also propose a new optimizer, called ScaledAdam, which scales the update by each tensor's current scale to keep the relative change about the same, and also explictly learns the parameter scale. It achieves faster converge and better performance than Adam. Extensive experiments on LibriSpeech, Aishell-1, and WenetSpeech datasets demonstrate the effectiveness of our proposed Zipformer over other state-of-the-art ASR models. Our code is publicly available at https://github.com/k2-fsa/icefall.",Oral 6D,https://openreview.net/pdf?id=9WD9KwssyT,https://openreview.net/forum?id=9WD9KwssyT
"['Anshuman Chhabra', 'Peizhao Li', 'Prasant Mohapatra', 'Hongfu Liu']",ICLR,"""What Data Benefits My Classifier?"" Enhancing Model Performance and Interpretability through Influence-Based Data Selection",https://iclr.cc/virtual/2024/oral/19774,2024," Classification models are ubiquitously deployed in society and necessitate high utility, fairness, and robustness performance. Current research efforts mainly focus on improving model architectures and learning algorithms on fixed datasets to achieve this goal. In contrast, in this paper, we address an orthogonal yet crucial problem: given a fixed convex learning model (or a convex surrogate for a non-convex model) and a function of interest, we assess what data benefits the model by interpreting the feature space, and then aim to improve performance as measured by this function. To this end, we propose the use of influence estimation models for interpreting the classifier's performance from the perspective of the data feature space. Additionally, we propose data selection approaches based on influence that enhance model utility, fairness, and robustness. Through extensive experiments on synthetic and real-world datasets, we validate and demonstrate the effectiveness of our approaches not only for conventional classification scenarios, but also under more challenging scenarios such as distribution shifts, fairness poisoning attacks, utility evasion attacks, online learning, and active learning.",Oral 7B,https://openreview.net/pdf?id=HE9eUQlAvo,https://openreview.net/forum?id=HE9eUQlAvo
"['Jen-tse Huang', 'Wenxuan Wang', 'Eric John Li', 'Man Ho LAM', 'Shujie Ren', 'Youliang Yuan', 'Wenxiang Jiao', 'Zhaopeng Tu', 'Michael Lyu']",ICLR,On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs,https://iclr.cc/virtual/2024/oral/19775,2024," Large Language Models (LLMs) have recently showcased their remarkable capacities, not only in natural language processing tasks but also across diverse domains such as clinical medicine, legal consultation, and education. LLMs become more than mere applications, evolving into assistants capable of addressing diverse user requests. This narrows the distinction between human beings and artificial intelligence agents, raising intriguing questions regarding the potential manifestation of personalities, temperaments, and emotions within LLMs. In this paper, we propose a framework, PsychoBench, for evaluating diverse psychological aspects of LLMs. Comprising thirteen scales commonly used in clinical psychology, PsychoBench further classifies these scales into four distinct categories: personality traits, interpersonal relationships, motivational tests, and emotional abilities. Our study examines five popular models, namely text-davinci-003, ChatGPT, GPT-4, LLaMA-2-7b, and LLaMA-2-13b. Additionally, we employ a jailbreak approach to bypass the safety alignment protocols and test the intrinsic natures of LLMs. We have made PsychoBench openly accessible via https://github.com/CUHK-ARISE/PsychoBench.",Oral 7D,https://openreview.net/pdf?id=H3UayAQWoE,https://openreview.net/forum?id=H3UayAQWoE
"['Yiding Jiang', 'Christina Baek', 'J Kolter']",ICLR,"On the Joint Interaction of Models, Data, and Features",https://iclr.cc/virtual/2024/oral/19712,2024," Learning features from data is one of the defining characteristics of deep learning,but the theoretical understanding of the role features play in deep learning is still inearly development. To address this gap, we introduce a new tool, the interactiontensor, for empirically analyzing the interaction between data and model throughfeatures. With the interaction tensor, we make several key observations abouthow features are distributed in data and how models with different random seedslearn different features. Based on these observations, we propose a conceptualframework for feature learning. Under this framework, the expected accuracy for asingle hypothesis and agreement for a pair of hypotheses can both be derived inclosed form. We demonstrate that the proposed framework can explain empiricallyobserved phenomena, including the recently discovered Generalization Disagreement Equality (GDE) that allows for estimating the generalization error with onlyunlabeled data. Further, our theory also provides explicit construction of naturaldata distributions that break the GDE. Thus, we believe this work provides valuablenew insight into our understanding of feature learning.",Oral 7C,https://openreview.net/pdf?id=ze7DOLi394,https://openreview.net/forum?id=ze7DOLi394
"['Haiming Wang', 'Huajian Xin', 'Chuanyang Zheng', 'Zhengying Liu', 'Qingxing Cao', 'Yinya Huang', 'Jing Xiong', 'Han Shi', 'Enze Xie', 'Jian Yin', 'Zhenguo Li', 'Xiaodan Liang']",ICLR,LEGO-Prover: Neural Theorem Proving with Growing Libraries,https://iclr.cc/virtual/2024/oral/19793,2024," Despite the success of large language models (LLMs), the task of theorem proving still remains one of the hardest reasoning tasks that is far from being fully solved. Prior methods using language models have demonstrated promising results, but they still struggle to prove even middle school level theorems. One common limitation of these methods is that they assume a fixed theorem library during the whole theorem proving process. However, as we all know, creating new useful theorems or even new theories is not only helpful but crucial and necessary for advancing mathematics and proving harder and deeper results. In this work, we present LEGO-Prover, which employs a growing skill library containing verified lemmas as skills to augment the capability of LLMs used in theorem proving. By constructing the proof modularly, LEGO-Prover enables LLMs to utilize existing skills retrieved from the library and to create new skills during the proving process. These skills are further evolved (by prompting an LLM) to enrich the library on another scale. Modular and reusable skills are constantly added to the library to enable tackling increasingly intricate mathematical problems. Moreover, the learned library further bridges the gap between human proofs and formal proofs by making it easier to impute missing steps. LEGO-Prover advances the state-of-the-art pass rate on miniF2F-valid (48.0\% to 57.0\%) and miniF2F-test (45.5\% to 50.0\%). During the proving process, LEGO-Prover also generates over 20,000 skills (theorems/lemmas) and adds them to the growing library. Our ablation study indicates that these newly added skills are indeed helpful for proving theorems, resulting in a 4.9\% improvement in success rate",Oral 8C,https://openreview.net/pdf?id=3f5PALef5B,https://openreview.net/forum?id=3f5PALef5B
"['Hengrui Zhang', 'Jiani Zhang', 'Zhengyuan Shen', 'Balasubramaniam Srinivasan', 'Xiao Qin', 'Christos Faloutsos', 'Huzefa Rangwala', 'George Karypis']",ICLR,Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space,https://iclr.cc/virtual/2024/oral/19792,2024," Recent advances in tabular data generation have greatly enhanced synthetic data quality. However, extending diffusion models to tabular data is challenging due to the intricately varied distributions and a blend of data types of tabular data. This paper introduces TabSyn, a methodology that synthesizes tabular data by leveraging a diffusion model within a variational autoencoder (VAE) crafted latent space. The key advantages of the proposed Tabsyn include (1) Generality: the ability to handle a broad spectrum of data types by converting them into a single unified space and explicitly capturing inter-column relations; (2) Quality: optimizing the distribution of latent embeddings to enhance the subsequent training of diffusion models, which helps generate high-quality synthetic data; (3) Speed: much fewer number of reverse steps and faster synthesis speed than existing diffusion-based methods. Extensive experiments on six datasets with five metrics demonstrate that Tabsyn outperforms existing methods. Specifically, it reduces the error rates by 86% and 67% for column-wise distribution and pair-wise column correlation estimations compared with the most competitive baselines. The code has been made available at https://github.com/amazon-science/tabsyn.",Oral 8A,https://openreview.net/pdf?id=4Ay23yeuz0,https://openreview.net/forum?id=4Ay23yeuz0
"['Ziheng Qin', 'Kai Wang', 'Zangwei Zheng', 'Jianyang Gu', 'Xiangyu Peng', 'Zhaopan Xu', 'Zhou Daquan', 'Lei Shang', 'Baigui Sun', 'Xuansong Xie', 'Yang You']",ICLR,InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning,https://iclr.cc/virtual/2024/oral/19779,2024," Data pruning aims to obtain lossless performances with less overall cost. A common approach is to filter out samples that make less contribution to the training. This could lead to gradient expectation bias compared to the original data. To solve this problem, we propose InfoBatch, a novel framework aiming to achieve lossless training acceleration by unbiased dynamic data pruning. Specifically, InfoBatchrandomly prunes a portion of less informative samples based on the loss distribution and rescales the gradients of the remaining samples to approximate the original gradient. As a plug-and-play and architecture-agnostic framework, InfoBatch consistently obtains lossless training results on classification, semantic segmentation, vision pertaining, and instruction fine-tuning tasks. On CIFAR10/100, ImageNet-1K, and ADE20K, InfoBatch losslessly saves 40% overall cost. For pertaining MAE and diffusion model, InfoBatch can respectively save 24.8% and 27% cost. For LLaMA instruction fine-tuning, combining InfoBatch and the recent coreset selection method (DQ) can achieve 10 times acceleration. Our results encourage more exploration on the data efficiency aspect of large model training. Code is publicly available at NUS-HPC-AI-Lab/InfoBatch.",Oral 8B,https://openreview.net/pdf?id=C61sk5LsK6,https://openreview.net/forum?id=C61sk5LsK6
"['Nathan Frey', 'Dan Berenberg', 'Karina Zadorozhny', 'Joseph Kleinhenz', 'Julien Lafrance-Vanasse', 'Isidro Hotzel', 'Yan Wu', 'Stephen Ra', 'Richard Bonneau', 'Kyunghyun Cho', 'Andreas Loukas', 'Vladimir Gligorijevic', 'Saeed Saremi']",ICLR,Protein Discovery with Discrete Walk-Jump Sampling,https://iclr.cc/virtual/2024/oral/19713,2024," We resolve difficulties in training and sampling from a discrete generative model by learning a smoothed energy function, sampling from the smoothed data manifold with Langevin Markov chain Monte Carlo (MCMC), and projecting back to the true data manifold with one-step denoising. Our $\textit{Discrete Walk-Jump Sampling}$ formalism combines the contrastive divergence training of an energy-based model and improved sample quality of a score-based model, while simplifying training and sampling by requiring only a single noise level. We evaluate the robustness of our approach on generative modeling of antibody proteins and introduce the $\textit{distributional conformity score}$ to benchmark protein generative models. By optimizing and sampling from our models for the proposed distributional conformity score, 97-100\% of generated samples are successfully expressed and purified and 70\% of functional designs show equal or improved binding affinity compared to known functional antibodies on the first attempt in a single round of laboratory experiments. We also report the first demonstration of long-run fast-mixing MCMC chains where diverse antibody protein classes are visited in a single MCMC chain.",Oral 1A,https://openreview.net/pdf?id=zMPHKOmQNb,https://openreview.net/forum?id=zMPHKOmQNb
"['Yang He', 'Lingao Xiao', 'Joey Tianyi Zhou', 'Ivor Tsang']",ICLR,Multisize Dataset Condensation,https://iclr.cc/virtual/2024/oral/19777,2024," While dataset condensation effectively enhances training efficiency, its application in on-device scenarios brings unique challenges. 1) Due to the fluctuating computational resources of these devices, there's a demand for a flexible dataset size that diverges from a predefined size. 2) The limited computational power on devices often prevents additional condensation operations. These two challenges connect to the ""subset degradation problem"" in traditional dataset condensation: a subset from a larger condensed dataset is often unrepresentative compared to directly condensing the whole dataset to that smaller size. In this paper, we propose Multisize Dataset Condensation (MDC) by **compressing $N$ condensation processes into a single condensation process to obtain datasets with multiple sizes.** Specifically, we introduce an ""adaptive subset loss"" on top of the basic condensation loss to mitigate the ""subset degradation problem"". Our MDC method offers several benefits: 1) No additional condensation process is required; 2) reduced storage requirement by reusing condensed images. Experiments validate our findings on networks including ConvNet, ResNet and DenseNet, and datasets including SVHN,  CIFAR-10, CIFAR-100 and ImageNet. For example, we achieved 5.22%-6.40% average accuracy gains on condensing CIFAR-10 to ten images per class. Code is available at: [https://github.com/he-y/Multisize-Dataset-Condensation](https://github.com/he-y/Multisize-Dataset-Condensation).",Oral 8D,https://openreview.net/pdf?id=FVhmnvqnsI,https://openreview.net/forum?id=FVhmnvqnsI
"['Suyu Ge', 'Yunan Zhang', 'Liyuan Liu', 'Minjia Zhang', 'Jiawei Han', 'Jianfeng Gao']",ICLR,Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs,https://iclr.cc/virtual/2024/oral/19718,2024," In this study, we introduce adaptive KV cache compression, a plug-and-play method that reduces the memory footprint of generative inference for Large Language Models (LLMs). Different from the conventional KV cache that retains key and value vectors for all context tokens, we conduct targeted profiling to discern the intrinsic structure of attention modules. Based on the recognized structure, we then construct the KV cache in an adaptive manner: evicting long-range contexts on attention heads emphasizing local contexts, discarding non-special tokens on attention heads centered on special tokens, and only employing the standard KV cache for attention heads that broadly attend to all tokens. Moreover, with the lightweight attention profiling used to guide the construction of the adaptive KV cache, FastGen can be deployed without resource-intensive fine-tuning or re-training. In our experiments across various asks, FastGen demonstrates substantial reduction on GPU memory consumption with negligible generation quality loss. We will release our code and the compatible CUDA kernel for reproducibility.",Oral 1C,https://openreview.net/pdf?id=uNrFpDPMyo,https://openreview.net/forum?id=uNrFpDPMyo
"['Sherry Yang', 'Yilun Du', 'Seyed Ghasemipour', 'Jonathan Tompson', 'Leslie Kaelbling', 'Dale Schuurmans', 'Pieter Abbeel']",ICLR,Learning Interactive Real-World Simulators,https://iclr.cc/virtual/2024/oral/19722,2024," Generative models trained on internet data have revolutionized how text, image, and video content can be created. Perhaps the next milestone for generative models is to simulate realistic experience in response to actions taken by humans, robots, and other interactive agents. Applications of a real-world simulator range from controllable content creation in games and movies, to training embodied agents purely in simulation that can be directly deployed in the real world. We explore the possibility of learning a universal simulator (UniSim) of real-world interaction through generative modeling. We first make the important observation that natural datasets available for learning a real-world simulator are often rich along different axes (e.g., abundant objects in image data, densely sampled actions in robotics data, and diverse movements in navigation data). With careful orchestration of diverse datasets, each providing a different aspect of the overall experience, UniSim can emulate how humans and agents interact with the world by simulating the visual outcome of both high-level instructions such as “open the drawer” and low-level controls such as “move by x,y” from otherwise static scenes and objects. There are numerous use cases for such a real-world simulator. As an example, we use UniSim to train both high-level vision-language planners and low-level reinforcement learning policies, each of which exhibit zero-shot real-world transfer after training purely in a learned real-world simulator. We also show that other types of intelligence such as video captioning models can benefit from training with simulated experience in UniSim, opening up even wider applications.",Oral 1B,https://openreview.net/pdf?id=sFyTZEqmUY,https://openreview.net/forum?id=sFyTZEqmUY
"['Akari Asai', 'Zeqiu Wu', 'Yizhong Wang', 'Avi Sil', 'Hannaneh Hajishirzi']",ICLR,"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection",https://iclr.cc/virtual/2024/oral/19736,2024," Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the parametric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues. However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation. We introduce a new framework called Self-Reflective Retrieval-Augmented Generation (Self-RAG) that enhances an LM's quality and factuality through retrieval and self-reflection. Our framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its generations using special tokens, called {\it reflection} tokens. Generating reflection tokens makes the LM controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements. Experiments show that Self-RAG (7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks. Specifically, Self-RAG outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA, reasoning, and fact verification tasks, and it shows significant gains in improving factuality and citation accuracy for long-form generations relative to these models. Our code and trained models are available at https://selfrag.github.io/",Oral 2A,https://openreview.net/pdf?id=hSyW5go0v8,https://openreview.net/forum?id=hSyW5go0v8
"['Yicong Hong', 'Kai Zhang', 'Jiuxiang Gu', 'Sai Bi', 'Yang Zhou', 'Difan Liu', 'Feng Liu', 'Kalyan Sunkavalli', 'Trung Bui', 'Hao Tan']",ICLR,LRM: Large Reconstruction Model for Single Image to 3D,https://iclr.cc/virtual/2024/oral/19721,2024," We propose the first Large Reconstruction Model (LRM) that predicts the 3D model of an object from a single input image within just 5 seconds. In contrast to many previous methods that are trained on small-scale datasets such as ShapeNet in a category-specific fashion, LRM adopts a highly scalable transformer-based architecture with 500 million learnable parameters to directly predict a neural radiance field (NeRF) from the input image. We train our model in an end-to-end manner on massive multi-view data containing around 1 million objects, including both synthetic renderings from Objaverse and real captures from MVImgNet. This combination of a high-capacity model and large-scale training data empowers our model to be highly generalizable and produce high-quality 3D reconstructions from various testing inputs, including real-world in-the-wild captures and images created by generative models. Video demos and interactable 3D meshes can be found on our LRM project webpage: https://yiconghong.me/LRM.",Oral 2B,https://openreview.net/pdf?id=sllU8vvsFF,https://openreview.net/forum?id=sllU8vvsFF
"['Pablo Pernías', 'Dominic Rampas', 'Mats L. Richter', 'Christopher Pal', 'Marc Aubreville']",ICLR,Würstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models,https://iclr.cc/virtual/2024/oral/19738,2024," We introduce Würstchen, a novel architecture for text-to-image synthesis that combines competitive performance with unprecedented cost-effectiveness for large-scale text-to-image diffusion models.A key contribution of our work is to develop a latent diffusion technique in which we learn a detailed but extremely compact semantic image representation used to guide the diffusion process. This highly compressed representation of an image provides much more detailed guidance compared to latent representations of language and this significantly reduces the computational requirements to achieve state-of-the-art results. Our approach also improves the quality of text-conditioned image generation based on our user preference study.The training requirements of our approach consists of 24,602 A100-GPU hours - compared to Stable Diffusion 2.1's 200,000 GPU hours.  Our approach also requires less training data to achieve these results. Furthermore, our compact latent representations allows us to perform inference over twice as fast, slashing the usual costs and carbon footprint of a state-of-the-art (SOTA) diffusion model significantly, without compromising the end performance. In a broader comparison against SOTA models our approach is substantially more efficient and compares favourably in terms of image quality.We believe that this work motivates more emphasis on the prioritization of both performance and computational accessibility.",Oral 2C,https://openreview.net/pdf?id=gU58d5QeGv,https://openreview.net/forum?id=gU58d5QeGv
"['Iman Mirzadeh', 'Keivan Alizadeh-Vahid', 'Sachin Mehta', 'Carlo C del Mundo', 'Oncel Tuzel', 'Golnoosh Samei', 'Mohammad Rastegari', 'Mehrdad Farajtabar']",ICLR,ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models,https://iclr.cc/virtual/2024/oral/19725,2024," Large Language Models (LLMs) with billions of parameters have drastically transformed AI applications. However, their demanding computation during inference has raised significant challenges for deployment on resource-constrained devices. Despite recent trends favoring alternative activation functions such as GELU or SiLU, known for increased computation, this study strongly advocates for reinstating ReLU activation in LLMs. We demonstrate that using the ReLU activation function has a negligible impact on convergence and performance while significantly reducing computation and weight transfer. This reduction is particularly valuable during the memory-bound inference step, where efficiency is paramount. Exploring sparsity patterns in ReLU-based LLMs, we unveil the reutilization of activated neurons for generating new tokens and leveraging these insights, we propose practical strategies to substantially reduce LLM inference computation up to three times, using ReLU activations with minimal performance trade-offs.",Oral 3A,https://openreview.net/pdf?id=osoWxY8q2E,https://openreview.net/forum?id=osoWxY8q2E
"['Jason Zhang', 'Amy Lin', 'Moneish Kumar', 'Tzu-Hsuan Yang', 'Deva Ramanan', 'Shubham Tulsiani']",ICLR,Cameras as Rays: Pose Estimation via Ray Diffusion,https://iclr.cc/virtual/2024/oral/19778,2024," Estimating camera poses is a fundamental task for 3D reconstruction and remains challenging given sparsely sampled views (<10). In contrast to existing approaches that pursue top-down prediction of global parametrizations of camera extrinsics, we propose a distributed representation of camera pose that treats a camera as a bundle of rays. This representation allows for a tight coupling with spatial image features improving pose precision. We observe that this representation is naturally suited for set-level transformers and develop a regression-based approach that maps image patches to corresponding rays. To capture the inherent uncertainties in sparse-view pose inference, we adapt this approach to learn a denoising diffusion model which allows us to sample plausible modes while improving performance. Our proposed methods, both regression- and diffusion-based, demonstrate state-of-the-art performance on camera pose estimation on CO3D while generalizing to unseen object categories and in-the-wild captures.",Oral 3B,https://openreview.net/pdf?id=EanCFCwAjM,https://openreview.net/forum?id=EanCFCwAjM
"['Ian Gemp', 'Luke Marris', 'Georgios Piliouras']",ICLR,Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization,https://iclr.cc/virtual/2024/oral/19744,2024," We propose the first loss function for approximate Nash equilibria of normal-form games that is amenable to unbiased Monte Carlo estimation. This construction allows us to deploy standard non-convex stochastic optimization techniques for approximating Nash equilibria, resulting in novel algorithms  with provable guarantees. We complement our theoretical analysis with experiments demonstrating that stochastic gradient descent can outperform previous state-of-the-art approaches.",Oral 3C,https://openreview.net/pdf?id=cc8h3I3V4E,https://openreview.net/forum?id=cc8h3I3V4E
"['Miltiadis (Miltos) Kofinas', 'Boris Knyazev', 'Yan Zhang', 'Yunlu Chen', 'Gertjan J Burghouts', 'Efstratios Gavves', 'Cees G Snoek', 'David Zhang']",ICLR,Graph Neural Networks for Learning Equivariant Representations of Neural Networks,https://iclr.cc/virtual/2024/oral/19727,2024," Neural networks that process the parameters of other neural networks find applications in domains as diverse as classifying implicit neural representations, generating neural network weights, and predicting generalization errors. However, existing approaches either overlook the inherent permutation symmetry in the neural network or rely on intricate weight-sharing patterns to achieve equivariance, while ignoring the impact of the network architecture itself. In this work, we propose to represent neural networks as computational graphs of parameters, which allows us to harness powerful graph neural networks and transformers that preserve permutation symmetry. Consequently, our approach enables a single model to encode neural computational graphs with diverse architectures. We showcase the effectiveness of our method on a wide range of tasks, including classification and editing of implicit neural representations, predicting generalization performance, and learning to optimize, while consistently outperforming state-of-the-art methods. The source code is open-sourced at https://github.com/mkofinas/neural-graphs.",Oral 4B,https://openreview.net/pdf?id=oO6FsMyDBt,https://openreview.net/forum?id=oO6FsMyDBt
"['Haoqi Yuan', 'Zhancun Mu', 'Feiyang Xie', 'Zongqing Lu']",ICLR,Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning,https://iclr.cc/virtual/2024/oral/19728,2024," Pre-training on task-agnostic large datasets is a promising approach for enhancing the sample efficiency of reinforcement learning (RL) in solving complex tasks. We present PTGM, a novel method that pre-trains goal-based models to augment RL by providing temporal abstractions and behavior regularization. PTGM involves pre-training a low-level, goal-conditioned policy and training a high-level policy to generate goals for subsequent RL tasks. To address the challenges posed by the high-dimensional goal space, while simultaneously maintaining the agent's capability to accomplish various skills, we propose clustering goals in the dataset to form a discrete high-level action space. Additionally, we introduce a pre-trained goal prior model to regularize the behavior of the high-level policy in RL, enhancing sample efficiency and learning stability. Experimental results in a robotic simulation environment and the challenging open-world environment of Minecraft demonstrate PTGM’s superiority in sample efficiency and task performance compared to baselines. Moreover, PTGM exemplifies enhanced interpretability and generalization of the acquired low-level skills.",Oral 4C,https://openreview.net/pdf?id=o2IEmeLL9r,https://openreview.net/forum?id=o2IEmeLL9r
"['Tianrong Chen', 'Jiatao Gu', 'Laurent Dinh', 'Evangelos Theodorou', 'Joshua Susskind', 'Shuangfei Zhai']",ICLR,Generative Modeling with Phase Stochastic Bridge,https://iclr.cc/virtual/2024/oral/19720,2024," Diffusion models (DMs) represent state-of-the-art generative models for continuous inputs. DMs work by constructing a Stochastic Differential Equation (SDE) in the input space (ie, position space), and using a neural network to reverse it. In this work, we introduce a novel generative modeling framework grounded in \textbf{phase space dynamics}, where a phase space is defined as {an augmented space encompassing both position and velocity.} Leveraging insights from Stochastic Optimal Control, we construct a path measure in the phase space that enables efficient sampling. {In contrast to DMs, our framework demonstrates the capability to generate realistic data points at an early stage of dynamics propagation.} This early prediction sets the stage for efficient data generation by leveraging additional velocity information along the trajectory. On standard image generation benchmarks, our model yields favorable performance over baselines in the regime of small Number of Function Evaluations (NFEs). Furthermore, our approach rivals the performance of diffusion models equipped with efficient sampling techniques, underscoring its potential as a new tool generative modeling.",Oral 5A,https://openreview.net/pdf?id=tUtGjQEDd4,https://openreview.net/forum?id=tUtGjQEDd4
"['André F. Cruz', 'Moritz Hardt']",ICLR,Unprocessing Seven Years of Algorithmic Fairness,https://iclr.cc/virtual/2024/oral/19731,2024," Seven years ago, researchers proposed a postprocessing method to equalize the error rates of a model across different demographic groups. The work launched hundreds of papers purporting to improve over the postprocessing baseline. We empirically evaluate these claims through thousands of model evaluations on several tabular datasets. We find that the fairness-accuracy Pareto frontier achieved by postprocessing contains all other methods we were feasibly able to evaluate. In doing so, we address two common methodological errors that have confounded previous observations. One relates to the comparison of methods with different unconstrained base models. The other concerns methods achieving different levels of constraint relaxation. At the heart of our study is a simple idea we call unprocessing that roughly corresponds to the inverse of postprocessing. Unprocessing allows for a direct comparison of methods using different underlying models and levels of relaxation.",Oral 5B,https://openreview.net/pdf?id=jr03SfWsBS,https://openreview.net/forum?id=jr03SfWsBS
"['Sebastian Pineda Arango', 'Fabio Ferreira', 'Arlind Kadra', 'Frank Hutter', 'Josif Grabocka']",ICLR,Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How,https://iclr.cc/virtual/2024/oral/19719,2024," With the ever-increasing number of pretrained models, machine learning practitioners are continuously faced with which pretrained model to use, and how to finetune it for a new dataset. In this paper, we propose a methodology that jointly searches for the optimal pretrained model and the hyperparameters for finetuning it. Our method transfers knowledge about the performance of many pretrained models with multiple hyperparameter configurations on a series of datasets. To this aim, we evaluated over 20k hyperparameter configurations for finetuning 24 pretrained image classification models on 87 datasets to generate a large-scale meta-dataset. We meta-learn a gray-box performance predictor on the learning curves of this meta-dataset and use it for fast hyperparameter optimization on new datasets. We empirically demonstrate that our resulting approach can quickly select an accurate pretrained model for a new dataset together with its optimal hyperparameters.",Oral 5C,https://openreview.net/pdf?id=tqh1zdXIra,https://openreview.net/forum?id=tqh1zdXIra
"['Ahmad Faiz', 'Sotaro Kaneda', 'Ruhan Wang', 'Rita Osi', 'Prateek Sharma', 'Fan Chen', 'Lei Jiang']",ICLR,LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models,https://iclr.cc/virtual/2024/oral/19750,2024," The carbon footprint associated with large language models (LLMs) is a significant concern, encompassing emissions from their training, inference, experimentation, and storage processes, including operational and embodied carbon emissions. An essential aspect is accurately estimating the carbon impact of emerging LLMs even before their training, which heavily relies on GPU usage. Existing studies have reported the carbon footprint of LLM training, but only one tool, mlco2, can predict the carbon footprint of new neural networks prior to physical training. However, mlco2 has several serious limitations. It cannot extend its estimation to dense or mixture-of-experts (MoE) LLMs, disregards critical architectural parameters, focuses solely on GPUs, and cannot model embodied carbon footprints. Addressing these gaps, we introduce \textit{\carb}, an end-to-end carbon footprint projection model designed for both dense and MoE LLMs. Compared to mlco2, \carb~significantly enhances the accuracy of carbon footprint estimations for various LLMs. The source code is released at \url{https://github.com/SotaroKaneda/MLCarbon}.",Oral 6B,https://openreview.net/pdf?id=aIok3ZD9to,https://openreview.net/forum?id=aIok3ZD9to
"['Ido Amos', 'Jonathan Berant', 'Ankit Gupta']",ICLR,Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors,https://iclr.cc/virtual/2024/oral/19761,2024," Modeling long-range dependencies across sequences is a longstanding goal in machine learning and has led to architectures, such as state space models, that dramatically outperform Transformers on long sequences. However, these impressive empirical gains have been by and large demonstrated on benchmarks (e.g. Long Range Arena), where models are randomly initialized and trained to predict a target label from an input sequence. In this work, we show that random initialization leads to gross overestimation of the differences between architectures and that pretraining with standard denoising objectives, using only the downstream task data , leads to dramatic gains across multiple architectures and to very small gaps between Transformers and state space models (SSMs). In stark contrast to prior works, we find vanilla Transformers to match the performance of S4 on Long Range Arena when properly pretrained, and we improve the best reported results of SSMs on the PathX-256 task by 20 absolute points. Subsequently, we analyze the utility of previously-proposed structured parameterizations for SSMs and show they become mostly redundant in the presence of data-driven initialization obtained through pretraining. Our work shows that, when evaluating different architectures on supervised tasks, incorporation of data-driven priors via pretraining is essential for reliable performance estimation, and can be done efficiently.",Oral 6C,https://openreview.net/pdf?id=PdaPky8MUn,https://openreview.net/forum?id=PdaPky8MUn
"['Pascal Chang', 'Jingwei Tang', 'Markus Gross', 'Vinicius Da Costa De Azevedo']",ICLR,How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models,https://iclr.cc/virtual/2024/oral/19723,2024," Video editing and generation methods often rely on pre-trained image-based diffusion models. During the diffusion process, however, the reliance on rudimentary noise sampling techniques that do not preserve correlations present in subsequent frames of a video is detrimental to the quality of the results. This either produces high-frequency flickering, or texture-sticking artifacts that are not amenable to post-processing. With this in mind, we propose a novel method for preserving temporal correlations in a sequence of noise samples. This approach is materialized by a novel noise representation, dubbed $\int$-noise (integral noise), that reinterprets individual noise samples as a continuously integrated noise field: pixel values do not represent discrete values, but are rather the integral of an underlying infinite-resolution noise over the pixel area. Additionally, we propose a carefully tailored transport method that uses $\int$-noise to accurately advect noise samples over a sequence of frames, maximizing the correlation between different frames while also preserving the noise properties. Our results demonstrate that the proposed $\int$-noise can be used for a variety of tasks, such as video restoration, surrogate rendering, and conditional video generation.",Oral 6A,https://openreview.net/pdf?id=pzElnMrgSD,https://openreview.net/forum?id=pzElnMrgSD
"['Yubo Zhuang', 'Xiaohui Chen', 'Yun Yang', 'Richard Zhang']",ICLR,Statistically Optimal $K$-means Clustering via Nonnegative Low-rank Semidefinite Programming,https://iclr.cc/virtual/2024/oral/19717,2024," $K$-means clustering is a widely used machine learning method for identifying patterns in large datasets. Recently, semidefinite programming (SDP) relaxations have been proposed for solving the $K$-means optimization problem, which enjoy strong statistical optimality guarantees. However, the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. In contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm widely used by machine learning practitioners, but it lacks a solid statistical underpinning and theoretical guarantees. In this paper, we consider an NMF-like algorithm that solves a nonnegative low-rank restriction of the SDP-relaxed $K$-means formulation using a nonconvex Burer--Monteiro factorization approach. The resulting algorithm is as simple and scalable as state-of-the-art NMF algorithms while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments, we observe that our algorithm achieves significantly smaller mis-clustering errors compared to the existing state-of-the-art while maintaining scalability.",Oral 7A,https://openreview.net/pdf?id=v7ZPwoHU1j,https://openreview.net/forum?id=v7ZPwoHU1j
"['Shangbin Feng', 'Weijia Shi', 'Yuyang Bai', 'Vidhisha Balachandran', 'Tianxing He', 'Yulia Tsvetkov']",ICLR,Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models,https://iclr.cc/virtual/2024/oral/19753,2024," By design, large language models (LLMs) are static general-purpose models, expensive to retrain or update frequently. As they are increasingly adopted for knowledge-intensive tasks, it becomes evident that these design choices lead to failures to generate factual, relevant, and up-to-date knowledge. To this end, we propose Knowledge Card, a modular framework to plug in new factual and relevant knowledge into general-purpose LLMs. We first introduce knowledge cards---specialized language models trained on corpora from specific domains and sources. Knowledge cards serve as parametric repositories that are selected at inference time to generate background knowledge for the base LLM. We then propose three content selectors to dynamically select and retain information in documents generated by knowledge cards, specifically controlling for relevance, brevity, and factuality of outputs. Finally, we propose two complementary integration approaches to augment the base LLM with the (relevant, factual) knowledge curated from the specialized LMs. Through extensive experiments, we demonstrate that Knowledge Card achieves state-of-the-art performance on six benchmark datasets. Ultimately, Knowledge Card framework enables dynamic synthesis and updates of knowledge from diverse domains. Its modularity will ensure that relevant knowledge can be continuously updated through the collective efforts of the research community.",Oral 7B,https://openreview.net/pdf?id=WbWtOYIzIK,https://openreview.net/forum?id=WbWtOYIzIK
"['Yuxin Wen', 'Yuchen Liu', 'Chen Chen', 'Lingjuan Lyu']",ICLR,"Detecting, Explaining, and Mitigating Memorization in Diffusion Models",https://iclr.cc/virtual/2024/oral/19787,2024," Recent breakthroughs in diffusion models have exhibited exceptional image-generation capabilities. However, studies show that some outputs are merely replications of training data. Such replications present potential legal challenges for model owners, especially when the generated content contains proprietary information. In this work, we introduce a straightforward yet effective method for detecting memorized prompts by inspecting the magnitude of text-conditional predictions. Our proposed method seamlessly integrates without disrupting sampling algorithms, and delivers high accuracy even at the first generation step, with a single generation per prompt. Building on our detection strategy, we unveil an explainable approach that shows the contribution of individual words or tokens to memorization. This offers an interactive medium for users to adjust their prompts. Moreover, we propose two strategies i.e., to mitigate memorization by leveraging the magnitude of text-conditional predictions, either through minimization during inference or filtering during training. These proposed strategies effectively counteract memorization while maintaining high-generation quality. Code is available at https://github.com/YuxinWenRick/diffusion_memorization.",Oral 8A,https://openreview.net/pdf?id=84n3UwkH7b,https://openreview.net/forum?id=84n3UwkH7b
"['Atsushi Shimizu', 'Xiaoou Cheng', 'Christopher Musco', 'Jonathan Weare']",ICLR,Improved Active Learning via Dependent Leverage Score Sampling,https://iclr.cc/virtual/2024/oral/19770,2024," We show how to obtain improved active learning methods in the agnostic (adversarial noise) setting by combining marginal leverage score sampling with non-independent sampling strategies that promote spatial coverage. In particular, we propose an easily implemented method based on the \emph{pivotal sampling algorithm}, which we test on problems motivated by learning-based methods for parametric PDEs and uncertainty quantification. In comparison to independent sampling, our method reduces the number of samples needed to reach a given target accuracy by up to $50\%$.We support our findings with two theoretical results. First, we show that any non-independent leverage score sampling method that obeys a weak \emph{one-sided $\ell_{\infty}$ independence condition} (which includes pivotal sampling) can actively learn $d$ dimensional linear functions with $O(d\log d)$ samples, matching independent sampling. This result extends recent work on matrix Chernoff bounds under $\ell_{\infty}$ independence, and may be of interest for analyzing other sampling strategies beyond pivotal sampling. Second, we show that, for the important case of polynomial regression, our pivotal method obtains an improved bound of $O(d)$ samples.",Oral 8B,https://openreview.net/pdf?id=IYxDy2jDFL,https://openreview.net/forum?id=IYxDy2jDFL
"['Yapei Chang', 'Kyle Lo', 'Tanya Goyal', 'Mohit Iyyer']",ICLR,BooookScore: A systematic exploration of book-length summarization in the era of LLMs,https://iclr.cc/virtual/2024/oral/19789,2024," Summarizing book-length documents ($>$100K tokens)  that exceed the context window size of large language models (LLMs) requires first breaking the input document into smaller chunks and then prompting an LLM to merge, update, and compress chunk-level summaries. Despite the complexity and importance of this task, it has yet to be meaningfully studied due to the challenges of evaluation: existing book-length summarization datasets (e.g., BookSum) are in the pretraining data of most public LLMs, and existing evaluation methods struggle to capture errors made by modern LLM summarizers. In this paper, we present the first study of the coherence of LLM-based book-length summarizers implemented via two prompting workflows: (1) hierarchically merging chunk-level summaries, and (2) incrementally updating a running summary. We obtain 1193 fine-grained human annotations on GPT-4 generated summaries of 100 recently-published books and identify eight common types of coherence errors made by LLMs. Because human evaluation is expensive and time-consuming, we develop an automatic metric, BooookScore, that measures the proportion of sentences in a summary that do not contain any of the identified error types. BooookScore has high agreement with human annotations and allows us to systematically evaluate the impact of many other critical parameters (e.g., chunk size, base LLM) while saving \$15K USD and 500 hours in human evaluation costs. We find that closed-source LLMs such as GPT-4 and Claude 2 produce summaries with higher BooookScore than those generated by open-source models. While LLaMA 2 falls behind other models, Mixtral achieves performance on par with GPT-3.5-Turbo. Incremental updating yields lower BooookScore but higher level of detail than hierarchical merging, a trade-off sometimes preferred by annotators. We release code and annotations to spur more principled research on book-length summarization.",Oral 8D,https://openreview.net/pdf?id=7Ttk3RzDeu,https://openreview.net/forum?id=7Ttk3RzDeu
"['Bo ZHAO', 'Konda Reddy Mopuri', 'Hakan Bilen']",ICLR,Dataset Condensation with Gradient Matching,https://iclr.cc/virtual/2021/oral/3391,2021," As the state-of-the-art machine learning methods in many fields rely on larger datasets, storing datasets and training models on them become significantly more expensive. This paper proposes a training set synthesis technique for data-efficient learning, called Dataset Condensation, that learns to condense large dataset into a small set of informative synthetic samples for training deep neural networks from scratch. We formulate this goal as a gradient matching problem between the gradients of deep neural network weights that are trained on the original and our synthetic data. We rigorously evaluate its performance in several computer vision benchmarks and demonstrate that it significantly outperforms the state-of-the-art methods. Finally we explore the use of our method in continual learning and neural architecture search and report promising gains when limited memory and computations are available.",Oral Session 1,https://openreview.net/pdf?id=mSAKhLYLSsl,https://openreview.net/forum?id=mSAKhLYLSsl
"['Jeff Donahue', 'Sander Dieleman', 'Mikolaj Binkowski', 'Erich Elsen', 'Karen Simonyan']",ICLR,End-to-end Adversarial Text-to-Speech,https://iclr.cc/virtual/2021/oral/3498,2021," Modern text-to-speech synthesis pipelines typically involve multiple processing stages, each of which is designed or learnt independently from the rest. In this work, we take on the challenging task of learning to synthesise speech from normalised text or phonemes in an end-to-end manner, resulting in models which operate directly on character or phoneme input sequences and produce raw speech audio outputs. Our proposed generator is feed-forward and thus efficient for both training and inference, using a differentiable alignment scheme based on token length prediction. It learns to produce high fidelity audio through a combination of adversarial feedback and prediction losses constraining the generated audio to roughly match the ground truth in terms of its total duration and mel-spectrogram. To allow the model to capture temporal variation in the generated audio, we employ soft dynamic time warping in the spectrogram-based prediction loss. The resulting model achieves a mean opinion score exceeding 4 on a 5 point scale, which is comparable to the state-of-the-art models relying on multi-stage training and additional supervision.",Oral Session 4,https://openreview.net/pdf?id=rsf1z-JSj87,https://openreview.net/forum?id=rsf1z-JSj87
"['Glen Berseth', 'Daniel Geng', 'Coline M Devin', 'Nicholas Rhinehart', 'Chelsea Finn', 'Dinesh Jayaraman', 'Sergey Levine']",ICLR,SMiRL: Surprise Minimizing Reinforcement Learning in Unstable Environments,https://iclr.cc/virtual/2021/oral/3453,2021," Every living organism struggles against disruptive environmental forces to carve out and maintain an orderly niche. We propose that such a struggle to achieve and preserve order might offer a principle for the emergence of useful behaviors in artificial agents. We formalize this idea into an unsupervised reinforcement learning method called surprise minimizing reinforcement learning (SMiRL). SMiRL alternates between learning a density model to evaluate the surprise of a stimulus, and improving the policy to seek more predictable stimuli. The policy seeks out stable and repeatable situations that counteract the environment's prevailing sources of entropy. This might include avoiding other hostile agents, or finding a stable, balanced pose for a bipedal robot in the face of disturbance forces. We demonstrate that our surprise minimizing agents can successfully play Tetris, Doom, control a humanoid to avoid falls, and navigate to escape enemies in a maze without any task-specific reward supervision. We further show that SMiRL can be used together with standard task rewards to accelerate reward-driven learning.",Oral Session 3,https://openreview.net/pdf?id=cPZOyoDloxl,https://openreview.net/forum?id=cPZOyoDloxl
"['Durmus Alp Emre Acar', 'Yue Zhao', 'Ramon Matas', 'Matthew Mattina', 'Paul Whatmough', 'Venkatesh Saligrama']",ICLR,Federated Learning Based on Dynamic Regularization,https://iclr.cc/virtual/2021/oral/3503,2021," We propose a novel federated learning method for distributively training neural network models, where the server orchestrates cooperation between a subset of randomly chosen devices in each round. We view Federated Learning problem primarily from a communication perspective and allow more device level computations to save transmission costs. We point out a fundamental dilemma, in that the minima of the local-device level empirical loss are inconsistent with those of the global empirical loss. Different from recent prior works, that either attempt inexact minimization or utilize devices for parallelizing gradient computation, we propose a dynamic regularizer for each device at each round, so that in the limit the global and device solutions are aligned. We demonstrate both through empirical results on real and synthetic data as well as analytical results that our scheme leads to efficient training, in both convex and non-convex settings, while being fully agnostic to device heterogeneity and robust to large number of devices, partial participation and unbalanced data.",Oral Session 2,https://openreview.net/pdf?id=B7v4QMR6Z9w,https://openreview.net/forum?id=B7v4QMR6Z9w
"['Ankit Vani', 'Max Schwarzer', 'Yuchen Lu', 'Eeshan Dhekane', 'Aaron Courville']",ICLR,Iterated learning for emergent systematicity in VQA,https://iclr.cc/virtual/2021/oral/3425,2021," Although neural module networks have an architectural bias towards compositionality, they require gold standard layouts to generalize systematically in practice. When instead learning layouts and modules jointly, compositionality does not arise automatically and an explicit pressure is necessary for the emergence of layouts exhibiting the right structure. We propose to address this problem using iterated learning, a cognitive science theory of the emergence of compositional languages in nature that has primarily been applied to simple referential games in machine learning. Considering the layouts of module networks as samples from an emergent language, we use iterated learning to encourage the development of structure within this language. We show that the resulting layouts support systematic generalization in neural agents solving the more complex task of visual question-answering. Our regularized iterated learning method can outperform baselines without iterated learning on SHAPES-SyGeT (SHAPES Systematic Generalization Test), a new split of the SHAPES dataset we introduce to evaluate systematic generalization, and on CLOSURE, an extension of CLEVR also designed to test systematic generalization. We demonstrate superior performance in recovering ground-truth compositional program structure with limited supervision on both SHAPES-SyGeT and CLEVR.",Oral Session 5,https://openreview.net/pdf?id=Pd_oMxH8IlF,https://openreview.net/forum?id=Pd_oMxH8IlF
"['Brenden Petersen', 'Mikel Landajuela Larma', 'Terrell N Mundhenk', 'Claudio Santiago', 'Soo Kim', 'Joanne Kim']",ICLR,Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients,https://iclr.cc/virtual/2021/oral/3539,2021," Discovering the underlying mathematical expressions describing a dataset is a core challenge for artificial intelligence. This is the problem of $\textit{symbolic regression}$. Despite recent advances in training neural networks to solve complex tasks, deep learning approaches to symbolic regression are underexplored. We propose a framework that leverages deep learning for symbolic regression via a simple idea: use a large model to search the space of small models. Specifically, we use a recurrent neural network to emit a distribution over tractable mathematical expressions and employ a novel risk-seeking policy gradient to train the network to generate better-fitting expressions. Our algorithm outperforms several baseline methods (including Eureqa, the gold standard for symbolic regression) in its ability to exactly recover symbolic expressions on a series of benchmark problems, both with and without added noise. More broadly, our contributions include a framework that can be applied to optimize hierarchical, variable-length objects under a black-box performance metric, with the ability to incorporate constraints in situ, and a risk-seeking policy gradient formulation that optimizes for best-case performance instead of expected performance.",Oral Session 6,https://openreview.net/pdf?id=m5Qsh0kBQG,https://openreview.net/forum?id=m5Qsh0kBQG
"['Alexey Dosovitskiy', 'Lucas Beyer', 'Alexander Kolesnikov', 'Dirk Weissenborn', 'Xiaohua Zhai', 'Thomas Unterthiner', 'Mostafa Dehghani', 'Matthias Minderer', 'Georg Heigold', 'Sylvain Gelly', 'Jakob Uszkoreit', 'Neil Houlsby']",ICLR,An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,https://iclr.cc/virtual/2021/oral/3458,2021," While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.",Oral Session 7,https://openreview.net/pdf?id=YicbFdNTTy,https://openreview.net/forum?id=YicbFdNTTy
"['Jonathan Gray', 'Adam Lerer', 'Anton Bakhtin', 'Noam Brown']",ICLR,Human-Level Performance in No-Press Diplomacy via Equilibrium Search,https://iclr.cc/virtual/2021/oral/3485,2021," Prior AI breakthroughs in complex games have focused on either the purely adversarial or purely cooperative settings. In contrast, Diplomacy is a game of shifting alliances that involves both cooperation and competition. For this reason, Diplomacy has proven to be a formidable research challenge. In this paper we describe an agent for the no-press variant of Diplomacy that combines supervised learning on human data with one-step lookahead search via regret minimization. Regret minimization techniques have been behind previous AI successes in adversarial games, most notably poker, but have not previously been shown to be successful in large-scale games involving cooperation. We show that our agent greatly exceeds the performance of past no-press Diplomacy bots, is unexploitable by expert humans, and ranks in the top 2% of human players when playing anonymous games on a popular Diplomacy website.",Oral Session 8,https://openreview.net/pdf?id=0-uUGPbIjD,https://openreview.net/forum?id=0-uUGPbIjD
"['Alexander Richard', 'Dejan Markovic', 'Israel Gebru', 'Steven Krenn', 'Gladstone A Butler', 'Fernando Torre', 'Yaser Sheikh']",ICLR,Neural Synthesis of Binaural Speech From Mono Audio,https://iclr.cc/virtual/2021/oral/3468,2021," We present a neural rendering approach for binaural sound synthesis that can produce realistic and spatially accurate binaural sound in realtime. The network takes, as input, a single-channel audio source and synthesizes, as output, two-channel binaural sound, conditioned on the relative position and orientation of the listener with respect to the source. We investigate deficiencies of the l2-loss on raw waveforms in a theoretical analysis and introduce an improved loss that overcomes these limitations. In an empirical evaluation, we establish that our approach is the first to generate spatially accurate waveform outputs (as measured by real recordings) and outperforms existing approaches by a considerable margin, both quantitatively and in a perceptual study. Dataset and code are available online.",Outstanding Paper Session 1,https://openreview.net/pdf?id=uAX8q61EVRu,https://openreview.net/forum?id=uAX8q61EVRu
"['Chenlin Meng', 'Jiaming Song', 'Yang Song', 'Shengjia Zhao', 'Stefano Ermon']",ICLR,Improved Autoregressive Modeling with Distribution Smoothing,https://iclr.cc/virtual/2021/oral/3431,2021," While autoregressive models excel at image compression, their sample quality is often lacking. Although not realistic, generated images often have high likelihood according to the model, resembling the case of adversarial examples. Inspired by a successful adversarial defense method, we incorporate randomized smoothing into autoregressive generative modeling. We first model a smoothed version of the data distribution, and then reverse the smoothing process to recover the original data distribution. This procedure drastically improves the sample quality of existing autoregressive models on several synthetic and real-world image datasets while obtaining competitive likelihoods on synthetic datasets.",Oral Session 9,https://openreview.net/pdf?id=rJA5Pz7lHKb,https://openreview.net/forum?id=rJA5Pz7lHKb
"['Ruochen Wang', 'Minhao Cheng', 'Xiangning Chen', 'Xiaocheng Tang', 'Cho-Jui Hsieh']",ICLR,Rethinking Architecture Selection in Differentiable NAS,https://iclr.cc/virtual/2021/oral/3495,2021," Differentiable Neural Architecture Search is one of the most popular Neural Architecture Search (NAS) methods for its search efficiency and simplicity, accomplished by jointly optimizing the model weight and architecture parameters in a weight-sharing supernet via gradient-based algorithms. At the end of the search phase, the operations with the largest architecture parameters will be selected to form the final architecture, with the implicit assumption that the values of architecture parameters reflect the operation strength. While much has been discussed about the supernet's optimization, the architecture selection process has received little attention. We provide empirical and theoretical analysis to show that the magnitude of architecture parameters does not necessarily indicate how much the operation contributes to the supernet's performance. We propose an alternative perturbation-based architecture selection that directly measures each operation's influence on the supernet. We re-evaluate several differentiable NAS methods with the proposed architecture selection and find that it is able to extract significantly improved architectures from the underlying supernets consistently. Furthermore, we find that several failure modes of DARTS can be greatly alleviated with the proposed selection method, indicating that much of the poor generalization observed in DARTS can be attributed to the failure of magnitude-based architecture selection rather than entirely the optimization of its supernet.",Outstanding Paper Session 2,https://openreview.net/pdf?id=PKubaeJkw3,https://openreview.net/forum?id=PKubaeJkw3
"['Marcin Andrychowicz', 'Anton Raichuk', 'Piotr Stanczyk', 'Manu Orsini', 'Sertan Girgin', 'Raphaël Marinier', 'Léonard Hussenot-Desenonges', 'Matthieu Geist', 'Olivier Pietquin', 'Marcin Michalski', 'Sylvain Gelly', 'Olivier Bachem']",ICLR,What Matters for On-Policy Deep Actor-Critic Methods? A Large-Scale Study,https://iclr.cc/virtual/2021/oral/3534,2021," In recent years, reinforcement learning (RL) has been successfully applied to many different continuous control tasks. While RL algorithms are often conceptually simple, their state-of-the-art implementations take numerous low- and high-level design decisions that strongly affect the performance of the resulting agents. Those choices are usually not extensively discussed in the literature, leading to discrepancy between published descriptions of algorithms and their implementations. This makes it hard to attribute progress in RL and slows down overall progress [Engstrom'20]. As a step towards filling that gap, we implement >50 such ``""choices"" in a unified on-policy deep actor-critic framework, allowing us to investigate their impact in a large-scale empirical study. We train over 250'000 agents in five continuous control environments of different complexity and provide insights and practical recommendations for the training of on-policy deep actor-critic RL agents.",Oral Session 10,https://openreview.net/pdf?id=nIAxjsniDzg,https://openreview.net/forum?id=nIAxjsniDzg
"['Lizhen Nie', 'Mao Ye', 'Qiang Liu', 'Dan Nicolae']",ICLR,VCNet and Functional Targeted Regularization For Learning Causal Effects of Continuous Treatments,https://iclr.cc/virtual/2021/oral/3476,2021," Motivated by the rising abundance of observational data with continuous treatments, we investigate the problem of estimating the average dose-response curve (ADRF). Available parametric methods are limited in their model space, and previous attempts in leveraging neural network to enhance model expressiveness relied on partitioning continuous treatment into blocks and using separate heads for each block; this however produces in practice discontinuous ADRFs. Therefore, the question of how to adapt the structure and training of neural network to estimate ADRFs remains open. This paper makes two important contributions. First, we propose a novel varying coefficient neural network (VCNet) that improves model expressiveness while preserving continuity of the estimated ADRF. Second, to improve finite sample performance, we generalize targeted regularization to obtain a doubly robust estimator of the whole ADRF curve.",Oral Session 11,https://openreview.net/pdf?id=RmB-88r9dL,https://openreview.net/forum?id=RmB-88r9dL
"['Colin Wei', 'Kendrick Shen', 'Yining Chen', 'Tengyu Ma']",ICLR,Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data,https://iclr.cc/virtual/2021/oral/3532,2021," Self-training algorithms, which train a model to fit pseudolabels predicted by another previously-learned model, have been very successful for learning with unlabeled data using neural networks. However, the current theoretical understanding of self-training only applies to linear models. This work provides a unified theoretical analysis of self-training with deep networks for semi-supervised learning, unsupervised domain adaptation, and unsupervised learning. At the core of our analysis is a simple but realistic “expansion” assumption, which states that a low-probability subset of the data must expand to a neighborhood with large probability relative to the subset. We also assume that neighborhoods of examples in different classes have minimal overlap. We prove that under these assumptions, the minimizers of population objectives based on self-training and input-consistency regularization will achieve high accuracy with respect to ground-truth labels. By using off-the-shelf generalization bounds, we immediately convert this result to sample complexity guarantees for neural nets that are polynomial in the margin and Lipschitzness. Our results help explain the empirical successes of recently proposed self-training algorithms which use input consistency regularization.",Oral Session 12,https://openreview.net/pdf?id=rC8sJ4i6kaH,https://openreview.net/forum?id=rC8sJ4i6kaH
"['Shuo Yang', 'Lu Liu', 'Min Xu']",ICLR,Free Lunch for Few-shot Learning:  Distribution Calibration,https://iclr.cc/virtual/2021/oral/3407,2021," Learning from a limited number of samples is challenging since the learned model can easily become overfitted based on the biased distribution formed by only a few training examples. In this paper, we calibrate the distribution of these few-sample classes by transferring statistics from the classes with sufficient examples. Then an adequate number of examples can be sampled from the calibrated distribution to expand the inputs to the classifier. We assume every dimension in the feature representation follows a Gaussian distribution so that the mean and the variance of the distribution can borrow from that of similar classes whose statistics are better estimated with an adequate number of samples. Our method can be built on top of off-the-shelf pretrained feature extractors and classification models without extra parameters. We show that a simple logistic regression classifier trained using the features sampled from our calibrated distribution can outperform the state-of-the-art accuracy on three datasets (~5% improvement on miniImageNet compared to the next best). The visualization of these generated features demonstrates that our calibrated distribution is an accurate estimation.",Oral Session 1,https://openreview.net/pdf?id=JWOiYxMG92s,https://openreview.net/forum?id=JWOiYxMG92s
"['Nicola De Cao', 'Gautier Izacard', 'Sebastian Riedel', 'Fabio Petroni']",ICLR,Autoregressive Entity Retrieval,https://iclr.cc/virtual/2021/spotlight/3521,2021," Entities are at the center of how we represent and aggregate knowledge. For instance, Encyclopedias such as Wikipedia are structured by entities (e.g., one per Wikipedia article). The ability to retrieve such entities given a query is fundamental for knowledge-intensive tasks such as entity linking and open-domain question answering. One way to understand current approaches is as classifiers among atomic labels, one for each entity. Their weight vectors are dense entity representations produced by encoding entity meta information such as their descriptions. This approach leads to several shortcomings: (i) context and entity affinity is mainly captured through a vector dot product, potentially missing fine-grained interactions between the two; (ii) a large memory footprint is needed to store dense representations when considering large entity sets; (iii) an appropriately hard set of negative data has to be subsampled at training time. In this work, we propose GENRE, the first system that retrieves entities by generating their unique names, left to right, token-by-token in an autoregressive fashion and conditioned on the context. This enables us to mitigate the aforementioned technical issues since: (i) the autoregressive formulation allows us to directly capture relations between context and entity name, effectively cross encoding both; (ii) the memory footprint is greatly reduced because the parameters of our encoder-decoder architecture scale with vocabulary size, not entity count; (iii) the exact softmax loss can be efficiently computed without the need to subsample negative data. We show the efficacy of the approach, experimenting with more than 20 datasets on entity disambiguation, end-to-end entity linking and document retrieval tasks, achieving new state-of-the-art or very competitive results while using a tiny fraction of the memory footprint of competing systems. Finally, we demonstrate that new entities can be added by simply specifying their unambiguous name. Code and pre-trained models at https://github.com/facebookresearch/GENRE.",Oral Session 4,https://openreview.net/pdf?id=5k8F6UU39V,https://openreview.net/forum?id=5k8F6UU39V
"['Zhengxian Lin', 'Kin-Ho Lam', 'Alan Fern']",ICLR,Contrastive Explanations for Reinforcement Learning via Embedded Self Predictions,https://iclr.cc/virtual/2021/oral/3434,2021," We investigate a deep reinforcement learning (RL) architecture that supports explaining why a learned agent prefers one action over another. The key idea is to learn action-values that are directly represented via human-understandable properties of expected futures. This is realized via the embedded self-prediction (ESP) model, which learns said properties in terms of human provided features. Action preferences can then be explained by contrasting the future properties predicted for each action. To address cases where there are a large number of features, we develop a novel method for computing minimal sufficient explanations from an ESP. Our case studies in three domains, including a complex strategy game, show that ESP models can be effectively learned and support insightful explanations.",Oral Session 3,https://openreview.net/pdf?id=Ud3DSz72nYR,https://openreview.net/forum?id=Ud3DSz72nYR
"['Gobinda Saha', 'Isha Garg', 'Kaushik Roy']",ICLR,Gradient Projection Memory for Continual Learning,https://iclr.cc/virtual/2021/oral/3429,2021," The ability to learn continually without forgetting the past tasks is a desired attribute for artificial learning systems. Existing approaches to enable such learning in artificial neural networks usually rely on network growth, importance based weight update or replay of old data from the memory. In contrast, we propose a novel approach where a neural network learns new tasks by taking gradient steps in the orthogonal direction to the gradient subspaces deemed important for the past tasks. We find the bases of these subspaces by analyzing network representations (activations) after learning each task with Singular Value Decomposition (SVD) in a single shot manner and store them in the memory as Gradient Projection Memory (GPM). With qualitative and quantitative analyses, we show that such orthogonal gradient descent induces minimum to no interference with the past tasks, thereby mitigates forgetting. We evaluate our algorithm on diverse image classification datasets with short and long sequences of tasks and report better or on-par performance compared to the state-of-the-art approaches.",Oral Session 2,https://openreview.net/pdf?id=3AOj0RCNC2,https://openreview.net/forum?id=3AOj0RCNC2
"['Luca Weihs', 'Aniruddha Kembhavi', 'Kiana Ehsani', 'Sarah M Pratt', 'Winson Han', 'Alvaro Herrasti', 'Eric Kolve', 'Dustin Schwenk', 'Roozbeh Mottaghi', 'Ali Farhadi']",ICLR,Learning Generalizable Visual Representations via Interactive Gameplay,https://iclr.cc/virtual/2021/oral/3514,2021," A growing body of research suggests that embodied gameplay, prevalent not just in human cultures but across a variety of animal species including turtles and ravens, is critical in developing the neural flexibility for creative problem solving, decision making, and socialization. Comparatively little is known regarding the impact of embodied gameplay upon artificial agents. While recent work has produced agents proficient in abstract games, these environments are far removed the real world and thus these agents can provide little insight into the advantages of embodied play. Hiding games, such as hide-and-seek, played universally, provide a rich ground for studying the impact of embodied gameplay on representation learning in the context of perspective taking, secret keeping, and false belief understanding. Here we are the first to show that embodied adversarial reinforcement learning agents playing Cache, a variant of hide-and-seek, in a high fidelity, interactive, environment, learn generalizable representations of their observations encoding information such as object permanence, free space, and containment. Moving closer to biologically motivated learning strategies, our agents' representations, enhanced by intentionality and memory, are developed through interaction and play. These results serve as a model for studying how facets of vision develop through interaction, provide an experimental framework for assessing what is learned by artificial agents, and demonstrates the value of moving from large, static, datasets towards experiential, interactive, representation learning.",Oral Session 5,https://openreview.net/pdf?id=UuchYL8wSZo,https://openreview.net/forum?id=UuchYL8wSZo
"['Guan-Horng Liu', 'Tianrong Chen', 'Evangelos Theodorou']",ICLR,DDPNOpt: Differential Dynamic Programming Neural Optimizer,https://iclr.cc/virtual/2021/spotlight/3512,2021," Interpretation of Deep Neural Networks (DNNs) training as an optimal control problem with nonlinear dynamical systems has received considerable attention recently, yet the algorithmic development remains relatively limited. In this work, we make an attempt along this line by reformulating the training procedure from the trajectory optimization perspective. We first show that most widely-used algorithms for training DNNs can be linked to the Differential Dynamic Programming (DDP), a celebrated second-order method rooted in the Approximate Dynamic Programming. In this vein, we propose a new class of optimizer, DDP Neural Optimizer (DDPNOpt), for training feedforward and convolution networks. DDPNOpt features layer-wise feedback policies which improve convergence and reduce sensitivity to hyper-parameter over existing methods. It outperforms other optimal-control inspired training methods in both convergence and complexity, and is competitive against state-of-the-art first and second order methods. We also observe DDPNOpt has surprising benefit in preventing gradient vanishing. Our work opens up new avenues for principled algorithmic design built upon the optimal control theory.",Oral Session 6,https://openreview.net/pdf?id=6s7ME_X5_Un,https://openreview.net/forum?id=6s7ME_X5_Un
"['Krzysztof Choromanski', 'Valerii Likhosherstov', 'David Dohan', 'Xingyou Song', 'Georgiana-Andreea Gane', 'Tamas Sarlos', 'Peter Hawkins', 'Jared Q Davis', 'Afroz Mohiuddin', 'Lukasz Kaiser', 'David Belanger', 'Lucy J Colwell', 'Adrian Weller']",ICLR,Rethinking Attention with Performers,https://iclr.cc/virtual/2021/oral/3397,2021," We introduce Performers, Transformer architectures which can estimate regular (softmax) full-rank-attention Transformers with provable accuracy, but using only linear (as opposed to quadratic) space and time complexity, without relying on any priors such as sparsity or low-rankness. To approximate softmax attention-kernels, Performers use a novel Fast Attention Via positive Orthogonal Random features approach (FAVOR+), which may be of independent interest for scalable kernel methods. FAVOR+ can also be used to efficiently model kernelizable attention mechanisms beyond softmax. This representational power is crucial to accurately compare softmax with other kernels for the first time on large-scale tasks, beyond the reach of regular Transformers, and investigate optimal attention-kernels. Performers are linear architectures fully compatible with regular Transformers and with strong theoretical guarantees: unbiased or nearly-unbiased estimation of the attention matrix, uniform convergence and low  estimation variance. We tested Performers on a rich set of tasks stretching from pixel-prediction through text models to protein sequence modeling. We demonstrate competitive results with other examined efficient sparse and dense attention methods, showcasing effectiveness of the novel attention-learning paradigm leveraged by Performers.",Oral Session 7,https://openreview.net/pdf?id=Ua6zuk0WRH,https://openreview.net/forum?id=Ua6zuk0WRH
"['Dibya Ghosh', 'Abhishek Gupta', 'Ashwin D Reddy', 'Justin Fu', 'Coline M Devin', 'Benjamin Eysenbach', 'Sergey Levine']",ICLR,Learning to Reach Goals via Iterated Supervised Learning,https://iclr.cc/virtual/2021/oral/3528,2021," Current reinforcement learning (RL) algorithms can be brittle and difficult to use, especially when learning goal-reaching behaviors from sparse rewards. Although supervised imitation learning provides a simple and stable alternative, it requires access to demonstrations from a human supervisor. In this paper, we study RL algorithms that use imitation learning to acquire goal reaching policies from scratch, without the need for expert demonstrations or a value function. In lieu of demonstrations, we leverage the property that any trajectory is a successful demonstration for reaching the final state in that same trajectory. We propose a simple algorithm in which an agent continually relabels and imitates the trajectories it generates to progressively learn goal-reaching behaviors from scratch. Each iteration, the agent collects new trajectories using the latest policy, and maximizes the likelihood of the actions along these trajectories under the goal that was actually reached, so as to improve the policy. We formally show that this iterated supervised learning procedure optimizes a bound on the RL objective, derive performance bounds of the learned policy, and empirically demonstrate improved goal-reaching performance and robustness over current RL algorithms in several benchmark tasks.",Oral Session 8,https://openreview.net/pdf?id=rALA0Xo6yNJ,https://openreview.net/forum?id=rALA0Xo6yNJ
"['Ian Gemp', 'Brian McWilliams', 'Claire Vernade', 'Thore Graepel']",ICLR,EigenGame: PCA as a Nash Equilibrium,https://iclr.cc/virtual/2021/oral/3445,2021, We present a novel view on principal components analysis as a competitive game in which each approximate eigenvector is controlled by a player whose goal is to maximize their own utility function. We analyze the properties of this PCA game and the behavior of its gradient based updates. The resulting algorithm---which combines elements from Oja's rule with a  generalized Gram-Schmidt orthogonalization---is naturally decentralized and hence parallelizable through message passing. We demonstrate the scalability of the algorithm with experiments on large image datasets and neural network activations. We discuss how this new view of PCA as a differentiable game can lead to further algorithmic developments and insights.,Outstanding Paper Session 1,https://openreview.net/pdf?id=NzTU59SYbNq,https://openreview.net/forum?id=NzTU59SYbNq
"['Nurit Spingarn Eliezer', 'Ron Banner', 'Tomer Michaeli']",ICLR,"GAN ""Steerability"" without optimization",https://iclr.cc/virtual/2021/spotlight/3478,2021," Recent research has shown remarkable success in revealing ""steering"" directions in the latent spaces of pre-trained GANs. These directions correspond to semantically meaningful image transformations (e.g., shift, zoom, color manipulations), and have the same interpretable effect across all categories that the GAN can generate. Some methods focus on user-specified transformations, while others discover transformations in an unsupervised manner. However, all existing techniques rely on an optimization procedure to expose those directions, and offer no control over the degree of allowed interaction between different transformations. In this paper, we show that ""steering"" trajectories can be computed in closed form directly from the generator's weights without any form of training or optimization. This applies to user-prescribed geometric transformations, as well as to unsupervised discovery of more complex effects. Our approach allows determining both linear and nonlinear trajectories, and has many advantages over previous methods. In particular, we can control whether one transformation is allowed to come on the expense of another (e.g., zoom-in with or without allowing translation to keep the object centered). Moreover, we can determine the natural end-point of the trajectory, which corresponds to the largest extent to which a transformation can be applied without incurring degradation. Finally, we show how transferring attributes between images can be achieved without optimization, even across different categories.",Oral Session 9,https://openreview.net/pdf?id=zDy_nQCXiIj,https://openreview.net/forum?id=zDy_nQCXiIj
"['Erik Arakelyan', 'Daniel Daza', 'Pasquale Minervini', 'Michael Cochez']",ICLR,Complex Query Answering with Neural Link Predictors,https://iclr.cc/virtual/2021/oral/3383,2021," Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\land$), disjunctions ($\lor$) and existential quantifiers ($\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.",Outstanding Paper Session 2,https://openreview.net/pdf?id=Mos9F9kDwkz,https://openreview.net/forum?id=Mos9F9kDwkz
"['Deunsol Yoon', 'Sunghoon Hong', 'Byung-Jun Lee', 'Kee-Eung Kim']",ICLR,Winning the L2RPN Challenge: Power Grid Management via Semi-Markov Afterstate Actor-Critic,https://iclr.cc/virtual/2021/spotlight/3461,2021," Safe and reliable electricity transmission in power grids is crucial for modern society. It is thus quite natural that there has been a growing interest in the automatic management of power grids, exempliﬁed by the Learning to Run a Power Network Challenge (L2RPN), modeling the problem as a reinforcement learning (RL) task. However, it is highly challenging to manage a real-world scale power grid, mostly due to the massive scale of its state and action space. In this paper, we present an off-policy actor-critic approach that effectively tackles the unique challenges in power grid management by RL, adopting the hierarchical policy together with the afterstate representation. Our agent ranked ﬁrst in the latest challenge (L2RPN WCCI 2020), being able to avoid disastrous situations while maintaining the highest level of operational efﬁciency in every test scenarios. This paper provides a formal description of the algorithmic aspect of our approach, as well as further experimental studies on diverse power grids.",Oral Session 10,https://openreview.net/pdf?id=LmUJqB1Cz8,https://openreview.net/forum?id=LmUJqB1Cz8
"['Mikhail Yurochkin', 'Yuekai Sun']",ICLR,SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness,https://iclr.cc/virtual/2021/oral/3499,2021," In this paper, we cast fair machine learning as invariant machine learning. We first formulate a version of individual fairness that enforces invariance on certain sensitive sets. We then design a transport-based regularizer that enforces this version of individual fairness and develop an algorithm to minimize the regularizer efficiently. Our theoretical results guarantee the proposed approach trains certifiably fair ML models. Finally, in the experimental studies we demonstrate improved fairness metrics in comparison to several recent fair training procedures on three ML tasks that are susceptible to algorithmic bias.",Oral Session 11,https://openreview.net/pdf?id=DktZb97_Fx,https://openreview.net/forum?id=DktZb97_Fx
"['Xudong Wang', 'Long Lian', 'Zhongqi Miao', 'Ziwei Liu', 'Stella Yu']",ICLR,Long-tailed Recognition by Routing Diverse Distribution-Aware Experts,https://iclr.cc/virtual/2021/spotlight/3456,2021," Natural data are often long-tail distributed over semantic classes. Existing recognition methods tend to focus on gaining performance on tail classes, often at the expense of losing performance on head classes and with increased classifier variance. The low tail performance manifests itself in large inter-class confusion and high classifier variance. We aim to reduce both the bias and the variance of a long-tailed classifier by RoutIng Diverse Experts (RIDE), consisting of three components: 1) a shared architecture for multiple classifiers (experts); 2) a distribution-aware diversity loss that encourages more diverse decisions for classes with fewer training instances; and 3) an expert routing module that dynamically assigns more ambiguous instances to additional experts.  With on-par computational complexity, RIDE significantly outperforms the state-of-the-art methods by 5% to 7% on all the benchmarks including CIFAR100-LT, ImageNet-LT, and iNaturalist 2018. RIDE is also a universal framework that can be applied to different backbone networks and integrated into various long-tailed algorithms and training mechanisms for consistent performance gains. Our code is publicly available at https://github.com/frank-xwang/RIDE-LongTailRecognition.",Oral Session 12,https://openreview.net/pdf?id=D9I3drBz4UC,https://openreview.net/forum?id=D9I3drBz4UC
"['Malik Tiomoko', 'Hafiz Tiomoko Ali', 'Romain Couillet']",ICLR,Deciphering and Optimizing Multi-Task Learning: a Random Matrix Approach,https://iclr.cc/virtual/2021/spotlight/3388,2021," This article provides theoretical insights into the inner workings of multi-task and transfer learning methods, by studying the tractable least-square support vector machine multi-task learning (LS-SVM MTL) method, in the limit of large ($p$) and numerous ($n$) data. By a random matrix analysis applied to a Gaussian mixture data model, the performance of MTL LS-SVM is shown to converge, as $n,p\to\infty$, to a deterministic limit involving simple (small-dimensional) statistics of the data.

We prove (i) that the standard MTL LS-SVM algorithm is in general strongly biased and may dramatically fail (to the point that individual single-task LS-SVMs may outperform the MTL approach, even for quite resembling tasks): our analysis provides a simple method to correct these biases, and that we reveal (ii) the sufficient statistics at play in the method, which can be efficiently estimated, even for quite small datasets. The latter result is exploited to automatically optimize the hyperparameters without resorting to any cross-validation procedure. 

Experiments on popular datasets demonstrate that our improved MTL LS-SVM method is computationally-efficient and outperforms sometimes much more elaborate state-of-the-art multi-task and transfer learning techniques.",Oral Session 1,https://openreview.net/pdf?id=Cri3xz59ga,https://openreview.net/forum?id=Cri3xz59ga
"['Avi Singh', 'Huihan Liu', 'Gaoyue Zhou', 'Albert Yu', 'Nicholas Rhinehart', 'Sergey Levine']",ICLR,Parrot: Data-Driven Behavioral Priors for Reinforcement Learning,https://iclr.cc/virtual/2021/oral/3481,2021," Reinforcement learning provides a general framework for flexible decision making and control, but requires extensive data collection for each new task that an agent needs to learn. In other machine learning fields, such as natural language processing or computer vision, pre-training on large, previously collected datasets to bootstrap learning for new tasks has emerged as a powerful paradigm to reduce data requirements when learning a new task. In this paper, we ask the following question: how can we enable similarly useful pre-training for RL agents? We propose a method for pre-training behavioral priors that can capture complex input-output relationships observed in successful trials from a wide range of previously seen tasks, and we show how this learned prior can be used for rapidly learning new tasks without impeding the RL agent's ability to try out novel behaviors. We demonstrate the effectiveness of our approach in challenging robotic manipulation domains involving image observations and sparse reward functions, where our method outperforms prior works by a substantial margin. Additional materials can be found on our project website: https://sites.google.com/view/parrot-rl",Oral Session 3,https://openreview.net/pdf?id=Ysuv-WOFeKR,https://openreview.net/forum?id=Ysuv-WOFeKR
"['Michael Schlichtkrull', 'Nicola De Cao', 'Ivan Titov']",ICLR,Interpreting Graph Neural Networks for NLP With Differentiable Edge Masking,https://iclr.cc/virtual/2021/spotlight/3482,2021," Graph neural networks (GNNs) have become a popular approach to integrating structural inductive biases into NLP models. However, there has been little work on interpreting them, and specifically on understanding which parts of the graphs (e.g. syntactic trees or co-reference structures) contribute to a prediction. In this work, we introduce a post-hoc method for interpreting the predictions of GNNs which identifies unnecessary edges. Given a trained GNN model, we learn a simple classifier that, for every edge in every layer, predicts if that edge can be dropped. We demonstrate that such a classifier can be trained in a fully differentiable fashion, employing stochastic gates and encouraging sparsity through the expected $L_0$ norm. We use our technique as an attribution method to analyze GNN models for two tasks -- question answering and semantic role labeling -- providing insights into the information flow in these models. We show that we can drop a large proportion of edges without deteriorating the performance of the model, while we can analyse the remaining edges for interpreting model predictions.",Oral Session 4,https://openreview.net/pdf?id=WznmQa42ZAx,https://openreview.net/forum?id=WznmQa42ZAx
"['Xin Yuan', 'Pedro Savarese', 'Michael Maire']",ICLR,Growing Efficient Deep Networks by Structured Continuous Sparsification,https://iclr.cc/virtual/2021/oral/3451,2021," We develop an approach to growing deep network architectures over the course of training, driven by a principled combination of accuracy and sparsity objectives.  Unlike existing pruning or architecture search techniques that operate on full-sized models or supernet architectures, our method can start from a small, simple seed architecture and dynamically grow and prune both layers and filters.  By combining a continuous relaxation of discrete network structure optimization with a scheme for sampling sparse subnetworks, we produce compact, pruned networks, while also drastically reducing the computational expense of training.  For example, we achieve $49.7\%$ inference FLOPs and $47.4\%$ training FLOPs savings compared to a baseline ResNet-50 on ImageNet, while maintaining $75.2\%$ top-1 validation accuracy --- all without any dedicated fine-tuning stage.  Experiments across CIFAR, ImageNet, PASCAL VOC, and Penn Treebank, with convolutional networks for image classification and semantic segmentation, and recurrent networks for language modeling, demonstrate that we both train faster and produce more efficient networks than competing architecture pruning or search methods.",Oral Session 2,https://openreview.net/pdf?id=wb3wxCObbRT,https://openreview.net/forum?id=wb3wxCObbRT
"['Linjun Zhang', 'Zhun Deng', 'Kenji Kawaguchi', 'Amirata Ghorbani', 'James Zou']",ICLR,How Does Mixup Help With Robustness and Generalization?,https://iclr.cc/virtual/2021/spotlight/3506,2021," Mixup is a popular data augmentation technique based on on convex combinations of pairs of examples and their labels. This simple technique has shown to substantially improve both the model's robustness as well as the generalization of the trained model. However,  it is not well-understood why such improvement occurs. In this paper, we provide theoretical analysis to demonstrate how using Mixup in training helps model robustness and generalization. For robustness, we show that minimizing the Mixup loss corresponds to approximately minimizing an upper bound of the adversarial loss. This explains why models obtained by Mixup training exhibits robustness to several kinds of adversarial attacks such as Fast Gradient Sign Method (FGSM). For generalization, we prove that Mixup augmentation corresponds to a specific type of data-adaptive regularization which reduces overfitting. Our analysis provides new insights and a framework to understand Mixup.",Oral Session 5,https://openreview.net/pdf?id=8yKEo06dKNo,https://openreview.net/forum?id=8yKEo06dKNo
"['Asher Trockman', 'Zico Kolter']",ICLR,Orthogonalizing Convolutional Layers with the Cayley Transform,https://iclr.cc/virtual/2021/spotlight/3428,2021," Recent work has highlighted several advantages of enforcing orthogonality in the weight layers of deep networks, such as maintaining the stability of activations, preserving gradient norms, and enhancing adversarial robustness by enforcing low Lipschitz constants. Although numerous methods exist for enforcing the orthogonality of fully-connected layers, those for convolutional layers are more heuristic in nature, often focusing on penalty methods or limited classes of convolutions. In this work, we propose and evaluate an alternative approach to directly parameterize convolutional layers that are constrained to be orthogonal. Specifically, we propose to apply the Cayley transform to a skew-symmetric convolution in the Fourier domain, so that the inverse convolution needed by the Cayley transform can be computed efficiently. We compare our method to previous Lipschitz-constrained and orthogonal convolutional layers and show that it indeed preserves orthogonality to a high degree even for large convolutions. Applied to the problem of certified adversarial robustness, we show that networks incorporating the layer outperform existing deterministic methods for certified defense against $\ell_2$-norm-bounded adversaries, while scaling to larger architectures than previously investigated. Code is available at https://github.com/locuslab/orthogonal-convolutions.",Oral Session 6,https://openreview.net/pdf?id=Pbj8H_jEHYv,https://openreview.net/forum?id=Pbj8H_jEHYv
"['Biao Zhang', 'Ankur Bapna', 'Rico Sennrich', 'Orhan Firat']",ICLR,Share or Not? Learning to Schedule Language-Specific Capacity for Multilingual Translation,https://iclr.cc/virtual/2021/oral/3440,2021," Using a mix of shared and language-specific (LS) parameters has shown promise in multilingual neural machine  translation (MNMT), but the question of when and where LS capacity matters most is still under-studied. We offer such a study by proposing conditional language-specific routing (CLSR). CLSR employs hard binary gates conditioned on token representations to dynamically select LS or shared paths. By manipulating these gates, it can schedule LS capacity across sub-layers in MNMT subject to the guidance of translation signals and budget constraints. Moreover, CLSR can easily scale up to massively multilingual settings. Experiments with Transformer on OPUS-100 and WMT datasets show that: 1) MNMT is sensitive to both the amount and the position of LS modeling: distributing 10%-30% LS computation to the top and/or bottom encoder/decoder layers delivers the best performance; and 2) one-to-many translation benefits more from CLSR compared to many-to-one translation, particularly with unbalanced training data. Our study further verifies the trade-off between the shared capacity and LS capacity for multilingual translation. We corroborate our analysis by confirming the soundness of our findings as foundation of our improved multilingual Transformers. Source code and models are available at https://github.com/googleinterns/cct-m4.",Oral Session 7,https://openreview.net/pdf?id=Wj4ODo0uyCF,https://openreview.net/forum?id=Wj4ODo0uyCF
"['Amy Zhang', 'Rowan T McAllister', 'Roberto Calandra', 'Yarin Gal', 'Sergey Levine']",ICLR,Learning Invariant Representations for Reinforcement Learning without Reconstruction,https://iclr.cc/virtual/2021/oral/3480,2021," We study how representation learning can accelerate reinforcement learning from rich observations, such as images, without relying either on domain knowledge or pixel-reconstruction. Our goal is to learn representations that provide for effective downstream control and invariance to task-irrelevant details. Bisimulation metrics quantify behavioral similarity between states in continuous MDPs, which we propose using to learn robust latent representations which encode only the task-relevant information from observations. Our method trains encoders such that distances in latent space equal bisimulation distances in state space. We demonstrate the effectiveness of our method at disregarding task-irrelevant information using modified visual MuJoCo tasks, where the background is replaced with moving distractors and natural videos, while achieving SOTA performance. We also test a first-person highway driving task where our method learns invariance to clouds, weather, and time of day. Finally, we provide generalization results drawn from properties of bisimulation metrics, and links to causal inference.",Oral Session 8,https://openreview.net/pdf?id=-2FCwDKRREu,https://openreview.net/forum?id=-2FCwDKRREu
"['Yang Song', 'Jascha Sohl-Dickstein', 'Durk Kingma', 'Abhishek Kumar', 'Stefano Ermon', 'Ben Poole']",ICLR,Score-Based Generative Modeling through Stochastic Differential Equations,https://iclr.cc/virtual/2021/oral/3402,2021," Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. 
Crucially, the reverse-time SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity generation of $1024\times 1024$ images for the first time from a score-based generative model.",Outstanding Paper Session 1,https://openreview.net/pdf?id=PxTIG12RRHS,https://openreview.net/forum?id=PxTIG12RRHS
"['Shengyu Zhao', 'Jonathan Cui', 'Yilun Sheng', 'Yue Dong', 'Xiao Liang', 'Eric Chang', 'Yan Xu']",ICLR,Large Scale Image Completion via Co-Modulated Generative Adversarial Networks,https://iclr.cc/virtual/2021/spotlight/3543,2021," Numerous task-specific variants of conditional generative adversarial networks have been developed for image completion. Yet, a serious limitation remains that all existing algorithms tend to fail when handling large-scale missing regions. To overcome this challenge, we propose a generic new approach that bridges the gap between image-conditional and recent modulated unconditional generative architectures via co-modulation of both conditional and stochastic style representations. Also, due to the lack of good quantitative metrics for image completion, we propose the new Paired/Unpaired Inception Discriminative Score (P-IDS/U-IDS), which robustly measures the perceptual fidelity of inpainted images compared to real images via linear separability in a feature space. Experiments demonstrate superior performance in terms of both quality and diversity over state-of-the-art methods in free-form image completion and easy generalization to image-to-image translation. Code is available at https://github.com/zsyzzsoft/co-mod-gan.",Oral Session 9,https://openreview.net/pdf?id=sSjqmfsk95O,https://openreview.net/forum?id=sSjqmfsk95O
"['Atsushi Nitanda', 'Taiji Suzuki']",ICLR,Optimal Rates for Averaged Stochastic Gradient Descent under Neural Tangent Kernel Regime,https://iclr.cc/virtual/2021/oral/3527,2021," We analyze the convergence of the averaged stochastic gradient descent for overparameterized two-layer neural networks for regression problems. It was recently found that a neural tangent kernel (NTK) plays an important role in showing the global convergence of gradient-based methods under the NTK regime, where the learning dynamics for overparameterized neural networks can be almost characterized by that for the associated reproducing kernel Hilbert space (RKHS). However, there is still room for a convergence rate analysis in the NTK regime. In this study, we show that the averaged stochastic gradient descent can achieve the minimax optimal convergence rate, with the global convergence guarantee, by exploiting the complexities of the target function and the RKHS associated with the NTK. Moreover, we show that the target function specified by the NTK of a ReLU network can be learned at the optimal convergence rate through a smooth approximation of a ReLU network under certain conditions.",Outstanding Paper Session 2,https://openreview.net/pdf?id=PULSD5qI2N1,https://openreview.net/forum?id=PULSD5qI2N1
"['Siyi Hu', 'Fengda Zhu', 'Xiaojun Chang', 'Xiaodan Liang']",ICLR,UPDeT: Universal Multi-agent RL via Policy Decoupling with Transformers,https://iclr.cc/virtual/2021/spotlight/3403,2021," Recent advances in multi-agent reinforcement learning have been largely limited in training one model from scratch for every new task. The limitation is due to the restricted model architecture related to fixed input and output dimensions. This hinders the experience accumulation and transfer of the learned agent over tasks with diverse levels of difficulty (e.g. 3 vs 3 or 5 vs 6 multi-agent games).  In this paper, we make the first attempt to explore a universal multi-agent reinforcement learning pipeline, designing one single architecture to fit tasks with the requirement of different observation and action configurations. Unlike previous RNN-based models, we utilize a transformer-based model to generate a flexible policy by decoupling the policy distribution from the intertwined input observation with an importance weight measured by the merits of the self-attention mechanism. Compared to a standard transformer block, the proposed model, named as Universal Policy Decoupling Transformer (UPDeT), further relaxes the action restriction and makes the multi-agent task's decision process more explainable. UPDeT is general enough to be plugged into any multi-agent reinforcement learning pipeline and equip them with strong generalization abilities that enables the handling of multiple tasks at a time. Extensive experiments on large-scale SMAC multi-agent competitive games demonstrate that the proposed UPDeT-based multi-agent reinforcement learning achieves significant results relative to state-of-the-art approaches, demonstrating advantageous transfer capability in terms of both performance and training speed (10 times faster).",Oral Session 10,https://openreview.net/pdf?id=v9c7hr9ADKx,https://openreview.net/forum?id=v9c7hr9ADKx
"['Xiaoxia (Shirley) Wu', 'Ethan Dyer', 'Behnam Neyshabur']",ICLR,When Do Curricula Work?,https://iclr.cc/virtual/2021/oral/3401,2021," Inspired by human learning, researchers have proposed ordering examples during training based on their difficulty. Both curriculum learning, exposing a network to easier examples early in training, and anti-curriculum learning, showing the most difficult examples first, have been suggested as improvements to the standard i.i.d. training. In this work, we set out to investigate the relative benefits of ordered learning. We first investigate the implicit curricula resulting from architectural and optimization bias and find that samples are learned in a highly consistent order. Next, to quantify the benefit of explicit curricula, we conduct extensive experiments over thousands of orderings spanning three kinds of learning: curriculum, anti-curriculum, and random-curriculum -- in which the size of the training dataset is dynamically increased over time, but the examples are randomly ordered. We find that for standard benchmark datasets, curricula have only marginal benefits, and that randomly ordered samples perform as well or better than curricula and anti-curricula, suggesting that any benefit is entirely due to the dynamic training set size. Inspired by common use cases of curriculum learning in practice, we investigate the role of limited training time budget and noisy data in the success of curriculum learning. Our experiments demonstrate that curriculum, but not anti-curriculum or random ordering can indeed improve the performance either with limited training time budget or in the existence of noisy data.",Oral Session 11,https://openreview.net/pdf?id=tW4QEInpni,https://openreview.net/forum?id=tW4QEInpni
"['Nicklas Hansen', 'Rishabh Jangir', 'Yu Sun', 'Guillem Alenyà', 'Pieter Abbeel', 'Alexei Efros', 'Lerrel Pinto', 'Xiaolong Wang']",ICLR,Self-Supervised Policy Adaptation during Deployment,https://iclr.cc/virtual/2021/spotlight/3500,2021," In most real world scenarios, a policy trained by reinforcement learning in one environment needs to be deployed in another, potentially quite different environment. However, generalization across different environments is known to be hard. A natural solution would be to keep training after deployment in the new environment, but this cannot be done if the new environment offers no reward signal. Our work explores the use of self-supervision to allow the policy to continue training after deployment without using any rewards. While previous methods explicitly anticipate changes in the new environment, we assume no prior knowledge of those changes yet still obtain significant improvements. Empirical evaluations are performed on diverse simulation environments from DeepMind Control suite and ViZDoom, as well as real robotic manipulation tasks in  continuously changing environments, taking observations from an uncalibrated camera. Our method improves generalization in 31 out of 36 environments across various tasks and outperforms domain randomization on a majority of environments. Webpage and implementation: https://nicklashansen.github.io/PAD/.",Oral Session 12,https://openreview.net/pdf?id=o_V-MjyyGV_,https://openreview.net/forum?id=o_V-MjyyGV_
"['Konstantin-Klemens Lurz', 'Mohammad Bashiri', 'Konstantin Willeke', 'Akshay Jagadish', 'Eric Wang', 'Edgar Walker', 'Santiago Cadena', 'Taliah Muhammad', 'Erick M Cobos', 'Andreas Tolias', 'Alexander S Ecker', 'Fabian Sinz']",ICLR,Generalization in data-driven models of primary visual cortex,https://iclr.cc/virtual/2021/spotlight/3454,2021," Deep neural networks (DNN) have set new standards at predicting responses of neural populations to visual input.  Most such DNNs consist of a convolutional network (core) shared across all neurons which learns a representation of neural computation in visual cortex and a neuron-specific readout that linearly combines the relevant features in this representation. The goal of this paper is to test whether such a representation is indeed generally characteristic for visual cortex, i.e. generalizes between animals of a species, and what factors contribute to obtaining such a generalizing core. To push all non-linear computations into the core where the generalizing cortical features should be learned, we devise a novel readout that reduces the number of parameters per neuron in the readout by up to two orders of magnitude compared to the previous state-of-the-art. It does so by taking advantage of retinotopy and learns a Gaussian distribution over the neuron’s receptive field position.  With this new readout we train our network on neural responses from mouse primary visual cortex (V1) and obtain a gain in performance of 7% compared to the previous state-of-the-art network.  We then investigate whether the convolutional core indeed captures general cortical features by using the core in transfer learning to a different animal.  When transferring a core trained on thousands of neurons from various animals and scans we exceed the performance of training directly on that animal by 12%, and outperform a commonly used VGG16 core pre-trained on imagenet by 33%. In addition, transfer learning with our data-driven core is more data-efficient than direct training, achieving the same performance with only 40% of the data. Our model with its novel readout thus sets a new state-of-the-art for neural response prediction in mouse visual cortex from natural images, generalizes between animals, and captures better characteristic cortical features than current task-driven pre-training approaches such as VGG16.",Oral Session 1,https://openreview.net/pdf?id=Tp7kI90Htd,https://openreview.net/forum?id=Tp7kI90Htd
"['Giovanni Paolini', 'Ben Athiwaratkun', 'Jason Krone', 'Jie Ma', 'Alessandro Achille', 'RISHITA ANUBHAI', 'Cicero Nogueira dos Santos', 'Bing Xiang', 'Stefano Soatto']",ICLR,Structured Prediction as Translation between Augmented Natural Languages,https://iclr.cc/virtual/2021/spotlight/3411,2021," We propose a new framework, Translation between Augmented Natural Languages (TANL), to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. Instead of tackling the problem by training task-specific discriminative classifiers, we frame it as a translation task between augmented natural languages, from which the task-relevant information can be easily extracted. Our approach can match or outperform task-specific models on all tasks, and in particular achieves new state-of-the-art results on joint entity and relation extraction (CoNLL04, ADE, NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and semantic role labeling (CoNLL-2005 and CoNLL-2012). We accomplish this while using the same architecture and hyperparameters for all tasks, and even when training a single model to solve all tasks at the same time (multi-task learning). Finally, we show that our framework can also significantly improve the performance in a low-resource regime, thanks to better use of label semantics.",Oral Session 3,https://openreview.net/pdf?id=US-TP-xnXI,https://openreview.net/forum?id=US-TP-xnXI
"['Waïss Azizian', 'marc lelarge']",ICLR,Expressive Power of Invariant and Equivariant Graph Neural Networks,https://iclr.cc/virtual/2021/spotlight/3529,2021," Various classes of Graph Neural Networks (GNN) have been proposed and shown to be successful in a wide range of applications with graph structured data. In this paper, we propose a theoretical framework able to compare the expressive power of these GNN architectures. The current universality theorems only apply to intractable classes of GNNs. Here, we prove the first approximation guarantees for practical GNNs, paving the way for a better understanding of their generalization. Our theoretical results are proved for invariant GNNs computing a graph embedding (permutation of the nodes of the input graph does not affect the output) and equivariant GNNs computing an embedding of the nodes (permutation of the input permutes the output). We show that Folklore Graph Neural Networks (FGNN), which are tensor based GNNs augmented with matrix multiplication are the most expressive architectures proposed so far for a given tensor order. We illustrate our results on the Quadratic Assignment Problem (a NP-Hard combinatorial problem) by showing that FGNNs are able to learn how to solve the problem, leading to much better average performances than existing algorithms (based on spectral, SDP or other GNNs architectures). On a practical side, we also implement masked tensors to handle batches of graphs of varying sizes.",Oral Session 4,https://openreview.net/pdf?id=lxHgXYN4bwl,https://openreview.net/forum?id=lxHgXYN4bwl
"['Anirudh Goyal', 'Alex Lamb', 'Jordan Hoffmann', 'Shagun Sodhani', 'Sergey Levine', 'Yoshua Bengio', 'Bernhard Schoelkopf']",ICLR,Recurrent Independent Mechanisms,https://iclr.cc/virtual/2021/spotlight/3437,2021," We explore the hypothesis that learning modular structures which reflect the dynamics of the environment can lead to better generalization and robustness to changes that only affect a few of the underlying causes. We propose Recurrent Independent Mechanisms (RIMs), a new recurrent architecture in which multiple groups of recurrent cells operate with nearly independent transition dynamics, communicate only sparingly through the bottleneck of attention, and compete with each other so they are updated only at time steps where they are most relevant.  We show that this leads to specialization amongst the RIMs, which in turn allows for remarkably improved generalization on tasks where some factors of variation differ systematically between training and evaluation.",Oral Session 5,https://openreview.net/pdf?id=mLcmdlEUxy-,https://openreview.net/forum?id=mLcmdlEUxy-
"['Liam Li', 'Mikhail Khodak', 'Nina Balcan', 'Ameet Talwalkar']",ICLR,Geometry-Aware Gradient Algorithms for Neural Architecture Search,https://iclr.cc/virtual/2021/spotlight/3523,2021," Recent state-of-the-art methods for neural architecture search (NAS) exploit gradient-based optimization by relaxing the problem into continuous optimization over architectures and shared-weights, a noisy process that remains poorly understood. We argue for the study of single-level empirical risk minimization to understand NAS with weight-sharing, reducing the design of NAS methods to devising optimizers and regularizers that can quickly obtain high-quality solutions to this problem. Invoking the theory of mirror descent, we present a geometry-aware framework that exploits the underlying structure of this optimization to return sparse architectural parameters, leading to simple yet novel algorithms that enjoy fast convergence guarantees and achieve state-of-the-art accuracy on the latest NAS benchmarks in computer vision. Notably, we exceed the best published results for both CIFAR and ImageNet on both the DARTS search space and NAS-Bench-201; on the latter we achieve near-oracle-optimal performance on CIFAR-10 and CIFAR-100. Together, our theory and experiments demonstrate a principled way to co-design optimizers and continuous relaxations of discrete NAS search spaces.",Oral Session 2,https://openreview.net/pdf?id=MuSYkd1hxRP,https://openreview.net/forum?id=MuSYkd1hxRP
"['Stephen Tian', 'Suraj Nair', 'Frederik Ebert', 'Sudeep Dasari', 'Benjamin Eysenbach', 'Chelsea Finn', 'Sergey Levine']",ICLR,Model-Based Visual Planning with Self-Supervised Functional Distances,https://iclr.cc/virtual/2021/spotlight/3526,2021," A generalist robot must be able to complete a variety of tasks in its environment. One appealing way to specify each task is in terms of a goal observation. However, learning goal-reaching policies with reinforcement learning remains a challenging problem, particularly when hand-engineered reward functions are not available. Learned dynamics models are a promising approach for learning about the environment without rewards or task-directed data, but planning to reach goals with such a model requires a notion of functional similarity between observations and goal states. We present a self-supervised method for model-based visual goal reaching, which uses both a visual dynamics model as well as a dynamical distance function learned using model-free reinforcement learning. Our approach learns entirely using offline, unlabeled data, making it practical to scale to large and diverse datasets. In our experiments, we find that our method can successfully learn models that perform a variety of tasks at test-time, moving objects amid distractors with a simulated robotic arm and even learning to open and close a drawer using a real-world robot. In comparisons, we find that this approach substantially outperforms both model-free and model-based prior methods.",Oral Session 6,https://openreview.net/pdf?id=UcoXdfrORC,https://openreview.net/forum?id=UcoXdfrORC
"['Mandela Patrick', 'Po-Yao Huang', 'Yuki Asano', 'Florian Metze', 'Alexander G Hauptmann', 'Joao F. Henriques', 'Andrea Vedaldi']",ICLR,Support-set bottlenecks for video-text representation learning,https://iclr.cc/virtual/2021/spotlight/3462,2021," The dominant paradigm for learning video-text representations – noise contrastive learning – increases the similarity of the representations of pairs of samples that are known to be related, such as text and video from the same sample, and pushes away the representations of all other pairs. We posit that this last behaviour is too strict, enforcing dissimilar representations even for samples that are semantically-related – for example, visually similar videos or ones that share the same depicted action. In this paper, we propose a novel method that alleviates this by leveraging a generative model to naturally push these related samples together: each sample’s caption must be reconstructed as a weighted combination of a support set of visual representations. This simple idea ensures that representations are not overly-specialized to individual samples, are reusable across the dataset, and results in representations that explicitly encode semantics shared between samples, unlike noise contrastive learning. Our proposed method outperforms others by a large margin on MSR-VTT, VATEX, ActivityNet, and MSVD for video-to-text and text-to-video retrieval.",Oral Session 7,https://openreview.net/pdf?id=EqoXe2zmhrh,https://openreview.net/forum?id=EqoXe2zmhrh
"['John Co-Reyes', 'Yingjie Miao', 'Daiyi Peng', 'Esteban Real', 'Quoc V Le', 'Sergey Levine', 'Honglak Lee', 'Aleksandra Faust']",ICLR,Evolving Reinforcement Learning Algorithms,https://iclr.cc/virtual/2021/oral/3399,2021," We propose a method for meta-learning reinforcement learning algorithms by searching over the space of computational graphs which compute the loss function for a value-based model-free RL agent to optimize. The learned algorithms are domain-agnostic and can generalize to new environments not seen during training. Our method can both learn from scratch and bootstrap off known existing algorithms, like DQN, enabling interpretable modifications which improve performance. Learning from scratch on simple classical control and gridworld tasks, our method rediscovers the temporal-difference (TD) algorithm. Bootstrapped from DQN, we highlight two learned algorithms which obtain good generalization performance over other classical control tasks, gridworld type tasks, and Atari games. The analysis of the learned algorithm behavior shows resemblance to recently proposed RL algorithms that address overestimation in value-based methods.",Oral Session 8,https://openreview.net/pdf?id=0XXpJ4OtjW,https://openreview.net/forum?id=0XXpJ4OtjW
"['Taylor Webb', 'Ishan Sinha', 'Jonathan Cohen']",ICLR,Emergent Symbols through Binding in External Memory,https://iclr.cc/virtual/2021/spotlight/3467,2021," A key aspect of human intelligence is the ability to infer abstract rules directly from high-dimensional sensory data, and to do so given only a limited amount of training experience. Deep neural network algorithms have proven to be a powerful tool for learning directly from high-dimensional data, but currently lack this capacity for data-efficient induction of abstract rules, leading some to argue that symbol-processing mechanisms will be necessary to account for this capacity. In this work, we take a step toward bridging this gap by introducing the Emergent Symbol Binding Network (ESBN), a recurrent network augmented with an external memory that enables a form of variable-binding and indirection. This binding mechanism allows symbol-like representations to emerge through the learning process without the need to explicitly incorporate symbol-processing machinery, enabling the ESBN to learn rules in a manner that is abstracted away from the particular entities to which those rules apply. Across a series of tasks, we show that this architecture displays nearly perfect generalization of learned rules to novel entities given only a limited number of training examples, and outperforms a number of other competitive neural network architectures.",Oral Session 9,https://openreview.net/pdf?id=LSFCEb3GYU7,https://openreview.net/forum?id=LSFCEb3GYU7
"['Tobias Pfaff', 'Meire Fortunato', 'Alvaro Sanchez Gonzalez', 'Peter Battaglia']",ICLR,Learning Mesh-Based Simulation with Graph Networks,https://iclr.cc/virtual/2021/spotlight/3542,2021," Mesh-based simulations are central to modeling complex physical systems in many disciplines across science and engineering. Mesh representations support powerful numerical integration methods and their resolution can be adapted to strike favorable trade-offs between accuracy and efficiency. However, high-dimensional scientific simulations are very expensive to run, and solvers and parameters must often be tuned individually to each system studied.
Here we introduce MeshGraphNets, a framework for learning mesh-based simulations using graph neural networks. Our model can be trained to pass messages on a mesh graph and to adapt the mesh discretization during forward simulation. Our results show it can accurately predict the dynamics of a wide range of physical systems, including aerodynamics, structural mechanics, and cloth. The model's adaptivity supports learning resolution-independent dynamics and can scale to more complex state spaces at test time. Our method is also highly efficient, running 1-2 orders of magnitude faster than the simulation on which it is trained. Our approach broadens the range of problems on which neural network simulators can operate and promises to improve the efficiency of complex, scientific modeling tasks.",Outstanding Paper Session 1,https://openreview.net/pdf?id=roNqYL0_XP,https://openreview.net/forum?id=roNqYL0_XP
"['Aston Zhang', 'Yi Tay', 'Shuai Zhang', 'Alvin Chan', 'Anh Tuan Luu', 'Siu Hui', 'Jie Fu']",ICLR,Beyond Fully-Connected Layers with Quaternions: Parameterization of Hypercomplex Multiplications with $1/n$ Parameters,https://iclr.cc/virtual/2021/spotlight/3396,2021," Recent works have demonstrated reasonable success of representation learning in hypercomplex space. Specifically, “fully-connected layers with quaternions” (quaternions are 4D hypercomplex numbers), which replace real-valued matrix multiplications in fully-connected layers with Hamilton products of quaternions, both enjoy parameter savings with only 1/4 learnable parameters and achieve comparable performance in various applications. However, one key caveat is that hypercomplex space only exists at very few predefined dimensions (4D, 8D, and 16D). This restricts the flexibility of models that leverage hypercomplex multiplications. To this end, we propose parameterizing hypercomplex multiplications, allowing models to learn multiplication rules from data regardless of whether such rules are predefined. As a result, our method not only subsumes the Hamilton product, but also learns to operate on any arbitrary $n$D hypercomplex space, providing more architectural flexibility using arbitrarily $1/n$ learnable parameters compared with the fully-connected layer counterpart. Experiments of applications to the LSTM and transformer models on natural language inference, machine translation, text style transfer, and subject verb agreement demonstrate architectural flexibility and effectiveness of the proposed approach.",Outstanding Paper Session 2,https://openreview.net/pdf?id=rcQdycl0zyk,https://openreview.net/forum?id=rcQdycl0zyk
"['Zhiyuan Li', 'Yi Zhang', 'Sanjeev Arora']",ICLR,Why Are Convolutional Nets More Sample-Efficient than Fully-Connected Nets?,https://iclr.cc/virtual/2021/oral/3426,2021," Convolutional neural networks often dominate fully-connected counterparts in generalization performance, especially on image classification tasks. This is often explained in terms of \textquotedblleft better inductive bias.\textquotedblright\  However, this has not been made mathematically rigorous, and the hurdle is that the sufficiently wide fully-connected net can always simulate the convolutional net. Thus the training algorithm plays a role. The current work describes a natural task on which a provable sample complexity gap can be shown, for standard training algorithms. We construct a single natural distribution on $\mathbb{R}^d\times\{\pm 1\}$ on which any orthogonal-invariant algorithm (i.e. fully-connected networks trained with most gradient-based methods from gaussian initialization) requires $\Omega(d^2)$ samples to generalize while $O(1)$ samples suffice for convolutional architectures. Furthermore, we demonstrate a single target function, learning which on all possible distributions leads to an $O(1)$ vs $\Omega(d^2/\varepsilon)$ gap. The proof relies on the fact that SGD on fully-connected network is orthogonal equivariant. Similar results are achieved for $\ell_2$ regression and adaptive training algorithms, e.g. Adam and AdaGrad, which are only permutation equivariant.",Oral Session 11,https://openreview.net/pdf?id=uCY5MuAxcxU,https://openreview.net/forum?id=uCY5MuAxcxU
"['Adam Gleave', 'Michael Dennis', 'Shane Legg', 'Stuart Russell', 'Jan Leike']",ICLR,Quantifying Differences in Reward Functions,https://iclr.cc/virtual/2021/spotlight/3418,2021," For many tasks, the reward function is inaccessible to introspection or too complex to be specified procedurally, and must instead be learned from user data. Prior work has evaluated learned reward functions by evaluating policies optimized for the learned reward. However, this method cannot distinguish between the learned reward function failing to reflect user preferences and the policy optimization process failing to optimize the learned reward. Moreover, this method can only tell us about behavior in the evaluation environment, but the reward may incentivize very different behavior in even a slightly different deployment environment. To address these problems, we introduce the Equivalent-Policy Invariant Comparison (EPIC) distance to quantify the difference between two reward functions directly, without a policy optimization step. We prove EPIC is invariant on an equivalence class of reward functions that always induce the same optimal policy. Furthermore, we find EPIC can be efficiently approximated and is more robust than baselines to the choice of coverage distribution. Finally, we show that EPIC distance bounds the regret of optimal policies even under different transition dynamics, and we confirm empirically that it predicts policy training success. Our source code is available at https://github.com/HumanCompatibleAI/evaluating-rewards.",Oral Session 10,https://openreview.net/pdf?id=LwEQnp6CYev,https://openreview.net/forum?id=LwEQnp6CYev
"['Ruosong Wang', 'Dean Foster', 'Sham M Kakade']",ICLR,What are the Statistical Limits of Offline RL with Linear Function Approximation?,https://iclr.cc/virtual/2021/spotlight/3487,2021," Offline reinforcement learning seeks to utilize offline (observational) data to guide the learning of (causal) sequential decision making strategies. The hope is that offline reinforcement learning coupled with function approximation methods (to deal with the curse of dimensionality) can provide a means to help alleviate the excessive sample complexity burden in modern sequential decision making problems. However, the extent to which this broader approach can be effective is not well understood, where the literature largely consists of sufficient conditions. This work focuses on the basic question of what are necessary representational and distributional conditions that permit provable sample-efficient offline reinforcement learning. Perhaps surprisingly, our main result shows that even if: i) we have realizability in that the true value function of \emph{every} policy is linear in a given set of features and 2) our off-policy data has good  coverage over all features (under a strong spectral condition), any algorithm still (information-theoretically) requires a number of offline samples that is exponential in the problem horizon to non-trivially estimate the value of \emph{any} given policy. Our results highlight that sample-efficient offline policy evaluation is not possible unless significantly stronger conditions hold; such conditions include either having low distribution shift (where the offline data distribution is close to the distribution of the policy to be evaluated) or significantly stronger representational conditions (beyond realizability).",Oral Session 12,https://openreview.net/pdf?id=30EvkP2aQLD,https://openreview.net/forum?id=30EvkP2aQLD
"['David Klindt', 'Lukas Schott', 'Yash Sharma', 'Ivan Ustyuzhaninov', 'Wieland Brendel', 'Matthias Bethge', 'Dylan Paiton']",ICLR,Towards Nonlinear Disentanglement in Natural Data with Temporal Sparse Coding,https://iclr.cc/virtual/2021/oral/3443,2021," Disentangling the underlying generative factors from complex data has so far been limited to carefully constructed scenarios. We propose a path towards natural data by first showing that the statistics of natural data provide enough structure to enable disentanglement, both theoretically and empirically. Specifically, we provide evidence that objects in natural movies undergo transitions that are typically small in magnitude with occasional large jumps, which is characteristic of a temporally sparse distribution. To address this finding we provide a novel proof that relies on a sparse prior on temporally adjacent observations to recover the true latent variables up to permutations and sign flips, directly providing a stronger result than previous work. We show that equipping practical estimation methods with our prior often surpasses the current state-of-the-art on several established benchmark datasets without any impractical assumptions, such as knowledge of the number of changing generative factors. Furthermore, we contribute two new benchmarks, Natural Sprites and KITTI Masks, which integrate the measured natural dynamics to enable disentanglement evaluation with more realistic datasets. We leverage these benchmarks to test our theory, demonstrating improved performance. We also identify non-obvious challenges for current methods in scaling to more natural domains. Taken together our work addresses key issues in disentanglement research for moving towards more natural settings.",Oral Session 1,https://openreview.net/pdf?id=EbIDjBynYJ8,https://openreview.net/forum?id=EbIDjBynYJ8
"['Markus Rabe', 'Dennis Lee', 'Kshitij Bansal', 'Christian Szegedy']",ICLR,Mathematical Reasoning via Self-supervised Skip-tree Training,https://iclr.cc/virtual/2021/spotlight/3452,2021," We demonstrate that self-supervised language modeling applied to mathematical formulas enables logical reasoning. To measure the logical reasoning abilities of language models, we formulate several evaluation (downstream) tasks, such as inferring types, suggesting missing assumptions and completing equalities. For training language models for formal mathematics, we propose a novel skip-tree task. We find that models trained on the skip-tree task show surprisingly strong mathematical reasoning abilities, and outperform models trained on standard skip-sequence tasks. We also analyze the models' ability to formulate new conjectures by measuring how often the predictions are provable and useful in other proofs.",Oral Session 3,https://openreview.net/pdf?id=YmqAnY0CMEy,https://openreview.net/forum?id=YmqAnY0CMEy
"['Pim De Haan', 'Maurice Weiler', 'Taco Cohen', 'Max Welling']",ICLR,Gauge Equivariant Mesh CNNs: Anisotropic convolutions on geometric graphs,https://iclr.cc/virtual/2021/spotlight/3416,2021," A common approach to define convolutions on meshes is to interpret them as a graph and apply graph convolutional networks (GCNs).  Such GCNs utilize isotropic kernels and are therefore insensitive to the relative orientation of vertices and thus to the geometry of the mesh as a whole. We propose Gauge Equivariant Mesh CNNs which generalize GCNs to apply anisotropic gauge equivariant kernels. Since the resulting features carry orientation information, we introduce a geometric message passing scheme defined by parallel transporting features over mesh edges. Our experiments validate the significantly improved expressivity of the proposed model over conventional GCNs and other methods.",Oral Session 4,https://openreview.net/pdf?id=Jnspzp-oIZE,https://openreview.net/forum?id=Jnspzp-oIZE
"['Deniz Oktay', 'Nick McGreivy', 'Joshua Aduol', 'Alex Beatson', 'Ryan P Adams']",ICLR,Randomized Automatic Differentiation,https://iclr.cc/virtual/2021/oral/3515,2021," The successes of deep learning, variational inference, and many other fields have been aided by specialized implementations of reverse-mode automatic differentiation (AD) to compute gradients of mega-dimensional objectives. The AD techniques underlying these tools were designed to compute exact gradients to numerical precision, but modern machine learning models are almost always trained with stochastic gradient descent. Why spend computation and memory on exact (minibatch) gradients only to use them for stochastic optimization? We develop a general framework and approach for randomized automatic differentiation (RAD), which can allow unbiased gradient estimates to be computed with reduced memory in return for variance. We examine limitations of the general approach, and argue that we must leverage problem specific structure to realize benefits. We develop RAD techniques for a variety of simple neural network architectures, and show that for a fixed memory budget, RAD converges in fewer iterations than using a small batch size for feedforward networks, and in a similar number for recurrent networks. We also show that RAD can be applied to scientific computing, and use it to develop a low-memory stochastic gradient method for optimizing the control parameters of a linear reaction-diffusion PDE representing a fission reactor.",Oral Session 5,https://openreview.net/pdf?id=xpx9zj7CUlY,https://openreview.net/forum?id=xpx9zj7CUlY
"['Daniel Hsu', 'Ziwei Ji', 'Matus Telgarsky', 'Lan Wang']",ICLR,Generalization bounds via distillation,https://iclr.cc/virtual/2021/spotlight/3433,2021," This paper theoretically investigates the following empirical phenomenon: given a high-complexity network with poor generalization bounds, one can distill it into a network with nearly identical predictions but low complexity and vastly smaller generalization bounds.  The main contribution is an analysis showing that the original network inherits this good generalization bound from its distillation, assuming the use of well-behaved data augmentation.  This bound is presented both in an abstract and in a concrete form, the latter complemented by a reduction technique to handle modern computation graphs featuring convolutional layers, fully-connected layers, and skip connections, to name a few.  To round out the story, a (looser) classical uniform convergence analysis of compression is also presented, as well as a variety of experiments on cifar and mnist demonstrating similar generalization performance between the original network and its distillation.",Oral Session 2,https://openreview.net/pdf?id=EGdFhBzmAwB,https://openreview.net/forum?id=EGdFhBzmAwB
"['Huy Tuan Pham', 'Phan-Minh Nguyen']",ICLR,Global Convergence of Three-layer Neural Networks in the Mean Field Regime,https://iclr.cc/virtual/2021/oral/3513,2021," In the mean field regime, neural networks are appropriately scaled so that as the width tends to infinity, the learning dynamics tends to a nonlinear and nontrivial dynamical limit, known as the mean field limit. This lends a way to study large-width neural networks via analyzing the mean field limit. Recent works have successfully applied such analysis to two-layer networks and provided global convergence guarantees. The extension to multilayer ones however has been a highly challenging puzzle, and little is known about the optimization efficiency in the mean field regime when there are more than two layers. In this work, we prove a global convergence result for unregularized feedforward three-layer networks in the mean field regime. We first develop a rigorous framework to establish the mean field limit of three-layer networks under stochastic gradient descent training. To that end, we propose the idea of a neuronal embedding, which comprises of a fixed probability space that encapsulates neural networks of arbitrary sizes. The identified mean field limit is then used to prove a global convergence guarantee under suitable regularity and convergence mode assumptions, which – unlike previous works on two-layer networks – does not rely critically on convexity. Underlying the result is a universal approximation property, natural of neural networks, which importantly is shown to hold at any finite training time (not necessarily at convergence) via an algebraic topology argument.",Oral Session 6,https://openreview.net/pdf?id=KvyxFqZS_D,https://openreview.net/forum?id=KvyxFqZS_D
"['Javier Antorán', 'Umang Bhatt', 'Tameem Adel', 'Adrian Weller', 'José Miguel Hernández Lobato']",ICLR,Getting a CLUE: A  Method for Explaining Uncertainty Estimates,https://iclr.cc/virtual/2021/oral/3505,2021," Both uncertainty estimation and interpretability are important factors for trustworthy machine learning systems. However, there is little work at the intersection of these two areas. We address this gap by proposing a novel method for interpreting uncertainty estimates from differentiable probabilistic models, like Bayesian Neural Networks (BNNs). Our method, Counterfactual Latent Uncertainty Explanations (CLUE), indicates how to change an input, while keeping it on the data manifold, such that a BNN becomes more confident about the input's prediction. We validate CLUE through 1) a novel framework for evaluating counterfactual explanations of uncertainty, 2) a series of ablation experiments, and 3) a user study. Our experiments show that CLUE outperforms baselines and enables practitioners to better understand which input patterns are responsible for predictive uncertainty.",Oral Session 7,https://openreview.net/pdf?id=XSLF1XFq5h,https://openreview.net/forum?id=XSLF1XFq5h
"['Xizhou Zhu', 'Weijie Su', 'Lewei Lu', 'Bin Li', 'Xiaogang Wang', 'Jifeng Dai']",ICLR,Deformable DETR: Deformable Transformers for End-to-End Object Detection,https://iclr.cc/virtual/2021/oral/3448,2021," DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR, whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10$\times$ less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach. Code is released at https://github.com/fundamentalvision/Deformable-DETR.",Oral Session 9,https://openreview.net/pdf?id=gZ9hCDWe6ke,https://openreview.net/forum?id=gZ9hCDWe6ke
"['Denis Yarats', 'Ilya Kostrikov', 'Rob Fergus']",ICLR,Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels,https://iclr.cc/virtual/2021/spotlight/3441,2021," We propose a simple data augmentation technique that can be applied to standard model-free reinforcement learning algorithms, enabling robust learning directly from pixels without the need for auxiliary losses or pre-training.  The approach leverages input perturbations commonly used in computer vision tasks to transform input examples, as well as regularizing the value function and policy.  Existing model-free approaches, such as Soft Actor-Critic (SAC), are not able to train deep networks effectively from image pixels. However, the addition of our augmentation method dramatically improves SAC’s performance, enabling it to reach state-of-the-art performance on the DeepMind control suite, surpassing model-based (Hafner et al., 2019; Lee et al., 2019; Hafner et al., 2018) methods and recently proposed contrastive learning (Srinivas et al., 2020).  Our approach, which we dub DrQ: Data-regularized Q, can be combined with any model-free reinforcement learning algorithm. We further demonstrate this by applying it to DQN and significantly improve its data-efficiency on the Atari 100k benchmark.",Oral Session 8,https://openreview.net/pdf?id=GY6-6sTvGaf,https://openreview.net/forum?id=GY6-6sTvGaf
"['Sanjeevan Ahilan', 'Peter Dayan']",ICLR,Correcting experience replay for multi-agent communication,https://iclr.cc/virtual/2021/spotlight/3469,2021," We consider the problem of learning to communicate using multi-agent reinforcement learning (MARL). A common approach is to learn off-policy, using data sampled from a replay buffer. However, messages received in the past may not accurately reflect the current communication policy of each agent, and this complicates learning. We therefore introduce a 'communication correction' which accounts for the non-stationarity of observed communication induced by multi-agent learning. It works by relabelling the received message to make it likely under the communicator's current policy, and thus be a better reflection of the receiver's current environment. To account for cases in which agents are both senders and receivers, we introduce an ordered relabelling scheme. Our correction is computationally efficient and can be integrated with a range of off-policy algorithms. We find in our experiments that it substantially improves the ability of communicating MARL systems to learn across a variety of cooperative and competitive tasks.",Oral Session 11,https://openreview.net/pdf?id=xvxPuCkCNPO,https://openreview.net/forum?id=xvxPuCkCNPO
"['Max Smith', 'Thomas Anthony', 'Michael Wellman']",ICLR,Iterative Empirical Game Solving via Single Policy Best Response,https://iclr.cc/virtual/2021/spotlight/3518,2021," Policy-Space Response Oracles (PSRO) is a general algorithmic framework for learning policies in multiagent systems by interleaving empirical game analysis with deep reinforcement learning (DRL).
At each iteration, DRL is invoked to train a best response to a mixture of opponent policies.
The repeated application of DRL poses an expensive computational burden as we look to apply this algorithm to more complex domains.
We introduce two variations of PSRO designed to reduce the amount of simulation required during DRL training.
Both algorithms modify how PSRO adds new policies to the empirical game, based on learned responses to a single opponent policy.
The first, Mixed-Oracles, transfers knowledge from previous iterations of DRL, requiring training only against the opponent's newest policy.
The second, Mixed-Opponents, constructs a pure-strategy opponent by mixing existing strategy's action-value estimates, instead of their policies.
Learning against a single policy mitigates conflicting experiences on behalf of a learner facing an unobserved distribution of opponents.
We empirically demonstrate that these algorithms substantially reduce the amount of simulation during training required by PSRO, while producing equivalent or better solutions to the game.",Oral Session 10,https://openreview.net/pdf?id=R4aWTjmrEKM,https://openreview.net/forum?id=R4aWTjmrEKM
"['Naichen Shi', 'Dawei Li', 'Mingyi Hong', 'Ruoyu Sun']",ICLR,RMSprop converges with proper hyper-parameter,https://iclr.cc/virtual/2021/spotlight/3415,2021," Despite the existence of divergence examples, RMSprop remains 
one of the most popular algorithms in machine learning. Towards closing the gap between theory and practice, we prove that RMSprop converges with proper choice of hyper-parameters under certain conditions. More specifically, we prove that when the hyper-parameter $\beta_2$ is close enough to $1$, RMSprop and its random shuffling version converge to a bounded region in general, and to critical points in the interpolation regime. It is worth mentioning that our results do not depend on  ``bounded gradient""  assumption, which is often the key assumption utilized by existing theoretical work for Adam-type adaptive gradient method. Removing this assumption allows us to establish a phase transition from divergence to non-divergence for RMSprop. 

Finally, based on our theory, we conjecture that in practice there is a critical threshold $\sf{\beta_2^*}$, such that RMSprop generates reasonably good results only if $1>\beta_2\ge \sf{\beta_2^*}$. We provide empirical evidence for such a phase transition in our numerical experiments.",Oral Session 12,https://openreview.net/pdf?id=3UDSdyIcBDA,https://openreview.net/forum?id=3UDSdyIcBDA
"['Max B Paulus', 'Chris Maddison', 'Andreas Krause']",ICLR,Rao-Blackwellizing the Straight-Through Gumbel-Softmax Gradient Estimator,https://iclr.cc/virtual/2021/oral/3508,2021," Gradient estimation in models with discrete latent variables is a challenging problem, because the simplest unbiased estimators tend to have high variance. To counteract this, modern estimators either introduce bias, rely on multiple function evaluations, or use learned, input-dependent baselines. Thus, there is a need for estimators that require minimal tuning, are computationally cheap, and have low mean squared error. In this paper, we show that the variance of the straight-through variant of the popular Gumbel-Softmax estimator can be reduced through Rao-Blackwellization without increasing the number of function evaluations. This provably reduces the mean squared error. We empirically demonstrate that this leads to variance reduction, faster convergence, and generally improved performance in two unsupervised latent variable models.",Oral Session 4,https://openreview.net/pdf?id=Mk6PZtgAgfq,https://openreview.net/forum?id=Mk6PZtgAgfq
"['Muhammad Khalifa', 'Hady Elsahar', 'Marc Dymetman']",ICLR,A Distributional Approach to Controlled Text Generation,https://iclr.cc/virtual/2021/oral/3493,2021," We propose a  Distributional  Approach for addressing  Controlled  Text  Generation from pre-trained Language Models (LM). This approach permits to specify, in a single formal framework, both “pointwise’” and “distributional” constraints over the target LM — to our knowledge, the first model with such generality —while minimizing KL divergence from the initial LM distribution.  The optimal target distribution is then uniquely determined as an explicit EBM (Energy-BasedModel) representation. From that optimal representation, we then train a target controlled Autoregressive LM through an adaptive distributional variant of PolicyGradient.  We conduct a first set of experiments over pointwise constraints showing the advantages of our approach over a set of baselines, in terms of obtaining a controlled LM balancing constraint satisfaction with divergence from the pretrained LM.  We then perform experiments over distributional constraints, a unique feature of our approach, demonstrating its potential as a remedy to the problem of Bias in Language Models.  Through an ablation study, we show the effectiveness of our adaptive technique for obtaining faster convergence.
Code available at https://github.com/naver/gdc",Oral Session 1,https://openreview.net/pdf?id=jWkw45-9AbL,https://openreview.net/forum?id=jWkw45-9AbL
"['Yang Bai', 'Yuyuan Zeng', 'Yong Jiang', 'Shu-Tao Xia', 'Xingjun Ma', 'Yisen Wang']",ICLR,Improving Adversarial Robustness via Channel-wise Activation Suppressing,https://iclr.cc/virtual/2021/spotlight/3488,2021," The study of adversarial examples and their activations have attracted significant attention for secure and robust learning with deep neural networks (DNNs).  Different from existing works, in this paper, we highlight two new characteristics of adversarial examples from the channel-wise activation perspective:  1) the activation magnitudes of adversarial examples are higher than that of natural examples; and 2) the channels are activated more uniformly by adversarial examples than natural examples. We find that, while the state-of-the-art defense adversarial training has addressed the first issue of high activation magnitude via training on adversarial examples, the second issue of uniform activation remains.  This motivates us to suppress redundant activations from being activated by adversarial perturbations during the adversarial training process, via a Channel-wise Activation Suppressing (CAS) training strategy.  We show that CAS can train a model that inherently suppresses adversarial activations, and can be easily applied to existing defense methods to further improve their robustness. Our work provides a simplebut generic training strategy for robustifying the intermediate layer activations of DNNs.",Oral Session 3,https://openreview.net/pdf?id=zQTezqCCtNx,https://openreview.net/forum?id=zQTezqCCtNx
"['Yuxuan Zhang', 'Wenzheng Chen', 'Huan Ling', 'Jun Gao', 'Yinan Zhang', 'Antonio Torralba', 'Sanja Fidler']",ICLR,Image GANs meet Differentiable Rendering for Inverse Graphics and Interpretable 3D Neural Rendering,https://iclr.cc/virtual/2021/oral/3438,2021," Differentiable rendering has paved the way to training neural networks to perform “inverse graphics” tasks such as predicting 3D geometry from monocular photographs. To train high performing models, most of the current approaches rely on multi-view imagery which are not readily available in practice.  Recent Generative Adversarial Networks (GANs) that synthesize images, in contrast, seem to acquire 3D knowledge implicitly during training: object viewpoints can be manipulated by simply manipulating the latent codes. However, these latent codes often lack further physical interpretation and thus GANs cannot easily be inverted to perform explicit 3D reasoning. In this paper, we aim to extract and disentangle 3D knowledge learned by generative models by utilizing differentiable renderers. Key to our approach is to exploit GANs as a multi-view data generator to train an inverse graphics network using an off-the-shelf differentiable renderer, and the trained inverse graphics network as a teacher to disentangle the GAN's latent code into interpretable 3D properties. The entire architecture is trained iteratively using cycle consistency losses. We show that our approach significantly outperforms state-of-the-art inverse graphics networks trained on existing datasets, both quantitatively and via user studies. We further showcase the disentangled GAN as a controllable 3D “neural renderer"", complementing traditional graphics renderers.",Oral Session 5,https://openreview.net/pdf?id=yWkP7JuHX1,https://openreview.net/forum?id=yWkP7JuHX1
['Kenji Kawaguchi'],ICLR,On the Theory of Implicit Deep Learning: Global Convergence with Implicit Layers,https://iclr.cc/virtual/2021/spotlight/3393,2021," A deep equilibrium model uses implicit layers, which are implicitly defined through an equilibrium point of an infinite sequence of computation. It avoids any explicit computation of the infinite sequence by finding an equilibrium point directly via root-finding and by computing gradients via implicit differentiation. In this paper, we analyze the gradient dynamics of deep equilibrium models with nonlinearity only on weight matrices and non-convex objective functions of weights for regression and classification. Despite non-convexity, convergence to global optimum at a linear rate is guaranteed without any assumption on the width of the models, allowing the width to be smaller than the output dimension and the number of data points. Moreover, we prove a relation between the gradient dynamics of the deep implicit layer and the dynamics of trust region Newton method of a shallow explicit layer. This mathematically proven relation along with our numerical observation suggests the importance of understanding implicit bias of implicit layers and an open problem on the topic. Our proofs deal with implicit layers, weight tying and nonlinearity on weights, and differ from those in the related literature.",Oral Session 2,https://openreview.net/pdf?id=p-NZIuwqhI4,https://openreview.net/forum?id=p-NZIuwqhI4
"['Sejun Park', 'Chulhee Yun', 'Jaeho Lee', 'Jinwoo Shin']",ICLR,Minimum Width for Universal Approximation,https://iclr.cc/virtual/2021/spotlight/3473,2021," The universal approximation property of width-bounded networks has been studied as a dual of classical universal approximation results on depth-bounded networks. However, the critical width enabling the universal approximation has not been exactly characterized in terms of the input dimension $d_x$ and the output dimension $d_y$. In this work, we provide the first definitive result in this direction for networks using the ReLU activation functions: The minimum width required for the universal approximation of the $L^p$ functions is exactly $\max\{d_x+1,d_y\}$. We also prove that the same conclusion does not hold for the uniform approximation with ReLU, but does hold with an additional threshold activation function. Our proof technique can be also used to derive a tighter upper bound on the minimum width required for the universal approximation using networks with general activation functions.",Oral Session 6,https://openreview.net/pdf?id=O-XJwyoIF-k,https://openreview.net/forum?id=O-XJwyoIF-k
"['Naoyuki Terashita', 'Hiroki Ohashi', 'Yuichi Nonaka', 'Takashi Kanemaru']",ICLR,Influence Estimation for Generative Adversarial Networks,https://iclr.cc/virtual/2021/spotlight/3466,2021," Identifying harmful instances, whose absence in a training dataset improves model performance, is important for building better machine learning models. 
Although previous studies have succeeded in estimating harmful instances under supervised settings, they cannot be trivially extended to generative adversarial networks (GANs).
This is because previous approaches require that (i) the absence of a training instance directly affects the loss value and that (ii) the change in the loss directly measures the harmfulness of the instance for the performance of a model. 
In GAN training, however, neither of the requirements is satisfied. 
This is because, (i) the generator’s loss is not directly affected by the training instances as they are not part of the generator's training steps, and (ii) the values of GAN's losses normally do not capture the generative performance of a model.
To this end, (i) we propose an influence estimation method that uses the Jacobian of the gradient of the generator's loss with respect to the discriminator’s parameters (and vice versa) to trace how the absence of an instance in the discriminator’s training affects the generator’s parameters, and (ii) we propose a novel evaluation scheme, in which we assess harmfulness of each training instance on the basis of how GAN evaluation metric (e.g., inception score) is expected to change due to the removal of the instance.
We experimentally verified that our influence estimation method correctly inferred the changes in GAN evaluation metrics.
We also demonstrated that the removal of the identified harmful instances effectively improved the model’s generative performance with respect to various GAN evaluation metrics.",Oral Session 7,https://openreview.net/pdf?id=opHLcXxYTC_,https://openreview.net/forum?id=opHLcXxYTC_
"['Binh Tang', 'David S Matteson']",ICLR,Graph-Based Continual Learning,https://iclr.cc/virtual/2021/spotlight/3535,2021," Despite significant advances, continual learning models still suffer from catastrophic forgetting when exposed to incrementally available data from non-stationary distributions. Rehearsal approaches alleviate the problem by maintaining and replaying a small episodic memory of previous samples, often implemented as an array of independent memory slots. In this work, we propose to augment such an array with a learnable random graph that captures pairwise similarities between its samples, and use it not only to learn new tasks but also to guard against forgetting. Empirical results on several benchmark datasets show that our model consistently outperforms recently proposed baselines for task-free continual learning.",Oral Session 9,https://openreview.net/pdf?id=HHSEKOnPvaO,https://openreview.net/forum?id=HHSEKOnPvaO
"['T. Konstantin Rusch', 'Siddhartha Mishra']",ICLR,Coupled Oscillatory Recurrent Neural Network (coRNN): An accurate and (gradient) stable architecture for learning long time dependencies,https://iclr.cc/virtual/2021/oral/3381,2021," Circuits of biological neurons, such as in the functional parts of the brain can be modeled as networks of coupled oscillators. Inspired by the ability of these systems to express a rich set of outputs while keeping (gradients of) state variables bounded, we propose a novel architecture for recurrent neural networks. Our proposed RNN is based on a time-discretization of a system of second-order ordinary differential equations, modeling networks of controlled nonlinear oscillators. We prove precise bounds on the gradients of the hidden states, leading to the mitigation of the exploding and vanishing gradient problem for this RNN. Experiments show that the proposed RNN is comparable in performance to the state of the art on a variety of benchmarks, demonstrating the potential of this architecture to provide stable and accurate RNNs for processing complex sequential data.",Oral Session 8,https://openreview.net/pdf?id=F3s69XzWOia,https://openreview.net/forum?id=F3s69XzWOia
"['Rishabh Agarwal', 'Marlos C. Machado', 'Pablo Samuel Castro', 'Marc G Bellemare']",ICLR,Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning,https://iclr.cc/virtual/2021/spotlight/3525,2021," Reinforcement learning methods trained on few environments rarely learn policies that generalize to unseen environments. To improve generalization, we incorporate the inherent sequential structure in reinforcement learning into the representation learning process. This approach is orthogonal to recent approaches, which rarely exploit this structure explicitly. Specifically, we introduce a theoretically motivated policy similarity metric (PSM) for measuring behavioral similarity between states. PSM assigns high similarity to states for which the optimal policies in those states as well as in future states are similar. We also present a contrastive representation learning procedure to embed any state similarity metric, which we instantiate with PSM to obtain policy similarity embeddings (PSEs). We demonstrate that PSEs improve generalization on diverse benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control Suite.",Oral Session 11,https://openreview.net/pdf?id=qda7-sVg84,https://openreview.net/forum?id=qda7-sVg84
"['Yu Tian', 'Jian Ren', 'Menglei Chai', 'Kyle Olszewski', 'Xi Peng', 'Dimitris Metaxas', 'Sergey Tulyakov']",ICLR,A Good Image Generator Is What You Need for High-Resolution Video Synthesis,https://iclr.cc/virtual/2021/spotlight/3490,2021," Image and video synthesis are closely related areas aiming at generating content from noise. While rapid progress has been demonstrated in improving image-based models to handle large resolutions, high-quality renderings, and wide variations in image content, achieving comparable video generation results remains problematic. We present a framework that leverages contemporary image generators to render high-resolution videos. We frame the video synthesis problem as discovering a trajectory in the latent space of a pre-trained and fixed image generator. Not only does such a framework render high-resolution videos, but it also is an order of magnitude more computationally efficient. We introduce a motion generator that discovers the desired trajectory, in which content and motion are disentangled. With such a representation, our framework allows for a broad range of applications, including content and motion manipulation. Furthermore, we introduce a new task, which we call cross-domain video synthesis, in which the image and motion generators are trained on disjoint datasets belonging to different domains. This allows for generating moving objects for which the desired video data is not available. Extensive experiments on various datasets demonstrate the advantages of our methods over existing video generation techniques. Code will be released at https://github.com/snap-research/MoCoGAN-HD.",Oral Session 12,https://openreview.net/pdf?id=6puCSjH3hwA,https://openreview.net/forum?id=6puCSjH3hwA
"['Tom Zahavy', 'Andre Barreto', 'Daniel J Mankowitz', 'Shaobo Hou', 'Brendan ODonoghue', 'Iurii Kemaev', 'Satinder Singh']",ICLR,Discovering a set of policies for the worst case reward,https://iclr.cc/virtual/2021/spotlight/3392,2021," We study the problem of how to construct a set of policies that can be composed together to solve a collection of reinforcement learning tasks. Each task is a different reward function defined as a linear combination of  known features. We consider a specific class of policy compositions which we call set improving policies (SIPs): given a set of policies and a set of tasks, a SIP is any composition of the former whose performance is at least as good as that of its constituents across all the tasks. We focus on the most conservative instantiation of SIPs, set-max policies (SMPs), so our analysis extends to any SIP. This includes known policy-composition operators like generalized policy improvement. Our main contribution is an algorithm that builds a set of policies in order to maximize the worst-case performance of the resulting SMP on the set of tasks. The algorithm works by successively adding new policies to the set. We show that the worst-case performance of the resulting SMP strictly improves at each iteration, and the algorithm only stops when there does not exist a policy that leads to improved performance. We empirically evaluate our algorithm on a grid world and also on a set of domains from the DeepMind control suite. We confirm our theoretical results regarding the monotonically improving performance of our algorithm. Interestingly, we also show empirically that the sets of policies computed by the algorithm are diverse, leading to different trajectories in the grid world and very distinct locomotion skills in the control suite.",Oral Session 10,https://openreview.net/pdf?id=PUkhWz65dy5,https://openreview.net/forum?id=PUkhWz65dy5
"['Aymeric Fromherz', 'Klas Leino', 'Matt Fredrikson', 'Bryan Parno', 'Corina Pasareanu']",ICLR,Fast Geometric Projections for Local Robustness Certification,https://iclr.cc/virtual/2021/spotlight/3423,2021," Local robustness ensures that a model classifies all inputs within an $\ell_p$-ball consistently, which precludes various forms of adversarial inputs.
In this paper, we present a fast procedure for checking local robustness in feed-forward neural networks with piecewise-linear activation functions.
Such networks partition the input space into a set of convex polyhedral regions in which the network’s behavior is linear; 
hence, a systematic search for decision boundaries within the regions around a given input is sufficient for assessing robustness.
Crucially, we show how the regions around a point can be analyzed using simple geometric projections, thus admitting an efficient, highly-parallel GPU implementation that excels particularly for the $\ell_2$ norm, where previous work has been less effective.
Empirically we find this approach to be far more precise than many approximate verification approaches, while at the same time performing multiple orders of magnitude faster than complete verifiers, and scaling to much deeper networks.",Oral Session 3,https://openreview.net/pdf?id=zWy1uxjDdZJ,https://openreview.net/forum?id=zWy1uxjDdZJ
"['Mike Gartrell', 'Insu Han', 'Elvis Dohmatob', 'Jennifer Gillenwater', 'Victor-Emmanuel Brunel']",ICLR,Scalable Learning and MAP Inference for Nonsymmetric Determinantal Point Processes,https://iclr.cc/virtual/2021/oral/3519,2021," Determinantal point processes (DPPs) have attracted significant attention in machine learning for their ability to model subsets drawn from a large item collection. Recent work shows that nonsymmetric DPP (NDPP) kernels have significant advantages over symmetric kernels in terms of modeling power and predictive performance. However, for an item collection of size $M$, existing NDPP learning and inference algorithms require memory quadratic in $M$ and runtime cubic (for learning) or quadratic (for inference) in $M$, making them impractical for many typical subset selection tasks. In this work, we develop a learning algorithm with space and time requirements linear in $M$ by introducing a new NDPP kernel decomposition. We also derive a linear-complexity NDPP maximum a posteriori (MAP) inference algorithm that applies not only to our new kernel but also to that of prior work. Through evaluation on real-world datasets, we show that our algorithms scale significantly better, and can match the predictive performance of prior work.",Oral Session 4,https://openreview.net/pdf?id=HajQFbx_yB,https://openreview.net/forum?id=HajQFbx_yB
"['Phil Pope', 'Chen Zhu', 'Ahmed Abdelkader', 'Micah Goldblum', 'Tom Goldstein']",ICLR,The Intrinsic Dimension of Images and Its Impact on Learning,https://iclr.cc/virtual/2021/spotlight/3436,2021," It is widely believed that natural image data exhibits low-dimensional structure despite the high dimensionality of conventional pixel representations.  This idea underlies a common intuition for the remarkable success of deep learning in computer vision. In this work, we apply dimension estimation tools to popular datasets and investigate the role of low-dimensional structure in deep learning.  We find that common natural image datasets indeed have very low intrinsic dimension relative to the high number of pixels in the images.  Additionally, we find that low dimensional datasets are easier for neural networks to learn, and models solving these tasks generalize better from training to test data.   Along the way,  we develop a technique for validating our dimension estimation tools on synthetic data generated by GANs allowing us to actively manipulate the intrinsic dimension by controlling the image generation process. Code for our experiments may be found  \href{https://github.com/ppope/dimensions}{here}.",Oral Session 1,https://openreview.net/pdf?id=XJk19XzGq2J,https://openreview.net/forum?id=XJk19XzGq2J
"['Pierre Foret', 'Ariel Kleiner', 'Hossein Mobahi', 'Behnam Neyshabur']",ICLR,Sharpness-aware Minimization for Efficiently Improving Generalization,https://iclr.cc/virtual/2021/spotlight/3497,2021," In today's heavily overparameterized models, the value of the training loss provides few guarantees on model generalization ability. Indeed, optimizing only the training loss value, as is commonly done, can easily lead to suboptimal model quality. Motivated by the connection between geometry of the loss landscape and generalization---including a generalization bound that we prove here---we introduce a novel, effective procedure for instead simultaneously minimizing loss value and loss sharpness.  In particular, our procedure, Sharpness-Aware Minimization (SAM), seeks parameters that lie in neighborhoods having uniformly low loss; this formulation results in a min-max optimization problem on which gradient descent can be performed efficiently. We present empirical results showing that SAM improves model generalization across a variety of benchmark datasets (e.g., CIFAR-{10, 100}, ImageNet, finetuning tasks) and models, yielding novel state-of-the-art performance for several.  Additionally, we find that SAM natively provides robustness to label noise on par with that provided by state-of-the-art procedures that specifically target learning with noisy labels.",Oral Session 2,https://openreview.net/pdf?id=6Tm1mposlrM,https://openreview.net/forum?id=6Tm1mposlrM
"['Bilal Alsallakh', 'Narine Kokhlikyan', 'Vivek Miglani', 'Jun Yuan', 'Orion Reblitz-Richardson']",ICLR,Mind the Pad -- CNNs Can Develop Blind Spots,https://iclr.cc/virtual/2021/spotlight/3427,2021," We show how feature maps in convolutional networks are susceptible to spatial bias. Due to a combination of architectural choices, the activation at certain locations is systematically elevated or weakened. The major source of this bias is the padding mechanism. Depending on several aspects of convolution arithmetic, this mechanism can apply the padding unevenly, leading to asymmetries in the learned weights. We demonstrate how such bias can be detrimental to certain tasks such as small object detection: the activation is suppressed if the stimulus lies in the impacted area, leading to blind spots and misdetection. We explore alternative padding methods and propose solutions for analyzing and mitigating spatial bias.",Oral Session 5,https://openreview.net/pdf?id=m1CD7tPubNy,https://openreview.net/forum?id=m1CD7tPubNy
"['Yu Sun', 'Jiaming Liu', 'Yiran Sun', 'Brendt Wohlberg', 'Ulugbek Kamilov']",ICLR,Async-RED: A Provably Convergent Asynchronous Block Parallel Stochastic Method using Deep Denoising Priors,https://iclr.cc/virtual/2021/spotlight/3400,2021," Regularization by denoising (RED) is a recently developed framework for solving inverse problems by integrating advanced denoisers as image priors. Recent work has shown its state-of-the-art performance when combined with pre-trained deep denoisers. However, current RED algorithms are inadequate for parallel processing on multicore systems. We address this issue by proposing a new{asynchronous RED (Async-RED) algorithm that enables asynchronous parallel processing of data, making it significantly faster than its serial counterparts for large-scale inverse problems. The computational complexity of Async-RED is further reduced by using a random subset of measurements at every iteration. We present a complete theoretical analysis of the algorithm by establishing its convergence under explicit assumptions on the data-fidelity and the denoiser. We validate Async-RED on image recovery using pre-trained deep denoisers as priors.",Oral Session 6,https://openreview.net/pdf?id=9EsrXMzlFQY,https://openreview.net/forum?id=9EsrXMzlFQY
"['Gege Qi', 'Lijun GONG', 'Yibing Song', 'Kai Ma', 'Yefeng Zheng']",ICLR,Stabilized Medical Image Attacks,https://iclr.cc/virtual/2021/spotlight/3419,2021," Convolutional Neural Networks (CNNs) have advanced existing medical systems for automatic disease diagnosis. However, a threat to these systems arises that adversarial attacks make CNNs vulnerable. Inaccurate diagnosis results make a negative influence on human healthcare. There is a need to investigate potential adversarial attacks to robustify deep medical diagnosis systems. On the other side, there are several modalities of medical images (e.g., CT, fundus, and endoscopic image) of which each type is significantly different from others. It is more challenging to generate adversarial perturbations for different types of medical images. In this paper, we propose an image-based medical adversarial attack method to consistently produce adversarial perturbations on medical images. The objective function of our method consists of a loss deviation term and a loss stabilization term. The loss deviation term increases the divergence between the CNN prediction of an adversarial example and its ground truth label. Meanwhile, the loss stabilization term ensures similar CNN predictions of this example and its smoothed input. From the perspective of the whole iterations for perturbation generation, the proposed loss stabilization term exhaustively searches the perturbation space to smooth the single spot for local optimum escape. We further analyze the KL-divergence of the proposed loss function and find that the loss stabilization term makes the perturbations updated towards a fixed objective spot while deviating from the ground truth. This stabilization ensures the proposed medical attack effective for different types of medical images while producing perturbations in small variance. Experiments on several medical image analysis benchmarks including the recent COVID-19 dataset show the stability of the proposed method.",Oral Session 7,https://openreview.net/pdf?id=QfTXQiGYudJ,https://openreview.net/forum?id=QfTXQiGYudJ
"['Da Xu', 'Yuting Ye', 'Chuanwei Ruan']",ICLR,Understanding the role of importance weighting for deep learning,https://iclr.cc/virtual/2021/spotlight/3517,2021," The recent paper by Byrd & Lipton (2019), based on empirical observations, raises a major concern on the impact of importance weighting for the over-parameterized deep learning models. They observe that as long as the model can separate the training data, the impact of importance weighting diminishes as the training proceeds. Nevertheless, there lacks a rigorous characterization of this phenomenon. In this paper, we provide formal characterizations and theoretical justifications on the role of importance weighting with respect to the implicit bias of gradient descent and margin-based learning theory. We reveal both the optimization dynamics and generalization performance under deep learning models. Our work not only explains the various novel phenomenons observed for importance weighting in deep learning, but also extends to the studies where the weights are being optimized as part of the model, which applies to a number of topics under active research.",Oral Session 9,https://openreview.net/pdf?id=_WnwtieRHxM,https://openreview.net/forum?id=_WnwtieRHxM
"['Akinori Ebihara', 'Taiki Miyagawa', 'Kazuyuki Sakurai', 'Hitoshi Imaoka']",ICLR,Sequential Density Ratio Estimation for Simultaneous Optimization of Speed and Accuracy,https://iclr.cc/virtual/2021/spotlight/3404,2021," Classifying sequential data as early and as accurately as possible is a challenging yet critical problem, especially when a sampling cost is high. One algorithm that achieves this goal is the sequential probability ratio test (SPRT), which is known as Bayes-optimal: it can keep the expected number of data samples as small as possible, given the desired error upper-bound. However, the original SPRT makes two critical assumptions that limit its application in real-world scenarios: (i) samples are independently and identically distributed, and (ii) the likelihood of the data being derived from each class can be calculated precisely. Here, we propose the SPRT-TANDEM, a deep neural network-based SPRT algorithm that overcomes the above two obstacles. The SPRT-TANDEM sequentially estimates the log-likelihood ratio of two alternative hypotheses by leveraging a novel Loss function for Log-Likelihood Ratio estimation (LLLR) while allowing correlations up to $N (\in \mathbb{N})$  preceding samples. In tests on one original and two public video databases, Nosaic MNIST, UCF101, and SiW, the SPRT-TANDEM achieves statistically significantly better classification accuracy than other baseline classifiers, with a smaller number of data samples. The code and Nosaic MNIST are publicly available at https://github.com/TaikiMiyagawa/SPRT-TANDEM.",Oral Session 8,https://openreview.net/pdf?id=Rhsu5qD36cL,https://openreview.net/forum?id=Rhsu5qD36cL
"['aayam shrestha', 'Stefan Lee', 'Prasad Tadepalli', 'Alan Fern']",ICLR,DeepAveragers: Offline Reinforcement Learning By Solving Derived Non-Parametric MDPs,https://iclr.cc/virtual/2021/spotlight/3450,2021," We study an approach to offline reinforcement learning (RL) based on optimally solving  finitely-represented  MDPs  derived  from  a  static  dataset  of  experience. This approach can be applied on top of any learned representation and has the potential to easily support multiple solution objectives as well as zero-shot adjustment to changing environments and goals.  Our main contribution is to introduce the Deep Averagers with Costs MDP (DAC-MDP) and to investigate its solutions for offline RL.  DAC-MDPs are a non-parametric model that can leverage deep representations and account for limited data by introducing costs for exploiting under-represented parts of the model.  In theory, we show conditions that allow for lower-bounding the performance of DAC-MDP solutions. We also investigate the empirical behavior in a number of environments, including those with image-based observations. Overall, the experiments demonstrate that the framework can work in practice and scale to large complex offline RL problems.",Oral Session 11,https://openreview.net/pdf?id=eMP1j9efXtX,https://openreview.net/forum?id=eMP1j9efXtX
"['Hao Peng', 'Nikolaos Pappas', 'Dani Yogatama', 'Roy Schwartz', 'Noah Smith', 'Lingpeng Kong']",ICLR,Random Feature Attention,https://iclr.cc/virtual/2021/spotlight/3545,2021," Transformers are state-of-the-art models for a variety of sequence modeling tasks. At their core is an attention function which models pairwise interactions between the inputs at every timestep. While attention is powerful, it does not scale efficiently to long sequences due to its quadratic time and space complexity in the sequence length. We propose RFA, a linear time and space attention that uses random feature methods to approximate the softmax function, and explore its application in transformers. RFA can be used as a drop-in replacement for conventional softmax attention and offers a straightforward way of learning with recency bias through an optional gating mechanism. Experiments on language modeling and machine translation demonstrate that RFA achieves similar or better performance compared to strong transformer baselines. In the machine translation experiment, RFA decodes twice as fast as a vanilla transformer. Compared to existing efficient transformer variants, RFA is competitive in terms of both accuracy and efficiency on three long text classification datasets. Our analysis shows that RFA’s efficiency gains are especially notable on long sequences, suggesting that RFA will be particularly useful in tasks that require working with large inputs, fast decoding speed, or low memory footprints.",Oral Session 12,https://openreview.net/pdf?id=QtTKTdVrFBB,https://openreview.net/forum?id=QtTKTdVrFBB
"['Yuan Yin', 'Vincent Le Guen', 'Jérémie DONA', 'Emmanuel d Bezenac', 'Ibrahim Ayed', 'Nicolas THOME', 'patrick gallinari']",ICLR,Augmenting Physical Models with Deep Networks for Complex Dynamics Forecasting,https://iclr.cc/virtual/2021/oral/3444,2021," Forecasting complex dynamical phenomena in settings where only partial knowledge of their dynamics is available is a prevalent problem across various scientific fields. While purely data-driven approaches are arguably insufficient in this context, standard physical modeling based approaches tend to be over-simplistic, inducing non-negligible errors. In this work, we introduce the APHYNITY framework, a principled approach for augmenting incomplete physical dynamics described by differential equations with deep data-driven models. It consists in decomposing the dynamics into two components: a physical component accounting for the dynamics for which we have some prior knowledge, and a data-driven component accounting for errors of the physical model. The learning problem is carefully formulated such that the physical model explains as much of the data as possible, while the data-driven component only describes information that cannot be captured by the physical model, no more, no less. This not only provides the existence and uniqueness for this decomposition, but also ensures interpretability and benefits generalization. Experiments made on three important use cases, each representative of a different family of phenomena, i.e. reaction-diffusion equations, wave equations and the non-linear damped pendulum, show that APHYNITY can efficiently leverage approximate physical models to accurately forecast the evolution of the system and correctly identify relevant physical parameters.",Oral Session 10,https://openreview.net/pdf?id=kmG8vRXTFv,https://openreview.net/forum?id=kmG8vRXTFv
"['Xinran Wang', 'Yu Xiang', 'Jun Gao', 'Jie Ding']",ICLR,Information Laundering for Model Privacy,https://iclr.cc/virtual/2021/spotlight/3510,2021," In this work, we propose information laundering, a novel framework for enhancing model privacy. Unlike data privacy that concerns the protection of raw data information, model privacy aims to protect an already-learned model that is to be deployed for public use. The private model can be obtained from general learning methods, and its deployment means that it will return a deterministic or random response for a given input query. An information-laundered model consists of probabilistic components that deliberately maneuver the intended input and output for queries of the model, so the model's adversarial acquisition is less likely. Under the proposed framework, we develop an information-theoretic principle to quantify the fundamental tradeoffs between model utility and privacy leakage and derive the optimal design.",Oral Session 3,https://openreview.net/pdf?id=dyaIRud1zXg,https://openreview.net/forum?id=dyaIRud1zXg
"['Kashif Rasul', 'Abdul-Saboor Sheikh', 'Ingmar Schuster', 'Urs Bergmann', 'Roland Vollgraf']",ICLR,Multivariate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows,https://iclr.cc/virtual/2021/spotlight/3409,2021," Time series forecasting is often fundamental to scientific and engineering problems and enables decision making. With ever increasing data set sizes, a trivial solution to scale up predictions is to assume independence between interacting time series. However, modeling statistical dependencies can improve accuracy and enable analysis of interaction effects. Deep learning methods are well suited for this problem, but multi-variate models often assume a simple parametric distribution and do not scale to high dimensions. In this work we model the multi-variate temporal dynamics of time series via an autoregressive deep learning model, where the data distribution  is represented by a conditioned normalizing flow. This combination retains the power of autoregressive models, such as good performance in extrapolation into the future, with the flexibility of flows as a general purpose high-dimensional distribution model, while remaining computationally tractable. We show that it improves over the state-of-the-art for standard metrics on many real-world data sets with several thousand interacting time-series.",Oral Session 4,https://openreview.net/pdf?id=WiGQBFuVRv,https://openreview.net/forum?id=WiGQBFuVRv
"['Amartya Sanyal', 'Puneet Dokania', 'Varun Kanade', 'Philip Torr']",ICLR,How Benign is Benign Overfitting ?,https://iclr.cc/virtual/2021/spotlight/3470,2021," We investigate two causes for adversarial vulnerability in deep neural networks: bad data and (poorly) trained models. When trained with SGD, deep neural networks essentially achieve zero training error, even in the presence of label noise, while also exhibiting good generalization on natural test data, something referred to as benign overfitting (Bartlett et al., 2020; Chatterji & Long, 2020).  However, these models are vulnerable to adversarial attacks. We identify label noise as one of the causes for adversarial vulnerability, and provide theoretical and empirical evidence in support of this. Surprisingly, we find several instances of label noise in datasets such as MNIST and CIFAR, and that robustly trained models incur training error on some of these, i.e. they don’t fit the noise. However, removing noisy labels alone does not suffice to achieve adversarial robustness. We conjecture that in part sub-optimal representation learning is also responsible for adversarial vulnerability. By means of simple theoretical setups, we show how the choice of representation can drastically affect adversarial robustness.",Oral Session 1,https://openreview.net/pdf?id=g-wu9TMPODo,https://openreview.net/forum?id=g-wu9TMPODo
"['Faruk Ahmed', 'Yoshua Bengio', 'Harm van Seijen', 'Aaron Courville']",ICLR,Systematic generalisation with group invariant predictions,https://iclr.cc/virtual/2021/spotlight/3520,2021," We consider situations where the presence of dominant simpler correlations with the target variable in a training set can cause an SGD-trained neural network to be less reliant on more persistently correlating complex features. When the non-persistent, simpler correlations correspond to non-semantic background factors, a neural network trained on this data can exhibit dramatic failure upon encountering systematic distributional shift, where the correlating background features are recombined with different objects. We perform an empirical study on three synthetic datasets, showing that group invariance methods across inferred partitionings of the training set can lead to significant improvements at such test-time situations. We also suggest a simple invariance penalty, showing with experiments on our setups that it can perform better than alternatives. We find that even without assuming access to any systematically shifted validation sets, one can still find improvements over an ERM-trained reference model.",Oral Session 2,https://openreview.net/pdf?id=b9PoimzZFJ,https://openreview.net/forum?id=b9PoimzZFJ
"['Tolga Ergen', 'Mert Pilanci']",ICLR,Implicit Convex Regularizers of CNN Architectures: Convex Optimization of Two- and Three-Layer Networks in Polynomial Time,https://iclr.cc/virtual/2021/spotlight/3408,2021," We study training of Convolutional Neural Networks (CNNs) with ReLU activations and introduce exact convex optimization formulations with a polynomial complexity with respect to the number of data samples, the number of neurons, and data dimension. More specifically, we develop a convex analytic framework utilizing semi-infinite duality to obtain equivalent convex optimization problems for several two- and three-layer CNN architectures. We first prove that two-layer CNNs can be globally optimized via an $\ell_2$ norm regularized convex program. We then show that multi-layer circular CNN training problems with a single ReLU layer are equivalent to an $\ell_1$ regularized convex program that encourages sparsity in the spectral domain. We also extend these results to three-layer CNNs with two ReLU layers. Furthermore, we present extensions of our approach to different pooling methods, which elucidates the implicit architectural bias as convex regularizers.",Oral Session 5,https://openreview.net/pdf?id=0N8jUH4JMv6,https://openreview.net/forum?id=0N8jUH4JMv6
"['Alexander Vargo', 'Fan Zhang', 'Mikhail Yurochkin', 'Yuekai Sun']",ICLR,Individually Fair Gradient Boosting,https://iclr.cc/virtual/2021/spotlight/3502,2021," We consider the task of enforcing individual fairness in gradient boosting. Gradient boosting is a popular method for machine learning from tabular data, which arise often in applications where algorithmic fairness is a concern. At a high level, our approach is a functional gradient descent on a (distributionally) robust loss function that encodes our intuition of algorithmic fairness for the ML task at hand. Unlike prior approaches to individual fairness that only work with smooth ML models, our approach also works with non-smooth models such as decision trees. We show that our algorithm converges globally and generalizes. We also demonstrate the efficacy of our algorithm on three ML problems susceptible to algorithmic bias.",Oral Session 6,https://openreview.net/pdf?id=JBAa9we1AL,https://openreview.net/forum?id=JBAa9we1AL
"['Nils Lukas', 'Yuxuan Zhang', 'Florian Kerschbaum']",ICLR,Deep Neural Network Fingerprinting by Conferrable Adversarial Examples,https://iclr.cc/virtual/2021/spotlight/3541,2021," In Machine Learning as a Service, a provider trains a deep neural network and gives many users access. The hosted (source) model is susceptible to model stealing attacks, where an adversary derives a surrogate model from API access to the source model. For post hoc detection of such attacks, the provider needs a robust method to determine whether a suspect model is a surrogate of their model. We propose a fingerprinting method for deep neural network classifiers that extracts a set of inputs from the source model so that only surrogates agree with the source model on the classification of such inputs. These inputs are a subclass of transferable adversarial examples which we call conferrable adversarial examples that exclusively transfer with a target label from a source model to its surrogates. We propose a new method to generate these conferrable adversarial examples. We present an extensive study on the irremovability of our fingerprint against fine-tuning, weight pruning, retraining, retraining with different architectures, three model extraction attacks from related work, transfer learning, adversarial training, and two new adaptive attacks. Our fingerprint is robust against distillation, related model extraction attacks, and even transfer learning when the attacker has no access to the model provider's dataset. Our fingerprint is the first method that reaches a ROC AUC of 1.0 in verifying surrogates, compared to a ROC AUC of 0.63 by previous fingerprints.",Oral Session 7,https://openreview.net/pdf?id=VqzVhqxkjH1,https://openreview.net/forum?id=VqzVhqxkjH1
"['Xinshuai Dong', 'Anh Tuan Luu', 'Rongrong Ji', 'Hong Liu']",ICLR,Towards Robustness Against Natural Language Word Substitutions,https://iclr.cc/virtual/2021/spotlight/3472,2021," Robustness against word substitutions has a well-defined and widely acceptable form, i.e., using semantically similar words as substitutions, and thus it is considered as a fundamental stepping-stone towards broader robustness in natural language processing. Previous defense methods capture word substitutions in vector space by using either l_2-ball or hyper-rectangle, which results in perturbation sets that are not inclusive enough or unnecessarily large, and thus impedes mimicry of worst cases for robust training. In this paper, we introduce a novel Adversarial Sparse Convex Combination (ASCC) method. We model the word substitution attack space as a convex hull and leverages a regularization term to enforce perturbation towards an actual substitution, thus aligning our modeling better with the discrete textual space. Based on  ASCC method, we further propose ASCC-defense, which leverages ASCC to generate worst-case perturbations and incorporates adversarial training towards robustness. Experiments show that ASCC-defense outperforms the current state-of-the-arts in terms of robustness on two prevailing NLP tasks, i.e., sentiment analysis and natural language inference, concerning several attacks across multiple model architectures. Besides, we also envision a new class of defense towards robustness in NLP, where our robustly trained word vectors can be plugged into a normally trained model and enforce its robustness without applying any other defense techniques.",Oral Session 9,https://openreview.net/pdf?id=ks5nebunVn_,https://openreview.net/forum?id=ks5nebunVn_
['Irwan Bello'],ICLR,LambdaNetworks: Modeling long-range Interactions without Attention,https://iclr.cc/virtual/2021/spotlight/3395,2021," We present lambda layers -- an alternative framework to self-attention -- for capturing long-range interactions between an input and structured contextual information (e.g. a pixel surrounded by other pixels). Lambda layers capture such interactions by transforming available contexts into linear functions, termed lambdas, and applying these linear functions to each input separately. Similar to linear attention, lambda layers bypass expensive attention maps, but in contrast, they model both content and position-based interactions which enables their application to large structured inputs such as images. The resulting neural network architectures, LambdaNetworks, significantly outperform their convolutional and attentional counterparts on ImageNet classification, COCO object detection and instance segmentation, while being more computationally efficient. Additionally, we design LambdaResNets, a family of hybrid architectures across different scales, that considerably improves the speed-accuracy tradeoff of image classification models. LambdaResNets reach excellent accuracies on ImageNet while being 3.2 - 4.4x faster than the popular EfficientNets on modern machine learning accelerators. In large-scale semi-supervised training with an additional 130M pseudo-labeled images, LambdaResNets achieve up to 86.7% ImageNet accuracy while being 9.5x faster than EfficientNet NoisyStudent and 9x faster than a Vision Transformer with comparable accuracies.",Oral Session 8,https://openreview.net/pdf?id=xTJEN-ggl1b,https://openreview.net/forum?id=xTJEN-ggl1b
"['Max Schwarzer', 'Ankesh Anand', 'Rishab Goel', 'R Devon Hjelm', 'Aaron Courville', 'Philip Bachman']",ICLR,Data-Efficient Reinforcement Learning with Self-Predictive Representations,https://iclr.cc/virtual/2021/spotlight/3492,2021," While deep reinforcement learning excels at solving tasks where large amounts of data can be collected through virtually unlimited interaction with the environment, learning from limited interaction remains a key challenge. We posit that an agent can learn more efficiently if we augment reward maximization with self-supervised objectives based on structure in its visual input and sequential interaction with the environment.  Our method, Self-Predictive Representations (SPR), trains an agent to predict its own latent state representations multiple steps into the future. We compute target representations for future states using an encoder which is an exponential moving average of the agent’s parameters and we make predictions using a learned transition model.  On its own,  this future prediction objective outperforms prior methods for sample-efficient deep RL from pixels. We further improve performance by adding data augmentation to the future prediction loss, which forces the agent’s representations to be consistent across multiple views of an observation.  Our full self-supervised objective, which combines future prediction and data augmentation, achieves a median human-normalized score of 0.415 on Atari in a setting limited to 100k steps of environment interaction, which represents a 55% relative improvement over the previous state-of-the-art. Notably, even in this limited data regime, SPR exceeds expert human scores on 7 out of 26 games. We’ve made the code associated with this work available at https://github.com/mila-iqia/spr.",Oral Session 11,https://openreview.net/pdf?id=uCQfPZwRaUu,https://openreview.net/forum?id=uCQfPZwRaUu
"['Yikai Zhang', 'Songzhu Zheng', 'Pengxiang Wu', 'Mayank Goswami', 'Chao Chen']",ICLR,Learning with Feature-Dependent Label Noise: A Progressive Approach,https://iclr.cc/virtual/2021/spotlight/3511,2021," Label noise is frequently observed in real-world large-scale datasets. The noise is introduced due to a variety of reasons; it is heterogeneous and feature-dependent. Most existing approaches to handling noisy labels fall into two categories: they either assume an ideal feature-independent noise, or remain heuristic without theoretical guarantees. In this paper, we propose to target a new family of feature-dependent label noise, which is much more general than commonly used i.i.d. label noise and encompasses a broad spectrum of noise patterns. Focusing on this general noise family, we propose a progressive label correction algorithm that iteratively corrects labels and refines the model. We provide theoretical guarantees showing that for a wide variety of (unknown) noise patterns, a classifier trained with this strategy converges to be consistent with the Bayes classifier. In experiments, our method outperforms SOTA baselines and is robust to various noise types and levels.",Oral Session 12,https://openreview.net/pdf?id=ZPa2SyGcbwh,https://openreview.net/forum?id=ZPa2SyGcbwh
"['Hanxun Huang', 'Xingjun Ma', 'Sarah Erfani', 'James Bailey', 'Yisen Wang']",ICLR,Unlearnable Examples: Making Personal Data Unexploitable,https://iclr.cc/virtual/2021/spotlight/3385,2021," The volume of ""free"" data on the internet has been key to the current success of deep learning. However, it also raises privacy concerns about the unauthorized exploitation of personal data for training commercial models. It is thus crucial to develop methods to prevent unauthorized data exploitation. This paper raises the question: can data be made unlearnable for deep learning models? We present a type of error-minimizing noise that can indeed make training examples unlearnable. Error-minimizing noise is intentionally generated to reduce the error of one or more of the training example(s) close to zero, which can trick the model into believing there is ""nothing"" to learn from these example(s). The noise is restricted to be imperceptible to human eyes, and thus does not affect normal data utility. We empirically verify the effectiveness of error-minimizing noise in both sample-wise and class-wise forms. We also demonstrate its flexibility under extensive experimental settings and practicability in a case study of face recognition. Our work establishes an important ﬁrst step towards making personal data unexploitable to deep learning models.",Oral Session 10,https://openreview.net/pdf?id=iAmZUo0DxC0,https://openreview.net/forum?id=iAmZUo0DxC0
"['Pratyush Maini', 'Mohammad Yaghini', 'Nicolas Papernot']",ICLR,Dataset Inference: Ownership Resolution in Machine Learning,https://iclr.cc/virtual/2021/spotlight/3504,2021," With increasingly more data and computation involved in their training,  machine learning models constitute valuable intellectual property. This has spurred interest in model stealing, which is made more practical by advances in learning with partial, little, or no supervision. Existing defenses focus on inserting unique watermarks in a model's decision surface, but this is insufficient:  the watermarks are not sampled from the training distribution and thus are not always preserved during model stealing. In this paper, we make the key observation that knowledge contained in the stolen model's training set is what is common to all stolen copies. The adversary's goal, irrespective of the attack employed, is always to extract this knowledge or its by-products. This gives the original model's owner a strong advantage over the adversary: model owners have access to the original training data. We thus introduce $\textit{dataset inference}$, the process of identifying whether a suspected model copy has private knowledge from the original model's dataset, as a defense against model stealing. We develop an approach for dataset inference that combines statistical testing with the ability to estimate the distance of multiple data points to the decision boundary. Our experiments on CIFAR10, SVHN, CIFAR100 and ImageNet show that model owners can claim with confidence greater than 99% that their model (or dataset as a matter of fact) was stolen, despite only exposing 50 of the stolen model's training points. Dataset inference defends against state-of-the-art attacks even when the adversary is adaptive. Unlike prior work, it does not require retraining or overfitting the defended model.",Oral Session 3,https://openreview.net/pdf?id=hvdKKV2yt7T,https://openreview.net/forum?id=hvdKKV2yt7T
"['Pengfei Chen', 'Guangyong Chen', 'Junjie Ye', 'jingwei zhao', 'Pheng-Ann Heng']",ICLR,Noise against noise: stochastic label noise helps combat inherent label noise,https://iclr.cc/virtual/2021/spotlight/3537,2021," The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect, previously studied in optimization by analyzing the dynamics of parameter updates. In this paper, we are interested in learning with noisy labels, where we have a collection of samples with potential mislabeling. We show that a previously rarely discussed SGD noise, induced by stochastic label noise (SLN), mitigates the effects of inherent label noise. In contrast, the common SGD noise directly applied to model parameters does not. We formalize the differences and connections of SGD noise variants, showing that SLN induces SGD noise dependent on the sharpness of output landscape and the confidence of output probability, which may help escape from sharp minima and prevent overconfidence. SLN not only improves generalization in its simplest form but also boosts popular robust training methods, including sample selection and label correction. Specifically, we present an enhanced algorithm by applying SLN to label correction. Our code is released.",Oral Session 4,https://openreview.net/pdf?id=80FMcTSZ6J0,https://openreview.net/forum?id=80FMcTSZ6J0
"['Jingfeng Zhang', 'Jianing ZHU', 'Gang Niu', 'Bo Han', 'Masashi Sugiyama', 'Mohan Kankanhalli']",ICLR,Geometry-aware Instance-reweighted Adversarial Training,https://iclr.cc/virtual/2021/oral/3501,2021," In adversarial machine learning, there was a common belief that robustness and accuracy hurt each other. The belief was challenged by recent studies where we can maintain the robustness and improve the accuracy. However, the other direction, whether we can keep the accuracy and improve the robustness, is conceptually and practically more interesting, since robust accuracy should be lower than standard accuracy for any model. In this paper, we show this direction is also promising. Firstly, we find even over-parameterized deep networks may still have insufficient model capacity, because adversarial training has an overwhelming smoothing effect. Secondly, given limited model capacity, we argue adversarial data should have unequal importance: geometrically speaking, a natural data point closer to/farther from the class boundary is less/more robust, and the corresponding adversarial data point should be assigned with larger/smaller weight. Finally, to implement the idea, we propose geometry-aware instance-reweighted adversarial training, where the weights are based on how difficult it is to attack a natural data point. Experiments show that our proposal boosts the robustness of standard adversarial training; combining two directions, we improve both robustness and accuracy of standard adversarial training.",Oral Session 1,https://openreview.net/pdf?id=iAX0l6Cz8ub,https://openreview.net/forum?id=iAX0l6Cz8ub
"['Sebastian Farquhar', 'Yarin Gal', 'Tom Rainforth']",ICLR,On Statistical Bias In Active Learning: How and When to Fix It,https://iclr.cc/virtual/2021/spotlight/3414,2021," Active learning is a powerful tool when labelling data is expensive, but it introduces a bias because the training data no longer follows the population distribution. We formalize this bias and investigate the situations in which it can be harmful and sometimes even helpful. We further introduce novel corrective weights to remove bias when doing so is beneficial. Through this, our work not only provides a useful mechanism that can improve the active learning approach, but also an explanation for the empirical successes of various existing approaches which ignore this bias. In particular, we show that this bias can be actively helpful when training overparameterized models---like neural networks---with relatively modest dataset sizes.",Oral Session 2,https://openreview.net/pdf?id=JiYq3eqTKY,https://openreview.net/forum?id=JiYq3eqTKY
"['Bowen Jing', 'Stephan Eismann', 'Patricia Suriana', 'Raphael J Townshend', 'Ron Dror']",ICLR,Learning from Protein Structure with Geometric Vector Perceptrons,https://iclr.cc/virtual/2021/spotlight/3449,2021," Learning on 3D structures of large biomolecules is emerging as a distinct area in machine learning, but there has yet to emerge a unifying network architecture that simultaneously leverages the geometric and relational aspects of the problem domain. To address this gap, we introduce geometric vector perceptrons, which extend standard dense layers to operate on collections of Euclidean vectors. Graph neural networks equipped with such layers are able to perform both geometric and relational reasoning on efficient representations of macromolecules. We demonstrate our approach on two important problems in learning from protein structure: model quality assessment and computational protein design. Our approach improves over existing classes of architectures on both problems, including state-of-the-art convolutional neural networks and graph neural networks. We release our code at https://github.com/drorlab/gvp.",Oral Session 5,https://openreview.net/pdf?id=1YLJDvSx6J4,https://openreview.net/forum?id=1YLJDvSx6J4
"['Zhen Qin', 'Le Yan', 'Honglei Zhuang', 'Yi Tay', 'Rama Kumar Pasumarthi', 'Xuanhui Wang', 'Michael Bendersky', 'Marc Najork']",ICLR,Are Neural Rankers still Outperformed by Gradient Boosted Decision Trees?,https://iclr.cc/virtual/2021/spotlight/3536,2021," Despite the success of neural models on many major machine learning problems, their effectiveness on traditional Learning-to-Rank (LTR) problems is still not widely acknowledged. We first validate this concern by showing that most recent neural LTR models are, by a large margin, inferior to the best publicly available Gradient Boosted Decision Trees (GBDT) in terms of their reported ranking accuracy on benchmark datasets. This unfortunately was somehow overlooked in recent neural LTR papers. We then investigate why existing neural LTR models under-perform and identify several of their weaknesses. Furthermore, we propose a unified framework comprising of counter strategies to ameliorate the existing weaknesses of neural models. Our models are the first to be able to perform equally well, comparing with the best tree-based baseline, while outperforming recently published neural LTR models by a large margin. Our results can also serve as a benchmark to facilitate future improvement of neural LTR models.",Oral Session 6,https://openreview.net/pdf?id=Ut1vF_q_vC,https://openreview.net/forum?id=Ut1vF_q_vC
"['Felix Hill', 'Olivier Tieleman', 'Tamara von Glehn', 'Nathaniel Wong', 'Hamza Merzic', 'Stephen Clark']",ICLR,Grounded Language Learning Fast and Slow,https://iclr.cc/virtual/2021/spotlight/3457,2021," Recent work has shown that large text-based neural language models acquire a surprising propensity for one-shot learning. Here, we show that an agent situated in a simulated 3D world, and endowed with a novel dual-coding external memory, can exhibit similar one-shot word learning when trained with conventional RL algorithms. After a single introduction to a novel object via visual perception and language (""This is a dax""), the agent can manipulate the object as instructed (""Put the dax on the bed""), combining short-term, within-episode knowledge of the nonsense word with long-term lexical and motor knowledge. We find that, under certain training conditions and with a particular memory writing mechanism, the agent's one-shot word-object binding generalizes to novel exemplars within the same ShapeNet category, and is effective in settings with unfamiliar numbers of objects. We further show how dual-coding memory can be exploited as a signal for intrinsic motivation, stimulating the agent to seek names for objects that may be useful later. Together, the results demonstrate that deep neural networks can exploit meta-learning, episodic memory and an explicitly multi-modal environment to account for 'fast-mapping', a fundamental pillar of human cognitive development and a potentially transformative capacity for artificial agents.",Oral Session 8,https://openreview.net/pdf?id=wpSWuz_hyqA,https://openreview.net/forum?id=wpSWuz_hyqA
"['Qiang Zhang', 'Tete Xiao', 'Alexei Efros', 'Lerrel Pinto', 'Xiaolong Wang']",ICLR,Learning Cross-Domain Correspondence for Control with Dynamics Cycle-Consistency,https://iclr.cc/virtual/2021/oral/3380,2021," At the heart of many robotics problems is the challenge of learning correspondences across domains. For instance, imitation learning requires obtaining correspondence between humans and robots; sim-to-real requires correspondence between physics simulators and real hardware; transfer learning requires correspondences between different robot environments. In this paper, we propose to learn correspondence across such domains emphasizing on differing modalities (vision and internal state), physics parameters (mass and friction), and morphologies (number of limbs). Importantly, correspondences are learned using unpaired and randomly collected data from the two domains. We propose dynamics cycles that align dynamic robotic behavior across two domains using a cycle consistency constraint. Once this correspondence is found, we can directly transfer the policy trained on one domain to the other, without needing any additional fine-tuning on the second domain. We perform experiments across a variety of problem domains, both in simulation and on real robots. Our framework is able to align uncalibrated monocular video of a real robot arm to dynamic state-action trajectories of a simulated arm without paired data. Video demonstrations of our results are available at: https://sites.google.com/view/cycledynamics .",Oral Session 7,https://openreview.net/pdf?id=QIRlze3I6hX,https://openreview.net/forum?id=QIRlze3I6hX
"['Haoyu Ma', 'Tianlong Chen', 'Ting-Kuei Hu', 'Chenyu You', 'Xiaohui Xie', 'Zhangyang Wang']",ICLR,Undistillable: Making A Nasty Teacher That CANNOT teach students,https://iclr.cc/virtual/2021/spotlight/3446,2021," Knowledge Distillation (KD) is a widely used technique to transfer knowledge from pre-trained teacher models to  (usually more lightweight) student models. However, in certain situations, this technique is more of a curse than a blessing. For instance, KD poses a potential risk of exposing intellectual properties (IPs): even if a trained machine learning model is released in ``black boxes'' (e.g., as executable software or APIs without open-sourcing code), it can still be replicated by KD through imitating input-output behaviors. To prevent this unwanted effect of KD, this paper introduces and investigates a concept called $\textit{Nasty Teacher}$: a specially trained teacher network that yields nearly the same performance as a normal one, but would significantly degrade the performance of student models learned by imitating it. We propose a simple yet effective algorithm to build the nasty teacher, called $\textit{self-undermining knowledge distillation}$. Specifically, we aim to maximize the difference between the output of the nasty teacher and a normal pre-trained network. Extensive experiments on several datasets demonstrate that our method is effective on both standard KD and data-free KD, providing the desirable KD-immunity to model owners for the first time. We hope our preliminary study can draw more awareness and interest in this new practical problem of both social and legal importance. Our codes and pre-trained models can be found at: $\url{https://github.com/VITA-Group/Nasty-Teacher}$.",Oral Session 9,https://openreview.net/pdf?id=0zvfm-nZqQs,https://openreview.net/forum?id=0zvfm-nZqQs
"['Zhifeng Kong', 'Wei Ping', 'Jiaji Huang', 'Kexin Zhao', 'Bryan Catanzaro']",ICLR,DiffWave: A Versatile Diffusion Model for Audio Synthesis,https://iclr.cc/virtual/2021/oral/3465,2021," In this work, we propose DiffWave, a versatile diffusion probabilistic model for conditional and unconditional waveform generation. The model is non-autoregressive, and converts the white noise signal into structured waveform through a Markov chain with a constant number of steps at synthesis. It is efficiently trained by optimizing a variant of variational bound on the data likelihood. DiffWave produces high-fidelity audios in different waveform generation tasks, including neural vocoding conditioned on mel spectrogram, class-conditional generation, and unconditional generation. We demonstrate that DiffWave matches a strong WaveNet vocoder in terms of speech quality (MOS: 4.44 versus 4.43), while synthesizing orders of magnitude faster. In particular, it significantly outperforms autoregressive and GAN-based waveform models in the challenging unconditional generation task in terms of audio quality and sample diversity from various automatic and human evaluations.",Oral Session 11,https://openreview.net/pdf?id=a-xFK8Ymz5J,https://openreview.net/forum?id=a-xFK8Ymz5J
"['Zhenyu Liao', 'Romain Couillet', 'Michael W Mahoney']",ICLR,Sparse Quantized Spectral Clustering,https://iclr.cc/virtual/2021/spotlight/3382,2021," Given a large data matrix, sparsifying, quantizing, and/or performing other entry-wise nonlinear operations can have numerous benefits, ranging from speeding up iterative algorithms for core numerical linear algebra problems to providing nonlinear filters to design state-of-the-art neural network models. Here, we exploit tools from random matrix theory to make precise statements about how the eigenspectrum of a matrix changes under such nonlinear transformations. In particular, we show that very little change occurs in the informative eigenstructure, even under drastic sparsification/quantization, and consequently that very little downstream performance loss occurs when working with very aggressively sparsified or quantized spectral clustering problems.
We illustrate how these results depend on the nonlinearity, we characterize a phase transition beyond which spectral clustering becomes possible, and we show when such nonlinear transformations can introduce spurious non-informative eigenvectors.",Oral Session 12,https://openreview.net/pdf?id=pBqLS-7KYAF,https://openreview.net/forum?id=pBqLS-7KYAF
"['Andrii Zadaianchuk', 'Maximilian Seitzer', 'Georg Martius']",ICLR,Self-supervised Visual Reinforcement Learning with Object-centric Representations,https://iclr.cc/virtual/2021/spotlight/3422,2021," Autonomous agents need large repertoires of skills to act reasonably on new tasks that they have not seen before. However, acquiring these skills using only a stream of high-dimensional, unstructured, and unlabeled observations is a tricky challenge for any autonomous agent. Previous methods have used variational autoencoders to encode a scene into a low-dimensional vector that can be used as a goal for an agent to discover new skills. Nevertheless, in compositional/multi-object environments it is difficult to disentangle all the factors of variation into such a fixed-length representation of the whole scene. We propose to use object-centric representations as a modular and structured observation space, which is learned with a compositional generative world model.
We show that the structure in the representations in combination with goal-conditioned attention policies helps the autonomous agent to discover and learn useful skills. These skills can be further combined to address compositional tasks like the manipulation of several different objects.",Oral Session 10,https://openreview.net/pdf?id=xppLmXCbOw1,https://openreview.net/forum?id=xppLmXCbOw1
"['Chaojian Li', 'Zhongzhi Yu', 'Yonggan Fu', 'Yongan Zhang', 'Yang Zhao', 'Haoran You', 'Qixuan Yu', 'Yue Wang', 'Cong Hao', 'Yingyan Lin']",ICLR,HW-NAS-Bench: Hardware-Aware Neural Architecture Search Benchmark,https://iclr.cc/virtual/2021/spotlight/3544,2021," HardWare-aware Neural Architecture Search (HW-NAS) has recently gained tremendous attention by automating the design of deep neural networks deployed in more resource-constrained daily life devices. Despite its promising performance, developing optimal HW-NAS solutions can be prohibitively challenging as it requires cross-disciplinary knowledge in the algorithm, micro-architecture, and device-specific compilation. First, to determine the hardware-cost to be incorporated into the NAS process, existing works mostly adopt either pre-collected hardware-cost look-up tables or device-specific hardware-cost models. The former can be time-consuming due to the required knowledge of the device’s compilation method and how to set up the measurement pipeline, while building the latter is often a barrier for non-hardware experts like NAS researchers. Both of them limit the development of HW-NAS innovations and impose a barrier-to-entry to non-hardware experts. Second, similar to generic NAS, it can be notoriously difficult to benchmark HW-NAS algorithms due to their significant required computational resources and the differences in adopted search spaces, hyperparameters, and hardware devices. To this end, we develop HW-NAS-Bench, the first public dataset for HW-NAS research which aims to democratize HW-NAS research to non-hardware experts and make HW-NAS research more reproducible and accessible. To design HW-NAS-Bench, we carefully collected the measured/estimated hardware performance (e.g., energy cost and latency) of all the networks in the search spaces of both NAS-Bench-201 and FBNet, on six hardware devices that fall into three categories (i.e., commercial edge devices, FPGA, and ASIC). Furthermore, we provide a comprehensive analysis of the collected measurements in HW-NAS-Bench to provide insights for HW-NAS research. Finally, we demonstrate exemplary user cases to (1) show that HW-NAS-Bench allows non-hardware experts to perform HW-NAS by simply querying our pre-measured dataset and (2) verify that dedicated device-specific HW-NAS can indeed lead to optimal accuracy-cost trade-offs. The codes and all collected data are available at https://github.com/RICE-EIC/HW-NAS-Bench.",Oral Session 3,https://openreview.net/pdf?id=_0kaDkv3dVf,https://openreview.net/forum?id=_0kaDkv3dVf
"['Rui Zhao', 'Yang Gao', 'Pieter Abbeel', 'Volker Tresp', 'Wei Xu']",ICLR,Mutual Information State Intrinsic Control,https://iclr.cc/virtual/2021/spotlight/3509,2021," Reinforcement learning has been shown to be highly successful at many challenging tasks. However, success heavily relies on well-shaped rewards. Intrinsically motivated RL attempts to remove this constraint by defining an intrinsic reward function. Motivated by the self-consciousness concept in psychology, we make a natural assumption that the agent knows what constitutes itself, and propose a new intrinsic objective that encourages the agent to have maximum control on the environment. We mathematically formalize this reward as the mutual information between the agent state and the surrounding state under the current agent policy. With this new intrinsic motivation, we are able to outperform previous methods, including being able to complete the pick-and-place task for the first time without using any task reward. A video showing experimental results is available at https://youtu.be/AUCwc9RThpk.",Oral Session 4,https://openreview.net/pdf?id=OthEq8I5v1,https://openreview.net/forum?id=OthEq8I5v1
"['Xingang Pan', 'Bo DAI', 'Ziwei Liu', 'Chen Change Loy', 'Ping Luo']",ICLR,Do 2D GANs Know 3D Shape? Unsupervised 3D Shape Reconstruction from 2D Image GANs,https://iclr.cc/virtual/2021/oral/3389,2021," Natural images are projections of 3D objects on a 2D image plane. While state-of-the-art 2D generative models like GANs show unprecedented quality in modeling the natural image manifold, it is unclear whether they implicitly capture the underlying 3D object structures. And if so, how could we exploit such knowledge to recover the 3D shapes of objects in the images? To answer these questions, in this work, we present the first attempt to directly mine 3D geometric cues from an off-the-shelf 2D GAN that is trained on RGB images only. Through our investigation, we found that such a pre-trained GAN indeed contains rich 3D knowledge and thus can be used to recover 3D shape from a single 2D image in an unsupervised manner. The core of our framework is an iterative strategy that explores and exploits diverse viewpoint and lighting variations in the GAN image manifold. The framework does not require 2D keypoint or 3D annotations, or strong assumptions on object shapes (e.g. shapes are symmetric), yet it successfully recovers 3D shapes with high precision for human faces, cats, cars, and buildings. The recovered 3D shapes immediately allow high-quality image editing like relighting and object rotation. We quantitatively demonstrate the effectiveness of our approach compared to previous methods in both 3D shape reconstruction and face rotation. Our code is available at https://github.com/XingangPan/GAN2Shape.",Oral Session 1,https://openreview.net/pdf?id=FGqiDsBUKL0,https://openreview.net/forum?id=FGqiDsBUKL0
['Rewon Child'],ICLR,Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images,https://iclr.cc/virtual/2021/spotlight/3494,2021," We present a hierarchical VAE that, for the first time, generates samples quickly $\textit{and}$ outperforms the PixelCNN in log-likelihood on all natural image benchmarks. We begin by observing that, in theory, VAEs can actually represent autoregressive models, as well as faster, better models if they exist, when made sufficiently deep. Despite this, autoregressive models have historically outperformed VAEs in log-likelihood. We test if insufficient depth explains why by scaling a VAE to greater stochastic depth than previously explored and evaluating it CIFAR-10, ImageNet, and FFHQ. In comparison to the PixelCNN, these very deep VAEs achieve higher likelihoods, use fewer parameters, generate samples thousands of times faster, and are more easily applied to high-resolution images. Qualitative studies suggest this is because the VAE learns efficient hierarchical visual representations. We release our source code and models at https://github.com/openai/vdvae.",Oral Session 2,https://openreview.net/pdf?id=RLRXCV6DbEJ,https://openreview.net/forum?id=RLRXCV6DbEJ
"['Jang-Hyun Kim', 'Wonho Choo', 'Hosan Jeong', 'Hyun Oh Song']",ICLR,Co-Mixup: Saliency Guided Joint Mixup with Supermodular Diversity,https://iclr.cc/virtual/2021/oral/3405,2021," While deep neural networks show great performance on fitting to the training distribution, improving the networks' generalization performance to the test distribution and robustness to the sensitivity to input perturbations still remain as a challenge. Although a number of mixup based augmentation strategies have been proposed to partially address them, it remains unclear as to how to best utilize the supervisory signal within each input data for mixup from the optimization perspective. We propose a new perspective on batch mixup and formulate the optimal construction of a batch of mixup data maximizing the data saliency measure of each individual mixup data and encouraging the supermodular diversity among the constructed mixup data. This leads to a novel discrete optimization problem minimizing the difference between submodular functions. We also propose an efficient modular approximation based iterative submodular minimization algorithm for efficient mixup computation per each minibatch suitable for minibatch based neural network training. Our experiments show the proposed method achieves the state of the art generalization, calibration, and weakly supervised localization results compared to other mixup methods. The source code is available at https://github.com/snu-mllab/Co-Mixup.",Oral Session 6,https://openreview.net/pdf?id=gvxJzw8kW4b,https://openreview.net/forum?id=gvxJzw8kW4b
"['Matthew Smart', 'Anton Zilman']",ICLR,On the mapping between Hopfield networks and Restricted Boltzmann Machines,https://iclr.cc/virtual/2021/oral/3412,2021," Hopfield networks (HNs) and Restricted Boltzmann Machines (RBMs) are two important models at the interface of statistical physics, machine learning, and neuroscience. Recently, there has been interest in the relationship between HNs and RBMs, due to their similarity under the statistical mechanics formalism. An exact mapping between HNs and RBMs has been previously noted for the special case of orthogonal (“uncorrelated”) encoded patterns. We present here an exact mapping in the case of correlated pattern HNs, which are more broadly applicable to existing datasets. Specifically, we show that any HN with $N$ binary variables and $p",Oral Session 5,https://openreview.net/pdf?id=RGJbergVIoO,https://openreview.net/forum?id=RGJbergVIoO
"['Anand Gopalakrishnan', 'Sjoerd van Steenkiste', 'Jürgen Schmidhuber']",ICLR,Unsupervised Object Keypoint Learning using Local Spatial Predictability,https://iclr.cc/virtual/2021/spotlight/3455,2021," We propose PermaKey, a novel approach to representation learning based on object keypoints. It leverages the predictability of local image regions from spatial neighborhoods to identify salient regions that correspond to object parts, which are then converted to keypoints. Unlike prior approaches, it utilizes predictability to discover object keypoints, an intrinsic property of objects. This ensures that it does not overly bias keypoints to focus on characteristics that are not unique to objects, such as movement, shape, colour etc.  We demonstrate the efficacy of PermaKey on Atari where it learns keypoints corresponding to the most salient object parts and is robust to certain visual distractors. Further, on downstream RL tasks in the Atari domain we demonstrate how agents equipped with our keypoints outperform those using competing alternatives, even on challenging environments with moving backgrounds or distractor objects.",Oral Session 8,https://openreview.net/pdf?id=GJwMHetHc73,https://openreview.net/forum?id=GJwMHetHc73
"['Taiji Suzuki', 'Akiyama Shunta']",ICLR,Benefit of deep learning with non-convex noisy gradient descent: Provable excess risk bound and superiority to kernel methods,https://iclr.cc/virtual/2021/spotlight/3507,2021," Establishing a theoretical analysis that explains why deep learning can outperform shallow learning such as kernel methods is one of the biggest issues in the deep learning literature. Towards answering this question, we evaluate excess risk of a deep learning estimator trained by a noisy gradient descent with ridge regularization on a mildly overparameterized neural network, 
and discuss its superiority to a class of linear estimators that includes neural tangent kernel approach, random feature model, other kernel methods, $k$-NN estimator and so on. We consider a teacher-student regression model, and eventually show that {\it any} linear estimator can be outperformed by deep learning in a sense of the minimax optimal rate especially for a high dimension setting. The obtained excess bounds are so-called fast learning rate which is faster than $O(1/\sqrt{n})$ that is obtained by usual Rademacher complexity analysis. This discrepancy is induced by the non-convex geometry of the model and the noisy gradient descent used for neural network training provably reaches a near global optimal solution even though the loss landscape is highly non-convex. Although the noisy gradient descent does not employ any explicit or implicit sparsity inducing regularization, it shows a preferable generalization performance that dominates linear estimators.",Oral Session 7,https://openreview.net/pdf?id=2m0g1wEafh,https://openreview.net/forum?id=2m0g1wEafh
"['Yonggan Fu', 'Han Guo', 'Meng Li', 'Xin Yang', 'Yining Ding', 'Vikas Chandra', 'Yingyan Lin']",ICLR,CPT: Efficient Deep Neural Network Training via Cyclic Precision,https://iclr.cc/virtual/2021/spotlight/3546,2021," Low-precision deep neural network (DNN) training has gained tremendous attention as reducing precision is one of the most effective knobs for boosting DNNs' training time/energy efficiency. In this paper, we attempt to explore low-precision training from a new perspective as inspired by recent findings in understanding DNN training: we conjecture that DNNs' precision might have a similar effect as the learning rate during DNN training, and advocate dynamic precision along the training trajectory for further boosting the time/energy efficiency of DNN training. Specifically, we propose Cyclic Precision Training (CPT) to cyclically vary the precision between two boundary values which can be identified using a simple precision range test within the first few training epochs. Extensive simulations and ablation studies on five datasets and eleven models demonstrate that CPT's effectiveness is consistent across various models/tasks (including classification and language modeling). Furthermore, through experiments and visualization we show that CPT helps to (1) converge to a wider minima with a lower generalization error and (2) reduce training variance which we believe opens up a new design knob for simultaneously improving the optimization and efficiency of DNN training.",Oral Session 9,https://openreview.net/pdf?id=87ZwsaQNHPZ,https://openreview.net/forum?id=87ZwsaQNHPZ
"['Cheng Perng Phoo', 'Bharath Hariharan']",ICLR,Self-training For Few-shot Transfer Across Extreme Task Differences,https://iclr.cc/virtual/2021/oral/3442,2021," Most few-shot learning techniques are pre-trained on a large, labeled “base dataset”. In problem domains where such large labeled datasets are not available for pre-training (e.g., X-ray, satellite images), one must resort to pre-training in a different “source” problem domain (e.g., ImageNet), which can be very different from the desired target task. Traditional few-shot and transfer learning techniques fail in the presence of such extreme differences between the source and target tasks. In this paper, we present a simple and effective solution to tackle this extreme domain gap: self-training a source domain representation on unlabeled data from the target domain. We show that this improves one-shot performance on the target domain by 2.9 points on average on the challenging BSCD-FSL benchmark consisting of datasets from multiple domains.",Oral Session 11,https://openreview.net/pdf?id=O3Y56aqpChA,https://openreview.net/forum?id=O3Y56aqpChA
"['Ainesh Bakshi', 'Chiranjib Bhattacharyya', 'Ravi Kannan', 'David Woodruff', 'Samson Zhou']",ICLR,Learning a Latent Simplex in Input Sparsity Time,https://iclr.cc/virtual/2021/spotlight/3530,2021," We consider the problem of learning a latent $k$-vertex simplex $K\in\mathbb{R}^d$, given $\mathbf{A}\in\mathbb{R}^{d\times n}$, which can be viewed as $n$ data points that are formed by randomly perturbing some latent points in $K$, possibly beyond $K$. A large class of latent variable models, such as adversarial clustering, mixed membership stochastic block models, and topic models can be cast in this view of learning a latent simplex. Bhattacharyya and Kannan (SODA 2020) give an algorithm for learning such a $k$-vertex latent simplex in time roughly $O(k\cdot\text{nnz}(\mathbf{A}))$, where $\text{nnz}(\mathbf{A})$ is the number of non-zeros in $\mathbf{A}$. We show that the dependence on $k$ in the running time is unnecessary given a natural assumption about the mass of the top $k$ singular values of $\mathbf{A}$, which holds in many of these applications. Further, we show this assumption is necessary, as otherwise an algorithm for learning a latent simplex would imply a better low rank approximation algorithm than what is known. 

We obtain a spectral low-rank approximation to $\mathbf{A}$ in input-sparsity time and show that the column space thus obtained has small $\sin\Theta$ (angular) distance to the right top-$k$ singular space of $\mathbf{A}$. Our algorithm then selects $k$ points in the low-rank  subspace with the largest inner product (in absolute value) with $k$ carefully chosen random vectors. By working in the low-rank subspace, we avoid reading the entire matrix in each iteration and thus circumvent the $\Theta(k\cdot\text{nnz}(\mathbf{A}))$ running time.",Oral Session 12,https://openreview.net/pdf?id=04LZCAxMSco,https://openreview.net/forum?id=04LZCAxMSco
"['Stanislav Morozov', 'Andrey Voynov', 'Artem Babenko']",ICLR,On Self-Supervised Image Representations for GAN Evaluation,https://iclr.cc/virtual/2021/spotlight/3413,2021," The embeddings from CNNs pretrained on Imagenet classification are de-facto standard image representations for assessing GANs via FID, Precision and Recall measures. Despite broad previous criticism of their usage for non-Imagenet domains, these embeddings are still the top choice in most of the GAN literature. In this paper, we advocate the usage of the state-of-the-art self-supervised representations to evaluate GANs on the established non-Imagenet benchmarks. These representations, typically obtained via contrastive learning, are shown to provide better transfer to new tasks and domains, therefore, can serve as more universal embeddings of natural images. With extensive comparison of the recent GANs on the common datasets, we show that self-supervised representations produce a more reasonable ranking of models in terms of FID/Precision/Recall, while the ranking with classification-pretrained embeddings often can be misleading.",Oral Session 10,https://openreview.net/pdf?id=NeRdBeTionN,https://openreview.net/forum?id=NeRdBeTionN
"['Keyulu Xu', 'Mozhi Zhang', 'Jingling Li', 'Simon Du', 'Ken-Ichi Kawarabayashi', 'Stefanie Jegelka']",ICLR,How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks,https://iclr.cc/virtual/2021/oral/3390,2021," We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.",Oral Session 3,https://openreview.net/pdf?id=UH-cmocLJC,https://openreview.net/forum?id=UH-cmocLJC
"['Nils Wandel', 'Michael Weinmann', 'Reinhard Klein']",ICLR,"Learning Incompressible Fluid Dynamics from Scratch - Towards Fast, Differentiable Fluid Models that Generalize",https://iclr.cc/virtual/2021/spotlight/3460,2021," Fast and stable fluid simulations are an essential prerequisite for applications ranging from computer-generated imagery to computer-aided design in research and development. However, solving the partial differential equations of incompressible fluids is a challenging task and traditional numerical approximation schemes come at high computational costs. Recent deep learning based approaches promise vast speed-ups but do not generalize to new fluid domains, require fluid simulation data for training, or rely on complex pipelines that outsource major parts of the fluid simulation to traditional methods. In this work, we propose a novel physics-constrained training approach that generalizes to new fluid domains, requires no fluid simulation data, and allows convolutional neural networks to map a fluid state from time-point t to a subsequent state at time t+dt in a single forward pass. This simplifies the pipeline to train and evaluate neural fluid models. After training, the framework yields models that are capable of fast fluid simulations and can handle various fluid phenomena including the Magnus effect and Kármán vortex streets. We present an interactive real-time demo to show the speed and generalization capabilities of our trained models. Moreover, the trained neural networks are efficient differentiable fluid solvers as they offer a differentiable update step to advance the fluid simulation in time. We exploit this fact in a proof-of-concept optimal control experiment. Our models significantly outperform a recent differentiable fluid solver in terms of computational speed and accuracy.",Oral Session 4,https://openreview.net/pdf?id=KUDUoRsEphu,https://openreview.net/forum?id=KUDUoRsEphu
"['Beidi Chen', 'Zichang Liu', 'Binghui Peng', 'Zhaozhuo Xu', 'Jonathan L Li', 'Tri Dao', 'Zhao Song', 'Anshumali Shrivastava', 'Christopher Re']",ICLR,MONGOOSE: A Learnable LSH Framework for Efficient Neural Network Training,https://iclr.cc/virtual/2021/oral/3430,2021," Recent advances by practitioners in the deep learning community have breathed new life into Locality Sensitive Hashing (LSH), using it to reduce memory and time bottlenecks in neural network (NN) training. However, while LSH has sub-linear guarantees for approximate near-neighbor search in theory, it is known to have inefficient query time in practice due to its use of random hash functions. Moreover, when model parameters are changing, LSH suffers from update overhead. This work is motivated by an observation that model parameters evolve slowly, such that the changes do not always require an LSH update to maintain performance. This phenomenon points to the potential for a reduction in update time and allows for a modified learnable version of data-dependent LSH to improve query time at a low cost. We use the above insights to build MONGOOSE, an end-to-end LSH framework for efficient NN training. In particular, MONGOOSE is equipped with a scheduling algorithm to adaptively perform LSH updates with provable guarantees and learnable hash functions to improve query efficiency. Empirically, we validate MONGOOSE on large-scale deep learning models for recommendation systems and language modeling. We find that it achieves up to 8% better accuracy compared to previous LSH approaches, with $6.5 \times$ speed-up and $6\times$ reduction in memory usage.",Oral Session 6,https://openreview.net/pdf?id=wWK7yXkULyh,https://openreview.net/forum?id=wWK7yXkULyh
"['Talya Eden', 'Piotr Indyk', 'Shyam Narayanan', 'Ronitt Rubinfeld', 'Sandeep Silwal', 'Tal Wagner']",ICLR,Learning-based Support Estimation in Sublinear Time,https://iclr.cc/virtual/2021/spotlight/3522,2021," We consider the  problem of estimating the number of distinct elements in a large data set (or, equivalently, the support size of the distribution induced by the data set) from a random sample of its elements. The problem occurs in many applications, including biology, genomics, computer systems and linguistics. A line of research spanning the last decade resulted in algorithms that estimate the support up to $ \pm \varepsilon n$ from a sample of size $O(\log^2(1/\varepsilon) \cdot n/\log n)$, where $n$ is the data set size.  Unfortunately, this bound is known to be tight, limiting further improvements to the complexity of this problem. In this paper we consider estimation algorithms augmented with a machine-learning-based predictor that, given any element, returns an estimation of  its frequency.  We show that if the predictor is correct up to a constant approximation factor, then the sample complexity can be reduced significantly,  to
$$ \ \log (1/\varepsilon) \cdot n^{1-\Theta(1/\log(1/\varepsilon))}. $$
We evaluate the proposed algorithms on a collection of data sets, using the neural-network based estimators from {Hsu et al, ICLR'19} as predictors. Our experiments  demonstrate substantial (up to 3x) improvements in the estimation accuracy compared to the state of the art algorithm.",Oral Session 5,https://openreview.net/pdf?id=tilovEHA3YS,https://openreview.net/forum?id=tilovEHA3YS
"['Zhisheng Xiao', 'Karsten Kreis', 'Jan Kautz', 'Arash Vahdat']",ICLR,VAEBM: A Symbiosis between Variational Autoencoders and Energy-based Models,https://iclr.cc/virtual/2021/spotlight/3524,2021," Energy-based models (EBMs) have recently been successful in representing complex distributions of small images. However, sampling from them requires expensive Markov chain Monte Carlo (MCMC) iterations that mix slowly in high dimensional pixel space. Unlike EBMs, variational autoencoders (VAEs) generate samples quickly and are equipped with a latent space that enables fast traversal of the data manifold. However, VAEs tend to assign high probability density to regions in data space outside the actual data distribution and often fail at generating sharp images. In this paper, we propose VAEBM, a symbiotic composition of a VAE and an EBM that offers the best of both worlds. VAEBM captures the overall mode structure of the data distribution using a state-of-the-art VAE and it relies on its EBM component to explicitly exclude non-data-like regions from the model and refine the image samples. Moreover, the VAE component in VAEBM allows us to speed up MCMC updates by reparameterizing them in the VAE's latent space. Our experimental results show that VAEBM outperforms state-of-the-art VAEs and EBMs in generative quality on several benchmark image datasets by a large margin. It can generate high-quality images as large as 256$\times$256 pixels with short MCMC chains. We also demonstrate that VAEBM provides complete mode coverage and performs well in out-of-distribution detection.",Oral Session 8,https://openreview.net/pdf?id=5m3SEczOV8L,https://openreview.net/forum?id=5m3SEczOV8L
"['Dequan Wang', 'Evan Shelhamer', 'Shaoteng Liu', 'Bruno Olshausen', 'trevor darrell']",ICLR,Tent: Fully Test-Time Adaptation by Entropy Minimization,https://iclr.cc/virtual/2021/spotlight/3479,2021," A model must adapt itself to generalize to new and different data during testing. In this setting of fully test-time adaptation the model has only the test data and its own parameters. We propose to adapt by test entropy minimization (tent): we optimize the model for confidence as measured by the entropy of its predictions. Our method estimates normalization statistics and optimizes channel-wise affine transformations to update online on each batch. Tent reduces generalization error for image classification on corrupted ImageNet and CIFAR-10/100 and reaches a new state-of-the-art error on ImageNet-C. Tent handles source-free domain adaptation on digit recognition from SVHN to MNIST/MNIST-M/USPS, on semantic segmentation from GTA to Cityscapes, and on the VisDA-C benchmark. These results are achieved in one epoch of test-time optimization without altering training.",Oral Session 7,https://openreview.net/pdf?id=uXl3bZLkr3c,https://openreview.net/forum?id=uXl3bZLkr3c
"['Sanghyun Hong', 'Yigitcan Kaya', 'Ionut-Vlad Modoranu', 'Tudor Dumitras']",ICLR,"A Panda? No, It's a Sloth: Slowdown Attacks on Adaptive Multi-Exit Neural Network Inference",https://iclr.cc/virtual/2021/spotlight/3384,2021," Recent increases in the computational demands of deep neural networks (DNNs), combined with the observation that most input samples require only simple models, have sparked interest in input-adaptive multi-exit architectures, such as MSDNets or Shallow-Deep Networks. These architectures enable faster inferences and could bring DNNs to low-power devices, e.g., in the Internet of Things (IoT). However, it is unknown if the computational savings provided by this approach are robust against adversarial pressure. In particular, an adversary may aim to slowdown adaptive DNNs by increasing their average inference time—a threat analogous to the denial-of-service attacks from the Internet. In this paper, we conduct a systematic evaluation of this threat by experimenting with three generic multi-exit DNNs (based on VGG16, MobileNet, and ResNet56) and a custom multi-exit architecture, on two popular image classification benchmarks (CIFAR-10 and Tiny ImageNet). To this end, we show that adversarial example-crafting techniques can be modified to cause slowdown, and we propose a metric for comparing their impact on different architectures. We show that a slowdown attack reduces the efficacy of multi-exit DNNs by 90–100%, and it amplifies the latency by 1.5–5× in a typical IoT deployment. We also show that it is possible to craft universal, reusable perturbations and that the attack can be effective in realistic black-box scenarios, where the attacker has limited knowledge about the victim. Finally, we show that adversarial training provides limited protection against slowdowns. These results suggest that further research is needed for defending multi-exit architectures against this emerging threat. Our code is available at https://github.com/sanghyun-hong/deepsloth.",Oral Session 11,https://openreview.net/pdf?id=9xC2tWEwBD,https://openreview.net/forum?id=9xC2tWEwBD
"['Shangqing Liu', 'Yu Chen', 'Xiaofei Xie', 'Siow Jing Kai', 'Yang Liu']",ICLR,Retrieval-Augmented Generation for Code Summarization via Hybrid GNN,https://iclr.cc/virtual/2021/spotlight/3538,2021," Source code summarization aims to generate natural language summaries from structured code snippets for better understanding code functionalities. However, automatic code summarization is challenging due to the complexity of the source code and the language gap between the source code and natural language summaries. Most previous approaches either rely on retrieval-based (which can take advantage of similar examples seen from the retrieval database, but have low generalization performance) or generation-based methods (which have better generalization performance, but cannot take advantage of similar examples).
This paper proposes a novel retrieval-augmented mechanism to combine the benefits of both worlds.
Furthermore, to mitigate the limitation of Graph Neural Networks (GNNs) on capturing global graph structure information of source code, we propose a novel attention-based dynamic graph to complement the static graph representation of the source code, and design a hybrid message passing GNN for capturing both the local and global structural information. To evaluate the proposed approach, we release a new challenging benchmark, crawled from diversified large-scale open-source C projects (total 95k+ unique functions in the dataset). Our method achieves the state-of-the-art performance, improving existing methods by 1.42, 2.44 and 1.29 in terms of BLEU-4, ROUGE-L and METEOR.",Oral Session 10,https://openreview.net/pdf?id=zv-typ1gPxA,https://openreview.net/forum?id=zv-typ1gPxA
"['Suraj Srinivas', 'François Fleuret']",ICLR,Rethinking the Role of Gradient-based Attribution Methods for Model Interpretability,https://iclr.cc/virtual/2021/oral/3471,2021," Current methods for the interpretability of discriminative deep neural networks commonly rely on the model's input-gradients, i.e., the gradients of the output logits w.r.t. the inputs. The common assumption is that these input-gradients contain information regarding $p_{\theta} ( y\mid \mathbf{x} )$, the model's discriminative capabilities, thus justifying their use for interpretability. However, in this work, we show that these input-gradients can be arbitrarily manipulated as a consequence of the shift-invariance of softmax without changing the discriminative function. This leaves an open question: given that input-gradients can be arbitrary, why are they highly structured and explanatory in standard models?

In this work, we re-interpret the logits of standard softmax-based classifiers as unnormalized log-densities of the data distribution and show that input-gradients can be viewed as gradients of a class-conditional generative model $p_{\theta}(\mathbf{x} \mid y)$ implicit in the discriminative model. This leads us to hypothesize that the highly structured and explanatory nature of input-gradients may be due to the alignment of this class-conditional model $p_{\theta}(\mathbf{x} \mid y)$ with that of the ground truth data distribution $p_{\text{data}} (\mathbf{x} \mid y)$. We test this hypothesis by studying the effect of density alignment on gradient explanations. To achieve this density alignment, we use an algorithm called score-matching, and propose novel approximations to this algorithm to enable training large-scale models.

Our experiments show that improving the alignment of the implicit density model with the data distribution enhances gradient structure and explanatory power while reducing this alignment has the opposite effect. This also leads us to conjecture that unintended density alignment in standard neural network training may explain the highly structured nature of input-gradients observed in practice. Overall, our finding that input-gradients capture information regarding an implicit generative model implies that we need to re-think their use for interpreting discriminative models.",Oral Session 1,https://openreview.net/pdf?id=dYeAHXnpWJ4,https://openreview.net/forum?id=dYeAHXnpWJ4
"['Anastasios Angelopoulos', 'Stephen Bates', 'Michael Jordan', 'Jitendra Malik']",ICLR,Uncertainty Sets for Image Classifiers using Conformal Prediction,https://iclr.cc/virtual/2021/spotlight/3435,2021," Convolutional image classifiers can achieve high predictive accuracy, but quantifying their uncertainty remains an unresolved challenge, hindering their deployment in consequential settings. Existing uncertainty quantification techniques, such as Platt scaling, attempt to calibrate the network’s probability estimates, but they do not have formal guarantees. We present an algorithm that modifies any classifier to output a predictive set containing the true label with a user-specified probability, such as 90%. The algorithm is simple and fast like Platt scaling, but provides a formal finite-sample coverage guarantee for every model and dataset. Our method modifies an existing conformal prediction algorithm to give more stable predictive sets by regularizing the small scores of unlikely classes after Platt scaling. In experiments on both Imagenet and Imagenet-V2 with ResNet-152 and other classifiers, our scheme outperforms existing approaches, achieving coverage with sets that are often factors of 5 to 10 smaller than a stand-alone Platt scaling baseline.",Oral Session 2,https://openreview.net/pdf?id=eNdiU_DbM9,https://openreview.net/forum?id=eNdiU_DbM9
"['Zhiao Huang', 'Yuanming Hu', 'Tao Du', 'Siyuan Zhou', 'Hao Su', 'Joshua B Tenenbaum', 'Chuang Gan']",ICLR,PlasticineLab: A Soft-Body Manipulation Benchmark with Differentiable Physics,https://iclr.cc/virtual/2021/spotlight/3464,2021," Simulated virtual environments serve as one of the main driving forces behind developing and evaluating skill learning algorithms. However, existing environments typically only simulate rigid body physics. Additionally, the simulation process usually does not provide gradients that might be useful for planning and control optimizations. We introduce a new differentiable physics benchmark called PasticineLab, which includes a diverse collection of soft body manipulation tasks. In each task, the agent uses manipulators to deform the plasticine into a desired configuration. The underlying physics engine supports differentiable elastic and plastic deformation using the DiffTaichi system, posing many under-explored challenges to robotic agents. We evaluate several existing reinforcement learning (RL) methods and gradient-based methods on this benchmark. Experimental results suggest that 1) RL-based approaches struggle to solve most of the tasks efficiently;  2) gradient-based approaches, by optimizing open-loop control sequences with the built-in differentiable physics engine, can rapidly find a solution within tens of iterations, but still fall short on multi-stage tasks that require long-term planning. We expect that PlasticineLab will encourage the development of novel algorithms that combine differentiable physics and RL for more complex physics-based skill learning tasks. PlasticineLab will be made publicly available.",Oral Session 9,https://openreview.net/pdf?id=xCcdBRQEDW,https://openreview.net/forum?id=xCcdBRQEDW
"['Xiaoling Hu', 'Yusu Wang', 'Li Fuxin', 'Dimitris Samaras', 'Chao Chen']",ICLR,Topology-Aware Segmentation Using Discrete Morse Theory,https://iclr.cc/virtual/2021/spotlight/3475,2021," In the segmentation of fine-scale structures from natural and biomedical images, per-pixel accuracy is not the only metric of concern. Topological correctness, such as vessel connectivity and membrane closure, is crucial for downstream analysis tasks. In this paper, we propose a new approach to train deep image segmentation networks for better topological accuracy. In particular, leveraging the power of discrete Morse theory (DMT), we identify global structures, including 1D skeletons and 2D patches, which are important for topological accuracy. Trained with a novel loss based on these global structures, the network performance is significantly improved especially near topologically challenging locations (such as weak spots of connections and membranes). On diverse datasets, our method achieves superior performance on both the DICE score and topological metrics.",Oral Session 12,https://openreview.net/pdf?id=LGgdb4TS4Z,https://openreview.net/forum?id=LGgdb4TS4Z
"['Xiuyuan Cheng', 'Zichen Miao', 'Qiang Qiu']",ICLR,Graph Convolution with Low-rank Learnable Local Filters,https://iclr.cc/virtual/2021/spotlight/3484,2021," Geometric variations like rotation, scaling, and viewpoint changes pose a significant challenge to visual understanding. One common solution is to directly model certain intrinsic structures, e.g., using landmarks. However, it then becomes non-trivial to build effective deep models, especially when the underlying non-Euclidean grid is irregular and coarse. Recent deep models using graph convolutions provide an appropriate framework to handle such non-Euclidean data, but many of them, particularly those based on global graph Laplacians, lack expressiveness to capture local features required for representation of signals lying on the non-Euclidean grid. The current paper introduces a new type of graph convolution with learnable low-rank local filters, which is provably more expressive than previous spectral graph convolution methods. The model also provides a unified framework for both spectral and spatial graph convolutions. To improve model robustness, regularization by local graph Laplacians is introduced. The representation stability against input graph data perturbation is theoretically proved, making use of the graph filter locality and the local graph regularization. Experiments on spherical mesh data, real-world facial expression recognition/skeleton-based action recognition data, and data with simulated graph noise show the empirical advantage of the proposed model.",Oral Session 3,https://openreview.net/pdf?id=9OHFhefeB86,https://openreview.net/forum?id=9OHFhefeB86
"['Dominik Schmidt', 'Georgia Koppe', 'Zahra Monfared', 'Max Beutelspacher', 'Daniel Durstewitz']",ICLR,Identifying nonlinear dynamical systems with multiple time scales and long-range dependencies,https://iclr.cc/virtual/2021/spotlight/3540,2021," A main theoretical interest in biology and physics is to identify the nonlinear dynamical system (DS) that generated observed time series. Recurrent Neural Networks (RNN) are, in principle, powerful enough to approximate any underlying DS, but in their vanilla form suffer from the exploding vs. vanishing gradients problem. Previous attempts to alleviate this problem resulted either in more complicated, mathematically less tractable RNN architectures, or strongly limited the dynamical expressiveness of the RNN. 
Here we address this issue by suggesting a simple regularization scheme for vanilla RNN with ReLU activation which enables them to solve long-range dependency problems and express slow time scales, while retaining a simple mathematical structure which makes their DS properties partly analytically accessible. We prove two theorems that establish a tight connection between the regularized RNN dynamics and their gradients, illustrate on DS benchmarks that our regularization approach strongly eases the reconstruction of DS which harbor widely differing time scales, and show that our method is also en par with other long-range architectures like LSTMs on several tasks.",Oral Session 4,https://openreview.net/pdf?id=_XYzwxPIQu6,https://openreview.net/forum?id=_XYzwxPIQu6
"['Marisa Kirisame', 'Steven S. Lyubomirsky', 'Altan Haan', 'Jennifer Brennan', 'Mike He', 'Jared G Roesch', 'Tianqi Chen', 'Zachary Tatlock']",ICLR,Dynamic Tensor Rematerialization,https://iclr.cc/virtual/2021/spotlight/3533,2021," Checkpointing enables the training of deep learning models under restricted memory budgets by freeing intermediate activations from memory and recomputing them on demand. Current checkpointing techniques statically plan these recomputations offline and assume static computation graphs. We demonstrate that a simple online algorithm can achieve comparable performance by introducing Dynamic Tensor Rematerialization (DTR), a greedy online algorithm for checkpointing that is extensible and general, is parameterized by eviction policy, and supports dynamic models. We prove that DTR can train an $N$-layer linear feedforward network on an  $\Omega(\sqrt{N})$ memory budget with only $\mathcal{O}(N)$ tensor operations. DTR closely matches the performance of optimal static checkpointing in simulated experiments. We incorporate a DTR prototype into PyTorch merely by interposing on tensor allocations and operator calls and collecting lightweight metadata on tensors.",Oral Session 8,https://openreview.net/pdf?id=Vfs_2RnOD0H,https://openreview.net/forum?id=Vfs_2RnOD0H
"['Aditya Krishna Menon', 'Sadeep Jayasumana', 'Ankit Singh Rawat', 'Himanshu Jain', 'Andreas Veit', 'Sanjiv Kumar']",ICLR,Long-tail learning via logit adjustment,https://iclr.cc/virtual/2021/spotlight/3516,2021," Real-world classification problems typically exhibit an imbalanced or long-tailed label distribution, wherein many labels have only a few associated samples. This poses a challenge for generalisation on such labels, and also  makes naive learning biased towards dominant labels. In this paper,  we present a statistical framework that unifies and generalises several recent proposals to cope with these challenges. Our framework revisits the classic idea of logit adjustment based on the label frequencies, which encourages a large relative margin between logits of rare positive versus dominant negative labels. This yields two techniques  for long-tail learning, where such adjustment is either applied post-hoc to a trained model, or enforced in the loss during training. These techniques are statistically grounded, and practically effective on four real-world datasets with long-tailed label distributions.",Oral Session 5,https://openreview.net/pdf?id=37nvvqkCo5,https://openreview.net/forum?id=37nvvqkCo5
"['Xiu Su', 'Shan You', 'Tao Huang', 'Fei Wang', 'Chen Qian', 'Changshui Zhang', 'Chang Xu']",ICLR,Locally Free Weight Sharing for Network Width Search,https://iclr.cc/virtual/2021/spotlight/3486,2021," Searching for network width is an effective way to slim deep neural networks with hardware budgets. With this aim, a one-shot supernet is usually leveraged as a performance evaluator to rank the performance \wrt~different width. Nevertheless, current methods mainly follow a manually fixed weight sharing pattern, which is limited to distinguish the performance gap of different width. In this paper, to better evaluate each width, we propose a locally free weight sharing strategy (CafeNet) accordingly. In CafeNet, weights are more freely shared, and each width is jointly indicated by its base channels and free channels, where free channels are supposed to locate freely in a local zone to better represent each width. Besides, we propose to further reduce the search space by leveraging our introduced FLOPs-sensitive bins. As a result, our CafeNet can be trained stochastically and get optimized within a min-min strategy. Extensive experiments on ImageNet, CIFAR-10, CelebA and MS COCO dataset have verified our superiority comparing to other state-of-the-art baselines. For example, our method can further boost the benchmark NAS network EfficientNet-B0 by 0.41\% via searching its width more delicately.",Oral Session 6,https://openreview.net/pdf?id=S0UdquAnr9k,https://openreview.net/forum?id=S0UdquAnr9k
"['Yanzhi Chen', 'Dinghuai Zhang', 'Michael U Gutmann', 'Aaron Courville', 'Zhanxing Zhu']",ICLR,Neural Approximate Sufficient Statistics for Implicit Models,https://iclr.cc/virtual/2021/spotlight/3432,2021," We consider the fundamental problem of how to automatically construct summary statistics for implicit generative models where the evaluation of the likelihood function is intractable but sampling data from the model is possible. The idea is to frame the task of constructing sufficient statistics as learning mutual information maximizing representations of the data with the help of deep neural networks. The infomax learning procedure does not need to estimate any density or density ratio. We apply our approach to both traditional approximate Bayesian computation and recent neural likelihood methods, boosting their performance on a range of tasks.",Oral Session 7,https://openreview.net/pdf?id=SRDuJssQud,https://openreview.net/forum?id=SRDuJssQud
"['Augustus Odena', 'Kensen Shi', 'David Bieber', 'Rishabh Singh', 'Charles Sutton', 'Hanjun Dai']",ICLR,BUSTLE: Bottom-Up Program Synthesis Through Learning-Guided Exploration,https://iclr.cc/virtual/2021/spotlight/3489,2021," Program synthesis is challenging largely because of the difficulty of search in a large space of programs. Human programmers routinely tackle the task of writing complex programs by writing sub-programs and then analyzing their intermediate results to compose them in appropriate ways. Motivated by this intuition, we present a new synthesis approach that leverages learning to guide a bottom-up search over programs. In particular, we train a model to prioritize compositions of intermediate values during search conditioned on a given set of input-output examples. This is a powerful combination because of several emergent properties. First, in bottom-up search, intermediate programs can be executed, providing semantic information to the neural network. Second, given the concrete values from those executions, we can exploit rich features based on recent work on property signatures. Finally, bottom-up search allows the system substantial flexibility in what order to generate the solution, allowing the synthesizer to build up a program from multiple smaller sub-programs. Overall, our empirical evaluation finds that the combination of learning and bottom-up search is remarkably effective, even with simple supervised learning approaches. We demonstrate the effectiveness of our technique on two datasets, one from the SyGuS competition and one of our own creation.",Oral Session 11,https://openreview.net/pdf?id=yHeg4PbFHh,https://openreview.net/forum?id=yHeg4PbFHh
"['Jacob Menick', 'Erich Elsen', 'Utku Evci', 'Simon Osindero', 'Karen Simonyan', 'Alex Graves']",ICLR,Practical Real Time Recurrent Learning with a Sparse Approximation,https://iclr.cc/virtual/2021/spotlight/3439,2021," Recurrent neural networks are usually trained with backpropagation through time, which requires storing a complete history of network states, and prohibits updating the weights ""online"" (after every timestep). Real Time Recurrent Learning (RTRL) eliminates the need for history storage and allows for online weight updates, but does so at the expense of computational costs that are quartic in the state size. This renders RTRL training intractable for all but the smallest networks, even ones that are made highly sparse.
We introduce the Sparse n-step Approximation (SnAp) to the RTRL influence matrix. SnAp only tracks the influence of a parameter on hidden units that are reached by the computation graph within $n$ timesteps of the recurrent core. SnAp with $n=1$ is no more expensive than backpropagation but allows training on arbitrarily long sequences. We find that it substantially outperforms other RTRL approximations with comparable costs such as Unbiased Online Recurrent Optimization. For highly sparse networks, SnAp with $n=2$ remains tractable and can outperform backpropagation through time in terms of learning speed when updates are done online.",Oral Session 10,https://openreview.net/pdf?id=q3KSThy2GwB,https://openreview.net/forum?id=q3KSThy2GwB
"['Omer Yair', 'Tomer Michaeli']",ICLR,Contrastive Divergence Learning is a Time Reversal Adversarial Game,https://iclr.cc/virtual/2021/spotlight/3477,2021," Contrastive divergence (CD) learning is a classical method for fitting unnormalized statistical models to data samples. Despite its wide-spread use, the convergence properties of this algorithm are still not well understood. The main source of difficulty is an unjustified approximation which has been used to derive the gradient of the loss. In this paper, we present an alternative derivation of CD that does not require any approximation and sheds new light on the objective that is actually being optimized by the algorithm. Specifically, we show that CD is an adversarial learning procedure, where a discriminator attempts to classify whether a Markov chain generated from the model has been time-reversed. Thus, although predating generative adversarial networks (GANs) by more than a decade, CD is, in fact, closely related to these techniques. Our derivation settles well with previous observations, which have concluded that CD's update steps cannot be expressed as the gradients of any fixed objective function. In addition, as a byproduct, our derivation reveals a simple correction that can be used as an alternative to Metropolis-Hastings rejection, which is required when the underlying Markov chain is inexact (e.g., when using Langevin dynamics with a large step).",Oral Session 1,https://openreview.net/pdf?id=MLSvqIHRidA,https://openreview.net/forum?id=MLSvqIHRidA
"['Yoav Levine', 'Barak Lenz', 'Opher Lieber', 'Omri Abend', 'Kevin Leyton-Brown', 'Moshe Tennenholtz', 'Yoav Shoham']",ICLR,PMI-Masking: Principled masking of correlated spans,https://iclr.cc/virtual/2021/spotlight/3496,2021," Masking tokens uniformly at random constitutes a common flaw in the pretraining of Masked Language Models (MLMs) such as BERT. We show that such uniform masking allows an MLM to minimize its training objective by latching onto shallow local signals, leading to pretraining inefficiency and suboptimal downstream performance. To address this flaw, we propose PMI-Masking, a principled masking strategy based on the concept of Pointwise Mutual Information (PMI), which jointly masks a token n-gram if it exhibits high collocation over the corpus. PMI-Masking motivates, unifies, and improves upon prior more heuristic approaches that attempt to address the drawback of random uniform token masking, such as whole-word masking, entity/phrase masking, and random-span masking. Specifically, we show experimentally that PMI-Masking reaches the performance of prior masking approaches in half the training time, and consistently improves performance at the end of pretraining.",Oral Session 2,https://openreview.net/pdf?id=3Aoft6NWFej,https://openreview.net/forum?id=3Aoft6NWFej
"['Yutong Xie', 'Chence Shi', 'Hao Zhou', 'Yuwei Yang', 'Weinan Zhang', 'Yong Yu', 'Lei Li']",ICLR,MARS: Markov Molecular Sampling for Multi-objective Drug Discovery,https://iclr.cc/virtual/2021/spotlight/3417,2021," Searching for novel molecules with desired chemical properties is crucial in drug discovery. Existing work focuses on developing neural models to generate either molecular sequences or chemical graphs. However, it remains a big challenge to find novel and diverse compounds satisfying several properties. In this paper, we propose MARS, a method for multi-objective drug molecule discovery. MARS is based on the idea of generating the chemical candidates by iteratively editing fragments of molecular graphs. To search for high-quality candidates, it employs Markov chain Monte Carlo sampling (MCMC) on molecules with an annealing scheme and an adaptive proposal. To further improve sample efficiency, MARS uses a graph neural network (GNN) to represent and select candidate edits, where the GNN is trained on-the-fly with samples from MCMC. Experiments show that MARS achieves state-of-the-art performance in various multi-objective settings where molecular bio-activity, drug-likeness, and synthesizability are considered. Remarkably, in the most challenging setting where all four objectives are simultaneously optimized, our approach outperforms previous methods significantly in comprehensive evaluations. The code is available at https://github.com/yutxie/mars.",Oral Session 12,https://openreview.net/pdf?id=kHSu4ebxFXY,https://openreview.net/forum?id=kHSu4ebxFXY
"['Eli Ovits', 'Lior Wolf']",ICLR,Fidelity-based Deep Adiabatic Scheduling,https://iclr.cc/virtual/2021/spotlight/3398,2021," Adiabatic quantum computation is a form of computation that acts by slowly interpolating a quantum system between an easy to prepare initial state and a final state that represents a solution to a given computational problem. The choice of the interpolation schedule is critical to the performance: if at a certain time point, the evolution is too rapid, the system has a high probability to transfer to a higher energy state, which does not represent a solution to the problem. On the other hand, an evolution that is too slow leads to a loss of computation time and increases the probability of failure due to decoherence. In this work, we train deep neural models to produce optimal schedules that are conditioned on the problem at hand.  We consider two types of problem representation: the Hamiltonian form, and the Quadratic Unconstrained Binary Optimization (QUBO) form. A novel loss function that scores schedules according to their approximated success probability is introduced. We benchmark our approach on random QUBO problems, Grover search, 3-SAT, and MAX-CUT problems and show that our approach outperforms, by a sizable margin, the linear schedules as well as alternative approaches that were very recently proposed.",Oral Session 4,https://openreview.net/pdf?id=NECTfffOvn1,https://openreview.net/forum?id=NECTfffOvn1
"['Zhuang Liu', 'Xuanlin Li', 'Bingyi Kang', 'trevor darrell']",ICLR,Regularization Matters in Policy Optimization - An Empirical Study on Continuous Control,https://iclr.cc/virtual/2021/spotlight/3387,2021," Deep Reinforcement Learning (Deep RL) has been receiving increasingly more attention  thanks to its encouraging performance on a variety of control tasks. Yet, conventional regularization techniques in training neural networks (e.g., $L_2$ regularization, dropout) have been largely ignored in RL methods, possibly because agents are typically trained and evaluated in the same environment, and because the deep RL community focuses more on high-level algorithm designs. In this work, we present the first comprehensive study of regularization techniques with multiple policy optimization algorithms on continuous control tasks. Interestingly, we find conventional regularization techniques on the policy networks can often bring large improvement, especially on harder tasks. Our findings are shown to be robust against training hyperparameter variations. We also compare these techniques with the more widely used entropy regularization. In addition, we study regularizing different components and find that only regularizing the policy network is typically the best. We further analyze why regularization may help generalization in RL from four perspectives - sample complexity, reward distribution, weight norm, and noise robustness. We hope our study provides guidance for future practices in regularizing policy optimization algorithms. Our code is available at https://github.com/xuanlinli17/iclr2021_rlreg .",Oral Session 9,https://openreview.net/pdf?id=yr1mzrH3IC,https://openreview.net/forum?id=yr1mzrH3IC
"['Elliot Meyerson', 'Risto Miikkulainen']",ICLR,The Traveling Observer Model: Multi-task Learning Through Spatial Variable Embeddings,https://iclr.cc/virtual/2021/spotlight/3459,2021," This paper frames a general prediction system as an observer traveling around a continuous space, measuring values at some locations, and predicting them at others. The observer is completely agnostic about any particular task being solved; it cares only about measurement locations and their values. This perspective leads to a machine learning framework in which seemingly unrelated tasks can be solved by a single model, by embedding their input and output variables into a shared space. An implementation of the framework is developed in which these variable embeddings are learned jointly with internal model parameters. In experiments, the approach is shown to (1) recover intuitive locations of variables in space and time, (2) exploit regularities across related datasets with completely disjoint input and output spaces, and (3) exploit regularities across seemingly unrelated tasks, outperforming task-specific single-task models and multi-task learning alternatives. The results suggest that even seemingly unrelated tasks may originate from similar underlying processes, a fact that the traveling observer model can use to make better predictions.",Oral Session 3,https://openreview.net/pdf?id=qYda4oLEc1,https://openreview.net/forum?id=qYda4oLEc1
"['Aashaka Shah', 'Chao-Yuan Wu', 'Jayashree Mohan', 'Vijay Chidambaram', 'Philipp Krähenbühl']",ICLR,Memory Optimization for Deep Networks,https://iclr.cc/virtual/2021/spotlight/3420,2021," Deep learning is slowly, but steadily, hitting a memory bottleneck. While the tensor computation in top-of-the-line GPUs increased by $32\times$ over the last five years, the total available memory only grew by $2.5\times$. This prevents researchers from exploring larger architectures, as training large networks requires more memory for storing intermediate outputs. In this paper, we present MONeT, an automatic framework that minimizes both the memory footprint and computational overhead of deep networks. MONeT jointly optimizes the checkpointing schedule and the implementation of various operators. MONeT is able to outperform all prior hand-tuned operations as well as automated checkpointing. MONeT reduces the overall memory requirement by $3\times$ for various PyTorch models, with a 9-16$\%$ overhead in computation. For the same computation cost, MONeT requires 1.2-1.8$\times$ less memory than current state-of-the-art automated checkpointing frameworks. Our code will be made publicly available upon acceptance.",Oral Session 6,https://openreview.net/pdf?id=bnY0jm4l59,https://openreview.net/forum?id=bnY0jm4l59
"['Cheng Lu', 'Jianfei Chen', 'Chongxuan Li', 'Qiuhao Wang', 'Jun Zhu']",ICLR,Implicit Normalizing Flows,https://iclr.cc/virtual/2021/spotlight/3463,2021," Normalizing flows define a probability distribution by an explicit invertible transformation $\boldsymbol{\mathbf{z}}=f(\boldsymbol{\mathbf{x}})$. In this work, we present implicit normalizing flows (ImpFlows), which generalize normalizing flows by allowing the mapping to be implicitly defined by the roots of an equation $F(\boldsymbol{\mathbf{z}}, \boldsymbol{\mathbf{x}})= \boldsymbol{\mathbf{0}}$. ImpFlows build on residual flows (ResFlows) with a proper balance between expressiveness and tractability. Through theoretical analysis, we show that the function space of ImpFlow is strictly richer than that of ResFlows. Furthermore, for any ResFlow with a fixed number of blocks, there exists some function that ResFlow has a non-negligible approximation error. However, the function is exactly representable by a single-block ImpFlow. We propose a scalable algorithm to train and draw samples from ImpFlows. Empirically, we evaluate ImpFlow on several classification and density modeling tasks, and ImpFlow outperforms ResFlow with a comparable amount of parameters on all the benchmarks.",Oral Session 7,https://openreview.net/pdf?id=8PS8m9oYtNy,https://openreview.net/forum?id=8PS8m9oYtNy
"['Ekdeep Singh Lubana', 'Robert Dick']",ICLR,A Gradient Flow Framework For Analyzing Network Pruning,https://iclr.cc/virtual/2021/spotlight/3406,2021," Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.",Oral Session 8,https://openreview.net/pdf?id=rumv7QmLUue,https://openreview.net/forum?id=rumv7QmLUue
"['Jun Han', 'Martin Min', 'Ligong Han', 'Erran Li', 'Xuan Zhang']",ICLR,Disentangled Recurrent Wasserstein Autoencoder,https://iclr.cc/virtual/2021/spotlight/3410,2021," Learning disentangled representations leads to interpretable models and facilitates data generation with style transfer, which has been extensively studied on static data such as images in an unsupervised learning framework. However, only a few works have explored unsupervised disentangled sequential representation learning due to challenges of generating sequential data. In this paper, we propose recurrent Wasserstein Autoencoder (R-WAE), a new framework for generative modeling of sequential data. R-WAE disentangles the representation of an input sequence into static and dynamic factors (i.e., time-invariant and time-varying parts). Our theoretical analysis shows that, R-WAE minimizes an upper bound of a penalized form of the Wasserstein distance between model distribution and sequential data distribution, and simultaneously maximizes the mutual information between input data and different disentangled latent factors, respectively. This is superior to (recurrent) VAE which does not explicitly enforce mutual information maximization between input data and disentangled latent representations. When the number of actions in sequential data is available as weak supervision information, R-WAE is extended to learn a categorical latent representation of actions to improve its disentanglement. Experiments on a variety of datasets show that our models outperform other baselines with the same settings in terms of disentanglement and unconditional video generation both quantitatively and qualitatively.",Oral Session 11,https://openreview.net/pdf?id=O7ms4LFdsX,https://openreview.net/forum?id=O7ms4LFdsX
"['Zirui Wang', 'Yulia Tsvetkov', 'Orhan Firat', 'Yuan Cao']",ICLR,Gradient Vaccine: Investigating and Improving Multi-task Optimization in Massively Multilingual Models,https://iclr.cc/virtual/2021/spotlight/3531,2021," Massively multilingual models subsuming tens or even hundreds of languages pose great challenges to multi-task optimization. While it is a common practice to apply a language-agnostic procedure optimizing a joint multilingual task objective, how to properly characterize and take advantage of its underlying problem structure for improving optimization efficiency remains under-explored. In this paper, we attempt to peek into the black-box of multilingual optimization through the lens of loss function geometry. We find that gradient similarity measured along the optimization trajectory is an important signal, which correlates well with not only language proximity but also the overall model performance. Such observation helps us to identify a critical limitation of existing gradient-based multi-task learning methods, and thus we derive a simple and scalable optimization procedure, named Gradient Vaccine, which encourages more geometrically aligned parameter updates for close tasks. Empirically, our method obtains significant model performance gains on multilingual machine translation and XTREME benchmark tasks for multilingual language models. Our work reveals the importance of properly measuring and utilizing language proximity in multilingual optimization, and has broader implications for multi-task learning beyond multilingual modeling.",Oral Session 2,https://openreview.net/pdf?id=F1vEjWK-lH_,https://openreview.net/forum?id=F1vEjWK-lH_
"['Wonseok Jeon', 'Chen-Yang Su', 'Paul Barde', 'Thang Doan', 'Derek Nowrouzezahrai', 'Joelle Pineau']",ICLR,Regularized Inverse Reinforcement Learning,https://iclr.cc/virtual/2021/spotlight/3483,2021," Inverse Reinforcement Learning (IRL) aims to facilitate a learner’s ability to imitate expert behavior by acquiring reward functions that explain the expert’s decisions. Regularized IRLapplies strongly convex regularizers to the learner’s policy in order to avoid the expert’s behavior being rationalized by arbitrary constant rewards, also known as degenerate solutions. We propose tractable solutions, and practical methods to obtain them, for regularized IRL. Current methods are restricted to the maximum-entropy IRL framework, limiting them to Shannon-entropy regularizers, as well as proposing solutions that are intractable in practice.  We present theoretical backing for our proposed IRL method’s applicability to both discrete and continuous controls, empirically validating our performance on a variety of tasks.",Oral Session 9,https://openreview.net/pdf?id=HgLO8yalfwc,https://openreview.net/forum?id=HgLO8yalfwc
"['Khai Nguyen', 'Nhat Ho', 'Tung Pham', 'Hung Bui']",ICLR,Distributional Sliced-Wasserstein and Applications to Generative Modeling,https://iclr.cc/virtual/2021/spotlight/3386,2021," Sliced-Wasserstein distance (SW) and its variant, Max Sliced-Wasserstein distance (Max-SW), have been used widely in the recent years due to their fast computation and scalability even when the probability measures lie in a very high dimensional space. However, SW requires many unnecessary projection samples to approximate its value while Max-SW only uses the most important projection, which ignores the information of other useful directions. In order to account for these weaknesses, we propose a novel distance, named Distributional Sliced-Wasserstein distance (DSW), that finds an optimal distribution over projections that can balance between exploring distinctive projecting directions and the informativeness of projections themselves. We show that the DSW is a generalization of Max-SW, and it can be computed efficiently by searching for the optimal push-forward measure over a set of probability measures over the unit sphere satisfying certain regularizing constraints that favor distinct directions. Finally, we conduct extensive experiments with large-scale datasets to demonstrate the favorable performances of the proposed distances over the previous sliced-based distances in generative modeling applications.",Oral Session 12,https://openreview.net/pdf?id=QYjO70ACDK,https://openreview.net/forum?id=QYjO70ACDK
"['He Zhao', 'Dinh Phung', 'Viet Huynh', 'Trung Le', 'Wray Buntine']",ICLR,Neural Topic Model via Optimal Transport,https://iclr.cc/virtual/2021/spotlight/3421,2021," Recently, Neural Topic Models (NTMs) inspired by variational autoencoders have obtained increasingly research interest due to their promising results on text analysis. However, it is usually hard for existing NTMs to achieve good document representation and coherent/diverse topics at the same time. Moreover, they often degrade their performance severely on short documents. The requirement of reparameterisation could also comprise their training quality and model flexibility. To address these shortcomings, we present a new neural topic model via the theory of optimal transport (OT). Specifically, we propose to learn the topic distribution of a document by directly minimising its OT distance to the document's word distributions. Importantly, the cost matrix of the OT distance models the weights between topics and words, which is constructed by the distances between topics and words in an embedding space. Our proposed model can be trained efficiently with a differentiable loss. Extensive experiments show that our framework significantly outperforms the state-of-the-art NTMs on discovering more coherent and diverse topics and deriving better document representations for both regular and short texts.",Oral Session 6,https://openreview.net/pdf?id=Oos98K9Lv-k,https://openreview.net/forum?id=Oos98K9Lv-k
"['Florian Tramer', 'Dan Boneh']",ICLR,Differentially Private Learning Needs Better Features (or Much More Data),https://iclr.cc/virtual/2021/spotlight/3394,2021," We demonstrate that differentially private machine learning has not yet reached its ''AlexNet moment'' on many canonical vision tasks: linear models trained on handcrafted features significantly outperform end-to-end deep neural networks for moderate privacy budgets.
To exceed the performance of handcrafted features, we show that private learning requires either much more private data, or access to features learned on public data from a similar domain.
Our work introduces simple yet strong baselines for differentially private learning that can inform the evaluation of future progress in this area.",Oral Session 8,https://openreview.net/pdf?id=YTWGvpFOQD-,https://openreview.net/forum?id=YTWGvpFOQD-
"['Xavier Puig', 'Tianmin Shu', 'Shuang Li', 'Zilin Wang', 'Yuan-Hong Liao', 'Joshua B Tenenbaum', 'Sanja Fidler', 'Antonio Torralba']",ICLR,Watch-And-Help: A Challenge for Social Perception and Human-AI Collaboration,https://iclr.cc/virtual/2021/spotlight/3491,2021," In this paper, we introduce Watch-And-Help (WAH), a challenge for testing social intelligence in agents. In WAH, an AI agent needs to help a human-like agent perform a complex household task efficiently. To succeed, the AI agent needs to i) understand the underlying goal of the task by watching a single demonstration of the human-like agent performing the same task (social perception), and ii) coordinate with the human-like agent to solve the task in an unseen environment as fast as possible (human-AI collaboration). For this challenge, we build VirtualHome-Social, a multi-agent household environment, and provide a benchmark including both planning and learning based baselines. We evaluate the performance of AI agents with the human-like agent as well as and with real humans using objective metrics and subjective user ratings. Experimental results demonstrate that our challenge and virtual environment enable a systematic evaluation on the important aspects of machine social intelligence at scale.",Oral Session 2,https://openreview.net/pdf?id=w_7JMpGZRh0,https://openreview.net/forum?id=w_7JMpGZRh0
"['Fumihiro Sasaki', 'Ryota Yamashina']",ICLR,Behavioral Cloning from Noisy Demonstrations,https://iclr.cc/virtual/2021/spotlight/3447,2021," We consider the problem of learning an optimal expert behavior policy given noisy demonstrations that contain observations from both optimal and non-optimal expert behaviors. Popular imitation learning algorithms, such as generative adversarial imitation learning, assume that (clear) demonstrations are given from optimal expert policies but not the non-optimal ones, and thus often fail to imitate the optimal expert behaviors given the noisy demonstrations. Prior works that address the problem require (1) learning policies through environment interactions in the same fashion as reinforcement learning, and (2) annotating each demonstration with confidence scores or rankings. However, such environment interactions and annotations in real-world settings take impractically long training time and a significant human effort. In this paper, we propose an imitation learning algorithm to address the problem without any environment interactions and annotations associated with the non-optimal demonstrations. The proposed algorithm learns ensemble policies with a generalized behavioral cloning (BC) objective function where we exploit another policy already learned by BC. Experimental results show that the proposed algorithm can learn behavior policies that are much closer to the optimal policies than ones learned by BC.",Oral Session 9,https://openreview.net/pdf?id=zrT3HcsWSAt,https://openreview.net/forum?id=zrT3HcsWSAt
"['Yoshua Bengio', 'Prateek Gupta', 'Tegan Maharaj', 'Nasim Rahaman', 'Martin Weiss', 'Tristan Deleu', 'Eilif B Muller', 'Meng Qu', 'victor schmidt', 'Pierre-luc St-charles', 'hannah alsdurf', 'Olexa Bilaniuk', 'david buckeridge', 'Gaétan Marceau Caron', 'pierre carrier', 'Joumana Ghosn', 'satya gagne', 'Chris J Pal', 'Irina Rish', 'Bernhard Schoelkopf', 'abhinav sharma', 'Jian Tang', 'Andrew Williams']",ICLR,Predicting Infectiousness for Proactive Contact Tracing,https://iclr.cc/virtual/2021/spotlight/3474,2021," The COVID-19 pandemic has spread rapidly worldwide, overwhelming manual contact tracing in many countries and resulting in widespread lockdowns for emergency containment. Large-scale digital contact tracing (DCT) has emerged as a potential solution to resume economic and social activity while minimizing spread of the virus. Various DCT methods have been proposed, each making trade-offs be-tween privacy, mobility restrictions, and public health. The most common approach, binary contact tracing (BCT), models infection as a binary event, informed only by an individual’s test results, with corresponding binary recommendations that either all or none of the individual’s contacts quarantine. BCT ignores the inherent uncertainty in contacts and the infection process, which could be used to tailor messaging to high-risk individuals, and prompt proactive testing or earlier warnings. It also does not make use of observations such as symptoms or pre-existing medical conditions, which could be used to make more accurate infectiousness predictions. In this paper, we use a recently-proposed COVID-19 epidemiological simulator to develop and test methods that can be deployed to a smartphone to locally and proactively predict an individual’s infectiousness (risk of infecting others) based on their contact history and other information, while respecting strong privacy constraints. Predictions are used to provide personalized recommendations to the individual via an app, as well as to send anonymized messages to the individual’s contacts, who use this information to better predict their own infectiousness, an approach we call proactive contact tracing (PCT). Similarly to other works, we find that compared to no tracing, all DCT methods tested are able to reduce spread of the disease and thus save lives, even at low adoption rates, strongly supporting a role for DCT methods in managing the pandemic. Further, we find a deep-learning based PCT method which improves over BCT for equivalent average mobility, suggesting PCT could help in safe re-opening and second-wave prevention.",Oral Session 2,https://openreview.net/pdf?id=lVgB2FUbzuQ,https://openreview.net/forum?id=lVgB2FUbzuQ
"['Dong Bok Lee', 'Dongchan Min', 'Seanie Lee', 'Sung Ju Hwang']",ICLR,Meta-GMVAE: Mixture of Gaussian VAE for Unsupervised Meta-Learning,https://iclr.cc/virtual/2021/spotlight/3424,2021," Unsupervised learning aims to learn meaningful representations from unlabeled data which can captures its intrinsic structure, that can be transferred to downstream tasks. Meta-learning, whose objective is to learn to generalize across tasks such that the learned model can rapidly adapt to a novel task, shares the spirit of unsupervised learning in that the both seek to learn more effective and efficient learning procedure than learning from scratch. The fundamental difference of the two is that the most meta-learning approaches are supervised, assuming full access to the labels. However, acquiring labeled dataset for meta-training not only is costly as it requires human efforts in labeling but also limits its applications to pre-defined task distributions. In this paper, we propose a principled unsupervised meta-learning model, namely Meta-GMVAE, based on Variational Autoencoder (VAE) and set-level variational inference. Moreover, we introduce a mixture of Gaussian (GMM) prior, assuming that each modality represents each class-concept in a randomly sampled episode, which we optimize with Expectation-Maximization (EM). Then, the learned model can be used for downstream few-shot classification tasks, where we obtain task-specific parameters by performing semi-supervised EM on the latent representations of the support and query set, and predict labels of the query set by computing aggregated posteriors. We validate our model on Omniglot and Mini-ImageNet datasets by evaluating its performance on downstream few-shot classification tasks. The results show that our model obtain impressive performance gains over existing unsupervised meta-learning baselines, even outperforming supervised MAML on a certain setting.",Oral Session 3,https://openreview.net/pdf?id=wS0UFjsNYjn,https://openreview.net/forum?id=wS0UFjsNYjn
"['Rose Wang', 'Esin Durmus', 'Noah Goodman', 'Tatsunori Hashimoto']",ICLR,Language modeling via stochastic processes,https://iclr.cc/virtual/2022/oral/5951,2022," Modern language models can generate high-quality short texts. However, they often meander or are incoherent when generating longer texts. These issues arise from the next-token-only language modeling objective. To address these issues, we introduce Time Control (TC), a language model that implicitly plans via a latent stochastic process. TC does this by learning a representation which maps the dynamics of how text changes in a document to the dynamics of a stochastic process of interest. Using this representation, the language model can generate text by first implicitly generating a document plan via a stochastic process, and then generating text that is consistent with this latent plan. Compared to domain-specific methods and fine-tuning GPT2 across a variety of text domains, TC improves performance on text infilling and discourse coherence. On long text generation settings, TC preserves the text structure both in terms of ordering (up to +40% better) and text length consistency (up to +17% better).  Human evaluators also prefer TC's output 28.6% more than the baselines.",Oral 1: AI Applications,https://openreview.net/pdf?id=pMQwKL1yctf,https://openreview.net/forum?id=pMQwKL1yctf
"['Nicolas Papernot', 'Thomas Steinke']",ICLR,Hyperparameter Tuning with Renyi Differential Privacy,https://iclr.cc/virtual/2022/oral/6747,2022," For many differentially private algorithms, such as the prominent noisy stochastic gradient descent (DP-SGD), the analysis needed to bound the privacy leakage of a single training run is well understood. However, few studies have reasoned about the privacy leakage resulting from the multiple training runs needed to fine tune the value of the training algorithm’s hyperparameters. In this work, we first illustrate how simply setting hyperparameters based on non-private training runs can leak private information. Motivated by this observation, we then provide privacy guarantees for hyperparameter search procedures within the framework of Renyi Differential Privacy. Our results improve and extend the work of Liu and Talwar (STOC 2019). Our analysis supports our previous observation that tuning hyperparameters does indeed leak private information, but we prove that, under certain assumptions, this leakage is modest, as long as each candidate training run needed to select hyperparameters is itself differentially private.","Oral 1: Learning in the wild,  Reinforcement learning",https://openreview.net/pdf?id=-70L8lpp9DF,https://openreview.net/forum?id=-70L8lpp9DF
"['Floris Geerts', 'Juan L. Reutter']",ICLR,Expressiveness and Approximation Properties of Graph Neural Networks,https://iclr.cc/virtual/2022/oral/6805,2022," Characterizing the separation power of graph neural networks (GNNs) provides an understanding of their limitations for graph learning tasks. Results regarding separation power are, however, usually geared at specific GNNs architectures, and tools for understanding arbitrary GNN architectures are generally lacking. We provide an elegant way to easily obtain bounds on the separation power of GNNs in terms of the Weisfeiler-Leman (WL) tests, which have become the yardstick to measure the separation power of GNNs. The crux is to view GNNs as expressions in a procedural tensor language describing the computations in the layers of the GNNs. Then, by a simple analysis of the obtained expressions, in terms of the number of indexes used and the nesting depth of summations, bounds on the separation power in terms of the WL-tests readily follow. We use tensor language to define Higher-Order Message-Passing Neural Networks (or k-MPNNs), a natural extension of MPNNs. Furthermore, the tensor language point of view allows for the derivation of universality results for classes of GNNs in a natural way. Our approach provides a toolbox with which GNN architecture designers can analyze the separation power of their GNNs, without needing to know the intricacies of the WL-tests. We also provide insights in what is needed to boost the separation power of GNNs.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=wIzUeM3TAU,https://openreview.net/forum?id=wIzUeM3TAU
"['Jake Topping', 'Francesco Di Giovanni', 'Benjamin Chamberlain', 'Xiaowen Dong', 'Michael Bronstein']",ICLR,Understanding over-squashing and bottlenecks on graphs via curvature,https://iclr.cc/virtual/2022/oral/6850,2022," Most graph neural networks (GNNs) use the message passing paradigm, in which node features are propagated on the input graph. Recent works pointed to the distortion of information flowing from distant nodes as a factor limiting the efficiency of message passing for tasks relying on long-distance interactions. This phenomenon, referred to as 'over-squashing', has been heuristically attributed to graph bottlenecks where the number of $k$-hop neighbors grows rapidly with $k$. We provide a precise description of the over-squashing phenomenon in GNNs and analyze how it arises from bottlenecks in the graph. For this purpose, we introduce a new edge-based combinatorial curvature and prove that negatively curved edges are responsible for the over-squashing issue. We also propose and experimentally test a  curvature-based graph rewiring method to alleviate the over-squashing.",Oral 2: Structured learning,https://openreview.net/pdf?id=7UmjRGzp-A,https://openreview.net/forum?id=7UmjRGzp-A
"['Ananya Kumar', 'Aditi Raghunathan', 'Robbie Jones', 'Tengyu Ma', 'Percy Liang']",ICLR,Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution,https://iclr.cc/virtual/2022/oral/5946,2022," When transferring a pretrained model to a downstream task, two popular methods are full fine-tuning (updating all the model parameters) and linear probing (updating only the last linear layer---the ""head""). It is well known that fine-tuning leads to better accuracy in-distribution (ID). However, in this paper, we find that fine-tuning can achieve worse accuracy than linear probing out-of-distribution (OOD) when the pretrained features are good and the distribution shift is large. On 10 distribution shift datasets (BREEDS-Living17, BREEDS-Entity30, DomainNet, CIFAR $\to$ STL, CIFAR-10.1, FMoW, ImageNetV2, ImageNet-R, ImageNet-A, ImageNet-Sketch), fine-tuning obtains on average 2% higher accuracy ID but 7% lower accuracy OOD than linear probing. We show theoretically that this tradeoff between ID and OOD accuracy arises even in a simple setting: fine-tuning overparameterized two-layer linear networks. We prove that the OOD error of fine-tuning is high when we initialize with a fixed or random head---this is because while fine-tuning learns the head, the lower layers of the neural network change simultaneously and distort the pretrained features. Our analysis suggests that the easy two-step strategy of linear probing then full fine-tuning (LP-FT), sometimes used as a fine-tuning heuristic, combines the benefits of both fine-tuning and linear probing. Empirically, LP-FT outperforms both fine-tuning and linear probing on the above datasets (1% better ID, 10% better OOD than full fine-tuning).",Oral 3: Learning from distribution shift,https://openreview.net/pdf?id=UYneFzXSJWh,https://openreview.net/forum?id=UYneFzXSJWh
"['Vadim Popov', 'Ivan Vovk', 'Vladimir Gogoryan', 'Tasnima Sadekova', 'Mikhail Kudinov', 'Jiansheng Wei']",ICLR,Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme,https://iclr.cc/virtual/2022/oral/6241,2022," Voice conversion is a common speech synthesis task which can be solved in different ways depending on a particular real-world scenario. The most challenging one often referred to as one-shot many-to-many voice conversion consists in copying target voice from only one reference utterance in the most general case when both source and target speakers do not belong to the training dataset. We present a scalable high-quality solution based on diffusion probabilistic modeling and demonstrate its superior quality compared to state-of-the-art one-shot voice conversion approaches. Moreover, focusing on real-time applications, we investigate general principles which can make diffusion models faster while keeping synthesis quality at a high level. As a result, we develop a novel Stochastic Differential Equations solver suitable for various diffusion model types and generative tasks as shown through empirical studies and justify it by theoretical analysis.",Oral 4: Sequence modeling,https://openreview.net/pdf?id=8c50f-DoWAu,https://openreview.net/forum?id=8c50f-DoWAu
"['Sebastian Flennerhag', 'Yannick Schroecker', 'Tom Zahavy', 'Hado van Hasselt', 'David Silver', 'Satinder Singh']",ICLR,Bootstrapped Meta-Learning,https://iclr.cc/virtual/2022/oral/6253,2022," Meta-learning empowers artificial intelligence to increase its efficiency by learning how to learn. Unlocking this potential involves overcoming a challenging meta-optimisation problem. We propose an algorithm that tackles this problem by letting the meta-learner teach itself. The algorithm first bootstraps a target from the meta-learner, then optimises the meta-learner by minimising the distance to that target under a chosen (pseudo-)metric. Focusing on meta-learning with gradients, we establish conditions that guarantee performance improvements and show that metric can be used to control meta-optimisation. Meanwhile, the bootstrapping mechanism can extend the effective meta-learning horizon without requiring backpropagation through all updates. We achieve a new state-of-the art for model-free agents on the Atari ALE benchmark and demonstrate that it yields both performance and efficiency gains in multi-task meta-learning. Finally, we explore how bootstrapping opens up new possibilities and find that it can meta-learn efficient exploration in an epsilon-greedy Q-learning agent - without backpropagating through the update rule.",Oral 3: Meta-learning and adaptation,https://openreview.net/pdf?id=b-ny3x071E5,https://openreview.net/forum?id=b-ny3x071E5
"['Fan Bao', 'Chongxuan Li', 'Jun Zhu', 'Bo Zhang']",ICLR,Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models,https://iclr.cc/virtual/2022/oral/7167,2022," Diffusion probabilistic models (DPMs) represent a class of powerful generative models. Despite their success, the inference of DPMs is expensive since it generally needs to iterate over thousands of timesteps. A key problem in the inference is to estimate the variance in each timestep of the reverse process. In this work, we present a surprising result that both the optimal reverse variance and the corresponding optimal KL divergence of a DPM have analytic forms w.r.t. its score function. Building upon it, we propose \textit{Analytic-DPM}, a training-free inference framework that estimates the analytic forms of the variance and KL divergence using the Monte Carlo method and a pretrained score-based model. Further, to correct the potential bias caused by the score-based model, we derive both lower and upper bounds of the optimal variance and clip the estimate for a better result. Empirically, our analytic-DPM improves the log-likelihood of various DPMs, produces high-quality samples, and meanwhile enjoys a $20\times$ to $80\times$ speed up.","Oral 4: Probablistic Models, Vision",https://openreview.net/pdf?id=0xiJLKH-ufZ,https://openreview.net/forum?id=0xiJLKH-ufZ
"['Steeven Janny', 'Fabien Baradel', 'Natalia Neverova', 'Madiha Nadri', 'Greg Mori', 'Christian Wolf']",ICLR,Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space,https://iclr.cc/virtual/2022/oral/6542,2022," Learning causal relationships in high-dimensional data (images, videos) is a hard task, as they are often defined on low dimensional manifolds and must be extracted from complex signals dominated by appearance, lighting, textures and also spurious correlations in the data. We present a method for learning counterfactual reasoning of physical processes in pixel space, which requires the prediction of the impact of interventions on initial conditions. Going beyond the identification of structural relationships, we deal with the challenging problem of forecasting raw video over long horizons. Our method does not require the knowledge or supervision of any ground truth positions or other object or scene properties. Our model learns and acts on a suitable hybrid latent representation based on a combination of dense features, sets of 2D keypoints and an additional latent vector per keypoint. We show that this better captures the dynamics of physical processes than purely dense or sparse representations. We introduce a new challenging and carefully designed counterfactual benchmark for predictions in pixel space and outperform strong baselines in physics-inspired ML and video prediction.",Oral 2: AI applications,https://openreview.net/pdf?id=1L0C5ROtFp,https://openreview.net/forum?id=1L0C5ROtFp
"['Haobo Wang', 'Ruixuan Xiao', 'Yixuan Li', 'Lei Feng', 'Gang Niu', 'Gang Chen', 'Junbo Zhao']",ICLR,PiCO: Contrastive Label Disambiguation for Partial Label Learning,https://iclr.cc/virtual/2022/oral/6039,2022," Partial label learning (PLL) is an important problem that allows each training example to be labeled with a coarse candidate set, which well suits many real-world data annotation scenarios with label ambiguity.  Despite the promise, the performance of PLL often lags behind the supervised counterpart. In this work, we bridge the gap by addressing two key research challenges in PLL---representation learning and label disambiguation---in one coherent framework. Specifically, our proposed framework PiCO consists of a contrastive learning module along with a novel class prototype-based label disambiguation algorithm. PiCO produces closely aligned representations for examples from the same classes and facilitates label disambiguation. Theoretically, we show that these two components are mutually beneficial, and can be rigorously justified from an expectation-maximization (EM) algorithm perspective. Extensive experiments demonstrate that PiCO significantly outperforms the current state-of-the-art approaches in PLL and even achieves comparable results to fully supervised learning. Code and data available: https://github.com/hbzju/PiCO.","Oral 1: Learning in the wild,  Reinforcement learning",https://openreview.net/pdf?id=EhYjZy6e1gJ,https://openreview.net/forum?id=EhYjZy6e1gJ
"['Albert Gu', 'Karan Goel', 'Christopher Re']",ICLR,Efficiently Modeling Long Sequences with Structured State Spaces,https://iclr.cc/virtual/2022/oral/6960,2022," A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies.  Although conventional models including RNNs, CNNs, and Transformers have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of $10000$ or more steps.  A promising recent approach proposed modeling sequences by simulating the fundamental state space model (SSM) \( x'(t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t) \), and showed that for appropriate choices of the state matrix \( A \), this system could handle long-range dependencies mathematically and empirically.  However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution.  We propose the Structured State Space sequence model (S4) based on a new parameterization for the SSM, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths.  Our technique involves conditioning \( A \) with a low-rank correction, allowing it to be diagonalized stably and reducing the SSM to the well-studied computation of a Cauchy kernel.  S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91\% accuracy on sequential CIFAR-10 with no data augmentation or auxiliary losses, on par with a larger 2-D ResNet, (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation $60\times$ faster (iii) SoTA on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors.",Oral 2: Structured learning,https://openreview.net/pdf?id=uYLFoz1vlAC,https://openreview.net/forum?id=uYLFoz1vlAC
"['X.Y. Han', 'Vardan Papyan', 'David Donoho']",ICLR,Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central Path,https://iclr.cc/virtual/2022/oral/6353,2022," The recently discovered Neural Collapse (NC) phenomenon occurs pervasively in today's deep net training paradigm of driving cross-entropy (CE) loss towards zero. During NC, last-layer features collapse to their class-means, both classifiers and class-means collapse to the same Simplex Equiangular Tight Frame, and classifier behavior collapses to the nearest-class-mean decision rule. Recent works demonstrated that deep nets trained with mean squared error (MSE) loss perform comparably to those trained with CE. As a preliminary, we empirically establish that NC emerges in such MSE-trained deep nets as well through experiments on three canonical networks and five benchmark datasets. We provide, in a Google Colab notebook, PyTorch code for reproducing MSE-NC and CE-NC: https://colab.research.google.com/github/neuralcollapse/neuralcollapse/blob/main/neuralcollapse.ipynb. The analytically-tractable MSE loss offers more mathematical opportunities than the hard-to-analyze CE loss, inspiring us to leverage MSE loss towards the theoretical investigation of NC. We develop three main contributions: (I) We show a new decomposition of the MSE loss into (A) terms directly interpretable through the lens of NC and which assume the last-layer classifier is exactly the least-squares classifier; and (B) a term capturing the deviation from this least-squares classifier. (II) We exhibit experiments on canonical datasets and networks demonstrating that term-(B) is negligible during training. This motivates us to introduce a new theoretical construct: the central path, where the linear classifier stays MSE-optimal for feature activations throughout the dynamics. (III) By studying renormalized gradient flow along the central path, we derive exact dynamics that predict NC.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=w1UbdvWH_R3,https://openreview.net/forum?id=w1UbdvWH_R3
"['S Chandra Mouli', 'Bruno Ribeiro']",ICLR,Asymmetry Learning for Counterfactually-invariant Classification in OOD Tasks,https://iclr.cc/virtual/2022/oral/6947,2022," Generalizing from observed to new related environments (out-of-distribution) is central to the reliability of classifiers. However, most classifiers fail to predict label $Y$ from input $X$ when the change in environment is due a (stochastic) input transformation $T^\text{te} \circ X'$ not observed in training, as in training we observe $T^\text{tr} \circ X'$, where $X'$ is a hidden variable. This work argues that when the transformations in train $T^\text{tr}$ and test $T^\text{te}$ are (arbitrary) symmetry transformations induced by a collection of known $m$ equivalence relations, the task of finding a robust OOD classifier can be defined as finding the simplest causal model that defines a causal connection between the target labels and the symmetry transformations that are associated with label changes. We then propose a new learning paradigm, asymmetry learning, that identifies which symmetries the classifier must break in order to correctly predict $Y$ in both train and test. Asymmetry learning performs a causal model search that, under certain identifiability conditions, finds classifiers that perform equally well in-distribution and out-of-distribution. Finally, we show how to learn counterfactually-invariant representations with asymmetry learning in two physics tasks.",Oral 3: Learning from distribution shift,https://openreview.net/pdf?id=avgclFZ221l,https://openreview.net/forum?id=avgclFZ221l
"['Anirudh Goyal', 'Aniket Didolkar', 'Alex Lamb', 'Kartikeya Badola', 'Nan Rosemary Ke', 'Nasim Rahaman', 'Jonathan Binas', 'Charles Blundell', 'Michael Mozer', 'Yoshua Bengio']",ICLR,Coordination Among Neural Modules Through a Shared Global Workspace,https://iclr.cc/virtual/2022/oral/6383,2022," Deep learning has seen a movement away from representing examples with a monolithic hidden state towards a richly structured state. For example, Transformers segment by position, and object-centric architectures decompose images into entities. In all these architectures, interactions between different elements are modeled via pairwise interactions: Transformers make use of self-attention to incorporate information from other positions and object-centric architectures make use of graph neural networks to model interactions among entities.  We consider how to improve on pairwise interactions in terms of global coordination and a coherent, integrated representation that can be used for downstream tasks. In cognitive science, a global workspace architecture has been proposed in which functionally  specialized  components share information through a common, bandwidth-limited communication channel. We explore the use of such a communication channel in the context of deep learning for modeling the structure of complex environments. The proposed method includes a shared workspace through which communication among different specialist modules takes place but due to limits on the communication bandwidth, specialist modules must compete for access. We show that capacity limitations have  a rational basis in that (1) they encourage specialization and compositionality and (2) they facilitate the synchronization of otherwise  independent specialists.",Oral 3: Meta-learning and adaptation,https://openreview.net/pdf?id=XzTtHjgPDsT,https://openreview.net/forum?id=XzTtHjgPDsT
"['Yusong Wu', 'Ethan Manilow', 'Yi Deng', 'Rigel Swavely', 'Kyle Kastner', 'Timotheus Cooijmans', 'Aaron Courville', 'Anna Huang', 'Jesse Engel']",ICLR,MIDI-DDSP: Detailed Control of Musical Performance via Hierarchical Modeling,https://iclr.cc/virtual/2022/oral/6967,2022," Musical expression requires control of both what notes that are played, and how they are performed. Conventional audio synthesizers provide detailed expressive controls, but at the cost of realism. Black-box neural audio synthesis and concatenative samplers can produce realistic audio, but have few mechanisms for control. In this work, we introduce MIDI-DDSP a hierarchical model of musical instruments that enables both realistic neural audio synthesis and detailed user control. Starting from interpretable Differentiable Digital Signal Processing (DDSP) synthesis parameters, we infer musical notes and high-level properties of their expressive performance (such as timbre, vibrato, dynamics, and articulation). This creates a 3-level hierarchy (notes, performance, synthesis) that affords individuals the option to intervene at each level, or utilize trained priors (performance given notes, synthesis given performance) for creative assistance. Through quantitative experiments and listening tests, we demonstrate that this hierarchy can reconstruct high-fidelity audio, accurately predict performance attributes for a note sequence, independently manipulate the attributes of a given performance,  and as a complete system, generate realistic audio from a novel note sequence. By utilizing an interpretable hierarchy, with multiple levels of granularity, MIDI-DDSP opens the door to assistive tools to empower individuals across a diverse range of musical experience.",Oral 1: AI Applications,https://openreview.net/pdf?id=UseMOjWENv,https://openreview.net/forum?id=UseMOjWENv
"['Shengjia Zhao', 'Abhishek Sinha', 'Yutong He', 'Aidan Perreault', 'Jiaming Song', 'Stefano Ermon']",ICLR,Comparing Distributions by Measuring Differences that Affect Decision Making,https://iclr.cc/virtual/2022/oral/6696,2022," Measuring the discrepancy between two probability distributions is a fundamental problem in machine learning and statistics. We propose a new class of discrepancies based on the optimal loss for a decision task -- two distributions are different if the optimal decision loss is higher on their mixture than on each individual distribution. By suitably choosing the decision task, this generalizes the Jensen-Shannon divergence and the maximum mean discrepancy family. We apply our approach to two-sample tests, and on various benchmarks, we achieve superior test power compared to competing methods. In addition, a modeler can directly specify their preferences when comparing distributions through the decision loss. We apply this property to understanding the effects of climate change on different social and economic activities, evaluating sample quality, and selecting features targeting different decision tasks.","Oral 4: Probablistic Models, Vision",https://openreview.net/pdf?id=KB5onONJIAU,https://openreview.net/forum?id=KB5onONJIAU
"['Nicholas Carlini', 'Andreas Terzis']",ICLR,Poisoning and Backdooring Contrastive Learning,https://iclr.cc/virtual/2022/oral/6317,2022," Multimodal contrastive learning methods like CLIP train on noisy and uncurated training datasets. This is cheaper than labeling datasets manually, and even improves out-of-distribution robustness. We show that this practice makes backdoor and poisoning attacks a significant threat. By poisoning just 0.01% of a dataset (e.g., just 300 images of the 3 million-example Conceptual Captions dataset), we can cause the model to misclassify test images by overlaying a small patch. Targeted poisoning attacks, whereby the model misclassifies a particular test input  with an adversarially-desired label, are even easier requiring control of 0.0001% of the dataset (e.g., just three out of the 3 million images). Our attacks call into question whether training on noisy and uncurated Internet scrapes is desirable.","Oral 1: Learning in the wild,  Reinforcement learning",https://openreview.net/pdf?id=iC4UHbQ01Mp,https://openreview.net/forum?id=iC4UHbQ01Mp
"['Meng Qu', 'Huiyu Cai', 'Jian Tang']",ICLR,Neural Structured Prediction for Inductive Node Classification,https://iclr.cc/virtual/2022/oral/5948,2022," This paper studies node classification in the inductive setting, i.e., aiming to learn a model on labeled training graphs and generalize it to infer node labels on unlabeled test graphs. This problem has been extensively studied with graph neural networks (GNNs) by learning effective node representations, as well as traditional structured prediction methods for modeling the structured output of node labels, e.g., conditional random fields (CRFs). In this paper, we present a new approach called the Structured Proxy Network (SPN), which combines the advantages of both worlds. SPN defines flexible potential functions of CRFs with GNNs. However, learning such a model is nontrivial as it involves optimizing a maximin game with high-cost inference. Inspired by the underlying connection between joint and marginal distributions defined by Markov networks, we propose to solve an approximate version of the optimization problem as a proxy, which yields a near-optimal solution, making learning more efficient. Extensive experiments on two settings show that our approach outperforms many competitive baselines.",Oral 2: Structured learning,https://openreview.net/pdf?id=YWNAX0caEjI,https://openreview.net/forum?id=YWNAX0caEjI
"['Rachid Riad', 'Olivier Teboul', 'David Grangier', 'Neil Zeghidour']",ICLR,Learning Strides in Convolutional Neural Networks,https://iclr.cc/virtual/2022/oral/7069,2022," Convolutional neural networks typically contain several downsampling operators, such as strided convolutions or pooling layers, that progressively reduce the resolution of intermediate representations. This provides some shift-invariance while reducing the computational complexity of the whole architecture. A critical hyperparameter of such layers is their stride: the integer factor of downsampling. As strides are not differentiable, finding the best configuration either requires cross-validation or discrete optimization (e.g. architecture search), which rapidly become prohibitive as the search space grows exponentially with the number of downsampling layers. Hence, exploring this search space by gradient descent would allow finding better configurations at a lower computational cost. This work introduces DiffStride, the first downsampling layer with learnable strides. Our layer learns the size of a cropping mask in the Fourier domain, that effectively performs resizing in a differentiable way. Experiments on audio and image classification show the generality and effectiveness of our solution: we use DiffStride as a drop-in replacement to standard downsampling layers and outperform them. In particular, we show that introducing our layer into a ResNet-18 architecture allows keeping consistent high performance on CIFAR10, CIFAR100 and ImageNet even when training starts from poor random stride configurations. Moreover, formulating strides as learnable variables allows us to introduce a regularization term that controls the computational complexity of the architecture. We show how this regularization allows trading off accuracy for efficiency on ImageNet.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=M752z9FKJP,https://openreview.net/forum?id=M752z9FKJP
"['Olivia Wiles', 'Sven Gowal', 'Florian Stimberg', 'Sylvestre-Alvise Rebuffi', 'Ira Ktena', 'Krishnamurthy Dvijotham', 'Ali Taylan Cemgil']",ICLR,A Fine-Grained Analysis on Distribution Shift,https://iclr.cc/virtual/2022/oral/7003,2022," Robustness to distribution shifts is critical for deploying machine learning models in the real world. Despite this necessity, there has been little work in defining the underlying mechanisms that cause these shifts and evaluating the robustness of algorithms across multiple, different distribution shifts. To this end, we introduce a framework that enables fine-grained analysis of various distribution shifts. We provide a holistic analysis of current state-of-the-art methods by evaluating 19 distinct methods grouped into five categories across both synthetic and real-world datasets.  Overall, we train more than 85K models. Our experimental framework can be easily extended to include new methods, shifts, and datasets. We find, unlike previous work (Gulrajani & Lopez-Paz, 2021), that progress has been made over a standard ERM baseline; in particular, pretraining and augmentations (learned or heuristic) offer large gains in many cases. However, the best methods are not consistent over different datasets and shifts. We will open source our experimental framework, allowing future work to evaluate new methods over multiple shifts to obtain a more complete picture of a method's effectiveness. Code is available at github.com/deepmind/distribution shift framework.",Oral 3: Learning from distribution shift,https://openreview.net/pdf?id=Dl4LetuLdyK,https://openreview.net/forum?id=Dl4LetuLdyK
"['Lixu Wang', 'Shichao Xu', 'Ruiqi Xu', 'Xiao Wang', 'Qi Zhu']",ICLR,Non-Transferable Learning: A New Approach for Model Ownership Verification and Applicability Authorization,https://iclr.cc/virtual/2022/oral/6144,2022," As Artificial Intelligence as a Service gains popularity, protecting well-trained models as intellectual property is becoming increasingly important. There are two common types of protection methods: ownership verification and usage authorization. In this paper, we propose Non-Transferable Learning (NTL), a novel approach that captures the exclusive data representation in the learned model and restricts the model generalization ability to certain domains. This approach provides effective solutions to both model verification and authorization. Specifically: 1) For ownership verification, watermarking techniques are commonly used but are often vulnerable to sophisticated watermark removal methods. By comparison, our NTL-based ownership verification provides robust resistance to state-of-the-art watermark removal methods, as shown in extensive experiments with 6 removal approaches over the digits, CIFAR10 & STL10, and VisDA datasets. 2) For usage authorization, prior solutions focus on authorizing specific users to access the model, but authorized users can still apply the model to any data without restriction. Our NTL-based authorization approach instead provides data-centric protection, which we call applicability authorization, by significantly degrading the performance of the model on unauthorized data. Its effectiveness is also shown through experiments on aforementioned datasets.",Oral 2: AI applications,https://openreview.net/pdf?id=tYRrOdSnVUy,https://openreview.net/forum?id=tYRrOdSnVUy
"['Huaxiu Yao', 'Linjun Zhang', 'Chelsea Finn']",ICLR,Meta-Learning with Fewer Tasks through Task Interpolation,https://iclr.cc/virtual/2022/oral/7141,2022," Meta-learning enables algorithms to quickly learn a newly encountered task with just a few labeled examples by transferring previously learned knowledge. However, the bottleneck of current meta-learning algorithms is the requirement of a large number of meta-training tasks, which may not be accessible in real-world scenarios. To address the challenge that available tasks may not densely sample the space of tasks, we propose to augment the task set through interpolation. By meta-learning with task interpolation (MLTI), our approach effectively generates additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels. Under both gradient-based and metric-based meta-learning settings, our theoretical analysis shows MLTI corresponds to a data-adaptive meta-regularization and further improves the generalization. Empirically, in our experiments on eight datasets from diverse domains including image recognition, pose prediction, molecule property prediction, and medical image classification, we find that the proposed general MLTI framework is compatible with representative meta-learning algorithms and consistently outperforms other state-of-the-art strategies.",Oral 3: Meta-learning and adaptation,https://openreview.net/pdf?id=ajXWF7bVR8d,https://openreview.net/forum?id=ajXWF7bVR8d
"['Evan Hernandez', 'Sarah Schwettmann', 'David Bau', 'Teona Bagashvili', 'Antonio Torralba', 'Jacob Andreas']",ICLR,Natural Language Descriptions of Deep Features,https://iclr.cc/virtual/2022/oral/5989,2022," Some neurons in deep networks specialize in recognizing highly specific perceptual, structural, or semantic features of inputs. In computer vision, techniques exist for identifying neurons that respond to individual concept categories like colors, textures, and object classes. But these techniques are limited in scope, labeling only a small subset of neurons and behaviors in any network. Is a richer characterization of neuron-level computation possible? We introduce a procedure (called MILAN, for mutual information-guided linguistic annotation of neurons) that automatically labels neurons with open-ended, compositional, natural language descriptions. Given a neuron, MILAN generates a description by searching for a natural language string that maximizes pointwise mutual information with the image regions in which the neuron is active. MILAN produces fine-grained descriptions that capture categorical, relational, and logical structure in learned features. These descriptions obtain high agreement with human-generated feature descriptions across a diverse set of model architectures and tasks, and can aid in understanding and controlling learned models. We highlight three applications of natural language neuron descriptions. First, we use MILAN for analysis, characterizing the distribution and importance of neurons selective for attribute, category, and relational information in vision models. Second, we use MILAN for auditing, surfacing neurons sensitive to human faces in datasets designed to obscure them. Finally, we use MILAN for editing, improving robustness in an image classifier by deleting neurons sensitive to text features spuriously correlated with class labels.",Oral 4: Sequence modeling,https://openreview.net/pdf?id=NudBMY-tzDr,https://openreview.net/forum?id=NudBMY-tzDr
"['Mia Chiquier', 'Chengzhi Mao', 'Carl Vondrick']",ICLR,Real-Time Neural Voice Camouflage,https://iclr.cc/virtual/2022/oral/6987,2022," Automatic speech recognition systems have created exciting possibilities for applications, however they also enable opportunities for systematic eavesdropping.We propose a method to camouflage a person's voice from these systems without inconveniencing the conversation between people in the room. Standard adversarial attacks are not effective in real-time streaming situations because the characteristics of the signal will have changed by the time the attack is executed. We introduce predictive adversarial attacks, which achieves real-time performance by forecasting the attack vector that will be the most effective in the future. Under real-time constraints, our method jams the established speech recognition system DeepSpeech 3.9x more than online projected gradient descent as measured through word error rate, and 6.6x more as measured through character error rate. We furthermore demonstrate our approach is practically effective in realistic environments with complex scene geometries.",Oral 1: AI Applications,https://openreview.net/pdf?id=qj1IZ-6TInc,https://openreview.net/forum?id=qj1IZ-6TInc
"['Asiri Wijesinghe', 'Qing Wang']",ICLR,"A New Perspective on ""How Graph Neural Networks Go Beyond Weisfeiler-Lehman?""",https://iclr.cc/virtual/2022/oral/6437,2022," We propose a new perspective on designing powerful Graph Neural Networks (GNNs). In a nutshell, this enables a general solution to inject structural properties of graphs into a message-passing aggregation scheme of GNNs. As a theoretical basis, we develop a new hierarchy of local isomorphism on neighborhood subgraphs. Then, we theoretically characterize how message-passing GNNs can be designed to be more expressive than the Weisfeiler Lehman test. To elaborate this characterization, we propose a novel neural model, called GraphSNN, and prove that this model is strictly more expressive than the Weisfeiler Lehman test in distinguishing graph structures. We empirically verify the strength of our model on different graph learning tasks. It is shown that our model consistently improves the state-of-the-art methods on the benchmark tasks without sacrificing computational simplicity and efficiency.",Oral 2: Structured learning,https://openreview.net/pdf?id=uxgg9o7bI_3,https://openreview.net/forum?id=uxgg9o7bI_3
"['Yifei Wang', 'Jonathan Lacotte', 'Mert Pilanci']",ICLR,The Hidden Convex Optimization Landscape of Regularized Two-Layer ReLU Networks: an Exact Characterization of Optimal Solutions,https://iclr.cc/virtual/2022/oral/7125,2022," We prove that finding all globally optimal two-layer ReLU neural networks can be performed by solving a convex optimization program with cone constraints. Our analysis is novel, characterizes all optimal solutions, and does not leverage duality-based analysis which was recently used to lift neural network training into convex spaces. Given the set of solutions of our convex optimization program, we show how to construct exactly the entire set of optimal neural networks. We provide a detailed characterization of this optimal set and its invariant transformations. As additional consequences of our convex perspective, (i) we establish that Clarke stationary points found by stochastic gradient descent correspond to the global optimum of a subsampled convex problem (ii) we provide a polynomial-time algorithm for checking if a neural network is a global minimum of the training loss (iii) we provide an explicit construction of a continuous path between any neural network and the global minimum of its sublevel set and (iv) characterize the minimal size of the hidden layer so that the neural network optimization landscape has no spurious valleys.Overall, we provide a rich framework for studying the landscape of neural network training loss through convexity.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=Z7Lk2cQEG8a,https://openreview.net/forum?id=Z7Lk2cQEG8a
"['Ye Yuan', 'Yuda Song', 'Zhengyi Luo', 'Wen Sun', 'Kris Kitani']",ICLR,Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design,https://iclr.cc/virtual/2022/oral/6197,2022," An agent's functionality is largely determined by its design, i.e., skeletal structure and joint attributes (e.g., length, size, strength). However, finding the optimal agent design for a given function is extremely challenging since the problem is inherently combinatorial and the design space is prohibitively large. Additionally, it can be costly to evaluate each candidate design which requires solving for its optimal controller. To tackle these problems, our key idea is to incorporate the design procedure of an agent into its decision-making process. Specifically, we learn a conditional policy that, in an episode, first applies a sequence of transform actions to modify an agent's skeletal structure and joint attributes, and then applies control actions under the new design. To handle a variable number of joints across designs, we use a graph-based policy where each graph node represents a joint and uses message passing with its neighbors to output joint-specific actions. Using policy gradient methods, our approach enables joint optimization of agent design and control as well as experience sharing across different designs, which improves sample efficiency substantially.  Experiments show that our approach, Transform2Act, outperforms prior methods significantly in terms of convergence speed and final performance. Notably, Transform2Act can automatically discover plausible designs similar to giraffes, squids, and spiders. Code and videos are available at https://sites.google.com/view/transform2act.","Oral 1: Learning in the wild,  Reinforcement learning",https://openreview.net/pdf?id=UcDUxjPYWSr,https://openreview.net/forum?id=UcDUxjPYWSr
"['Bo Wan', 'Wenjuan Han', 'Zilong Zheng', 'Tinne Tuytelaars']",ICLR,Unsupervised Vision-Language Grammar Induction with Shared Structure Modeling,https://iclr.cc/virtual/2022/oral/6111,2022," We introduce a new task, unsupervised vision-language (VL) grammar induction. Given an image-caption pair, the goal is to extract a shared hierarchical structure for both image and language simultaneously.  We argue that such structured output, grounded in both modalities, is a clear step towards the high-level understanding of multimodal information. Besides challenges existing in conventional visually grounded grammar induction tasks, VL grammar induction requires a model to capture contextual semantics and perform a fine-grained alignment. To address these challenges, we propose a novel method, CLIORA, which constructs a shared vision-language constituency tree structure with context-dependent semantics for all possible phrases in different levels of the tree. It computes a matching score between each constituent and image region, trained via contrastive learning.  It integrates two levels of fusion, namely at feature-level and at score-level, so as to allow fine-grained alignment. We introduce a new evaluation metric for VL grammar induction, CCRA, and show a 3.3% improvement over a strong baseline on Flickr30k Entities. We also evaluate our model via two derived tasks, i.e., language grammar induction and phrase grounding, and improve over the state-of-the-art for both.","Oral 4: Probablistic Models, Vision",https://openreview.net/pdf?id=N0n_QyQ5lBF,https://openreview.net/forum?id=N0n_QyQ5lBF
"['Shuxiao Chen', 'Koby Crammer', 'Hangfeng He', 'Dan Roth', 'Weijie J Su']",ICLR,Weighted Training for Cross-Task Learning,https://iclr.cc/virtual/2022/oral/7204,2022," In this paper, we introduce Target-Aware Weighted Training (TAWT), a weighted training algorithm for cross-task learning based on minimizing a representation-based task distance between the source and target tasks. We show that TAWT is easy to implement, is computationally efficient, requires little hyperparameter tuning, and enjoys non-asymptotic learning-theoretic guarantees. The effectiveness of TAWT is corroborated through extensive experiments with BERT on four sequence tagging tasks in natural language processing (NLP), including part-of-speech (PoS) tagging, chunking, predicate detection, and named entity recognition (NER). As a byproduct, the proposed representation-based task distance allows one to reason in a theoretically principled way about several critical aspects of cross-task learning, such as the choice of the source data and the impact of fine-tuning.",Oral 3: Meta-learning and adaptation,https://openreview.net/pdf?id=ltM1RMZntpu,https://openreview.net/forum?id=ltM1RMZntpu
"['António Farinhas', 'Wilker Aziz', 'Vlad Niculae', 'Andre Martins']",ICLR,Sparse Communication via Mixed Distributions,https://iclr.cc/virtual/2022/oral/5896,2022," Neural networks and other machine learning models compute continuous representations, while humans communicate mostly through discrete symbols. Reconciling these two forms of communication is desirable for generating human-readable interpretations or learning discrete latent variable models, while maintaining end-to-end differentiability. Some existing approaches (such as the Gumbel-Softmax transformation) build continuous relaxations that are discrete approximations in the zero-temperature limit, while others (such as sparsemax transformations and the Hard Concrete distribution) produce discrete/continuous hybrids. In this paper, we build rigorous theoretical foundations for these hybrids, which we call ""mixed random variables.'' Our starting point is a new ""direct sum'' base measure defined on the face lattice of the probability simplex. From this measure, we introduce new entropy and Kullback-Leibler divergence functions that subsume the discrete and differential cases and have interpretations in terms of code optimality. Our framework suggests two strategies for representing and sampling mixed random variables, an extrinsic (""sample-and-project'’) and an intrinsic one (based on face stratification). We experiment with both approaches on an  emergent communication benchmark and on modeling MNIST and Fashion-MNIST data with variational auto-encoders with mixed latent variables.",Oral 3: Learning from distribution shift,https://openreview.net/pdf?id=WAid50QschI,https://openreview.net/forum?id=WAid50QschI
"['Jason Wei', 'Maarten Bosma', 'Vincent Zhao', 'Kelvin Guu', 'Wei Yu', 'Brian Lester', 'Nan Du', 'Andrew Dai', 'Quoc V Le']",ICLR,Finetuned Language Models are Zero-Shot Learners,https://iclr.cc/virtual/2022/oral/6255,2022," This paper explores a simple method for improving the zero-shot learning abilities of language models. We show that instruction tuning—finetuning language models on a collection of datasets described via instructions—substantially improves zero-shot performance on unseen tasks. We take a 137B parameter pretrained language model and instruction tune it on over 60 NLP datasets verbalized via natural language instruction templates. We evaluate this instruction-tuned model, which we call FLAN, on unseen task types. FLAN substantially improves the performance of its unmodified counterpart and surpasses zero-shot 175B GPT-3 on 20 of 25 datasets that we evaluate. FLAN even outperforms few-shot GPT-3 by a large margin on ANLI, RTE, BoolQ, AI2-ARC, OpenbookQA, and StoryCloze. Ablation studies reveal that number of finetuning datasets, model scale, and natural language instructions are key to the success of instruction tuning.",Oral 4: Sequence modeling,https://openreview.net/pdf?id=gEZrGCozdqR,https://openreview.net/forum?id=gEZrGCozdqR
"['Minghao Guo', 'Veronika Thost', 'Beichen Li', 'Payel Das', 'Jie Chen', 'Wojciech Matusik']",ICLR,Data-Efficient Graph Grammar Learning for Molecular Generation,https://iclr.cc/virtual/2022/oral/7012,2022," The problem of molecular generation has received significant attention recently. Existing methods are typically based on deep neural networks and require training on large datasets with tens of thousands of samples. In practice, however, the size of class-specific chemical datasets is usually limited (e.g., dozens of samples) due to labor-intensive experimentation and data collection. Another major challenge is to generate only physically synthesizable molecules. This is a non-trivial task for neural network-based generative models since the relevant chemical knowledge can only be extracted and generalized from the limited training data. In this work, we propose a data-efficient generative model that can be learned from datasets with orders of magnitude smaller sizes than common benchmarks. At the heart of this method is a learnable graph grammar that generates molecules from a sequence of production rules. Without any human assistance, these production rules are automatically constructed from training data. Furthermore, additional chemical knowledge can be incorporated into the model by further grammar optimization. Our learned graph grammar yields state-of-the-art results on generating high-quality molecules for three monomer datasets that contain only ${\sim}20$ samples each. Our approach also achieves remarkable performance in a challenging polymer generation task with $only$ $117$ training samples and is competitive against existing methods using $81$k data points.",Oral 2: AI applications,https://openreview.net/pdf?id=l4IHywGq6a,https://openreview.net/forum?id=l4IHywGq6a
"['Boris Oreshkin', 'Florent Bocquelet', 'Felix G. Harvey', 'Bay Raitt', 'Dominic Laflamme']",ICLR,ProtoRes: Proto-Residual Network for Pose Authoring via Learned Inverse Kinematics,https://iclr.cc/virtual/2022/oral/6540,2022," Our work focuses on the development of a learnable neural representation of human pose for advanced AI assisted animation tooling. Specifically, we tackle the problem of constructing a full static human pose based on sparse and variable user inputs (e.g. locations and/or orientations of a subset of body joints). To solve this problem, we propose a novel neural architecture that combines residual connections with prototype encoding of a partially specified pose to create a new complete pose from the learned latent space. We show that our architecture outperforms a baseline based on Transformer, both in terms of accuracy and computational efficiency. Additionally, we develop a user interface to integrate our neural model in Unity, a real-time 3D development platform. Furthermore, we introduce two new datasets representing the static human pose modeling problem, based on high-quality human motion capture data, which will be released publicly along with model code.",Oral 1: AI Applications,https://openreview.net/pdf?id=s03AQxehtd_,https://openreview.net/forum?id=s03AQxehtd_
"['Shoufa Chen', 'Enze Xie', 'Chongjian GE', 'Runjian Chen', 'Ding Liang', 'Ping Luo']",ICLR,CycleMLP: A MLP-like Architecture for Dense Prediction,https://iclr.cc/virtual/2022/oral/6274,2022," This paper presents a simple MLP-like architecture, CycleMLP, which is a versatile backbone for visual recognition and dense predictions. As compared to modern MLP architectures, e.g. , MLP-Mixer, ResMLP, and gMLP, whose architectures are correlated to image size and thus are infeasible in object detection and segmentation, CycleMLP has two advantages compared to modern approaches. (1) It can copewith various image sizes. (2) It achieves linear computational complexity to image size by using local windows. In contrast, previous MLPs have $O(N^2)$ computations due to fully spatial connections. We build a family of models which surpass existing MLPs and even state-of-the-art Transformer-based models, e.g. Swin Transformer, while using fewer parameters and FLOPs. We expand the MLP-like models’ applicability, making them a versatile backbone for dense prediction tasks. CycleMLP achieves competitive results on object detection, instance segmentation, and semantic segmentation. In particular, CycleMLP-Tiny outperforms Swin-Tiny by 1.3% mIoU on ADE20K dataset with fewer FLOPs. Moreover, CycleMLP also shows excellent zero-shot robustness on ImageNet-C dataset.",Oral 2: Structured learning,https://openreview.net/pdf?id=NMEceG4v69Y,https://openreview.net/forum?id=NMEceG4v69Y
"['Chulhee Yun', 'Shashank Rajput', 'Suvrit Sra']",ICLR,Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond,https://iclr.cc/virtual/2022/oral/7031,2022," In distributed learning, local SGD (also known as federated averaging) and its simple baseline minibatch SGD are widely studied optimization methods. Most existing analyses of these methods assume independent and unbiased gradient estimates obtained via with-replacement sampling. In contrast, we study shuffling-based variants: minibatch and local Random Reshuffling, which draw stochastic gradients without replacement and are thus closer to practice. For smooth functions satisfying the Polyak-Łojasiewicz condition, we obtain convergence bounds (in the large epoch regime) which show that these shuffling-based variants converge faster than their with-replacement counterparts. Moreover, we prove matching lower bounds showing that our convergence analysis is tight. Finally, we propose an algorithmic modification called synchronized shuffling that leads to convergence rates faster than our lower bounds in near-homogeneous settings.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=LdlwbBP2mlq,https://openreview.net/forum?id=LdlwbBP2mlq
"['Benjamin Eysenbach', 'Ruslan Salakhutdinov', 'Sergey Levine']",ICLR,The Information Geometry of Unsupervised Reinforcement Learning,https://iclr.cc/virtual/2022/oral/6207,2022," How can a reinforcement learning (RL) agent prepare to solve downstream tasks if those tasks are not known a priori? One approach is unsupervised skill discovery, a class of algorithms that learn a set of policies without access to a reward function. Such algorithms bear a close resemblance to representation learning algorithms (e.g., contrastive learning) in supervised learning, in that both are pretraining algorithms that maximize some approximation to a mutual information objective. While prior work has shown that the set of skills learned by such methods can accelerate downstream RL tasks, prior work offers little analysis into whether these skill learning algorithms are optimal, or even what notion of optimality would be appropriate to apply to them. In this work, we show that unsupervised skill discovery algorithms based on mutual information maximization do not learn skills that are optimal for every possible reward function. However, we show that the distribution over skills provides an optimal initialization minimizing regret against adversarially-chosen reward functions, assuming a certain type of adaptation procedure. Our analysis also provides a geometric perspective on these skill learning methods.","Oral 1: Learning in the wild,  Reinforcement learning",https://openreview.net/pdf?id=3wU2UX0voE,https://openreview.net/forum?id=3wU2UX0voE
"['Omri Puny', 'Matan Atzmon', 'Edward Smith', 'Ishan Misra', 'Aditya Grover', 'Heli Ben-Hamu', 'Yaron Lipman']",ICLR,Frame Averaging for Invariant and Equivariant Network Design,https://iclr.cc/virtual/2022/oral/6190,2022," Many machine learning tasks involve learning functions that are known to be invariant or equivariant to certain symmetries of the input data. However, it is often challenging to design neural network architectures that respect these symmetries while being expressive and computationally efficient. For example, Euclidean motion invariant/equivariant graph or point cloud neural networks. We introduce Frame Averaging (FA), a highly general purpose and systematic framework for adapting known (backbone) architectures to become invariant or equivariant to new symmetry types. Our framework builds on the well known group averaging operator that guarantees invariance or equivariance but is intractable. In contrast, we observe that for many important classes of symmetries, this operator can be replaced with an averaging operator over a small subset of the group elements, called a frame. We show that averaging over a frame guarantees exact invariance or equivariance while often being much simpler to compute than averaging over the entire group. Furthermore, we prove that FA-based models have maximal expressive power in a broad setting and in general preserve the expressive power of their backbone architectures. Using frame averaging, we propose a new class of universal Graph Neural Networks (GNNs), universal Euclidean motion invariant point cloud networks, and Euclidean motion invariant Message Passing (MP) GNNs. We demonstrate the practical effectiveness of FA on several applications including point cloud normal estimation, beyond $2$-WL graph separation, and $n$-body dynamics prediction, achieving state-of-the-art results in all of these benchmarks.",Oral 3: Learning from distribution shift,https://openreview.net/pdf?id=zIUyj55nXR,https://openreview.net/forum?id=zIUyj55nXR
"['Xuechen Li', 'Florian Tramer', 'Percy Liang', 'Tatsunori Hashimoto']",ICLR,Large Language Models Can Be Strong Differentially Private Learners,https://iclr.cc/virtual/2022/oral/6895,2022," Differentially Private (DP) learning has seen limited success for building large deep learning models of text, and straightforward attempts at applying Differentially Private Stochastic Gradient Descent (DP-SGD) to NLP tasks have resulted in large performance drops and high computational overhead.We show that this performance drop can be mitigated with (1) the use of large pretrained language models; (2) non-standard hyperparameters that suit DP optimization; and (3) fine-tuning objectives which are aligned with the pretraining procedure.With the above, we obtain NLP models that outperform state-of-the-art DP-trained models under the same privacy budget and strong non-private baselines---by directly fine-tuning pretrained models with DP optimization on moderately-sized corpora. To address the computational challenge of running DP-SGD with large Transformers, we propose a memory saving technique that allows clipping in DP-SGD to run without instantiating per-example gradients for any linear layer in the model. The technique enables privately training Transformers with almost the same memory cost as non-private training at a modest run-time overhead. Contrary to conventional wisdom that DP optimization fails at learning high-dimensional models (due to noise that scales with dimension) empirical results reveal that private learning with pretrained language models tends to not suffer from dimension-dependent performance degradation.Code to reproduce results can be found at https://github.com/lxuechen/private-transformers.",Oral 4: Sequence modeling,https://openreview.net/pdf?id=bVuP3ltATMz,https://openreview.net/forum?id=bVuP3ltATMz
"['Pingchuan Ma', 'Tao Du', 'Joshua B Tenenbaum', 'Wojciech Matusik', 'Chuang Gan']",ICLR,RISP: Rendering-Invariant State Predictor with Differentiable Simulation and Rendering for Cross-Domain Parameter Estimation,https://iclr.cc/virtual/2022/oral/6922,2022," This work considers identifying parameters characterizing a physical system's dynamic motion directly from a video whose rendering configurations are inaccessible. Existing solutions require massive training data or lack generalizability to unknown rendering configurations. We propose a novel approach that marries domain randomization and differentiable rendering gradients to address this problem. Our core idea is to train a rendering-invariant state-prediction (RISP) network that transforms image differences into state differences independent of rendering configurations, e.g., lighting, shadows, or material reflectance. To train this predictor, we formulate a new loss on rendering variances using gradients from differentiable rendering. Moreover, we present an efficient, second-order method to compute the gradients of this loss, allowing it to be integrated seamlessly into modern deep learning frameworks. We evaluate our method in rigid-body and deformable-body simulation environments using four tasks: state estimation, system identification, imitation learning, and visuomotor control. We further demonstrate the efficacy of our approach on a real-world example: inferring the state and action sequences of a quadrotor from a video of its motion sequences. Compared with existing methods, our approach achieves significantly lower reconstruction errors and has better generalizability among unknown rendering configurations.","Oral 4: Probablistic Models, Vision",https://openreview.net/pdf?id=uSE03demja,https://openreview.net/forum?id=uSE03demja
"['Marine Schimel', 'Ta-Chu Kao', 'Kristopher Jensen', 'Guillaume Hennequin']",ICLR,iLQR-VAE : control-based learning of input-driven dynamics with applications to neural data,https://iclr.cc/virtual/2022/oral/6080,2022," Understanding how neural dynamics give rise to behaviour is one of the most fundamental questions in systems neuroscience. To achieve this, a common approach is to record neural populations in behaving animals, and model these data as emanating from a latent dynamical system whose state trajectories can then be related back to behavioural observations via some form of decoding. As recordings are typically performed in localized circuits that form only a part of the wider implicated network, it is important to simultaneously learn the local dynamics and infer any unobserved external input that might drive them. Here, we introduce iLQR-VAE, a novel control-based approach to variational inference in nonlinear dynamical systems, capable of learning both latent dynamics, initial conditions, and ongoing external inputs. As in recent deep learning approaches, our method is based on an input-driven sequential variational autoencoder (VAE). The main novelty lies in the use of the powerful iterative linear quadratic regulator algorithm (iLQR) in the recognition model. Optimization of the standard evidence lower-bound requires differentiating through iLQR solutions, which is made possible by recent advances in differentiable control. Importantly, having the recognition model be implicitly defined by the generative model greatly reduces the number of free parameters and allows for flexible, high-quality inference. This makes it possible for instance to evaluate the model on a single long trial after training on smaller chunks. We demonstrate the effectiveness of iLQR-VAE on a range of synthetic systems, with autonomous as well as input-driven dynamics. We further apply it to neural and behavioural recordings in non-human primates performing two different reaching tasks, and show that iLQR-VAE yields high-quality kinematic reconstructions from the neural data.",Oral 2: AI applications,https://openreview.net/pdf?id=wRODLDHaAiW,https://openreview.net/forum?id=wRODLDHaAiW
"['Sabri Eyuboglu', 'Maya Varma', 'Khaled Saab', 'Jean-Benoit Delbrouck', 'Christopher Lee-Messer', 'Jared Dunnmon', 'James Y Zou', 'Christopher Re']",ICLR,Domino: Discovering Systematic Errors with Cross-Modal Embeddings,https://iclr.cc/virtual/2022/oral/6149,2022," Machine learning models that achieve high overall accuracy often make systematic errors on important subsets (or slices) of data. Identifying underperforming slices is particularly challenging when working with high-dimensional inputs (e.g. images, audio), where important slices are often unlabeled. In order to address this issue, recent studies have proposed automated slice discovery methods (SDMs), which leverage learned model representations to mine input data for slices on which a model performs poorly. To be useful to a practitioner, these methods must identify slices that are both underperforming and coherent (i.e. united by a human-understandable concept). However, no quantitative evaluation framework currently exists for rigorously assessing SDMs with respect to these criteria. Additionally, prior qualitative evaluations have shown that SDMs often identify slices that are incoherent. In this work, we address these challenges by first designing a principled evaluation framework that enables a quantitative comparison of SDMs across 1,235 slice discovery settings in three input domains (natural images, medical images, and time-series data).Then, motivated by the recent development of powerful cross-modal representation learning approaches, we present Domino, an SDM that leverages cross-modal embeddings and a novel error-aware mixture model to discover and describe coherent slices. We find that Domino accurately identifies 36% of the 1,235 slices in our framework -- a 12 percentage point improvement over prior methods. Further, Domino is the first SDM that can provide natural language descriptions of identified slices, correctly generating the exact name of the slice in 35% of settings.",Oral 3: Meta-learning and adaptation,https://openreview.net/pdf?id=FPCMqjI0jXN,https://openreview.net/forum?id=FPCMqjI0jXN
"['Kohei Miyaguchi', 'Takayuki Katsuki', 'Akira Koseki', 'Toshiya Iwamori']",ICLR,Variational Inference for Discriminative Learning with Generative Modeling of Feature Incompletion,https://iclr.cc/virtual/2022/oral/6534,2022," We are concerned with the problem of distributional prediction with incomplete features: The goal is to estimate the distribution of target variables given feature vectors with some of the elements missing. A typical approach to this problem is to perform missing-value imputation and regression, simultaneously or sequentially, which we call the generative approach. Another approach is to perform regression after appropriately encoding missing values into the feature, which we call the discriminative approach. In comparison, the generative approach is more robust to the feature corruption while the discriminative approach is more favorable to maximize the performance of prediction. In this study, we propose a hybrid method to take the best of both worlds. Our method utilizes the black-box variational inference framework so that it can be applied to a wide variety of modern machine learning models, including the variational autoencoders. We also confirmed the effectiveness of the proposed method empirically.",Oral 2: Structured learning,https://openreview.net/pdf?id=qnQN4yr6FJz,https://openreview.net/forum?id=qnQN4yr6FJz
"['Sagar Vaze', 'Kai Han', 'Andrea Vedaldi', 'Andrew Zisserman']",ICLR,Open-Set Recognition: A Good Closed-Set Classifier is All You Need,https://iclr.cc/virtual/2022/oral/6728,2022," The ability to identify whether or not a test sample belongs to one of the semantic classes in a classifier's training set is critical to practical deployment of the model. This task is termed open-set recognition (OSR) and has received significant attention in recent years. In this paper, we first demonstrate that the ability of a classifier to make the 'none-of-above' decision is highly correlated with its accuracy on the closed-set classes. We find that this relationship holds across loss objectives and architectures, and further demonstrate the trend both on the standard OSR benchmarks as well as on a large-scale ImageNet evaluation. Second, we use this correlation to boost the performance of the maximum softmax probability OSR 'baseline' by improving its closed-set accuracy, and with this strong baseline achieve state-of-the-art on a number of OSR benchmarks. Similarly, we boost the performance of the existing state-of-the-art method by improving its closed-set accuracy, but the resulting discrepancy with the strong baseline is marginal. Our third contribution is to present the 'Semantic Shift Benchmark' (SSB), which better respects the task of detecting semantic novelty, as opposed to low-level distributional shifts as tackled by neighbouring machine learning fields. On this new evaluation, we again demonstrate that there is negligible difference between the strong baseline and the existing state-of-the-art. Code available at: https://github.com/sgvaze/osr closed set all you_need.",Oral 1: AI Applications,https://openreview.net/pdf?id=5hLP5JY9S2d,https://openreview.net/forum?id=5hLP5JY9S2d
"['Yonathan Efroni', 'Dipendra Kumar Misra', 'Akshay Krishnamurthy', 'Alekh Agarwal', 'John Langford']",ICLR,Provably Filtering Exogenous Distractors using Multistep Inverse Dynamics,https://iclr.cc/virtual/2022/oral/6734,2022," Many real-world applications of reinforcement learning (RL) require the agent to deal with high-dimensional observations such as those generated from a megapixel camera. Prior work has addressed such problems with representation learning, through which the agent can provably extract endogenous, latent state information from raw observations and subsequently plan efficiently. However, such approaches can fail in the presence of temporally correlated noise in the observations, a phenomenon that is common in practice. We initiate the formal study of latent state discovery in the presence of such exogenous noise sources by proposing a new model, the Exogenous Block MDP (EX-BMDP), for rich observation RL. We start by establishing several negative results, by highlighting failure cases of prior representation learning based approaches. Then, we introduce the Predictive Path Elimination (PPE) algorithm, that learns a generalization of inverse dynamics and is provably sample and computationally efficient in EX-BMDPs when the endogenous state dynamics are near deterministic. The sample complexity of PPE depends polynomially on the size of the latent endogenous state space while not directly depending on the size of the observation space, nor the exogenous state space. We provide experiments on challenging exploration problems which show that our approach works empirically.","Oral 1: Learning in the wild,  Reinforcement learning",https://openreview.net/pdf?id=RQLLzMCefQu,https://openreview.net/forum?id=RQLLzMCefQu
"['Qing Jin', 'Jian Ren', 'Richard Zhuang', 'Sumant Hanumante', 'Zhengang Li', 'Zhiyu Chen', 'Yanzhi Wang', 'Kaiyuan Yang', 'Sergey Tulyakov']",ICLR,F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization,https://iclr.cc/virtual/2022/oral/5944,2022," Neural network quantization is a promising compression technique to reduce memory footprint and save energy consumption, potentially leading to real-time inference. However, there is a performance gap between quantized and full-precision models. To reduce it, existing quantization approaches require high-precision INT32 or full-precision multiplication during inference for scaling or dequantization. This introduces a noticeable cost in terms of memory, speed, and required energy. To tackle these issues, we present F8Net, a novel quantization framework consisting in only ﬁxed-point 8-bit multiplication. To derive our method, we ﬁrst discuss the advantages of ﬁxed-point multiplication with different formats of ﬁxed-point numbers and study the statistical behavior of the associated ﬁxed-point numbers. Second, based on the statistical and algorithmic analysis, we apply different ﬁxed-point formats for weights and activations of different layers. We introduce a novel algorithm to automatically determine the right format for each layer during training. Third, we analyze a previous quantization algorithm—parameterized clipping activation (PACT)—and reformulate it using ﬁxed-point arithmetic. Finally, we unify the recently proposed method for quantization ﬁne-tuning and our ﬁxed-point approach to show the potential of our method. We verify F8Net on ImageNet for MobileNet V1/V2 and ResNet18/50. Our approach achieves comparable and better performance, when compared not only to existing quantization techniques with INT32 multiplication or ﬂoating point arithmetic, but also to the full-precision counterparts, achieving state-of-the-art performance.",Oral 3: Learning from distribution shift,https://openreview.net/pdf?id=_CfpJazzXT2,https://openreview.net/forum?id=_CfpJazzXT2
"['Hangbo Bao', 'Li Dong', 'Songhao Piao', 'Furu Wei']",ICLR,BEiT: BERT Pre-Training of Image Transformers,https://iclr.cc/virtual/2022/oral/6324,2022," We introduce a self-supervised vision representation model BEiT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e., image patches (such as 16 x 16 pixels), and visual tokens (i.e., discrete tokens). We first ``tokenize'' the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEiT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods.","Oral 4: Probablistic Models, Vision",https://openreview.net/pdf?id=p-BhZSz59o4,https://openreview.net/forum?id=p-BhZSz59o4
['Alex Rogozhnikov'],ICLR,Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation,https://iclr.cc/virtual/2022/oral/6603,2022," Tensor computations underlie modern scientific computing and deep learning.A number of tensor frameworks emerged varying in execution model, hardware support, memory management, model definition, etc.However, tensor operations in all frameworks follow the same paradigm.Recent neural network architectures demonstrate demand for higher expressiveness of tensor operations.The current paradigm is not suited to write readable, reliable, or easy-to-modify code for multidimensional tensor manipulations. Moreover, some commonly used operations do not provide sufficient checks and can break a tensor structure.These mistakes are elusive as no tools or tests can detect them.Independently, API discrepancies complicate code transfer between frameworks.We propose einops notation: a uniform and generic way to manipulate tensor structure, that significantly improves code readability and flexibility by focusing on the structure of input and output tensors.We implement einops notation in a Python package that efficiently supports multiple widely used frameworks and provides framework-independent minimalist API for tensor manipulations.",Oral 2: AI applications,https://openreview.net/pdf?id=oapKSVM2bcj,https://openreview.net/forum?id=oapKSVM2bcj
"['Huiqi Deng', 'Qihan Ren', 'Hao Zhang', 'Quanshi Zhang']",ICLR,DISCOVERING AND EXPLAINING THE REPRESENTATION BOTTLENECK OF DNNS,https://iclr.cc/virtual/2022/oral/6623,2022," This paper explores the bottleneck of feature representations of deep neural networks (DNNs), from the perspective of the complexity of interactions between input variables encoded in DNNs. To this end, we focus on the multi-order interaction between input variables, where the order represents the complexity of interactions. We discover that a DNN is more likely to encode both too simple and too complex interactions, but usually fails to learn interactions of intermediate complexity. Such a phenomenon is widely shared by different DNNs for different tasks. This phenomenon indicates a cognition gap between DNNs and humans, and we call it a representation bottleneck. We theoretically prove the underlying reason for the representation bottleneck. Furthermore, we propose losses to encourage/penalize the learning of interactions of specific complexities, and analyze the representation capacities of interactions of different complexities. The code is available at https://github.com/Nebularaid2000/bottleneck.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=iRCUlgmdfHJ,https://openreview.net/forum?id=iRCUlgmdfHJ
"['Shiori Sagawa', 'Pang Wei Koh', 'Tony Lee', 'Irena Gao', 'Sang Michael Xie', 'Kendrick Shen', 'Ananya Kumar', 'Weihua Hu', 'Michihiro Yasunaga', 'Henrik Marklund', 'Sara Beery', 'Etienne David', 'Ian Stavness', 'Wei Guo', 'Jure Leskovec', 'Kate Saenko', 'Tatsunori Hashimoto', 'Sergey Levine', 'Chelsea Finn', 'Percy Liang']",ICLR,Extending the WILDS Benchmark for Unsupervised Adaptation,https://iclr.cc/virtual/2022/oral/6964,2022," Machine learning systems deployed in the wild are often trained on a source distribution but deployed on a different target distribution. Unlabeled data can be a powerful point of leverage for mitigating these distribution shifts, as it is frequently much more available than labeled data and can often be obtained from distributions beyond the source distribution as well. However, existing distribution shift benchmarks with unlabeled data do not reflect the breadth of scenarios that arise in real-world applications. In this work, we present the WILDS 2.0 update, which extends 8 of the 10 datasets in the WILDS benchmark of distribution shifts to include curated unlabeled data that would be realistically obtainable in deployment. These datasets span a wide range of applications (from histology to wildlife conservation), tasks (classification, regression, and detection), and modalities (photos, satellite images, microscope slides, text, molecular graphs). The update maintains consistency with the original WILDS benchmark by using identical labeled training, validation, and test sets, as well as identical evaluation metrics. We systematically benchmark state-of-the-art methods that use unlabeled data, including domain-invariant, self-training, and self-supervised methods, and show that their success on WILDS is limited. To facilitate method development, we provide an open-source package that automates data loading and contains the model architectures and methods used in this paper. Code and leaderboards are available at https://wilds.stanford.edu.",Oral 3: Meta-learning and adaptation,https://openreview.net/pdf?id=z7p2V6KROOV,https://openreview.net/forum?id=z7p2V6KROOV
"['Minkai Xu', 'Lantao Yu', 'Yang Song', 'Chence Shi', 'Stefano Ermon', 'Jian Tang']",ICLR,GeoDiff: A Geometric Diffusion Model for Molecular Conformation Generation,https://iclr.cc/virtual/2022/oral/7029,2022," Predicting molecular conformations from molecular graphs is a fundamental problem in cheminformatics and drug discovery. Recently, significant progress has been achieved with machine learning approaches, especially with deep generative models. Inspired by the diffusion process in classical non-equilibrium thermodynamics where heated particles will diffuse from original states to a noise distribution, in this paper, we propose a novel generative model named GeoDiff for molecular conformation prediction. GeoDiff treats each atom as a particle and learns to directly reverse the diffusion process (i.e., transforming from a noise distribution to stable conformations) as a Markov chain. Modeling such a generation process is however very challenging as the likelihood of conformations should be roto-translational invariant. We theoretically show that Markov chains evolving with equivariant Markov kernels can induce an invariant distribution by design, and further propose building blocks for the Markov kernels to preserve the desirable equivariance property. The whole framework can be efficiently trained in an end-to-end fashion by optimizing a weighted variational lower bound to the (conditional) likelihood. Experiments on multiple benchmarks show that GeoDiff is superior or comparable to existing state-of-the-art approaches, especially on large molecules.",Oral 4: Sequence modeling,https://openreview.net/pdf?id=PzcvxEMzvQC,https://openreview.net/forum?id=PzcvxEMzvQC
"['Shuming Kong', 'Yanyan Shen', 'Linpeng Huang']",ICLR,Resolving Training Biases via Influence-based Data Relabeling,https://iclr.cc/virtual/2022/oral/6492,2022," The performance of supervised learning methods easily suffers from the training bias issue caused by train-test distribution mismatch or label noise. Influence function is a  technique that estimates the impacts of a training sample on the model’s predictions. Recent studies on \emph{data resampling} have employed influence functions to identify \emph{harmful} training samples that will degrade model's test performance. They have shown that discarding or downweighting the identified harmful training samples is an effective way to resolve training biases. In this work, we move one step forward and propose an influence-based relabeling framework named RDIA for reusing harmful training samples toward better model performance. To achieve this, we use influence functions to estimate how relabeling a training sample would affect model's test performance and further develop a novel relabeling function R. We theoretically prove that applying R to relabel harmful training samples allows the model to achieve lower test loss than simply discarding them for any classification tasks using cross-entropy loss. Extensive experiments on ten real-world datasets demonstrate RDIA outperforms the state-of-the-art data resampling methods and improves model's robustness against label noise.","Oral 4: Probablistic Models, Vision",https://openreview.net/pdf?id=EskfH0bwNVn,https://openreview.net/forum?id=EskfH0bwNVn
"['Divyam Madaan', 'Jaehong Yoon', 'Yuanchun Li', 'Yunxin Liu', 'Sung Ju Hwang']",ICLR,Representational Continuity for Unsupervised Continual Learning,https://iclr.cc/virtual/2022/oral/7120,2022," Continual learning (CL) aims to learn a sequence of tasks without forgetting the previously acquired knowledge. However, recent CL advances are restricted to supervised continual learning (SCL) scenarios. Consequently, they are not scalable to real-world applications where the data distribution is often biased and unannotated. In this work, we focus on unsupervised continual learning (UCL), where we learn the feature representations on an unlabelled sequence of tasks and show that reliance on annotated data is not necessary for continual learning. We conduct a systematic study analyzing the learned feature representations and show that unsupervised visual representations are surprisingly more robust to catastrophic forgetting, consistently achieve better performance, and generalize better to out-of-distribution tasks than SCL. Furthermore, we find that UCL achieves a smoother loss landscape through qualitative analysis of the learned representations and learns meaningful feature representations. Additionally, we propose Lifelong Unsupervised Mixup (Lump), a simple yet effective technique that interpolates between the current task and previous tasks' instances to alleviate catastrophic forgetting for unsupervised representations.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=9Hrka5PA7LW,https://openreview.net/forum?id=9Hrka5PA7LW
"['Shi Zhan Liu', 'Hang Yu', 'Cong Liao', 'Jianguo Li', 'Weiyao Lin', 'Alex Liu ·']",ICLR,Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting,https://iclr.cc/virtual/2022/oral/6828,2022," Accurate prediction of the future given the past based on time series data is of paramount importance, since it opens the door for decision making and risk management ahead of time. In practice, the challenge is to build a flexible but parsimonious model that can capture a wide range of temporal dependencies. In this paper, we propose Pyraformer by exploring the multiresolution representation of the time series. Specifically, we introduce the pyramidal attention module (PAM) in which the inter-scale tree structure summarizes features at different resolutions and the intra-scale neighboring connections model the temporal dependencies of different ranges. Under mild conditions, the maximum length of the signal traversing path in Pyraformer is a constant (i.e., $\mathcal O(1)$) with regard to the sequence length $L$, while its time and space complexity scale linearly with $L$. Extensive numerical results show that Pyraformer typically achieves the highest prediction accuracy in both single-step and long-range forecasting tasks with the least amount of time and memory consumption, especially when the sequence is long.",Oral 4: Sequence modeling,https://openreview.net/pdf?id=0EXmFzUn5I,https://openreview.net/forum?id=0EXmFzUn5I
"['Kyle Hsu', 'Moo Kim', 'Rafael Rafailov', 'Jiajun Wu', 'Chelsea Finn']",ICLR,Vision-Based Manipulators Need to Also See from Their Hands,https://iclr.cc/virtual/2022/oral/6103,2022," We study how the choice of visual perspective affects learning and generalization in the context of physical manipulation from raw sensor observations. Compared with the more commonly used global third-person perspective, a hand-centric (eye-in-hand) perspective affords reduced observability, but we find that it consistently improves training efficiency and out-of-distribution generalization. These benefits hold across a variety of learning algorithms, experimental settings, and distribution shifts, and for both simulated and real robot apparatuses. However, this is only the case when hand-centric observability is sufficient; otherwise, including a third-person perspective is necessary for learning, but also harms out-of-distribution generalization. To mitigate this, we propose to regularize the third-person information stream via a variational information bottleneck. On six representative manipulation tasks with varying hand-centric observability adapted from the Meta-World benchmark, this results in a state-of-the-art reinforcement learning agent operating from both perspectives improving its out-of-distribution generalization on every task. While some practitioners have long put cameras in the hands of robots, our work systematically analyzes the benefits of doing so and provides simple and broadly applicable insights for improving end-to-end learned vision-based robotic manipulation.",Oral 1: AI Applications,https://openreview.net/pdf?id=RJkAHKp7kNZ,https://openreview.net/forum?id=RJkAHKp7kNZ
"['Zongze Wu', 'Yotam Nitzan', 'Eli Shechtman', 'Dani Lischinski']",ICLR,StyleAlign: Analysis and Applications of Aligned StyleGAN Models,https://iclr.cc/virtual/2022/oral/6949,2022," In this paper, we perform an in-depth study of the properties and applications of aligned generative models.We refer to two models as aligned if they share the same architecture, and one of them (the child) is obtained from the other (the parent) via fine-tuning to another domain, a common practice in transfer learning. Several works already utilize some basic properties of aligned StyleGAN models to perform image-to-image translation. Here, we perform the first detailed exploration of model alignment, also focusing on StyleGAN. First, we empirically analyze aligned models and provide answers to important questions regarding their nature. In particular, we find that the child model's latent spaces are semantically aligned with those of the parent, inheriting incredibly rich semantics, even for distant data domains such as human faces and churches. Second, equipped with this better understanding, we leverage aligned models to solve a diverse set of tasks. In addition to image translation, we demonstrate fully automatic cross-domain image morphing. We further show that zero-shot vision tasks may be performed in the child domain, while relying exclusively on supervision in the parent domain. We demonstrate qualitatively and quantitatively that our approach yields state-of-the-art results, while requiring only simple fine-tuning and inversion.",Oral 2: AI applications,https://openreview.net/pdf?id=Qg2vi4ZbHM9,https://openreview.net/forum?id=Qg2vi4ZbHM9
"['Rose Wang', 'Esin Durmus', 'Noah Goodman', 'Tatsunori Hashimoto']",ICLR,Language modeling via stochastic processes,https://iclr.cc/virtual/2022/oral/5951,2022," Modern language models can generate high-quality short texts. However, they often meander or are incoherent when generating longer texts. These issues arise from the next-token-only language modeling objective. To address these issues, we introduce Time Control (TC), a language model that implicitly plans via a latent stochastic process. TC does this by learning a representation which maps the dynamics of how text changes in a document to the dynamics of a stochastic process of interest. Using this representation, the language model can generate text by first implicitly generating a document plan via a stochastic process, and then generating text that is consistent with this latent plan. Compared to domain-specific methods and fine-tuning GPT2 across a variety of text domains, TC improves performance on text infilling and discourse coherence. On long text generation settings, TC preserves the text structure both in terms of ordering (up to +40% better) and text length consistency (up to +17% better).  Human evaluators also prefer TC's output 28.6% more than the baselines.",Oral 1: AI Applications,https://openreview.net/pdf?id=pMQwKL1yctf,https://openreview.net/forum?id=pMQwKL1yctf
"['Floris Geerts', 'Juan L. Reutter']",ICLR,Expressiveness and Approximation Properties of Graph Neural Networks,https://iclr.cc/virtual/2022/oral/6805,2022," Characterizing the separation power of graph neural networks (GNNs) provides an understanding of their limitations for graph learning tasks. Results regarding separation power are, however, usually geared at specific GNNs architectures, and tools for understanding arbitrary GNN architectures are generally lacking. We provide an elegant way to easily obtain bounds on the separation power of GNNs in terms of the Weisfeiler-Leman (WL) tests, which have become the yardstick to measure the separation power of GNNs. The crux is to view GNNs as expressions in a procedural tensor language describing the computations in the layers of the GNNs. Then, by a simple analysis of the obtained expressions, in terms of the number of indexes used and the nesting depth of summations, bounds on the separation power in terms of the WL-tests readily follow. We use tensor language to define Higher-Order Message-Passing Neural Networks (or k-MPNNs), a natural extension of MPNNs. Furthermore, the tensor language point of view allows for the derivation of universality results for classes of GNNs in a natural way. Our approach provides a toolbox with which GNN architecture designers can analyze the separation power of their GNNs, without needing to know the intricacies of the WL-tests. We also provide insights in what is needed to boost the separation power of GNNs.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=wIzUeM3TAU,https://openreview.net/forum?id=wIzUeM3TAU
"['Jake Topping', 'Francesco Di Giovanni', 'Benjamin Chamberlain', 'Xiaowen Dong', 'Michael Bronstein']",ICLR,Understanding over-squashing and bottlenecks on graphs via curvature,https://iclr.cc/virtual/2022/oral/6850,2022," Most graph neural networks (GNNs) use the message passing paradigm, in which node features are propagated on the input graph. Recent works pointed to the distortion of information flowing from distant nodes as a factor limiting the efficiency of message passing for tasks relying on long-distance interactions. This phenomenon, referred to as 'over-squashing', has been heuristically attributed to graph bottlenecks where the number of $k$-hop neighbors grows rapidly with $k$. We provide a precise description of the over-squashing phenomenon in GNNs and analyze how it arises from bottlenecks in the graph. For this purpose, we introduce a new edge-based combinatorial curvature and prove that negatively curved edges are responsible for the over-squashing issue. We also propose and experimentally test a  curvature-based graph rewiring method to alleviate the over-squashing.",Oral 2: Structured learning,https://openreview.net/pdf?id=7UmjRGzp-A,https://openreview.net/forum?id=7UmjRGzp-A
"['Steeven Janny', 'Fabien Baradel', 'Natalia Neverova', 'Madiha Nadri', 'Greg Mori', 'Christian Wolf']",ICLR,Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space,https://iclr.cc/virtual/2022/oral/6542,2022," Learning causal relationships in high-dimensional data (images, videos) is a hard task, as they are often defined on low dimensional manifolds and must be extracted from complex signals dominated by appearance, lighting, textures and also spurious correlations in the data. We present a method for learning counterfactual reasoning of physical processes in pixel space, which requires the prediction of the impact of interventions on initial conditions. Going beyond the identification of structural relationships, we deal with the challenging problem of forecasting raw video over long horizons. Our method does not require the knowledge or supervision of any ground truth positions or other object or scene properties. Our model learns and acts on a suitable hybrid latent representation based on a combination of dense features, sets of 2D keypoints and an additional latent vector per keypoint. We show that this better captures the dynamics of physical processes than purely dense or sparse representations. We introduce a new challenging and carefully designed counterfactual benchmark for predictions in pixel space and outperform strong baselines in physics-inspired ML and video prediction.",Oral 2: AI applications,https://openreview.net/pdf?id=1L0C5ROtFp,https://openreview.net/forum?id=1L0C5ROtFp
"['Nicolas Papernot', 'Thomas Steinke']",ICLR,Hyperparameter Tuning with Renyi Differential Privacy,https://iclr.cc/virtual/2022/oral/6747,2022," For many differentially private algorithms, such as the prominent noisy stochastic gradient descent (DP-SGD), the analysis needed to bound the privacy leakage of a single training run is well understood. However, few studies have reasoned about the privacy leakage resulting from the multiple training runs needed to fine tune the value of the training algorithm’s hyperparameters. In this work, we first illustrate how simply setting hyperparameters based on non-private training runs can leak private information. Motivated by this observation, we then provide privacy guarantees for hyperparameter search procedures within the framework of Renyi Differential Privacy. Our results improve and extend the work of Liu and Talwar (STOC 2019). Our analysis supports our previous observation that tuning hyperparameters does indeed leak private information, but we prove that, under certain assumptions, this leakage is modest, as long as each candidate training run needed to select hyperparameters is itself differentially private.","Oral 1: Learning in the wild,  Reinforcement learning",https://openreview.net/pdf?id=-70L8lpp9DF,https://openreview.net/forum?id=-70L8lpp9DF
"['Sebastian Flennerhag', 'Yannick Schroecker', 'Tom Zahavy', 'Hado van Hasselt', 'David Silver', 'Satinder Singh']",ICLR,Bootstrapped Meta-Learning,https://iclr.cc/virtual/2022/oral/6253,2022," Meta-learning empowers artificial intelligence to increase its efficiency by learning how to learn. Unlocking this potential involves overcoming a challenging meta-optimisation problem. We propose an algorithm that tackles this problem by letting the meta-learner teach itself. The algorithm first bootstraps a target from the meta-learner, then optimises the meta-learner by minimising the distance to that target under a chosen (pseudo-)metric. Focusing on meta-learning with gradients, we establish conditions that guarantee performance improvements and show that metric can be used to control meta-optimisation. Meanwhile, the bootstrapping mechanism can extend the effective meta-learning horizon without requiring backpropagation through all updates. We achieve a new state-of-the art for model-free agents on the Atari ALE benchmark and demonstrate that it yields both performance and efficiency gains in multi-task meta-learning. Finally, we explore how bootstrapping opens up new possibilities and find that it can meta-learn efficient exploration in an epsilon-greedy Q-learning agent - without backpropagating through the update rule.",Oral 3: Meta-learning and adaptation,https://openreview.net/pdf?id=b-ny3x071E5,https://openreview.net/forum?id=b-ny3x071E5
"['Ananya Kumar', 'Aditi Raghunathan', 'Robbie Jones', 'Tengyu Ma', 'Percy Liang']",ICLR,Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution,https://iclr.cc/virtual/2022/oral/5946,2022," When transferring a pretrained model to a downstream task, two popular methods are full fine-tuning (updating all the model parameters) and linear probing (updating only the last linear layer---the ""head""). It is well known that fine-tuning leads to better accuracy in-distribution (ID). However, in this paper, we find that fine-tuning can achieve worse accuracy than linear probing out-of-distribution (OOD) when the pretrained features are good and the distribution shift is large. On 10 distribution shift datasets (BREEDS-Living17, BREEDS-Entity30, DomainNet, CIFAR $\to$ STL, CIFAR-10.1, FMoW, ImageNetV2, ImageNet-R, ImageNet-A, ImageNet-Sketch), fine-tuning obtains on average 2% higher accuracy ID but 7% lower accuracy OOD than linear probing. We show theoretically that this tradeoff between ID and OOD accuracy arises even in a simple setting: fine-tuning overparameterized two-layer linear networks. We prove that the OOD error of fine-tuning is high when we initialize with a fixed or random head---this is because while fine-tuning learns the head, the lower layers of the neural network change simultaneously and distort the pretrained features. Our analysis suggests that the easy two-step strategy of linear probing then full fine-tuning (LP-FT), sometimes used as a fine-tuning heuristic, combines the benefits of both fine-tuning and linear probing. Empirically, LP-FT outperforms both fine-tuning and linear probing on the above datasets (1% better ID, 10% better OOD than full fine-tuning).",Oral 3: Learning from distribution shift,https://openreview.net/pdf?id=UYneFzXSJWh,https://openreview.net/forum?id=UYneFzXSJWh
"['Vadim Popov', 'Ivan Vovk', 'Vladimir Gogoryan', 'Tasnima Sadekova', 'Mikhail Kudinov', 'Jiansheng Wei']",ICLR,Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme,https://iclr.cc/virtual/2022/oral/6241,2022," Voice conversion is a common speech synthesis task which can be solved in different ways depending on a particular real-world scenario. The most challenging one often referred to as one-shot many-to-many voice conversion consists in copying target voice from only one reference utterance in the most general case when both source and target speakers do not belong to the training dataset. We present a scalable high-quality solution based on diffusion probabilistic modeling and demonstrate its superior quality compared to state-of-the-art one-shot voice conversion approaches. Moreover, focusing on real-time applications, we investigate general principles which can make diffusion models faster while keeping synthesis quality at a high level. As a result, we develop a novel Stochastic Differential Equations solver suitable for various diffusion model types and generative tasks as shown through empirical studies and justify it by theoretical analysis.",Oral 4: Sequence modeling,https://openreview.net/pdf?id=8c50f-DoWAu,https://openreview.net/forum?id=8c50f-DoWAu
"['Yusong Wu', 'Ethan Manilow', 'Yi Deng', 'Rigel Swavely', 'Kyle Kastner', 'Timotheus Cooijmans', 'Aaron Courville', 'Anna Huang', 'Jesse Engel']",ICLR,MIDI-DDSP: Detailed Control of Musical Performance via Hierarchical Modeling,https://iclr.cc/virtual/2022/oral/6967,2022," Musical expression requires control of both what notes that are played, and how they are performed. Conventional audio synthesizers provide detailed expressive controls, but at the cost of realism. Black-box neural audio synthesis and concatenative samplers can produce realistic audio, but have few mechanisms for control. In this work, we introduce MIDI-DDSP a hierarchical model of musical instruments that enables both realistic neural audio synthesis and detailed user control. Starting from interpretable Differentiable Digital Signal Processing (DDSP) synthesis parameters, we infer musical notes and high-level properties of their expressive performance (such as timbre, vibrato, dynamics, and articulation). This creates a 3-level hierarchy (notes, performance, synthesis) that affords individuals the option to intervene at each level, or utilize trained priors (performance given notes, synthesis given performance) for creative assistance. Through quantitative experiments and listening tests, we demonstrate that this hierarchy can reconstruct high-fidelity audio, accurately predict performance attributes for a note sequence, independently manipulate the attributes of a given performance,  and as a complete system, generate realistic audio from a novel note sequence. By utilizing an interpretable hierarchy, with multiple levels of granularity, MIDI-DDSP opens the door to assistive tools to empower individuals across a diverse range of musical experience.",Oral 1: AI Applications,https://openreview.net/pdf?id=UseMOjWENv,https://openreview.net/forum?id=UseMOjWENv
"['X.Y. Han', 'Vardan Papyan', 'David Donoho']",ICLR,Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central Path,https://iclr.cc/virtual/2022/oral/6353,2022," The recently discovered Neural Collapse (NC) phenomenon occurs pervasively in today's deep net training paradigm of driving cross-entropy (CE) loss towards zero. During NC, last-layer features collapse to their class-means, both classifiers and class-means collapse to the same Simplex Equiangular Tight Frame, and classifier behavior collapses to the nearest-class-mean decision rule. Recent works demonstrated that deep nets trained with mean squared error (MSE) loss perform comparably to those trained with CE. As a preliminary, we empirically establish that NC emerges in such MSE-trained deep nets as well through experiments on three canonical networks and five benchmark datasets. We provide, in a Google Colab notebook, PyTorch code for reproducing MSE-NC and CE-NC: https://colab.research.google.com/github/neuralcollapse/neuralcollapse/blob/main/neuralcollapse.ipynb. The analytically-tractable MSE loss offers more mathematical opportunities than the hard-to-analyze CE loss, inspiring us to leverage MSE loss towards the theoretical investigation of NC. We develop three main contributions: (I) We show a new decomposition of the MSE loss into (A) terms directly interpretable through the lens of NC and which assume the last-layer classifier is exactly the least-squares classifier; and (B) a term capturing the deviation from this least-squares classifier. (II) We exhibit experiments on canonical datasets and networks demonstrating that term-(B) is negligible during training. This motivates us to introduce a new theoretical construct: the central path, where the linear classifier stays MSE-optimal for feature activations throughout the dynamics. (III) By studying renormalized gradient flow along the central path, we derive exact dynamics that predict NC.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=w1UbdvWH_R3,https://openreview.net/forum?id=w1UbdvWH_R3
"['Fan Bao', 'Chongxuan Li', 'Jun Zhu', 'Bo Zhang']",ICLR,Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models,https://iclr.cc/virtual/2022/oral/7167,2022," Diffusion probabilistic models (DPMs) represent a class of powerful generative models. Despite their success, the inference of DPMs is expensive since it generally needs to iterate over thousands of timesteps. A key problem in the inference is to estimate the variance in each timestep of the reverse process. In this work, we present a surprising result that both the optimal reverse variance and the corresponding optimal KL divergence of a DPM have analytic forms w.r.t. its score function. Building upon it, we propose \textit{Analytic-DPM}, a training-free inference framework that estimates the analytic forms of the variance and KL divergence using the Monte Carlo method and a pretrained score-based model. Further, to correct the potential bias caused by the score-based model, we derive both lower and upper bounds of the optimal variance and clip the estimate for a better result. Empirically, our analytic-DPM improves the log-likelihood of various DPMs, produces high-quality samples, and meanwhile enjoys a $20\times$ to $80\times$ speed up.","Oral 4: Probablistic Models, Vision",https://openreview.net/pdf?id=0xiJLKH-ufZ,https://openreview.net/forum?id=0xiJLKH-ufZ
"['Lixu Wang', 'Shichao Xu', 'Ruiqi Xu', 'Xiao Wang', 'Qi Zhu']",ICLR,Non-Transferable Learning: A New Approach for Model Ownership Verification and Applicability Authorization,https://iclr.cc/virtual/2022/oral/6144,2022," As Artificial Intelligence as a Service gains popularity, protecting well-trained models as intellectual property is becoming increasingly important. There are two common types of protection methods: ownership verification and usage authorization. In this paper, we propose Non-Transferable Learning (NTL), a novel approach that captures the exclusive data representation in the learned model and restricts the model generalization ability to certain domains. This approach provides effective solutions to both model verification and authorization. Specifically: 1) For ownership verification, watermarking techniques are commonly used but are often vulnerable to sophisticated watermark removal methods. By comparison, our NTL-based ownership verification provides robust resistance to state-of-the-art watermark removal methods, as shown in extensive experiments with 6 removal approaches over the digits, CIFAR10 & STL10, and VisDA datasets. 2) For usage authorization, prior solutions focus on authorizing specific users to access the model, but authorized users can still apply the model to any data without restriction. Our NTL-based authorization approach instead provides data-centric protection, which we call applicability authorization, by significantly degrading the performance of the model on unauthorized data. Its effectiveness is also shown through experiments on aforementioned datasets.",Oral 2: AI applications,https://openreview.net/pdf?id=tYRrOdSnVUy,https://openreview.net/forum?id=tYRrOdSnVUy
"['Albert Gu', 'Karan Goel', 'Christopher Re']",ICLR,Efficiently Modeling Long Sequences with Structured State Spaces,https://iclr.cc/virtual/2022/oral/6960,2022," A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies.  Although conventional models including RNNs, CNNs, and Transformers have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of $10000$ or more steps.  A promising recent approach proposed modeling sequences by simulating the fundamental state space model (SSM) \( x'(t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t) \), and showed that for appropriate choices of the state matrix \( A \), this system could handle long-range dependencies mathematically and empirically.  However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution.  We propose the Structured State Space sequence model (S4) based on a new parameterization for the SSM, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths.  Our technique involves conditioning \( A \) with a low-rank correction, allowing it to be diagonalized stably and reducing the SSM to the well-studied computation of a Cauchy kernel.  S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91\% accuracy on sequential CIFAR-10 with no data augmentation or auxiliary losses, on par with a larger 2-D ResNet, (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation $60\times$ faster (iii) SoTA on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors.",Oral 2: Structured learning,https://openreview.net/pdf?id=uYLFoz1vlAC,https://openreview.net/forum?id=uYLFoz1vlAC
"['Haobo Wang', 'Ruixuan Xiao', 'Yixuan Li', 'Lei Feng', 'Gang Niu', 'Gang Chen', 'Junbo Zhao']",ICLR,PiCO: Contrastive Label Disambiguation for Partial Label Learning,https://iclr.cc/virtual/2022/oral/6039,2022," Partial label learning (PLL) is an important problem that allows each training example to be labeled with a coarse candidate set, which well suits many real-world data annotation scenarios with label ambiguity.  Despite the promise, the performance of PLL often lags behind the supervised counterpart. In this work, we bridge the gap by addressing two key research challenges in PLL---representation learning and label disambiguation---in one coherent framework. Specifically, our proposed framework PiCO consists of a contrastive learning module along with a novel class prototype-based label disambiguation algorithm. PiCO produces closely aligned representations for examples from the same classes and facilitates label disambiguation. Theoretically, we show that these two components are mutually beneficial, and can be rigorously justified from an expectation-maximization (EM) algorithm perspective. Extensive experiments demonstrate that PiCO significantly outperforms the current state-of-the-art approaches in PLL and even achieves comparable results to fully supervised learning. Code and data available: https://github.com/hbzju/PiCO.","Oral 1: Learning in the wild,  Reinforcement learning",https://openreview.net/pdf?id=EhYjZy6e1gJ,https://openreview.net/forum?id=EhYjZy6e1gJ
"['Anirudh Goyal', 'Aniket Didolkar', 'Alex Lamb', 'Kartikeya Badola', 'Nan Rosemary Ke', 'Nasim Rahaman', 'Jonathan Binas', 'Charles Blundell', 'Michael Mozer', 'Yoshua Bengio']",ICLR,Coordination Among Neural Modules Through a Shared Global Workspace,https://iclr.cc/virtual/2022/oral/6383,2022," Deep learning has seen a movement away from representing examples with a monolithic hidden state towards a richly structured state. For example, Transformers segment by position, and object-centric architectures decompose images into entities. In all these architectures, interactions between different elements are modeled via pairwise interactions: Transformers make use of self-attention to incorporate information from other positions and object-centric architectures make use of graph neural networks to model interactions among entities.  We consider how to improve on pairwise interactions in terms of global coordination and a coherent, integrated representation that can be used for downstream tasks. In cognitive science, a global workspace architecture has been proposed in which functionally  specialized  components share information through a common, bandwidth-limited communication channel. We explore the use of such a communication channel in the context of deep learning for modeling the structure of complex environments. The proposed method includes a shared workspace through which communication among different specialist modules takes place but due to limits on the communication bandwidth, specialist modules must compete for access. We show that capacity limitations have  a rational basis in that (1) they encourage specialization and compositionality and (2) they facilitate the synchronization of otherwise  independent specialists.",Oral 3: Meta-learning and adaptation,https://openreview.net/pdf?id=XzTtHjgPDsT,https://openreview.net/forum?id=XzTtHjgPDsT
"['S Chandra Mouli', 'Bruno Ribeiro']",ICLR,Asymmetry Learning for Counterfactually-invariant Classification in OOD Tasks,https://iclr.cc/virtual/2022/oral/6947,2022," Generalizing from observed to new related environments (out-of-distribution) is central to the reliability of classifiers. However, most classifiers fail to predict label $Y$ from input $X$ when the change in environment is due a (stochastic) input transformation $T^\text{te} \circ X'$ not observed in training, as in training we observe $T^\text{tr} \circ X'$, where $X'$ is a hidden variable. This work argues that when the transformations in train $T^\text{tr}$ and test $T^\text{te}$ are (arbitrary) symmetry transformations induced by a collection of known $m$ equivalence relations, the task of finding a robust OOD classifier can be defined as finding the simplest causal model that defines a causal connection between the target labels and the symmetry transformations that are associated with label changes. We then propose a new learning paradigm, asymmetry learning, that identifies which symmetries the classifier must break in order to correctly predict $Y$ in both train and test. Asymmetry learning performs a causal model search that, under certain identifiability conditions, finds classifiers that perform equally well in-distribution and out-of-distribution. Finally, we show how to learn counterfactually-invariant representations with asymmetry learning in two physics tasks.",Oral 3: Learning from distribution shift,https://openreview.net/pdf?id=avgclFZ221l,https://openreview.net/forum?id=avgclFZ221l
"['Evan Hernandez', 'Sarah Schwettmann', 'David Bau', 'Teona Bagashvili', 'Antonio Torralba', 'Jacob Andreas']",ICLR,Natural Language Descriptions of Deep Features,https://iclr.cc/virtual/2022/oral/5989,2022," Some neurons in deep networks specialize in recognizing highly specific perceptual, structural, or semantic features of inputs. In computer vision, techniques exist for identifying neurons that respond to individual concept categories like colors, textures, and object classes. But these techniques are limited in scope, labeling only a small subset of neurons and behaviors in any network. Is a richer characterization of neuron-level computation possible? We introduce a procedure (called MILAN, for mutual information-guided linguistic annotation of neurons) that automatically labels neurons with open-ended, compositional, natural language descriptions. Given a neuron, MILAN generates a description by searching for a natural language string that maximizes pointwise mutual information with the image regions in which the neuron is active. MILAN produces fine-grained descriptions that capture categorical, relational, and logical structure in learned features. These descriptions obtain high agreement with human-generated feature descriptions across a diverse set of model architectures and tasks, and can aid in understanding and controlling learned models. We highlight three applications of natural language neuron descriptions. First, we use MILAN for analysis, characterizing the distribution and importance of neurons selective for attribute, category, and relational information in vision models. Second, we use MILAN for auditing, surfacing neurons sensitive to human faces in datasets designed to obscure them. Finally, we use MILAN for editing, improving robustness in an image classifier by deleting neurons sensitive to text features spuriously correlated with class labels.",Oral 4: Sequence modeling,https://openreview.net/pdf?id=NudBMY-tzDr,https://openreview.net/forum?id=NudBMY-tzDr
"['Mia Chiquier', 'Chengzhi Mao', 'Carl Vondrick']",ICLR,Real-Time Neural Voice Camouflage,https://iclr.cc/virtual/2022/oral/6987,2022," Automatic speech recognition systems have created exciting possibilities for applications, however they also enable opportunities for systematic eavesdropping.We propose a method to camouflage a person's voice from these systems without inconveniencing the conversation between people in the room. Standard adversarial attacks are not effective in real-time streaming situations because the characteristics of the signal will have changed by the time the attack is executed. We introduce predictive adversarial attacks, which achieves real-time performance by forecasting the attack vector that will be the most effective in the future. Under real-time constraints, our method jams the established speech recognition system DeepSpeech 3.9x more than online projected gradient descent as measured through word error rate, and 6.6x more as measured through character error rate. We furthermore demonstrate our approach is practically effective in realistic environments with complex scene geometries.",Oral 1: AI Applications,https://openreview.net/pdf?id=qj1IZ-6TInc,https://openreview.net/forum?id=qj1IZ-6TInc
"['Shengjia Zhao', 'Abhishek Sinha', 'Yutong He', 'Aidan Perreault', 'Jiaming Song', 'Stefano Ermon']",ICLR,Comparing Distributions by Measuring Differences that Affect Decision Making,https://iclr.cc/virtual/2022/oral/6696,2022," Measuring the discrepancy between two probability distributions is a fundamental problem in machine learning and statistics. We propose a new class of discrepancies based on the optimal loss for a decision task -- two distributions are different if the optimal decision loss is higher on their mixture than on each individual distribution. By suitably choosing the decision task, this generalizes the Jensen-Shannon divergence and the maximum mean discrepancy family. We apply our approach to two-sample tests, and on various benchmarks, we achieve superior test power compared to competing methods. In addition, a modeler can directly specify their preferences when comparing distributions through the decision loss. We apply this property to understanding the effects of climate change on different social and economic activities, evaluating sample quality, and selecting features targeting different decision tasks.","Oral 4: Probablistic Models, Vision",https://openreview.net/pdf?id=KB5onONJIAU,https://openreview.net/forum?id=KB5onONJIAU
"['Rachid Riad', 'Olivier Teboul', 'David Grangier', 'Neil Zeghidour']",ICLR,Learning Strides in Convolutional Neural Networks,https://iclr.cc/virtual/2022/oral/7069,2022," Convolutional neural networks typically contain several downsampling operators, such as strided convolutions or pooling layers, that progressively reduce the resolution of intermediate representations. This provides some shift-invariance while reducing the computational complexity of the whole architecture. A critical hyperparameter of such layers is their stride: the integer factor of downsampling. As strides are not differentiable, finding the best configuration either requires cross-validation or discrete optimization (e.g. architecture search), which rapidly become prohibitive as the search space grows exponentially with the number of downsampling layers. Hence, exploring this search space by gradient descent would allow finding better configurations at a lower computational cost. This work introduces DiffStride, the first downsampling layer with learnable strides. Our layer learns the size of a cropping mask in the Fourier domain, that effectively performs resizing in a differentiable way. Experiments on audio and image classification show the generality and effectiveness of our solution: we use DiffStride as a drop-in replacement to standard downsampling layers and outperform them. In particular, we show that introducing our layer into a ResNet-18 architecture allows keeping consistent high performance on CIFAR10, CIFAR100 and ImageNet even when training starts from poor random stride configurations. Moreover, formulating strides as learnable variables allows us to introduce a regularization term that controls the computational complexity of the architecture. We show how this regularization allows trading off accuracy for efficiency on ImageNet.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=M752z9FKJP,https://openreview.net/forum?id=M752z9FKJP
"['Minghao Guo', 'Veronika Thost', 'Beichen Li', 'Payel Das', 'Jie Chen', 'Wojciech Matusik']",ICLR,Data-Efficient Graph Grammar Learning for Molecular Generation,https://iclr.cc/virtual/2022/oral/7012,2022," The problem of molecular generation has received significant attention recently. Existing methods are typically based on deep neural networks and require training on large datasets with tens of thousands of samples. In practice, however, the size of class-specific chemical datasets is usually limited (e.g., dozens of samples) due to labor-intensive experimentation and data collection. Another major challenge is to generate only physically synthesizable molecules. This is a non-trivial task for neural network-based generative models since the relevant chemical knowledge can only be extracted and generalized from the limited training data. In this work, we propose a data-efficient generative model that can be learned from datasets with orders of magnitude smaller sizes than common benchmarks. At the heart of this method is a learnable graph grammar that generates molecules from a sequence of production rules. Without any human assistance, these production rules are automatically constructed from training data. Furthermore, additional chemical knowledge can be incorporated into the model by further grammar optimization. Our learned graph grammar yields state-of-the-art results on generating high-quality molecules for three monomer datasets that contain only ${\sim}20$ samples each. Our approach also achieves remarkable performance in a challenging polymer generation task with $only$ $117$ training samples and is competitive against existing methods using $81$k data points.",Oral 2: AI applications,https://openreview.net/pdf?id=l4IHywGq6a,https://openreview.net/forum?id=l4IHywGq6a
"['Meng Qu', 'Huiyu Cai', 'Jian Tang']",ICLR,Neural Structured Prediction for Inductive Node Classification,https://iclr.cc/virtual/2022/oral/5948,2022," This paper studies node classification in the inductive setting, i.e., aiming to learn a model on labeled training graphs and generalize it to infer node labels on unlabeled test graphs. This problem has been extensively studied with graph neural networks (GNNs) by learning effective node representations, as well as traditional structured prediction methods for modeling the structured output of node labels, e.g., conditional random fields (CRFs). In this paper, we present a new approach called the Structured Proxy Network (SPN), which combines the advantages of both worlds. SPN defines flexible potential functions of CRFs with GNNs. However, learning such a model is nontrivial as it involves optimizing a maximin game with high-cost inference. Inspired by the underlying connection between joint and marginal distributions defined by Markov networks, we propose to solve an approximate version of the optimization problem as a proxy, which yields a near-optimal solution, making learning more efficient. Extensive experiments on two settings show that our approach outperforms many competitive baselines.",Oral 2: Structured learning,https://openreview.net/pdf?id=YWNAX0caEjI,https://openreview.net/forum?id=YWNAX0caEjI
"['Nicholas Carlini', 'Andreas Terzis']",ICLR,Poisoning and Backdooring Contrastive Learning,https://iclr.cc/virtual/2022/oral/6317,2022," Multimodal contrastive learning methods like CLIP train on noisy and uncurated training datasets. This is cheaper than labeling datasets manually, and even improves out-of-distribution robustness. We show that this practice makes backdoor and poisoning attacks a significant threat. By poisoning just 0.01% of a dataset (e.g., just 300 images of the 3 million-example Conceptual Captions dataset), we can cause the model to misclassify test images by overlaying a small patch. Targeted poisoning attacks, whereby the model misclassifies a particular test input  with an adversarially-desired label, are even easier requiring control of 0.0001% of the dataset (e.g., just three out of the 3 million images). Our attacks call into question whether training on noisy and uncurated Internet scrapes is desirable.","Oral 1: Learning in the wild,  Reinforcement learning",https://openreview.net/pdf?id=iC4UHbQ01Mp,https://openreview.net/forum?id=iC4UHbQ01Mp
"['Huaxiu Yao', 'Linjun Zhang', 'Chelsea Finn']",ICLR,Meta-Learning with Fewer Tasks through Task Interpolation,https://iclr.cc/virtual/2022/oral/7141,2022," Meta-learning enables algorithms to quickly learn a newly encountered task with just a few labeled examples by transferring previously learned knowledge. However, the bottleneck of current meta-learning algorithms is the requirement of a large number of meta-training tasks, which may not be accessible in real-world scenarios. To address the challenge that available tasks may not densely sample the space of tasks, we propose to augment the task set through interpolation. By meta-learning with task interpolation (MLTI), our approach effectively generates additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels. Under both gradient-based and metric-based meta-learning settings, our theoretical analysis shows MLTI corresponds to a data-adaptive meta-regularization and further improves the generalization. Empirically, in our experiments on eight datasets from diverse domains including image recognition, pose prediction, molecule property prediction, and medical image classification, we find that the proposed general MLTI framework is compatible with representative meta-learning algorithms and consistently outperforms other state-of-the-art strategies.",Oral 3: Meta-learning and adaptation,https://openreview.net/pdf?id=ajXWF7bVR8d,https://openreview.net/forum?id=ajXWF7bVR8d
"['Jason Wei', 'Maarten Bosma', 'Vincent Zhao', 'Kelvin Guu', 'Wei Yu', 'Brian Lester', 'Nan Du', 'Andrew Dai', 'Quoc V Le']",ICLR,Finetuned Language Models are Zero-Shot Learners,https://iclr.cc/virtual/2022/oral/6255,2022," This paper explores a simple method for improving the zero-shot learning abilities of language models. We show that instruction tuning—finetuning language models on a collection of datasets described via instructions—substantially improves zero-shot performance on unseen tasks. We take a 137B parameter pretrained language model and instruction tune it on over 60 NLP datasets verbalized via natural language instruction templates. We evaluate this instruction-tuned model, which we call FLAN, on unseen task types. FLAN substantially improves the performance of its unmodified counterpart and surpasses zero-shot 175B GPT-3 on 20 of 25 datasets that we evaluate. FLAN even outperforms few-shot GPT-3 by a large margin on ANLI, RTE, BoolQ, AI2-ARC, OpenbookQA, and StoryCloze. Ablation studies reveal that number of finetuning datasets, model scale, and natural language instructions are key to the success of instruction tuning.",Oral 4: Sequence modeling,https://openreview.net/pdf?id=gEZrGCozdqR,https://openreview.net/forum?id=gEZrGCozdqR
"['Olivia Wiles', 'Sven Gowal', 'Florian Stimberg', 'Sylvestre-Alvise Rebuffi', 'Ira Ktena', 'Krishnamurthy Dvijotham', 'Ali Taylan Cemgil']",ICLR,A Fine-Grained Analysis on Distribution Shift,https://iclr.cc/virtual/2022/oral/7003,2022," Robustness to distribution shifts is critical for deploying machine learning models in the real world. Despite this necessity, there has been little work in defining the underlying mechanisms that cause these shifts and evaluating the robustness of algorithms across multiple, different distribution shifts. To this end, we introduce a framework that enables fine-grained analysis of various distribution shifts. We provide a holistic analysis of current state-of-the-art methods by evaluating 19 distinct methods grouped into five categories across both synthetic and real-world datasets.  Overall, we train more than 85K models. Our experimental framework can be easily extended to include new methods, shifts, and datasets. We find, unlike previous work (Gulrajani & Lopez-Paz, 2021), that progress has been made over a standard ERM baseline; in particular, pretraining and augmentations (learned or heuristic) offer large gains in many cases. However, the best methods are not consistent over different datasets and shifts. We will open source our experimental framework, allowing future work to evaluate new methods over multiple shifts to obtain a more complete picture of a method's effectiveness. Code is available at github.com/deepmind/distribution shift framework.",Oral 3: Learning from distribution shift,https://openreview.net/pdf?id=Dl4LetuLdyK,https://openreview.net/forum?id=Dl4LetuLdyK
"['Boris Oreshkin', 'Florent Bocquelet', 'Felix G. Harvey', 'Bay Raitt', 'Dominic Laflamme']",ICLR,ProtoRes: Proto-Residual Network for Pose Authoring via Learned Inverse Kinematics,https://iclr.cc/virtual/2022/oral/6540,2022," Our work focuses on the development of a learnable neural representation of human pose for advanced AI assisted animation tooling. Specifically, we tackle the problem of constructing a full static human pose based on sparse and variable user inputs (e.g. locations and/or orientations of a subset of body joints). To solve this problem, we propose a novel neural architecture that combines residual connections with prototype encoding of a partially specified pose to create a new complete pose from the learned latent space. We show that our architecture outperforms a baseline based on Transformer, both in terms of accuracy and computational efficiency. Additionally, we develop a user interface to integrate our neural model in Unity, a real-time 3D development platform. Furthermore, we introduce two new datasets representing the static human pose modeling problem, based on high-quality human motion capture data, which will be released publicly along with model code.",Oral 1: AI Applications,https://openreview.net/pdf?id=s03AQxehtd_,https://openreview.net/forum?id=s03AQxehtd_
"['Bo Wan', 'Wenjuan Han', 'Zilong Zheng', 'Tinne Tuytelaars']",ICLR,Unsupervised Vision-Language Grammar Induction with Shared Structure Modeling,https://iclr.cc/virtual/2022/oral/6111,2022," We introduce a new task, unsupervised vision-language (VL) grammar induction. Given an image-caption pair, the goal is to extract a shared hierarchical structure for both image and language simultaneously.  We argue that such structured output, grounded in both modalities, is a clear step towards the high-level understanding of multimodal information. Besides challenges existing in conventional visually grounded grammar induction tasks, VL grammar induction requires a model to capture contextual semantics and perform a fine-grained alignment. To address these challenges, we propose a novel method, CLIORA, which constructs a shared vision-language constituency tree structure with context-dependent semantics for all possible phrases in different levels of the tree. It computes a matching score between each constituent and image region, trained via contrastive learning.  It integrates two levels of fusion, namely at feature-level and at score-level, so as to allow fine-grained alignment. We introduce a new evaluation metric for VL grammar induction, CCRA, and show a 3.3% improvement over a strong baseline on Flickr30k Entities. We also evaluate our model via two derived tasks, i.e., language grammar induction and phrase grounding, and improve over the state-of-the-art for both.","Oral 4: Probablistic Models, Vision",https://openreview.net/pdf?id=N0n_QyQ5lBF,https://openreview.net/forum?id=N0n_QyQ5lBF
"['Yifei Wang', 'Jonathan Lacotte', 'Mert Pilanci']",ICLR,The Hidden Convex Optimization Landscape of Regularized Two-Layer ReLU Networks: an Exact Characterization of Optimal Solutions,https://iclr.cc/virtual/2022/oral/7125,2022," We prove that finding all globally optimal two-layer ReLU neural networks can be performed by solving a convex optimization program with cone constraints. Our analysis is novel, characterizes all optimal solutions, and does not leverage duality-based analysis which was recently used to lift neural network training into convex spaces. Given the set of solutions of our convex optimization program, we show how to construct exactly the entire set of optimal neural networks. We provide a detailed characterization of this optimal set and its invariant transformations. As additional consequences of our convex perspective, (i) we establish that Clarke stationary points found by stochastic gradient descent correspond to the global optimum of a subsampled convex problem (ii) we provide a polynomial-time algorithm for checking if a neural network is a global minimum of the training loss (iii) we provide an explicit construction of a continuous path between any neural network and the global minimum of its sublevel set and (iv) characterize the minimal size of the hidden layer so that the neural network optimization landscape has no spurious valleys.Overall, we provide a rich framework for studying the landscape of neural network training loss through convexity.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=Z7Lk2cQEG8a,https://openreview.net/forum?id=Z7Lk2cQEG8a
"['Marine Schimel', 'Ta-Chu Kao', 'Kristopher Jensen', 'Guillaume Hennequin']",ICLR,iLQR-VAE : control-based learning of input-driven dynamics with applications to neural data,https://iclr.cc/virtual/2022/oral/6080,2022," Understanding how neural dynamics give rise to behaviour is one of the most fundamental questions in systems neuroscience. To achieve this, a common approach is to record neural populations in behaving animals, and model these data as emanating from a latent dynamical system whose state trajectories can then be related back to behavioural observations via some form of decoding. As recordings are typically performed in localized circuits that form only a part of the wider implicated network, it is important to simultaneously learn the local dynamics and infer any unobserved external input that might drive them. Here, we introduce iLQR-VAE, a novel control-based approach to variational inference in nonlinear dynamical systems, capable of learning both latent dynamics, initial conditions, and ongoing external inputs. As in recent deep learning approaches, our method is based on an input-driven sequential variational autoencoder (VAE). The main novelty lies in the use of the powerful iterative linear quadratic regulator algorithm (iLQR) in the recognition model. Optimization of the standard evidence lower-bound requires differentiating through iLQR solutions, which is made possible by recent advances in differentiable control. Importantly, having the recognition model be implicitly defined by the generative model greatly reduces the number of free parameters and allows for flexible, high-quality inference. This makes it possible for instance to evaluate the model on a single long trial after training on smaller chunks. We demonstrate the effectiveness of iLQR-VAE on a range of synthetic systems, with autonomous as well as input-driven dynamics. We further apply it to neural and behavioural recordings in non-human primates performing two different reaching tasks, and show that iLQR-VAE yields high-quality kinematic reconstructions from the neural data.",Oral 2: AI applications,https://openreview.net/pdf?id=wRODLDHaAiW,https://openreview.net/forum?id=wRODLDHaAiW
"['Asiri Wijesinghe', 'Qing Wang']",ICLR,"A New Perspective on ""How Graph Neural Networks Go Beyond Weisfeiler-Lehman?""",https://iclr.cc/virtual/2022/oral/6437,2022," We propose a new perspective on designing powerful Graph Neural Networks (GNNs). In a nutshell, this enables a general solution to inject structural properties of graphs into a message-passing aggregation scheme of GNNs. As a theoretical basis, we develop a new hierarchy of local isomorphism on neighborhood subgraphs. Then, we theoretically characterize how message-passing GNNs can be designed to be more expressive than the Weisfeiler Lehman test. To elaborate this characterization, we propose a novel neural model, called GraphSNN, and prove that this model is strictly more expressive than the Weisfeiler Lehman test in distinguishing graph structures. We empirically verify the strength of our model on different graph learning tasks. It is shown that our model consistently improves the state-of-the-art methods on the benchmark tasks without sacrificing computational simplicity and efficiency.",Oral 2: Structured learning,https://openreview.net/pdf?id=uxgg9o7bI_3,https://openreview.net/forum?id=uxgg9o7bI_3
"['Ye Yuan', 'Yuda Song', 'Zhengyi Luo', 'Wen Sun', 'Kris Kitani']",ICLR,Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design,https://iclr.cc/virtual/2022/oral/6197,2022," An agent's functionality is largely determined by its design, i.e., skeletal structure and joint attributes (e.g., length, size, strength). However, finding the optimal agent design for a given function is extremely challenging since the problem is inherently combinatorial and the design space is prohibitively large. Additionally, it can be costly to evaluate each candidate design which requires solving for its optimal controller. To tackle these problems, our key idea is to incorporate the design procedure of an agent into its decision-making process. Specifically, we learn a conditional policy that, in an episode, first applies a sequence of transform actions to modify an agent's skeletal structure and joint attributes, and then applies control actions under the new design. To handle a variable number of joints across designs, we use a graph-based policy where each graph node represents a joint and uses message passing with its neighbors to output joint-specific actions. Using policy gradient methods, our approach enables joint optimization of agent design and control as well as experience sharing across different designs, which improves sample efficiency substantially.  Experiments show that our approach, Transform2Act, outperforms prior methods significantly in terms of convergence speed and final performance. Notably, Transform2Act can automatically discover plausible designs similar to giraffes, squids, and spiders. Code and videos are available at https://sites.google.com/view/transform2act.","Oral 1: Learning in the wild,  Reinforcement learning",https://openreview.net/pdf?id=UcDUxjPYWSr,https://openreview.net/forum?id=UcDUxjPYWSr
"['Shuxiao Chen', 'Koby Crammer', 'Hangfeng He', 'Dan Roth', 'Weijie J Su']",ICLR,Weighted Training for Cross-Task Learning,https://iclr.cc/virtual/2022/oral/7204,2022," In this paper, we introduce Target-Aware Weighted Training (TAWT), a weighted training algorithm for cross-task learning based on minimizing a representation-based task distance between the source and target tasks. We show that TAWT is easy to implement, is computationally efficient, requires little hyperparameter tuning, and enjoys non-asymptotic learning-theoretic guarantees. The effectiveness of TAWT is corroborated through extensive experiments with BERT on four sequence tagging tasks in natural language processing (NLP), including part-of-speech (PoS) tagging, chunking, predicate detection, and named entity recognition (NER). As a byproduct, the proposed representation-based task distance allows one to reason in a theoretically principled way about several critical aspects of cross-task learning, such as the choice of the source data and the impact of fine-tuning.",Oral 3: Meta-learning and adaptation,https://openreview.net/pdf?id=ltM1RMZntpu,https://openreview.net/forum?id=ltM1RMZntpu
"['Xuechen Li', 'Florian Tramer', 'Percy Liang', 'Tatsunori Hashimoto']",ICLR,Large Language Models Can Be Strong Differentially Private Learners,https://iclr.cc/virtual/2022/oral/6895,2022," Differentially Private (DP) learning has seen limited success for building large deep learning models of text, and straightforward attempts at applying Differentially Private Stochastic Gradient Descent (DP-SGD) to NLP tasks have resulted in large performance drops and high computational overhead.We show that this performance drop can be mitigated with (1) the use of large pretrained language models; (2) non-standard hyperparameters that suit DP optimization; and (3) fine-tuning objectives which are aligned with the pretraining procedure.With the above, we obtain NLP models that outperform state-of-the-art DP-trained models under the same privacy budget and strong non-private baselines---by directly fine-tuning pretrained models with DP optimization on moderately-sized corpora. To address the computational challenge of running DP-SGD with large Transformers, we propose a memory saving technique that allows clipping in DP-SGD to run without instantiating per-example gradients for any linear layer in the model. The technique enables privately training Transformers with almost the same memory cost as non-private training at a modest run-time overhead. Contrary to conventional wisdom that DP optimization fails at learning high-dimensional models (due to noise that scales with dimension) empirical results reveal that private learning with pretrained language models tends to not suffer from dimension-dependent performance degradation.Code to reproduce results can be found at https://github.com/lxuechen/private-transformers.",Oral 4: Sequence modeling,https://openreview.net/pdf?id=bVuP3ltATMz,https://openreview.net/forum?id=bVuP3ltATMz
"['António Farinhas', 'Wilker Aziz', 'Vlad Niculae', 'Andre Martins']",ICLR,Sparse Communication via Mixed Distributions,https://iclr.cc/virtual/2022/oral/5896,2022," Neural networks and other machine learning models compute continuous representations, while humans communicate mostly through discrete symbols. Reconciling these two forms of communication is desirable for generating human-readable interpretations or learning discrete latent variable models, while maintaining end-to-end differentiability. Some existing approaches (such as the Gumbel-Softmax transformation) build continuous relaxations that are discrete approximations in the zero-temperature limit, while others (such as sparsemax transformations and the Hard Concrete distribution) produce discrete/continuous hybrids. In this paper, we build rigorous theoretical foundations for these hybrids, which we call ""mixed random variables.'' Our starting point is a new ""direct sum'' base measure defined on the face lattice of the probability simplex. From this measure, we introduce new entropy and Kullback-Leibler divergence functions that subsume the discrete and differential cases and have interpretations in terms of code optimality. Our framework suggests two strategies for representing and sampling mixed random variables, an extrinsic (""sample-and-project'’) and an intrinsic one (based on face stratification). We experiment with both approaches on an  emergent communication benchmark and on modeling MNIST and Fashion-MNIST data with variational auto-encoders with mixed latent variables.",Oral 3: Learning from distribution shift,https://openreview.net/pdf?id=WAid50QschI,https://openreview.net/forum?id=WAid50QschI
"['Sagar Vaze', 'Kai Han', 'Andrea Vedaldi', 'Andrew Zisserman']",ICLR,Open-Set Recognition: A Good Closed-Set Classifier is All You Need,https://iclr.cc/virtual/2022/oral/6728,2022," The ability to identify whether or not a test sample belongs to one of the semantic classes in a classifier's training set is critical to practical deployment of the model. This task is termed open-set recognition (OSR) and has received significant attention in recent years. In this paper, we first demonstrate that the ability of a classifier to make the 'none-of-above' decision is highly correlated with its accuracy on the closed-set classes. We find that this relationship holds across loss objectives and architectures, and further demonstrate the trend both on the standard OSR benchmarks as well as on a large-scale ImageNet evaluation. Second, we use this correlation to boost the performance of the maximum softmax probability OSR 'baseline' by improving its closed-set accuracy, and with this strong baseline achieve state-of-the-art on a number of OSR benchmarks. Similarly, we boost the performance of the existing state-of-the-art method by improving its closed-set accuracy, but the resulting discrepancy with the strong baseline is marginal. Our third contribution is to present the 'Semantic Shift Benchmark' (SSB), which better respects the task of detecting semantic novelty, as opposed to low-level distributional shifts as tackled by neighbouring machine learning fields. On this new evaluation, we again demonstrate that there is negligible difference between the strong baseline and the existing state-of-the-art. Code available at: https://github.com/sgvaze/osr closed set all you_need.",Oral 1: AI Applications,https://openreview.net/pdf?id=5hLP5JY9S2d,https://openreview.net/forum?id=5hLP5JY9S2d
"['Pingchuan Ma', 'Tao Du', 'Joshua B Tenenbaum', 'Wojciech Matusik', 'Chuang Gan']",ICLR,RISP: Rendering-Invariant State Predictor with Differentiable Simulation and Rendering for Cross-Domain Parameter Estimation,https://iclr.cc/virtual/2022/oral/6922,2022," This work considers identifying parameters characterizing a physical system's dynamic motion directly from a video whose rendering configurations are inaccessible. Existing solutions require massive training data or lack generalizability to unknown rendering configurations. We propose a novel approach that marries domain randomization and differentiable rendering gradients to address this problem. Our core idea is to train a rendering-invariant state-prediction (RISP) network that transforms image differences into state differences independent of rendering configurations, e.g., lighting, shadows, or material reflectance. To train this predictor, we formulate a new loss on rendering variances using gradients from differentiable rendering. Moreover, we present an efficient, second-order method to compute the gradients of this loss, allowing it to be integrated seamlessly into modern deep learning frameworks. We evaluate our method in rigid-body and deformable-body simulation environments using four tasks: state estimation, system identification, imitation learning, and visuomotor control. We further demonstrate the efficacy of our approach on a real-world example: inferring the state and action sequences of a quadrotor from a video of its motion sequences. Compared with existing methods, our approach achieves significantly lower reconstruction errors and has better generalizability among unknown rendering configurations.","Oral 4: Probablistic Models, Vision",https://openreview.net/pdf?id=uSE03demja,https://openreview.net/forum?id=uSE03demja
"['Chulhee Yun', 'Shashank Rajput', 'Suvrit Sra']",ICLR,Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond,https://iclr.cc/virtual/2022/oral/7031,2022," In distributed learning, local SGD (also known as federated averaging) and its simple baseline minibatch SGD are widely studied optimization methods. Most existing analyses of these methods assume independent and unbiased gradient estimates obtained via with-replacement sampling. In contrast, we study shuffling-based variants: minibatch and local Random Reshuffling, which draw stochastic gradients without replacement and are thus closer to practice. For smooth functions satisfying the Polyak-Łojasiewicz condition, we obtain convergence bounds (in the large epoch regime) which show that these shuffling-based variants converge faster than their with-replacement counterparts. Moreover, we prove matching lower bounds showing that our convergence analysis is tight. Finally, we propose an algorithmic modification called synchronized shuffling that leads to convergence rates faster than our lower bounds in near-homogeneous settings.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=LdlwbBP2mlq,https://openreview.net/forum?id=LdlwbBP2mlq
['Alex Rogozhnikov'],ICLR,Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation,https://iclr.cc/virtual/2022/oral/6603,2022," Tensor computations underlie modern scientific computing and deep learning.A number of tensor frameworks emerged varying in execution model, hardware support, memory management, model definition, etc.However, tensor operations in all frameworks follow the same paradigm.Recent neural network architectures demonstrate demand for higher expressiveness of tensor operations.The current paradigm is not suited to write readable, reliable, or easy-to-modify code for multidimensional tensor manipulations. Moreover, some commonly used operations do not provide sufficient checks and can break a tensor structure.These mistakes are elusive as no tools or tests can detect them.Independently, API discrepancies complicate code transfer between frameworks.We propose einops notation: a uniform and generic way to manipulate tensor structure, that significantly improves code readability and flexibility by focusing on the structure of input and output tensors.We implement einops notation in a Python package that efficiently supports multiple widely used frameworks and provides framework-independent minimalist API for tensor manipulations.",Oral 2: AI applications,https://openreview.net/pdf?id=oapKSVM2bcj,https://openreview.net/forum?id=oapKSVM2bcj
"['Shoufa Chen', 'Enze Xie', 'Chongjian GE', 'Runjian Chen', 'Ding Liang', 'Ping Luo']",ICLR,CycleMLP: A MLP-like Architecture for Dense Prediction,https://iclr.cc/virtual/2022/oral/6274,2022," This paper presents a simple MLP-like architecture, CycleMLP, which is a versatile backbone for visual recognition and dense predictions. As compared to modern MLP architectures, e.g. , MLP-Mixer, ResMLP, and gMLP, whose architectures are correlated to image size and thus are infeasible in object detection and segmentation, CycleMLP has two advantages compared to modern approaches. (1) It can copewith various image sizes. (2) It achieves linear computational complexity to image size by using local windows. In contrast, previous MLPs have $O(N^2)$ computations due to fully spatial connections. We build a family of models which surpass existing MLPs and even state-of-the-art Transformer-based models, e.g. Swin Transformer, while using fewer parameters and FLOPs. We expand the MLP-like models’ applicability, making them a versatile backbone for dense prediction tasks. CycleMLP achieves competitive results on object detection, instance segmentation, and semantic segmentation. In particular, CycleMLP-Tiny outperforms Swin-Tiny by 1.3% mIoU on ADE20K dataset with fewer FLOPs. Moreover, CycleMLP also shows excellent zero-shot robustness on ImageNet-C dataset.",Oral 2: Structured learning,https://openreview.net/pdf?id=NMEceG4v69Y,https://openreview.net/forum?id=NMEceG4v69Y
"['Benjamin Eysenbach', 'Ruslan Salakhutdinov', 'Sergey Levine']",ICLR,The Information Geometry of Unsupervised Reinforcement Learning,https://iclr.cc/virtual/2022/oral/6207,2022," How can a reinforcement learning (RL) agent prepare to solve downstream tasks if those tasks are not known a priori? One approach is unsupervised skill discovery, a class of algorithms that learn a set of policies without access to a reward function. Such algorithms bear a close resemblance to representation learning algorithms (e.g., contrastive learning) in supervised learning, in that both are pretraining algorithms that maximize some approximation to a mutual information objective. While prior work has shown that the set of skills learned by such methods can accelerate downstream RL tasks, prior work offers little analysis into whether these skill learning algorithms are optimal, or even what notion of optimality would be appropriate to apply to them. In this work, we show that unsupervised skill discovery algorithms based on mutual information maximization do not learn skills that are optimal for every possible reward function. However, we show that the distribution over skills provides an optimal initialization minimizing regret against adversarially-chosen reward functions, assuming a certain type of adaptation procedure. Our analysis also provides a geometric perspective on these skill learning methods.","Oral 1: Learning in the wild,  Reinforcement learning",https://openreview.net/pdf?id=3wU2UX0voE,https://openreview.net/forum?id=3wU2UX0voE
"['Sabri Eyuboglu', 'Maya Varma', 'Khaled Saab', 'Jean-Benoit Delbrouck', 'Christopher Lee-Messer', 'Jared Dunnmon', 'James Y Zou', 'Christopher Re']",ICLR,Domino: Discovering Systematic Errors with Cross-Modal Embeddings,https://iclr.cc/virtual/2022/oral/6149,2022," Machine learning models that achieve high overall accuracy often make systematic errors on important subsets (or slices) of data. Identifying underperforming slices is particularly challenging when working with high-dimensional inputs (e.g. images, audio), where important slices are often unlabeled. In order to address this issue, recent studies have proposed automated slice discovery methods (SDMs), which leverage learned model representations to mine input data for slices on which a model performs poorly. To be useful to a practitioner, these methods must identify slices that are both underperforming and coherent (i.e. united by a human-understandable concept). However, no quantitative evaluation framework currently exists for rigorously assessing SDMs with respect to these criteria. Additionally, prior qualitative evaluations have shown that SDMs often identify slices that are incoherent. In this work, we address these challenges by first designing a principled evaluation framework that enables a quantitative comparison of SDMs across 1,235 slice discovery settings in three input domains (natural images, medical images, and time-series data).Then, motivated by the recent development of powerful cross-modal representation learning approaches, we present Domino, an SDM that leverages cross-modal embeddings and a novel error-aware mixture model to discover and describe coherent slices. We find that Domino accurately identifies 36% of the 1,235 slices in our framework -- a 12 percentage point improvement over prior methods. Further, Domino is the first SDM that can provide natural language descriptions of identified slices, correctly generating the exact name of the slice in 35% of settings.",Oral 3: Meta-learning and adaptation,https://openreview.net/pdf?id=FPCMqjI0jXN,https://openreview.net/forum?id=FPCMqjI0jXN
"['Minkai Xu', 'Lantao Yu', 'Yang Song', 'Chence Shi', 'Stefano Ermon', 'Jian Tang']",ICLR,GeoDiff: A Geometric Diffusion Model for Molecular Conformation Generation,https://iclr.cc/virtual/2022/oral/7029,2022," Predicting molecular conformations from molecular graphs is a fundamental problem in cheminformatics and drug discovery. Recently, significant progress has been achieved with machine learning approaches, especially with deep generative models. Inspired by the diffusion process in classical non-equilibrium thermodynamics where heated particles will diffuse from original states to a noise distribution, in this paper, we propose a novel generative model named GeoDiff for molecular conformation prediction. GeoDiff treats each atom as a particle and learns to directly reverse the diffusion process (i.e., transforming from a noise distribution to stable conformations) as a Markov chain. Modeling such a generation process is however very challenging as the likelihood of conformations should be roto-translational invariant. We theoretically show that Markov chains evolving with equivariant Markov kernels can induce an invariant distribution by design, and further propose building blocks for the Markov kernels to preserve the desirable equivariance property. The whole framework can be efficiently trained in an end-to-end fashion by optimizing a weighted variational lower bound to the (conditional) likelihood. Experiments on multiple benchmarks show that GeoDiff is superior or comparable to existing state-of-the-art approaches, especially on large molecules.",Oral 4: Sequence modeling,https://openreview.net/pdf?id=PzcvxEMzvQC,https://openreview.net/forum?id=PzcvxEMzvQC
"['Omri Puny', 'Matan Atzmon', 'Edward Smith', 'Ishan Misra', 'Aditya Grover', 'Heli Ben-Hamu', 'Yaron Lipman']",ICLR,Frame Averaging for Invariant and Equivariant Network Design,https://iclr.cc/virtual/2022/oral/6190,2022," Many machine learning tasks involve learning functions that are known to be invariant or equivariant to certain symmetries of the input data. However, it is often challenging to design neural network architectures that respect these symmetries while being expressive and computationally efficient. For example, Euclidean motion invariant/equivariant graph or point cloud neural networks. We introduce Frame Averaging (FA), a highly general purpose and systematic framework for adapting known (backbone) architectures to become invariant or equivariant to new symmetry types. Our framework builds on the well known group averaging operator that guarantees invariance or equivariance but is intractable. In contrast, we observe that for many important classes of symmetries, this operator can be replaced with an averaging operator over a small subset of the group elements, called a frame. We show that averaging over a frame guarantees exact invariance or equivariance while often being much simpler to compute than averaging over the entire group. Furthermore, we prove that FA-based models have maximal expressive power in a broad setting and in general preserve the expressive power of their backbone architectures. Using frame averaging, we propose a new class of universal Graph Neural Networks (GNNs), universal Euclidean motion invariant point cloud networks, and Euclidean motion invariant Message Passing (MP) GNNs. We demonstrate the practical effectiveness of FA on several applications including point cloud normal estimation, beyond $2$-WL graph separation, and $n$-body dynamics prediction, achieving state-of-the-art results in all of these benchmarks.",Oral 3: Learning from distribution shift,https://openreview.net/pdf?id=zIUyj55nXR,https://openreview.net/forum?id=zIUyj55nXR
"['Hangbo Bao', 'Li Dong', 'Songhao Piao', 'Furu Wei']",ICLR,BEiT: BERT Pre-Training of Image Transformers,https://iclr.cc/virtual/2022/oral/6324,2022," We introduce a self-supervised vision representation model BEiT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e., image patches (such as 16 x 16 pixels), and visual tokens (i.e., discrete tokens). We first ``tokenize'' the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEiT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods.","Oral 4: Probablistic Models, Vision",https://openreview.net/pdf?id=p-BhZSz59o4,https://openreview.net/forum?id=p-BhZSz59o4
"['Huiqi Deng', 'Qihan Ren', 'Hao Zhang', 'Quanshi Zhang']",ICLR,DISCOVERING AND EXPLAINING THE REPRESENTATION BOTTLENECK OF DNNS,https://iclr.cc/virtual/2022/oral/6623,2022," This paper explores the bottleneck of feature representations of deep neural networks (DNNs), from the perspective of the complexity of interactions between input variables encoded in DNNs. To this end, we focus on the multi-order interaction between input variables, where the order represents the complexity of interactions. We discover that a DNN is more likely to encode both too simple and too complex interactions, but usually fails to learn interactions of intermediate complexity. Such a phenomenon is widely shared by different DNNs for different tasks. This phenomenon indicates a cognition gap between DNNs and humans, and we call it a representation bottleneck. We theoretically prove the underlying reason for the representation bottleneck. Furthermore, we propose losses to encourage/penalize the learning of interactions of specific complexities, and analyze the representation capacities of interactions of different complexities. The code is available at https://github.com/Nebularaid2000/bottleneck.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=iRCUlgmdfHJ,https://openreview.net/forum?id=iRCUlgmdfHJ
"['Zongze Wu', 'Yotam Nitzan', 'Eli Shechtman', 'Dani Lischinski']",ICLR,StyleAlign: Analysis and Applications of Aligned StyleGAN Models,https://iclr.cc/virtual/2022/oral/6949,2022," In this paper, we perform an in-depth study of the properties and applications of aligned generative models.We refer to two models as aligned if they share the same architecture, and one of them (the child) is obtained from the other (the parent) via fine-tuning to another domain, a common practice in transfer learning. Several works already utilize some basic properties of aligned StyleGAN models to perform image-to-image translation. Here, we perform the first detailed exploration of model alignment, also focusing on StyleGAN. First, we empirically analyze aligned models and provide answers to important questions regarding their nature. In particular, we find that the child model's latent spaces are semantically aligned with those of the parent, inheriting incredibly rich semantics, even for distant data domains such as human faces and churches. Second, equipped with this better understanding, we leverage aligned models to solve a diverse set of tasks. In addition to image translation, we demonstrate fully automatic cross-domain image morphing. We further show that zero-shot vision tasks may be performed in the child domain, while relying exclusively on supervision in the parent domain. We demonstrate qualitatively and quantitatively that our approach yields state-of-the-art results, while requiring only simple fine-tuning and inversion.",Oral 2: AI applications,https://openreview.net/pdf?id=Qg2vi4ZbHM9,https://openreview.net/forum?id=Qg2vi4ZbHM9
"['Kohei Miyaguchi', 'Takayuki Katsuki', 'Akira Koseki', 'Toshiya Iwamori']",ICLR,Variational Inference for Discriminative Learning with Generative Modeling of Feature Incompletion,https://iclr.cc/virtual/2022/oral/6534,2022," We are concerned with the problem of distributional prediction with incomplete features: The goal is to estimate the distribution of target variables given feature vectors with some of the elements missing. A typical approach to this problem is to perform missing-value imputation and regression, simultaneously or sequentially, which we call the generative approach. Another approach is to perform regression after appropriately encoding missing values into the feature, which we call the discriminative approach. In comparison, the generative approach is more robust to the feature corruption while the discriminative approach is more favorable to maximize the performance of prediction. In this study, we propose a hybrid method to take the best of both worlds. Our method utilizes the black-box variational inference framework so that it can be applied to a wide variety of modern machine learning models, including the variational autoencoders. We also confirmed the effectiveness of the proposed method empirically.",Oral 2: Structured learning,https://openreview.net/pdf?id=qnQN4yr6FJz,https://openreview.net/forum?id=qnQN4yr6FJz
"['Yonathan Efroni', 'Dipendra Kumar Misra', 'Akshay Krishnamurthy', 'Alekh Agarwal', 'John Langford']",ICLR,Provably Filtering Exogenous Distractors using Multistep Inverse Dynamics,https://iclr.cc/virtual/2022/oral/6734,2022," Many real-world applications of reinforcement learning (RL) require the agent to deal with high-dimensional observations such as those generated from a megapixel camera. Prior work has addressed such problems with representation learning, through which the agent can provably extract endogenous, latent state information from raw observations and subsequently plan efficiently. However, such approaches can fail in the presence of temporally correlated noise in the observations, a phenomenon that is common in practice. We initiate the formal study of latent state discovery in the presence of such exogenous noise sources by proposing a new model, the Exogenous Block MDP (EX-BMDP), for rich observation RL. We start by establishing several negative results, by highlighting failure cases of prior representation learning based approaches. Then, we introduce the Predictive Path Elimination (PPE) algorithm, that learns a generalization of inverse dynamics and is provably sample and computationally efficient in EX-BMDPs when the endogenous state dynamics are near deterministic. The sample complexity of PPE depends polynomially on the size of the latent endogenous state space while not directly depending on the size of the observation space, nor the exogenous state space. We provide experiments on challenging exploration problems which show that our approach works empirically.","Oral 1: Learning in the wild,  Reinforcement learning",https://openreview.net/pdf?id=RQLLzMCefQu,https://openreview.net/forum?id=RQLLzMCefQu
"['Shiori Sagawa', 'Pang Wei Koh', 'Tony Lee', 'Irena Gao', 'Sang Michael Xie', 'Kendrick Shen', 'Ananya Kumar', 'Weihua Hu', 'Michihiro Yasunaga', 'Henrik Marklund', 'Sara Beery', 'Etienne David', 'Ian Stavness', 'Wei Guo', 'Jure Leskovec', 'Kate Saenko', 'Tatsunori Hashimoto', 'Sergey Levine', 'Chelsea Finn', 'Percy Liang']",ICLR,Extending the WILDS Benchmark for Unsupervised Adaptation,https://iclr.cc/virtual/2022/oral/6964,2022," Machine learning systems deployed in the wild are often trained on a source distribution but deployed on a different target distribution. Unlabeled data can be a powerful point of leverage for mitigating these distribution shifts, as it is frequently much more available than labeled data and can often be obtained from distributions beyond the source distribution as well. However, existing distribution shift benchmarks with unlabeled data do not reflect the breadth of scenarios that arise in real-world applications. In this work, we present the WILDS 2.0 update, which extends 8 of the 10 datasets in the WILDS benchmark of distribution shifts to include curated unlabeled data that would be realistically obtainable in deployment. These datasets span a wide range of applications (from histology to wildlife conservation), tasks (classification, regression, and detection), and modalities (photos, satellite images, microscope slides, text, molecular graphs). The update maintains consistency with the original WILDS benchmark by using identical labeled training, validation, and test sets, as well as identical evaluation metrics. We systematically benchmark state-of-the-art methods that use unlabeled data, including domain-invariant, self-training, and self-supervised methods, and show that their success on WILDS is limited. To facilitate method development, we provide an open-source package that automates data loading and contains the model architectures and methods used in this paper. Code and leaderboards are available at https://wilds.stanford.edu.",Oral 3: Meta-learning and adaptation,https://openreview.net/pdf?id=z7p2V6KROOV,https://openreview.net/forum?id=z7p2V6KROOV
"['Kyle Hsu', 'Moo Kim', 'Rafael Rafailov', 'Jiajun Wu', 'Chelsea Finn']",ICLR,Vision-Based Manipulators Need to Also See from Their Hands,https://iclr.cc/virtual/2022/oral/6103,2022," We study how the choice of visual perspective affects learning and generalization in the context of physical manipulation from raw sensor observations. Compared with the more commonly used global third-person perspective, a hand-centric (eye-in-hand) perspective affords reduced observability, but we find that it consistently improves training efficiency and out-of-distribution generalization. These benefits hold across a variety of learning algorithms, experimental settings, and distribution shifts, and for both simulated and real robot apparatuses. However, this is only the case when hand-centric observability is sufficient; otherwise, including a third-person perspective is necessary for learning, but also harms out-of-distribution generalization. To mitigate this, we propose to regularize the third-person information stream via a variational information bottleneck. On six representative manipulation tasks with varying hand-centric observability adapted from the Meta-World benchmark, this results in a state-of-the-art reinforcement learning agent operating from both perspectives improving its out-of-distribution generalization on every task. While some practitioners have long put cameras in the hands of robots, our work systematically analyzes the benefits of doing so and provides simple and broadly applicable insights for improving end-to-end learned vision-based robotic manipulation.",Oral 1: AI Applications,https://openreview.net/pdf?id=RJkAHKp7kNZ,https://openreview.net/forum?id=RJkAHKp7kNZ
"['Shi Zhan Liu', 'Hang Yu', 'Cong Liao', 'Jianguo Li', 'Weiyao Lin', 'Alex Liu ·']",ICLR,Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting,https://iclr.cc/virtual/2022/oral/6828,2022," Accurate prediction of the future given the past based on time series data is of paramount importance, since it opens the door for decision making and risk management ahead of time. In practice, the challenge is to build a flexible but parsimonious model that can capture a wide range of temporal dependencies. In this paper, we propose Pyraformer by exploring the multiresolution representation of the time series. Specifically, we introduce the pyramidal attention module (PAM) in which the inter-scale tree structure summarizes features at different resolutions and the intra-scale neighboring connections model the temporal dependencies of different ranges. Under mild conditions, the maximum length of the signal traversing path in Pyraformer is a constant (i.e., $\mathcal O(1)$) with regard to the sequence length $L$, while its time and space complexity scale linearly with $L$. Extensive numerical results show that Pyraformer typically achieves the highest prediction accuracy in both single-step and long-range forecasting tasks with the least amount of time and memory consumption, especially when the sequence is long.",Oral 4: Sequence modeling,https://openreview.net/pdf?id=0EXmFzUn5I,https://openreview.net/forum?id=0EXmFzUn5I
"['Qing Jin', 'Jian Ren', 'Richard Zhuang', 'Sumant Hanumante', 'Zhengang Li', 'Zhiyu Chen', 'Yanzhi Wang', 'Kaiyuan Yang', 'Sergey Tulyakov']",ICLR,F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization,https://iclr.cc/virtual/2022/oral/5944,2022," Neural network quantization is a promising compression technique to reduce memory footprint and save energy consumption, potentially leading to real-time inference. However, there is a performance gap between quantized and full-precision models. To reduce it, existing quantization approaches require high-precision INT32 or full-precision multiplication during inference for scaling or dequantization. This introduces a noticeable cost in terms of memory, speed, and required energy. To tackle these issues, we present F8Net, a novel quantization framework consisting in only ﬁxed-point 8-bit multiplication. To derive our method, we ﬁrst discuss the advantages of ﬁxed-point multiplication with different formats of ﬁxed-point numbers and study the statistical behavior of the associated ﬁxed-point numbers. Second, based on the statistical and algorithmic analysis, we apply different ﬁxed-point formats for weights and activations of different layers. We introduce a novel algorithm to automatically determine the right format for each layer during training. Third, we analyze a previous quantization algorithm—parameterized clipping activation (PACT)—and reformulate it using ﬁxed-point arithmetic. Finally, we unify the recently proposed method for quantization ﬁne-tuning and our ﬁxed-point approach to show the potential of our method. We verify F8Net on ImageNet for MobileNet V1/V2 and ResNet18/50. Our approach achieves comparable and better performance, when compared not only to existing quantization techniques with INT32 multiplication or ﬂoating point arithmetic, but also to the full-precision counterparts, achieving state-of-the-art performance.",Oral 3: Learning from distribution shift,https://openreview.net/pdf?id=_CfpJazzXT2,https://openreview.net/forum?id=_CfpJazzXT2
"['Shuming Kong', 'Yanyan Shen', 'Linpeng Huang']",ICLR,Resolving Training Biases via Influence-based Data Relabeling,https://iclr.cc/virtual/2022/oral/6492,2022," The performance of supervised learning methods easily suffers from the training bias issue caused by train-test distribution mismatch or label noise. Influence function is a  technique that estimates the impacts of a training sample on the model’s predictions. Recent studies on \emph{data resampling} have employed influence functions to identify \emph{harmful} training samples that will degrade model's test performance. They have shown that discarding or downweighting the identified harmful training samples is an effective way to resolve training biases. In this work, we move one step forward and propose an influence-based relabeling framework named RDIA for reusing harmful training samples toward better model performance. To achieve this, we use influence functions to estimate how relabeling a training sample would affect model's test performance and further develop a novel relabeling function R. We theoretically prove that applying R to relabel harmful training samples allows the model to achieve lower test loss than simply discarding them for any classification tasks using cross-entropy loss. Extensive experiments on ten real-world datasets demonstrate RDIA outperforms the state-of-the-art data resampling methods and improves model's robustness against label noise.","Oral 4: Probablistic Models, Vision",https://openreview.net/pdf?id=EskfH0bwNVn,https://openreview.net/forum?id=EskfH0bwNVn
"['Divyam Madaan', 'Jaehong Yoon', 'Yuanchun Li', 'Yunxin Liu', 'Sung Ju Hwang']",ICLR,Representational Continuity for Unsupervised Continual Learning,https://iclr.cc/virtual/2022/oral/7120,2022," Continual learning (CL) aims to learn a sequence of tasks without forgetting the previously acquired knowledge. However, recent CL advances are restricted to supervised continual learning (SCL) scenarios. Consequently, they are not scalable to real-world applications where the data distribution is often biased and unannotated. In this work, we focus on unsupervised continual learning (UCL), where we learn the feature representations on an unlabelled sequence of tasks and show that reliance on annotated data is not necessary for continual learning. We conduct a systematic study analyzing the learned feature representations and show that unsupervised visual representations are surprisingly more robust to catastrophic forgetting, consistently achieve better performance, and generalize better to out-of-distribution tasks than SCL. Furthermore, we find that UCL achieves a smoother loss landscape through qualitative analysis of the learned representations and learns meaningful feature representations. Additionally, we propose Lifelong Unsupervised Mixup (Lump), a simple yet effective technique that interpolates between the current task and previous tasks' instances to alleviate catastrophic forgetting for unsupervised representations.",Oral 2: Understanding Deep Learning,https://openreview.net/pdf?id=9Hrka5PA7LW,https://openreview.net/forum?id=9Hrka5PA7LW
"['Edoardo Balzani', 'Jean-Paul Noel', 'Pedro Herrero-Vidal', 'Dora Angelaki', 'Cristina Savin']",ICLR,A probabilistic framework for task-aligned intra- and inter-area neural manifold estimation,https://iclr.cc/virtual/2023/oral/12559,2023," Latent manifolds provide a compact characterization of neural population activity and of shared co-variability across brain areas. Nonetheless, existing statistical tools for extracting neural manifolds face limitations in terms of interpretability of latents with respect to task variables, and can be hard to apply to datasets with no trial repeats. Here we propose a novel probabilistic framework that allows for interpretable partitioning of population variability within and across areas in the context of naturalistic behavior. Our approach for task aligned manifold estimation (TAME-GP) explicitly partitions variability into private and shared sources which can themselves be subdivided in task-relevant and task irrelevant components, uses a realistic Poisson noise model, and introduces temporal smoothing of latent trajectories in the form of a Gaussian Process prior. This TAME-GP graphical model allows for robust estimation of task-relevant variability in local population responses, and of shared co-variability between brain areas. We demonstrate the efficiency of our estimator on within model and biologically motivated simulated data. We also apply it to several datasets of neural population recordings during behavior. Overall, our results demonstrate the capacity of TAME-GP to capture meaningful intra- and inter-area neural variability with single trial resolution.",Oral 1 Track 3: Neuroscience and Cognitive Science & General Machine Learning,https://openreview.net/pdf?id=kt-dcBQcSA,
"['Daniel Bolya', 'Cheng-Yang Fu', 'Xiaoliang Dai', 'Peizhao Zhang', 'Christoph Feichtenhofer', 'Judy Hoffman']",ICLR,Token Merging: Your ViT But Faster,https://iclr.cc/virtual/2023/oral/12533,2023," We introduce Token Merging (ToMe), a simple method to increase the throughput of existing ViT models without needing to train. ToMe gradually combines similar tokens in a transformer using a general and light-weight matching algorithm that is as fast as pruning while being more accurate. Off-the-shelf, ToMe can 2x the throughput of state-of-the-art ViT-L @ 512 and ViT-H @ 518 models on images and 2.2x the throughput of ViT-L on video with only a 0.2-0.3% accuracy drop in each case. ToMe can also easily be applied during training, improving in practice training speed up to 2x for MAE fine-tuning on video. Training with ToMe further minimizes accuracy drop, leading to 2x the throughput of ViT-B on audio for only a 0.4% mAP drop. Qualitatively, we find that ToMe merges object parts into one token, even over multiple frames of video. Overall, ToMe’s accuracy and speed are competitive with state-of-the-art on images, video, and audio.",Oral 1 Track 1: Deep Learning and representational learning I,https://openreview.net/pdf?id=JroZRaRw7Eu,
"['Nicholas Carlini', 'Daphne Ippolito', 'Matthew Jagielski', 'Katherine Lee', 'Florian Tramer', 'Chiyuan Zhang']",ICLR,Quantifying Memorization Across Neural Language Models,https://iclr.cc/virtual/2023/oral/12637,2023," Large language models (LMs) have been shown to memorize parts of their training data, and when prompted appropriately, they will emit the memorized training data verbatim. This is undesirable because memorization violates privacy (exposing user data), degrades utility (repeated easy-to-memorize text is often low quality), and hurts fairness (some texts are memorized over others).We describe three log-linear relationships that quantify the degree to which LMs emit memorized training data. Memorization significantly grows as we increase (1) the capacity of a model, (2) the number of times an example has been duplicated, and (3) the number of tokens of context used to prompt the model. Surprisingly, we find the situation becomes complicated when generalizing these results across model families. On the whole, we find that memorization in LMs is more prevalent than previously believed and will likely get worse as models continues to scale, at least without active mitigations.",Oral 1 Track 4: Social Aspects of Machine Learning,https://openreview.net/pdf?id=TatRHT_1cK,
"['Matt Ricci', 'Noa Moriel', 'Zoe Piran', 'Mor Nitzan']",ICLR,Phase2vec: dynamical systems embedding with a physics-informed convolutional network,https://iclr.cc/virtual/2023/oral/12620,2023," Dynamical systems are found in innumerable forms across the physical and biological sciences, yet all these systems fall naturally into equivalence classes: conservative or dissipative, stable or unstable, compressible or incompressible. Predicting these classes from data remains an essential open challenge in computational physics on which existing time-series classification methods struggle. Here, we propose, phase2vec, an embedding method that learns high-quality, physically-meaningful representations of low-dimensional dynamical systems without supervision. Our embeddings are produced by a convolutional backbone that extracts geometric features from flow data and minimizes a physically-informed vector field reconstruction loss. The trained architecture can not only predict the equations of unseen data, but also produces embeddings that encode meaningful physical properties of input data (e.g. stability of fixed points, conservation of energy, and the incompressibility of flows) more faithfully than standard blackbox classifiers and state-of-the-art time series classification techniques. We additionally apply our embeddings to the analysis of meteorological data, showing we can detect climatically meaningful features. Collectively, our results demonstrate the viability of embedding approaches for the discovery of dynamical features in physical systems.",Oral 1 Track 2: Machine Learning for Sciences,https://openreview.net/pdf?id=z9C5dGip90,
"['Pierre Schumacher', 'Daniel Haeufle', 'Dieter Büchler', 'Syn Schmitt', 'Georg Martius']",ICLR,DEP-RL: Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems,https://iclr.cc/virtual/2023/oral/12529,2023," Muscle-actuated organisms are capable of learning an unparalleled diversity of dexterous movements despite their vast amount of muscles. Reinforcement learning (RL) on large musculoskeletal models, however, has not been able to show similar performance.  We conjecture that ineffective exploration in large overactuated action spaces is a key problem.This is supported by the finding that common exploration noise strategies are inadequate in synthetic examples of overactuated systems. We identify differential extrinsic plasticity (DEP), a method from the domain of self-organization, as being able to induce state-space covering exploration within seconds of interaction. By integrating DEP into RL, we achieve fast learning of reaching and locomotion in musculoskeletal systems, outperforming current approaches in all considered tasks in sample efficiency and robustness.",Oral 1 Track 5: Reinforcement Learning,https://openreview.net/pdf?id=C-xa_D3oTj6,
"['Shiwei Liu', 'Tianlong Chen', 'Zhenyu Zhang', 'Xuxi Chen', 'Tianjin Huang', 'AJAY JAISWAL', 'Zhangyang Wang']",ICLR,Sparsity May Cry: Let Us Fail (Current) Sparse Neural Networks Together!,https://iclr.cc/virtual/2023/oral/12658,2023," Sparse Neural Networks (SNNs) have received voluminous attention predominantly due to growing computational and memory footprints of consistently exploding parameter count in large-scale models. Similar to their dense counterparts, recent SNNs generalize just as well and are equipped with numerous favorable benefits (e.g., low complexity, high scalability, and robustness), sometimes even better than the original dense networks. As research effort is focused on developing increasingly sophisticated sparse algorithms, it is startling that a comprehensive benchmark to evaluate the effectiveness of these algorithms has been highly overlooked. In absence of a carefully crafted evaluation benchmark, most if not all, sparse algorithms are evaluated against fairly simple and naive tasks (eg. CIFAR-10/100, ImageNet, GLUE, etc.), which can potentially camouflage many advantages as well unexpected predicaments of SNNs. In pursuit of a more general evaluation and unveiling the true potential of sparse algorithms, we introduce “Sparsity May Cry” Benchmark (SMC-Bench), a collection of carefully-curated 4 diverse tasks with 10 datasets, that accounts for capturing a wide range of domain-specific and sophisticated knowledge. Our systemic evaluation of the most representative sparse algorithms reveals an important obscured observation: the state-of-the-art magnitude- and/or gradient-based sparse algorithms seemingly fail to perform on SMC-Bench when applied out-of-the-box, sometimes at significantly trivial sparsity as low as 5%. The observations seek the immediate attention of the sparsity research community to reconsider the highly proclaimed benefits of SNNs. We further conduct a thorough investigation into the reasons for the failure of common SNNs. Our analysis points out that such failure is intimately related to the “lazy regime” of large model training, which hints us with stronger pruning recipes that alleviate the failure on SMC-Bench (though still more or less suffering). By incorporating these well-thought and diverse tasks, SMC-Bench is designed to favor and encourage the development of more scalable and generalizable sparse algorithms. We open-source SMC-Bench to assist researchers in building next-generation sparse algorithms that scale and generalize: https://github.com/VITA-Group/SMC-Bench.",Oral 1 Track 6: Deep Learning and representational learning II,https://openreview.net/pdf?id=J6F3lLg4Kdp,
"['Chenhongyi Yang', 'Jiarui Xu', 'Shalini De Mello', 'Elliot J Crowley', 'Xiaolong Wang']",ICLR,GPViT: A High Resolution Non-Hierarchical Vision Transformer with Group Propagation,https://iclr.cc/virtual/2023/oral/12624,2023," We present the Group Propagation Vision Transformer (GPViT): a novel non- hierarchical (i.e. non-pyramidal) transformer model designed for general visual recognition with high-resolution features. High-resolution features (or tokens) are a natural fit for tasks that involve perceiving fine-grained details such as detection and segmentation, but exchanging global information between these features is expensive in memory and computation because of the way self-attention scales. We provide a highly efficient alternative Group Propagation Block (GP Block) to exchange global information. In each GP Block, features are first grouped to- gether by a fixed number of learnable group tokens; we then perform Group Propagation where global information is exchanged between the grouped fea- tures; finally, global information in the updated grouped features is returned back to the image features through a transformer decoder. We evaluate GPViT on a variety of visual recognition tasks including image classification, semantic seg- mentation, object detection, and instance segmentation. Our method achieves significant performance gains over previous works across all tasks, especially on tasks that require high-resolution outputs, for example, our GPViT-L3 out- performs Swin Transformer-B by 2.0 mIoU on ADE20K semantic segmentation with only half as many parameters. Code and pre-trained models are available at https://github.com/ChenhongyiYang/GPViT.",Oral 2 Track 1: Applications,https://openreview.net/pdf?id=IowKt5rYWsK,
"['Jiayuan Gu', 'Devendra Singh Chaplot', 'Hao Su', 'Jitendra Malik']",ICLR,Multi-skill Mobile Manipulation for Object Rearrangement,https://iclr.cc/virtual/2023/oral/12568,2023," We study a modular approach to tackle long-horizon mobile manipulation tasks for object rearrangement, which decomposes a full task into a sequence of subtasks. To tackle the entire task, prior work chains multiple stationary manipulation skills with a point-goal navigation skill, which are learned individually on subtasks. Although more effective than monolithic end-to-end RL policies, this framework suffers from compounding errors in skill chaining, e.g., navigating to a bad location where a stationary manipulation skill can not reach its target to manipulate. To this end, we propose that the manipulation skills should include mobility to have flexibility in interacting with the target object from multiple locations and at the same time the navigation skill could have multiple end points which lead to successful manipulation. We operationalize these ideas by implementing mobile manipulation skills rather than stationary ones and training a navigation skill trained with region goal instead of point goal. We evaluate our multi-skill mobile manipulation method M3 on 3 challenging long-horizon mobile manipulation tasks in the Home Assistant Benchmark (HAB), and show superior performance as compared to the baselines.",Oral 2 Track 4: Reinforcement Learning,https://openreview.net/pdf?id=Z3IClM_bzvP,
"['Ian Gemp', 'Charlie Chen', 'Brian McWilliams']",ICLR,The Symmetric Generalized Eigenvalue Problem as a Nash Equilibrium,https://iclr.cc/virtual/2023/oral/12610,2023," The symmetric generalized eigenvalue problem (SGEP) is a fundamental concept in numerical linear algebra. It captures the solution of many classical machine learning problems such as canonical correlation analysis, independent components analysis, partial least squares, linear discriminant analysis, principal components and others. Despite this, most general solvers are prohibitively expensive when dealing with *streaming data sets* (i.e., minibatches) and research has instead concentrated on finding efficient solutions to specific problem instances. In this work, we develop a game-theoretic formulation of the top-$k$ SGEP whose Nash equilibrium is the set of generalized eigenvectors. We also present a parallelizable algorithm with guaranteed asymptotic convergence to the Nash. Current state-of-the-art methods require $\mathcal{O}(d^2k)$ runtime complexity per iteration which is prohibitively expensive when the number of dimensions ($d$) is large. We show how to modify this parallel approach to achieve $\mathcal{O}(dk)$ runtime complexity. Empirically we demonstrate that this resulting algorithm is able to solve a variety of SGEP problem instances including a large-scale analysis of neural network activations.",Oral 2 Track 2: General Machine Learning,https://openreview.net/pdf?id=PEgBEB74JjB,
"['Paul F. Jaeger', 'Carsten Lüth', 'Lukas Klein', 'Till Bungert']",ICLR,A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification,https://iclr.cc/virtual/2023/oral/12528,2023," Reliable application of machine learning-based decision systems in the wild is one of the major challenges currently investigated by the field. A large portion of established approaches aims to detect erroneous predictions by means of assigning confidence scores. This confidence may be obtained by either quantifying the model's predictive uncertainty, learning explicit scoring functions, or assessing whether the input is in line with the training distribution. Curiously, while these approaches all state to address the same eventual goal of detecting failures of a classifier upon real-world application, they currently constitute largely separated research fields with individual evaluation protocols, which either exclude a substantial part of relevant methods or ignore large parts of relevant failure sources. In this work, we systematically reveal current pitfalls caused by these inconsistencies and derive requirements for a holistic and realistic evaluation of failure detection. To demonstrate the relevance of this unified perspective, we present a large-scale empirical study for the first time enabling benchmarking confidence scoring functions w.r.t all relevant methods and failure sources. The revelation of a simple softmax response baseline as the overall best performing method underlines the drastic shortcomings of current evaluation in the plethora of publicized research on confidence scoring. Code and trained models are at https://github.com/https://github.com/IML-DKFZ/fd-shifts",Oral 2 Track 6: Applications & Social Aspects of Machine Learning,https://openreview.net/pdf?id=YnkGMIh0gvX,
"['Brandon Cui', 'Andrei Lupu', 'Samuel Sokota', 'Hengyuan Hu', 'David Wu', 'Jakob Foerster']",ICLR,Adversarial Diversity in Hanabi,https://iclr.cc/virtual/2023/oral/12710,2023," Many Dec-POMDPs admit a qualitatively diverse set of ''reasonable'' joint policies, where reasonableness is indicated by symmetry equivariance, non-sabotaging behaviour and the graceful degradation of performance when paired with ad-hoc partners. Some of the work in diversity literature is concerned with generating these policies. Unfortunately, existing methods fail to produce teams of agents that are simultaneously diverse, high performing, and reasonable. In this work, we propose a novel approach, adversarial diversity (ADVERSITY), which is designed for turn-based Dec-POMDPs with public actions. ADVERSITY relies on off-belief learning to encourage reasonableness and skill, and on ''repulsive'' fictitious transitions to encourage diversity. We use this approach to generate new agents with distinct but reasonable play styles for the card game Hanabi and open-source our agents to be used for future research on (ad-hoc) coordination.",Oral 3 Track 1: Reinforcement Learning,https://openreview.net/pdf?id=uLE3WF3-H_5,
"['Roman Pogodin', 'Namrata Deka', 'Yazhe Li', 'Danica Sutherland', 'Victor Veitch', 'Arthur Gretton']",ICLR,Efficient Conditionally Invariant Representation Learning,https://iclr.cc/virtual/2023/oral/12711,2023," We introduce the Conditional Independence Regression CovariancE (CIRCE), a measure of conditional independence for multivariate continuous-valued variables. CIRCE applies as a regularizer in settings where we wish to learn neural features $\varphi(X)$ of data $X$ to estimate a target $Y$, while being conditionally independent of a distractor $Z$ given $Y$. Both $Z$ and $Y$ are assumed to be continuous-valued but relatively low dimensional, whereas $X$ and its features may be complex and high dimensional. Relevant settings include domain-invariant learning, fairness, and causal learning. The procedure requires just a single ridge regression from $Y$ to kernelized features of $Z$, which can be done in advance. It is then only necessary to enforce independence of $\varphi(X)$ from residuals of this regression, which is possible with attractive estimation properties and consistency guarantees. By contrast, earlier measures of conditional feature dependence require multiple regressions for each step of feature learning, resulting in more severe bias and variance, and greater computational cost. When sufficiently rich features are used, we establish that CIRCE is zero if and only if $\varphi(X) \perp \!\!\! \perp Z \mid Y$. In experiments, we show superior performance to previous methods on challenging benchmarks, including learning conditionally invariant image features. Code for image data experiments is available at github.com/namratadeka/circe.",Oral 3 Track 2: Deep Learning and representational learning,https://openreview.net/pdf?id=dJruFeSRym1,
"['Alexander Korotin', 'Daniil Selikhanovych', 'Evgeny Burnaev']",ICLR,Neural Optimal Transport,https://iclr.cc/virtual/2023/oral/12644,2023," We present a novel neural-networks-based algorithm to compute optimal transport maps and plans for strong and weak transport costs. To justify the usage of neural networks, we prove that they are universal approximators of transport plans between probability distributions. We evaluate the performance of our optimal transport algorithm on toy examples and on the unpaired image-to-image translation.",Oral 2 Track 5: Generative models & Theory,https://openreview.net/pdf?id=d8CBRlWNkqH,
"['Quentin Garrido', 'Yubei Chen', 'Adrien Bardes', 'Laurent Najman', 'Yann LeCun']",ICLR,On the duality between contrastive and non-contrastive self-supervised learning,https://iclr.cc/virtual/2023/oral/12556,2023," Recent approaches in self-supervised learning of image representations can be categorized into different families of methods and, in particular, can be divided into contrastive and non-contrastive approaches. While differences between the two families have been thoroughly discussed to motivate new approaches, we focus more on the theoretical similarities between them. By designing contrastive and covariance based non-contrastive criteria that can be related algebraically and shown to be equivalent under limited assumptions, we show how close those families can be. We further study popular methods and introduce variations of them, allowing us to relate this theoretical result to current practices and show the influence (or lack thereof) of design choices on downstream performance. Motivated by our equivalence result, we investigate the low performance of SimCLR and show how it can match VICReg's with careful hyperparameter tuning, improving significantly over known baselines. We also challenge the popular assumption that non-contrastive methods need large output dimensions. Our theoretical and quantitative results suggest that the numerical gaps between contrastive and non-contrastive methods in certain regimes can be closed given better network design choices and hyperparameter tuning. The evidence shows that unifying different SOTA methods is an important direction to build a better understanding of self-supervised learning.",Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=kDEL91Dufpa,
"['Tuomas Kynkäänniemi', 'Tero Karras', 'Miika Aittala', 'Timo Aila', 'Jaakko Lehtinen']",ICLR,The Role of ImageNet Classes in Fréchet Inception Distance,https://iclr.cc/virtual/2023/oral/12577,2023," Fréchet Inception Distance (FID) is the primary metric for ranking models in data-driven generative modeling. While remarkably successful, the metric is known to sometimes disagree with human judgement. We investigate a root cause of these discrepancies, and visualize what FID ""looks at"" in generated images. We show that the feature space that FID is (typically) computed in is so close to the ImageNet classifications that aligning the histograms of Top-$N$ classifications between sets of generated and real images can reduce FID substantially — without actually improving the quality of results. Thus, we conclude that FID is prone to intentional or accidental distortions. As a practical example of an accidental distortion, we discuss a case where an ImageNet pre-trained FastGAN achieves a FID comparable to StyleGAN2, while being worse in terms of human evaluation.",Oral 3 Track 3: Generative models,https://openreview.net/pdf?id=4oXTQ6m_ws8,
"['Hyungjin Chung', 'Jeongsol Kim', 'Michael McCann', 'Marc Klasky', 'Jong Ye']",ICLR,Diffusion Posterior Sampling for General Noisy Inverse Problems,https://iclr.cc/virtual/2023/oral/12524,2023," Diffusion models have been recently studied as powerful generative inverse problem solvers, owing to their high quality reconstructions and the ease of combining existing iterative solvers. However, most works focus on solving simple linear inverse problems in noiseless settings, which significantly under-represents the complexity of real-world problems. In this work, we extend diffusion solvers to efficiently handle general noisy (non)linear inverse problems via the Laplace approximation of the posterior sampling. Interestingly, the resulting posterior sampling scheme is a blended version of diffusion sampling with the manifold constrained gradient without a strict measurement consistency projection step, yielding a more desirable generative path in noisy settings compared to the previous studies. Our method demonstrates that diffusion models can incorporate various measurement noise statistics such as Gaussian and Poisson, and also efficiently handle noisy nonlinear inverse problems such as Fourier phase retrieval and non-uniform deblurring.",Oral 2 Track 3: Generative models,https://openreview.net/pdf?id=OnD9zGAGT0k,
"['Yubei Chen', 'Zeyu Yun', 'Yi Ma', 'Bruno Olshausen', 'Yann LeCun']",ICLR,Minimalistic Unsupervised Representation Learning with the Sparse Manifold Transform,https://iclr.cc/virtual/2023/oral/12555,2023," We describe a minimalistic and interpretable method for unsupervised representation learning that does not require data augmentation, hyperparameter tuning, or other engineering designs, but nonetheless achieves performance close to the state-of-the-art (SOTA) SSL methods. Our approach leverages the sparse manifold transform, which unifies sparse coding, manifold learning, and slow feature analysis. With a one-layer deterministic (one training epoch) sparse manifold transform, it is possible to achieve $99.3\%$ KNN top-1 accuracy on MNIST, $81.1\%$ KNN top-1 accuracy on CIFAR-10, and $53.2\%$ on CIFAR-100. With simple gray-scale augmentation, the model achieves $83.2\%$ KNN top-1 accuracy on CIFAR-10 and $57\%$ on CIFAR-100. These results significantly close the gap between simplistic ``white-box'' methods and SOTA methods. We also provide visualization to illustrate how an unsupervised representation transform is formed. The proposed method is closely connected to latent-embedding self-supervised methods and can be treated as the simplest form of VICReg. Though a small performance gap remains between our simple constructive model and SOTA methods, the evidence points to this as a promising direction for achieving a principled and white-box approach to unsupervised representation learning, which has potential to significantly improve learning efficiency.",Oral 4 Track 1: Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=nN_nBVKAhhD,
"['Derek Lim', 'Joshua Robinson', 'Lingxiao Zhao', 'Tess Smidt', 'Suvrit Sra', 'Haggai Maron', 'Stefanie Jegelka']",ICLR,Sign and Basis Invariant Networks for Spectral Graph Representation Learning,https://iclr.cc/virtual/2023/oral/12634,2023," We introduce SignNet and BasisNet---new neural architectures that are invariant to two key symmetries displayed by eigenvectors: (i) sign flips, since if v is an eigenvector then so is -v; and (ii) more general basis symmetries, which occur in higher dimensional eigenspaces with infinitely many choices of basis eigenvectors. We prove that under certain conditions our networks are universal, i.e., they can approximate any continuous function of eigenvectors with the desired invariances. When used with Laplacian eigenvectors, our networks are provably more expressive than existing spectral methods on graphs; for instance, they subsume all spectral graph convolutions, certain spectral graph invariants, and previously proposed graph positional encodings as special cases. Experiments show that our networks significantly outperform existing baselines on molecular graph regression, learning expressive graph representations, and learning neural fields on triangle meshes. Our code is available at https://github.com/cptq/SignNet-BasisNet.",Oral 3 Track 5: Deep Learning and representational learning & Neuroscience and Cognitive Science,https://openreview.net/pdf?id=Q-UHqMorzil,
"['Vincent Micheli', 'Eloi Alonso', 'François Fleuret']",ICLR,Transformers are Sample-Efficient World Models,https://iclr.cc/virtual/2023/oral/12543,2023," Deep reinforcement learning agents are notoriously sample inefficient, which considerably limits their application to real-world problems. Recently, many model-based methods have been designed to address this issue, with learning in the imagination of a world model being one of the most prominent approaches. However, while virtually unlimited interaction with a simulated environment sounds appealing, the world model has to be accurate over extended periods of time. Motivated by the success of Transformers in sequence modeling tasks, we introduce IRIS, a data-efficient agent that learns in a world model composed of a discrete autoencoder and an autoregressive Transformer. With the equivalent of only two hours of gameplay in the Atari 100k benchmark, IRIS achieves a mean human normalized score of 1.046, and outperforms humans on 10 out of 26 games, setting a new state of the art for methods without lookahead search. To foster future research on Transformers and world models for sample-efficient reinforcement learning, we release our code and models at https://github.com/eloialonso/iris.",Oral 4 Track 4: Reinforcement Learning II,https://openreview.net/pdf?id=vhFu1Acb0xb,
"['Edward Hu', 'Richard Chang', 'Oleh Rybkin', 'Dinesh Jayaraman']",ICLR,Planning Goals for Exploration,https://iclr.cc/virtual/2023/oral/12567,2023," Dropped into an unknown environment, what should an agent do to quickly learn about the environment and how to accomplish diverse tasks within it? We address this question within the goal-conditioned reinforcement learning paradigm, by identifying how the agent should set its goals at training time to maximize exploration. We propose ""Planning Exploratory Goals"" (PEG), a method that sets goals for each training episode to directly optimize an intrinsic exploration reward. PEG first chooses goal commands such that the agent's goal-conditioned policy, at its current level of training, will end up in states with high exploration potential. It then launches an exploration policy starting at those promising states. To enable this direct optimization, PEG learns world models and adapts sampling-based planning algorithms to ""plan goal commands"". In challenging simulated robotics environments including a multi-legged ant robot in a maze, and a robot arm on a cluttered tabletop, PEG exploration enables more efficient and effective training of goal-conditioned policies relative to baselines and ablations. Our ant successfully navigates a long maze, and the robot arm successfully builds a stack of three blocks upon command. Website: https://sites.google.com/view/exploratory-goals",Oral 4 Track 3: Reinforcement Learning I,https://openreview.net/pdf?id=6qeBuZSo7Pr,
"['Qiaochu Jiang', 'Sean Welleck', 'Jin Zhou', 'Timothée Lacroix', 'Jiacheng Liu', 'Wenda Li', 'Mateja Jamnik', 'Guillaume Lample', 'Yuhuai Wu']",ICLR,"Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs",https://iclr.cc/virtual/2023/oral/12537,2023," The formalization of existing mathematical proofs is a notoriously difficult process. Despite decades of research on automation and proof assistants, writing formal proofs remains arduous and only accessible to a few experts. While previous studies to automate formalization focused on powerful search algorithms, no attempts were made to take advantage of available informal proofs. In this work, we introduce Draft, Sketch, and Prove (DSP), a method that maps informal proofs to formal proof sketches, and uses the sketches to guide an automated prover by directing its search to easier sub-problems. We investigate two relevant setups where informal proofs are either written by humans or generated by a language model. Our experiments and ablation studies show that large language models are able to produce well-structured formal sketches that follow the same reasoning steps as the informal proofs. Guiding an automated prover with these sketches enhances its performance from $20.9\%$ to $39.3\%$ on a collection of mathematical competition problems.",Oral 4 Track 5: Machine Learning for Sciences & Probabilistic Methods,https://openreview.net/pdf?id=SMa9EAovKMC,
['Jae Oh Woo'],ICLR,Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle,https://iclr.cc/virtual/2023/oral/12573,2023," Acquiring labeled data is challenging in many machine learning applications with limited budgets. Active learning gives a procedure to select the most informative data points and improve data efficiency by reducing the cost of labeling. The info-max learning principle maximizing mutual information such as BALD has been successful and widely adapted in various active learning applications. However, this pool-based specific objective inherently introduces a redundant selection and further requires a high computational cost for batch selection. In this paper, we design and propose a new uncertainty measure, Balanced Entropy Acquisition (BalEntAcq), which captures the information balance between the uncertainty of underlying softmax probability and the label variable. To do this, we approximate each marginal distribution by Beta distribution. Beta approximation enables us to formulate BalEntAcq as a ratio between an augmented entropy and the marginalized joint entropy. The closed-form expression of BalEntAcq facilitates parallelization by estimating two parameters in each marginal Beta distribution. BalEntAcq is a purely standalone measure without requiring any relational computations with other data points. Nevertheless, BalEntAcq captures a well-diversified selection near the decision boundary with a margin, unlike other existing uncertainty measures such as BALD, Entropy, or Mean Standard Deviation (MeanSD). Finally, we demonstrate that our balanced entropy learning principle with BalEntAcq consistently outperforms well-known linearly scalable active learning methods, including a recently proposed PowerBALD, a simple but diversified version of BALD, by showing experimental results obtained from MNIST, CIFAR-100, SVHN, and TinyImageNet datasets.",Oral 4 Track 2: Probabilistic Methods,https://openreview.net/pdf?id=ZTMuZ68B1g,
"['Sumyeong Ahn', 'Jongwoo Ko', 'Se-Young Yun']",ICLR,CUDA: Curriculum of Data Augmentation for Long-tailed Recognition,https://iclr.cc/virtual/2023/oral/12600,2023," Class imbalance problems frequently occur in real-world tasks, and conventional deep learning algorithms are well known for performance degradation on imbalanced training datasets. To mitigate this problem, many approaches have aimed to balance among given classes by re-weighting or re-sampling training samples. These re-balancing methods increase the impact of minority classes and reduce the influence of majority classes on the output of models. However, the extracted representations may be of poor quality owing to the limited number of minority samples. To handle this restriction, several methods have been developed that increase the representations of minority samples by leveraging the features of the majority samples. Despite extensive recent studies, no deep analysis has been conducted on determination of classes to be augmented and strength of augmentation has been conducted. In this study, we first investigate the correlation between the degree of augmentation and class-wise performance, and find that the proper degree of augmentation must be allocated for each class to mitigate class imbalance problems. Motivated by this finding, we propose a simple and efficient novel curriculum, which is designed to find the appropriate per-class strength of data augmentation, called CUDA: CUrriculum of Data Augmentation for long-tailed recognition. CUDA can simply be integrated into existing long-tailed recognition methods. We present the results of experiments showing that CUDA effectively achieves better generalization performance compared to the state-of-the-art method on various imbalanced datasets such as CIFAR-100-LT, ImageNet-LT, and iNaturalist 2018.",Oral 4 Track 6: Deep Learning and representational learning- Reinforcement Learning,https://openreview.net/pdf?id=RgUPdudkWlN,
"['Neel Nanda', 'Lawrence Chan', 'Tom Lieberum', 'Jess Smith', 'Jacob Steinhardt']",ICLR,Progress measures for grokking via mechanistic interpretability,https://iclr.cc/virtual/2023/oral/12572,2023," Neural networks often exhibit emergent behavior in which qualitatively new capabilities that arise from scaling up the number of parameters, training data, or even the number of steps. One approach to understanding emergence is to find the continuous \textit{progress measures} that underlie the seemingly discontinuous qualitative changes. In this work, we argue that progress measures can be found via mechanistic interpretability---that is, by reverse engineering learned models into components and measuring the progress of each component over the course of training. As a case study, we study small transformers trained on a modular arithmetic tasks with emergent grokking behavior. We fully reverse engineer the algorithm learned by these networks, which uses discrete fourier transforms and trigonometric identities to convert addition to rotation about a circle. After confirming the algorithm via ablation, we then use our understanding of the algorithm to define progress measures that precede the grokking phase transition on this task. We see our result as demonstrating both that it is possible to fully reverse engineer trained networks, and that doing so can be invaluable to understanding their training dynamics.",Oral 5 Track 1: Unsupervised and Self-supervised learning & Social Aspects of Machine Learning-,https://openreview.net/pdf?id=9XFSbDPmdW,
"['Alexander Tyurin', 'Peter Richtarik']",ICLR,DASHA: Distributed Nonconvex Optimization with Communication Compression and Optimal Oracle Complexity,https://iclr.cc/virtual/2023/oral/12569,2023," We develop and analyze  DASHA: a new family of methods for nonconvex distributed optimization problems. When the local functions at the nodes have a finite-sum or an expectation form, our new methods, DASHA-PAGE, DASHA-MVR and DASHA-SYNC-MVR, improve the theoretical oracle and communication complexity of the previous state-of-the-art method MARINA by Gorbunov et al. (2020). In particular, to achieve an $\varepsilon$-stationary point, and considering the random sparsifier Rand$K$ as an example, our methods compute the optimal number of gradients $\mathcal{O}\left(\frac{\sqrt{m}}{\varepsilon\sqrt{n}}\right)$ and $\mathcal{O}\left(\frac{\sigma}{\varepsilon^{3/2}n}\right)$ in finite-sum and expectation form cases, respectively, while maintaining the SOTA communication complexity $\mathcal{O}\left(\frac{d}{\varepsilon \sqrt{n}}\right)$. Furthermore, unlike MARINA, the new methods DASHA, DASHA-PAGE and DASHA-MVR send compressed vectors only, which makes them more practical for federated learning. We extend our results to the case when the functions satisfy the Polyak-Lojasiewicz condition. Finally, our theory is corroborated in practice: we see a significant improvement in experiments with nonconvex classification and training of deep learning models.",Oral 5 Track 2: Optimization,https://openreview.net/pdf?id=VA1YpcNr7ul,
"['Dan Fu', 'Tri Dao', 'Khaled Saab', 'Armin Thomas', 'Atri Rudra', 'Christopher Re']",ICLR,Hungry Hungry Hippos: Towards Language Modeling with State Space Models,https://iclr.cc/virtual/2023/oral/12526,2023," State space models (SSMs) have demonstrated state-of-the-art sequence modeling performance in some modalities, but underperform attention in language modeling. Moreover, despite scaling nearly linearly in sequence length instead of quadratically, SSMs are still slower than Transformers due to poor hardware utilization. In this paper, we make progress on understanding the expressivity gap between SSMs and attention in language modeling, and on reducing the hardware barrier between SSMs and attention. First, we use synthetic language modeling tasks to understand the gap between SSMs and attention. We find that existing SSMs struggle with two capabilities: recalling earlier tokens in the sequence and comparing tokens across the sequence. To understand the impact on language modeling, we propose a new SSM layer, H3, that is explicitly designed for these abilities. H3 matches attention on the synthetic languages and comes within 0.4 PPL of Transformers on OpenWebText. Furthermore, a hybrid 125M-parameter H3-attention model that retains two attention layers surprisingly outperforms Transformers on OpenWebText by 1.0 PPL. Next, to improve the efficiency of training SSMs on modern hardware, we propose FlashConv. FlashConv uses a fused block FFT algorithm to improve efficiency on sequences up to 8K, and introduces a novel state passing algorithm that exploits the recurrent properties of SSMs to scale to longer sequences. FlashConv yields 2$\times$ speedup on the long-range arena benchmark and allows hybrid language models to generate text 2.4$\times$ faster than Transformers. Using FlashConv, we scale hybrid H3-attention language models up to 2.7B parameters on the Pile and find promising initial results, achieving lower perplexity than Transformers and outperforming Transformers in zero- and few-shot learning on a majority of tasks in the SuperGLUE benchmark.",Oral 5 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=COZDy0WYGg,
"['Anand Subramoney', 'Khaleelulla Khan Nazeer', 'Mark Schoene', 'Christian Mayr', 'David Kappel']",ICLR,Efficient recurrent architectures through activity sparsity and sparse back-propagation through time,https://iclr.cc/virtual/2023/oral/12578,2023," Recurrent neural networks (RNNs) are well suited for solving sequence tasks in resource-constrained systems due to their expressivity and  low computational requirements. However, there is still a need to bridge the gap between what RNNs are capable of in terms of efficiency and performance and real-world application requirements. The memory and computational requirements arising from propagating the activations of all the neurons at every time step to every connected neuron, together with the sequential dependence of activations, contribute to the inefficiency of training and using RNNs. We propose a solution inspired by biological neuron dynamics that makes the communication between RNN units sparse and discrete. This makes the backward pass with backpropagation through time (BPTT) computationally sparse and efficient as well. We base our model on the gated recurrent unit (GRU), extending it with units that emit discrete events for communication triggered by a threshold so that no information is communicated to other units in the absence of events.  We show theoretically that the communication between units, and hence the computation required for both the forward and backward passes, scales with the number of events in the network. Our model achieves efficiency without compromising task performance, demonstrating competitive performance compared to state-of-the-art recurrent network models in real-world tasks, including language modeling. The dynamic activity sparsity mechanism also makes our model well suited for novel energy-efficient neuromorphic hardware. Code is available at https://github.com/KhaleelKhan/EvNN/.",Oral 5 Track 5: Deep Learning and representational learning & Reinforcement Learning,https://openreview.net/pdf?id=lJdOlWg8td,
"['Andy Zeng', 'Maria Attarian', 'brian ichter', 'Krzysztof Choromanski', 'Adrian Wong', 'Stefan Welker', 'Federico Tombari', 'Aveek Purohit', 'Michael Ryoo', 'Vikas Sindhwani', 'Johnny Lee', 'Vincent Vanhoucke', 'Pete Florence']",ICLR,Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language,https://iclr.cc/virtual/2023/oral/12574,2023," We investigate how multimodal prompt engineering can use language as the intermediate representation to combine complementary knowledge from different pretrained (potentially multimodal) language models for a variety of tasks. This approach is both distinct from and complementary to the dominant paradigm of joint multimodal training. It also recalls a traditional systems-building view as in classical NLP pipelines, but with prompting large pretrained multimodal models. We refer to these as Socratic Models (SMs): a modular class of systems in which multiple pretrained models may be composed zero-shot via multimodal-informed prompting to capture new multimodal capabilities, without additional finetuning. We show that these systems provide competitive state-of-the-art performance for zero-shot image captioning and video-to-text retrieval, and also enable new applications such as (i) answering free-form questions about egocentric video, (ii) engaging in multimodal assistive dialogue with people (e.g., for cooking recipes), and (iii) robot perception and planning. We hope this work provides (a) results for stronger zero-shot baseline performance with analysis also highlighting their limitations, (b) new perspectives for building multimodal systems powered by large pretrained models, and (c) practical application advantages in certain regimes limited by data scarcity, training compute, or model access.",Oral 5 Track 4: Applications & Optimization,https://openreview.net/pdf?id=G2Q2Mh3avow,
"['Zhoujun Cheng', 'Tianbao Xie', 'Peng Shi', 'Chengzu Li', 'Rahul Nadkarni', 'Yushi Hu', 'Caiming Xiong', 'Dragomir Radev', 'Mari Ostendorf', 'Luke Zettlemoyer', 'Noah Smith', 'Tao Yu']",ICLR,Binding Language Models in Symbolic Languages,https://iclr.cc/virtual/2023/oral/12617,2023," Though end-to-end neural approaches have recently been dominating NLP tasks in both performance and ease-of-use, they lack interpretability and robustness. We propose Binder, a training-free neural-symbolic framework that maps the task input to a program, which (1) allows binding a unified API of language model (LM) functionalities to a programming language (e.g., SQL, Python) to extend its grammar coverage and thus tackle more diverse questions, (2) adopts an LM as both the program parser and the underlying model called by the API during execution, and (3) requires only a few in-context exemplar annotations. Specifically, we employ GPT-3 Codex as the LM. In the parsing stage, with only a few in-context exemplars, Codex is able to identify the part of the task input that cannot be answerable by the original programming language, correctly generate API calls to prompt Codex to solve the unanswerable part, and identify where to place the API calls while being compatible with the original grammar. In the execution stage, Codex can perform versatile functionalities (e.g., commonsense QA, information extraction) given proper prompts in the API calls. Binder achieves state-of-the-art results on WikiTableQuestions and TabFact datasets, with explicit output programs that benefit human debugging. Note that previous best systems are all finetuned on tens of thousands of task-specific samples, while Binder only uses dozens of annotations as in-context exemplars without any training. Our code is available at anonymized.",Oral 6 Track 4: Applications & Social Aspects of Machine Learning & General Machine Learning,https://openreview.net/pdf?id=lH1PV42cbF,
"['Matteo Pagliardini', 'Martin Jaggi', 'François Fleuret', 'Sai Karimireddy']",ICLR,Agree to Disagree: Diversity through Disagreement for Better Transferability,https://iclr.cc/virtual/2023/oral/12547,2023," Gradient-based learning algorithms have an implicit \emph{simplicity bias} which in effect can limit the diversity of predictors being sampled by the learning procedure. This behavior can hinder the transferability of trained models by (i) favoring the learning of simpler but spurious features --- present in the training data but absent from the test data --- and (ii) by only leveraging a small subset of predictive features.  Such an effect is especially magnified when the test distribution does not exactly match the train distribution---referred to as the Out of Distribution (OOD) generalization problem. However, given only the training data, it is not always possible to apriori assess if a given feature is spurious or transferable. Instead, we advocate for learning an ensemble of models which capture a diverse set of predictive features. Towards this, we propose a new algorithm D-BAT (Diversity-By-disAgreement Training), which enforces agreement among the models on the training data, but disagreement on the OOD data. We show how D-BAT naturally emerges from the notion of generalized discrepancy, as well as demonstrate in multiple experiments how the proposed method can mitigate shortcut-learning, enhance uncertainty and OOD detection, as well as improve transferability.",Oral 6 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=K7CbYQbyYhY,
"['Lingxiao Huang', 'Shaofeng Jiang', 'Jianing Lou', 'Xuan Wu']",ICLR,Near-optimal Coresets for Robust Clustering,https://iclr.cc/virtual/2023/oral/12650,2023," We consider robust clustering problems in $\mathbb{R}^d$, specifically $k$-clustering problems (e.g., $k$-Median and $k$-Means) with $m$ \emph{outliers}, where the cost for a given center set $C \subset \mathbb{R}^d$ aggregates the distances from $C$ to all but the furthest $m$ data points, instead of all points as in classical clustering. We focus on the $\epsilon$-coreset for robust clustering, a small proxy of the dataset that preserves the clustering cost within $\epsilon$-relative error for all center sets. Our main result is an $\epsilon$-coreset of size $O(m + \mathrm{poly}(k \epsilon^{-1}))$ that can be constructed in near-linear time. This significantly improves previous results, which either suffers an exponential dependence on $(m + k)$ [Feldman and Schulman, SODA'12], or has a weaker bi-criteria guarantee [Huang et al., FOCS'18]. Furthermore, we show this dependence in $m$ is nearly-optimal, and the fact that it is isolated from other factors may be crucial for dealing with large number of outliers. We construct our coresets by adapting to the outlier setting a recent framework [Braverman et al., FOCS'22] which was designed for capacity-constrained clustering, overcoming a new challenge that the participating terms in the cost, particularly the excluded $m$ outlier points, are dependent on the center set $C$. We validate our coresets on various datasets, and we observe a superior size-accuracy tradeoff compared with popular baselines including uniform sampling and sensitivity sampling. We also achieve a significant speedup of existing approximation algorithms for robust clustering using our coresets.",Oral 6 Track 1: Theory,https://openreview.net/pdf?id=Nc1ZkRW8Vde,
"['Siwei Chen', 'Yiqing Xu', 'Cunjun Yu', 'Linfeng Li', 'Xiao Ma', 'Zhongwen Xu', 'David Hsu']",ICLR,DaxBench: Benchmarking Deformable Object Manipulation with Differentiable Physics,https://iclr.cc/virtual/2023/oral/12570,2023," Deformable object manipulation (DOM) is a long-standing challenge in robotics and has attracted significant interest recently. This paper presents DaXBench, a differentiable simulation framework for DOM. While existing work often focuses on a specific type of deformable objects, DaXBench supports fluid, rope, cloth ...; it provides a general-purpose benchmark to evaluate widely different DOM methods, including planning, imitation learning, and reinforcement learning. DaXBench combines recent advances in deformable object simulation with JAX, a high-performance computational framework. All DOM tasks in DaXBench are wrapped with the OpenAI Gym API for easy integration with DOM algorithms. We hope that DaXBench provides to the research community a comprehensive, standardized benchmark and a valuable tool to support the development and evaluation of new DOM methods. The code and video are available online.",Oral 6 Track 2: Infrastructure & Social Aspects of Machine Learning,https://openreview.net/pdf?id=1NAzMofMnWl,
"['Phillip Rust', 'Jonas F. Lotz', 'Emanuele Bugliarello', 'Elizabeth Salesky', 'Miryam de Lhoneux', 'Desmond Elliott']",ICLR,Language Modelling with Pixels,https://iclr.cc/virtual/2023/oral/12679,2023," Language models are defined over a finite set of inputs, which creates a vocabulary bottleneck when we attempt to scale the number of supported languages. Tackling this bottleneck results in a trade-off between what can be represented in the embedding matrix and computational issues in the output layer. This paper introduces PIXEL, the Pixel-based Encoder of Language, which suffers from neither of these issues. PIXEL is a pretrained language model that renders text as images, making it possible to transfer representations across languages based on orthographic similarity or the co-activation of pixels. PIXEL is trained to reconstruct the pixels of masked patches instead of predicting a distribution over tokens. We pretrain the 86M parameter PIXEL model on the same English data as BERT and evaluate on syntactic and semantic tasks in typologically diverse languages, including various non-Latin scripts. We find that PIXEL substantially outperforms BERT on syntactic and semantic processing tasks on scripts that are not found in the pretraining data, but PIXEL is slightly weaker than BERT when working with Latin scripts. Furthermore, we find that PIXEL is more robust than BERT to orthographic attacks and linguistic code-switching, further confirming the benefits of modelling language with pixels.",Oral 6 Track 5: Applications- & Deep Learning and representational learning,https://openreview.net/pdf?id=FkSp8VW8RjH,
"['Mononito Goswami', 'Cristian Challu', 'Laurent Callot', 'Lenon Minorics', 'Andrey Kan']",ICLR,Unsupervised Model Selection for Time Series Anomaly Detection,https://iclr.cc/virtual/2023/oral/12666,2023," Anomaly detection in time-series has a wide range of practical applications. While numerous anomaly detection methods have been proposed in the literature, a recent survey concluded that no single method is the most accurate across various datasets. To make matters worse, anomaly labels are scarce and rarely available in practice. The practical problem of selecting the most accurate model for a given dataset without labels has received little attention in the literature. This paper answers this question \textit{i.e.} Given an unlabeled dataset and a set of candidate anomaly detectors, how can we select the most accurate model? To this end, we identify three classes of surrogate (unsupervised) metrics, namely, \textit{prediction error}, \textit{model centrality}, and \textit{performance on injected synthetic anomalies}, and show that some metrics are highly correlated with standard supervised anomaly detection performance metrics such as the $F_1$ score, but to varying degrees. We formulate metric combination with multiple imperfect surrogate metrics as a robust rank aggregation problem. We then provide theoretical justification behind the proposed approach. Large-scale experiments on multiple real-world datasets demonstrate that our proposed unsupervised approach is as effective as selecting the most accurate model based on partially labeled data.",Oral 6 Track 6: Deep Learning,https://openreview.net/pdf?id=gOZ_pKANaPW,
"['Ekin Akyürek', 'Dale Schuurmans', 'Jacob Andreas', 'Tengyu Ma', 'Denny Zhou']",ICLR,What learning algorithm is in-context learning? Investigations with linear models,https://iclr.cc/virtual/2023/oral/12597,2023," Neural sequence models, especially transformers, exhibit a remarkable capacity for in-context learning. They can construct new predictors from sequences of labeled examples $(x, f(x))$ presented in the input without further parameter updates. We investigate the hypothesis that transformer-based in-context learners implement standard learning algorithms implicitly, by encoding context-specific parametric models in their hidden representations, and updating these implicit models as new examples appear in the context. Using linear regression as a model problem, we offer three sources of evidence for this hypothesis. First, we prove by construction that transformers can implement learning algorithms for linear models based on gradient descent and closed-form computation of regression parameters. Second, we show that trained in-context learners closely match the predictors computed by gradient descent, ridge regression, and exact least-squares regression, transitioning between different predictors as transformer depth and dataset noise vary. Third, we present preliminary evidence that in-context learners share algorithmic features with these predictors: learners' late layers encode weight vectors and moment matrices.  These results suggest that in-context learning is understandable in algorithmic terms, and that (at least in the linear case) learners may work by rediscovering standard estimation algorithms.",Oral 6 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=K7CbYQbyYhY,
"['Noah Hollmann', 'Samuel Müller', 'Katharina Eggensperger', 'Frank Hutter']",ICLR,TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second,https://iclr.cc/virtual/2023/oral/12541,2023," We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods.TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass.TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior.This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures.On the $18$ datasets in the OpenML-CC18 suite that contain up to 1000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoML systems with up to $230\times$ speedup.This increases to a $5\,700\times$ speedup when using a GPU. We also validate these results on an additional 67 small numerical datasets from OpenML.We provide all our code, the trained TabPFN, an interactive browser demo and a Colab notebook at https://github.com/automl/TabPFN.",Oral 1 Track 1: Deep Learning and representational learning I,https://openreview.net/pdf?id=cp5PvcI6w8_,
"['Florian Eddie Dorner', 'Momchil Peychev', 'Nikola Konstantinov', 'Naman Goel', 'Elliott Ash', 'Martin Vechev']",ICLR,Human-Guided Fair Classification for Natural Language Processing,https://iclr.cc/virtual/2023/oral/12678,2023," Text classifiers have promising applications in high-stake tasks such as resume screening and content moderation. These classifiers must be fair and avoid discriminatory decisions by being invariant to perturbations of sensitive attributes such as gender or ethnicity. However, there is a gap between human intuition about these perturbations and the formal similarity specifications capturing them. While existing research has started to address this gap, current methods are based on hardcoded word replacements, resulting in specifications with limited expressivity or ones that fail to fully align with human intuition (e.g., in cases of asymmetric counterfactuals). This work proposes novel methods for bridging this gap by discovering expressive and intuitive individual fairness specifications. We show how to leverage unsupervised style transfer and GPT-3's zero-shot capabilities to automatically generate expressive candidate pairs of semantically similar sentences that differ along sensitive attributes. We then validate the generated pairs via an extensive crowdsourcing study, which confirms that a lot of these pairs align with human intuition about fairness in the context of toxicity classification. Finally, we show how limited amounts of human feedback can be leveraged to learn a similarity specification that can be used to train downstream fairness-aware models.",Oral 1 Track 4: Social Aspects of Machine Learning,https://openreview.net/pdf?id=N_g8TT9Cy7f,
"['Zhong Yi Wan', 'Leonardo Zepeda-Nunez', 'Anudhyan Boral', 'Fei Sha']",ICLR,"Evolve Smoothly, Fit Consistently: Learning Smooth Latent Dynamics For Advection-Dominated Systems",https://iclr.cc/virtual/2023/oral/12643,2023," We present a data-driven, space-time continuous framework to learn surrogate models for complex physical systems described by advection-dominated partial differential equations. Those systems have slow-decaying Kolmogorov n-width that hinders standard methods, including reduced order modeling, from producing high-fidelity simulations at low cost. In this work, we construct hypernetwork-based latent dynamical models directly on the parameter space of a compact representation network. We leverage the expressive power of the network and a specially designed consistency-inducing regularization to obtain latent trajectories that are both low-dimensional and smooth. These properties render our surrogate models highly efficient at inference time. We show the efficacy of our framework by learning models that generate accurate multi-step rollout predictions at much faster inference speed compared to competitors, for several challenging examples.",Oral 1 Track 2: Machine Learning for Sciences,https://openreview.net/pdf?id=Z4s73sJYQM,
"['Felix Chalumeau', 'Raphael Boige', 'Bryan Lim', 'Valentin Macé', 'Maxime Allard', 'Arthur Flajolet', 'Antoine Cully', 'Thomas PIERROT']",ICLR,Neuroevolution is a Competitive Alternative to Reinforcement Learning for Skill Discovery,https://iclr.cc/virtual/2023/oral/12705,2023," Deep Reinforcement Learning (RL) has emerged as a powerful paradigm for training neural policies to solve complex control tasks. However, these policies tend to be overfit to the exact specifications of the task and environment they were trained on, and thus do not perform well when conditions deviate slightly or when composed hierarchically to solve even more complex tasks. Recent work has shown that training a mixture of policies, as opposed to a single one, that are driven to explore different regions of the state-action space can address this shortcoming by generating a diverse set of behaviors, referred to as skills, that can be collectively used to great effect in adaptation tasks or for hierarchical planning. This is typically realized by including a diversity term - often derived from information theory - in the objective function optimized by RL. However these approaches often require careful hyperparameter tuning to be effective. In this work, we demonstrate that less widely-used neuroevolution methods, specifically Quality Diversity (QD), are a competitive alternative to information-theory-augmented RL for skill discovery. Through an extensive empirical evaluation comparing eight state-of-the-art algorithms (four flagship algorithms from each line of work) on the basis of (i) metrics directly evaluating the skills' diversity, (ii) the skills' performance on adaptation tasks, and (iii) the skills' performance when used as primitives for hierarchical planning; QD methods are found to provide equal, and sometimes improved, performance whilst being less sensitive to hyperparameters and more scalable. As no single method is found to provide near-optimal performance across all environments, there is a rich scope for further research which we support by proposing future directions and providing optimized open-source implementations.",Oral 1 Track 3: Neuroscience and Cognitive Science & General Machine Learning,https://openreview.net/pdf?id=6BHlZgyPOZY,
"['Chenjun Xiao', 'Han Wang', 'Yangchen Pan', 'Adam White', 'Martha White']",ICLR,The In-Sample Softmax for Offline Reinforcement Learning,https://iclr.cc/virtual/2023/oral/12538,2023," Reinforcement learning (RL) agents can leverage batches of previously collected data to extract a reasonable control policy. An emerging issue in this offline RL setting, however, is that the bootstrapping update underlying many of our methods suffers from insufficient action-coverage: standard max operator may select a maximal action that has not been seen in the dataset. Bootstrapping from these inaccurate values can lead to overestimation and even divergence. There are a growing number of methods that attempt to approximate an in-sample max, that only uses actions well-covered by the dataset. We highlight a simple fact: it is more straightforward to approximate an in-sample softmax using only actions in the dataset. We show that policy iteration based on the in-sample softmax converges, and that for decreasing temperatures it approaches the in-sample max. We derive an In-Sample Actor-Critic (AC), using this in-sample softmax, and show that it is consistently better or comparable to existing offline RL methods, and is also well-suited to fine-tuning. We release the code at github.com/hwang-ua/inac_pytorch.",Oral 1 Track 5: Reinforcement Learning,https://openreview.net/pdf?id=u-RuvyDYqCM,
"['Jezabel R. Garcia', 'Federica Freddi', 'Stathi Fotiadis', 'Maolin Li', 'Sattar Vakili', 'Alberto Bernacchia', 'Guillaume Hennequin']",ICLR,Fisher-Legendre (FishLeg) optimization of deep neural networks,https://iclr.cc/virtual/2023/oral/12665,2023," Incorporating second-order gradient information (curvature) into optimization can dramatically reduce the number of iterations required to train machine learning models. In natural gradient descent, such information comes from the Fisher information matrix which yields a number of desirable properties. As exact natural gradient updates are intractable for large models, successful methods such as KFAC and sequels approximate the Fisher in a structured form that can easily be inverted. However, this requires model/layer-specific tensor algebra and certain approximations that are often difficult to justify. Here, we use ideas from Legendre-Fenchel duality to learn a direct and efficiently evaluated model for the product of the inverse Fisher with any vector, in an online manner, leading to natural gradient steps that get progressively more accurate over time despite noisy gradients. We prove that the resulting “Fisher-Legendre” (FishLeg) optimizer converges to a (global) minimum of non-convex functions satisfying the PL condition, which applies in particular to deep linear networks. On standard auto-encoder benchmarks, we show empirically that FishLeg outperforms standard first-order optimization methods, and performs on par with or better than other second-order methods, especially when using small batches. Thanks to its generality, we expect our approach to facilitate the handling of a variety  neural network layers in future work.",Oral 1 Track 6: Deep Learning and representational learning II,https://openreview.net/pdf?id=c9lAOPvQHS,
"['Rajkumar Ramamurthy', 'Prithviraj Ammanabrolu', 'Kianté Brantley', 'Jack Hessel', 'Rafet Sifa', 'Christian Bauckhage', 'Hannaneh Hajishirzi', 'Yejin Choi']",ICLR,"Is Reinforcement Learning (Not) for Natural Language Processing: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization",https://iclr.cc/virtual/2023/oral/12652,2023," We tackle the problem of aligning pre-trained large language models (LMs) with human preferences. If we view text generation as a sequential decision-making problem, reinforcement learning (RL) appears to be a natural conceptual framework. However, using RL for LM-based generation faces empirical challenges, including training instability due to the combinatorial action space, as well as a lack of open-source libraries and benchmarks customized for LM alignment. Thus, a question rises in the research community: is RL a practical paradigm for NLP?To help answer this, we first introduce an open-source modular library, $RL4LMs$ (Reinforcement Learning for Language Models), for optimizing language generators with RL. The library consists of on-policy RL algorithms that can be used to train any encoder or encoder-decoder LM in the HuggingFace library (Wolf et al. 2020) with an arbitrary reward function. Next, we present the $GRUE$ (General Reinforced-language Understanding Evaluation) benchmark, a set of 6 language generation tasks which are supervised not by target strings, but by reward functions which capture automated measures of human preference.GRUE is the first leaderboard-style evaluation of RL algorithms for NLP tasks. Finally, we introduce an easy-to-use, performant RL algorithm, $NLPO$ (Natural Language Policy Optimization)} that learns to effectively reduce the combinatorial action space in language generation. We show 1) that RL techniques are generally better than supervised methods at aligning LMs to human preferences; and 2) that NLPO exhibits greater stability and performance than previous policy gradient methods (e.g., PPO (Schulman et al. 2017)), based on both automatic and human evaluations.",Oral 2 Track 1: Applications,https://openreview.net/pdf?id=8aHzds2uUyB,
"['Dian Wang', 'Jung Yeon Park', 'Neel Sortur', 'Lawson Wong', 'Robin Walters', 'Robert Platt']",ICLR,The Surprising Effectiveness of Equivariant Models in Domains with Latent Symmetry,https://iclr.cc/virtual/2023/oral/12585,2023," Extensive work has demonstrated that equivariant neural networks can significantly improve sample efficiency and generalization by enforcing an inductive bias in the network architecture. These applications typically assume that the domain symmetry is fully described by explicit transformations of the model inputs and outputs. However, many real-life applications contain only latent or partial symmetries which cannot be easily described by simple transformations of the input. In these cases, it is necessary to learn symmetry in the environment instead of imposing it mathematically on the network architecture. We discover, surprisingly, that imposing equivariance constraints that do not exactly match the domain symmetry is very helpful in learning the true symmetry in the environment. We differentiate between extrinsic and incorrect symmetry constraints and show that while imposing incorrect symmetry can impede the model's performance, imposing extrinsic symmetry can actually improve performance. We demonstrate that an equivariant model can significantly outperform non-equivariant methods on domains with latent symmetries both in supervised learning and in reinforcement learning for robotic manipulation and control problems.",Oral 2 Track 4: Reinforcement Learning,https://openreview.net/pdf?id=P4MUGRM4Acu,
"['Kuo-Hao Zeng', 'Luca Weihs', 'Roozbeh Mottaghi', 'Ali Farhadi']",ICLR,Moving Forward by Moving Backward: Embedding Action Impact over Action Semantics,https://iclr.cc/virtual/2023/oral/12721,2023," A common assumption when training embodied agents is that the impact of taking an action is stable; for instance, executing the ``move ahead'' action will always move the agent forward by a fixed distance, perhaps with some small amount of actuator-induced noise. This assumption is limiting; an agent may encounter settings that dramatically alter the impact of actions: a move ahead action on a wet floor may send the agent twice as far as it expects and using the same action with a broken wheel might transform the expected translation into a rotation. Instead of relying that the impact of an action stably reflects its pre-defined semantic meaning, we propose to model the impact of actions on-the-fly using latent embeddings. By combining these latent action embeddings with a novel, transformer-based, policy head, we design an Action Adaptive Policy (AAP). We evaluate our AAP on two challenging visual navigation tasks in the AI2-THOR and Habitat environments and show that our AAP is highly performant even when faced, at inference-time, with missing actions and, previously unseen, perturbed action spaces. Moreover, we observe significant improvement in robustness against these actions when evaluating in real-world scenarios.",Oral 3 Track 1: Reinforcement Learning,https://openreview.net/pdf?id=vmjctNUSWI,
"['Muhammad Shoaib Ahmed Siddiqui', 'Nitarshan Rajkumar', 'Tegan Maharaj', 'David Krueger', 'Sara Hooker']",ICLR,Metadata Archaeology: Unearthing Data Subsets by Leveraging Training Dynamics,https://iclr.cc/virtual/2023/oral/12633,2023," Modern machine learning research relies on relatively few carefully curated datasets. Even in these datasets, and typically in `untidy' or raw data, practitioners are faced with significant issues of data quality and diversity which can be prohibitively labor intensive to address. Existing methods for dealing with these challenges tend to make strong assumptions about the particular issues at play, and often require a priori knowledge or metadata such as domain labels. Our work is orthogonal to these methods: we instead focus on providing a unified and efficient framework for Metadata Archaeology -- uncovering and inferring metadata of examples in a dataset. We curate different subsets of data that might exist in a dataset (e.g. mislabeled, atypical, or out-of-distribution examples) using simple transformations, and leverage differences in learning dynamics between these probe suites to infer metadata of interest. Our method is on par with far more sophisticated mitigation methods across different tasks: identifying and correcting mislabeled examples, classifying minority-group samples, prioritizing points relevant for training and enabling scalable human auditing of relevant examples.",Oral 2 Track 2: General Machine Learning,https://openreview.net/pdf?id=PvLnIaJbt9,
['Arthur Jacot'],ICLR,Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear Functions,https://iclr.cc/virtual/2023/oral/12530,2023," We show that the representation cost of fully connected neural networks with homogeneous nonlinearities - which describes the implicit bias in function space of networks with $L_2$-regularization or with losses such as the cross-entropy - converges as the depth of the network goes to infinity to a notion of rank over nonlinear functions. We then inquire under which conditions the global minima of the loss recover the `true' rank of the data: we show that for too large depths the global minimum will be approximately rank 1 (underestimating the rank); we then argue that there is a range of depths which grows with the number of datapoints where the true rank is recovered. Finally, we discuss the effect of the rank of a classifier on the topology of the resulting class boundaries and show that autoencoders with optimal nonlinear rank are naturally denoising.",Oral 2 Track 5: Generative models & Theory,https://openreview.net/pdf?id=6iDHce-0B-a,
"['Huiwon Jang', 'Hankook Lee', 'Jinwoo Shin']",ICLR,Unsupervised Meta-learning via Few-shot Pseudo-supervised Contrastive Learning,https://iclr.cc/virtual/2023/oral/12586,2023," Unsupervised meta-learning aims to learn generalizable knowledge across a distribution of tasks constructed from unlabeled data. Here, the main challenge is how to construct diverse tasks for meta-learning without label information; recent works have proposed to create, e.g., pseudo-labeling via pretrained representations or creating synthetic samples via generative models. However, such a task construction strategy is fundamentally limited due to heavy reliance on the immutable pseudo-labels during meta-learning and the quality of the representations or the generated samples. To overcome the limitations, we propose a simple yet effective unsupervised meta-learning framework, coined Pseudo-supervised Contrast (PsCo), for few-shot classification. We are inspired by the recent self-supervised learning literature; PsCo utilizes a momentum network and a queue of previous batches to improve pseudo-labeling and construct diverse tasks in a progressive manner. Our extensive experiments demonstrate that PsCo outperforms existing unsupervised meta-learning methods under various in-domain and cross-domain few-shot classification benchmarks. We also validate that PsCo is easily scalable to a large-scale benchmark, while recent prior-art meta-schemes are not.",Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=TdTGGj7fYYJ,
"['Uday Kamal', 'Saurabh Dash', 'Saibal Mukhopadhyay']",ICLR,Associative Memory Augmented Asynchronous Spatiotemporal Representation Learning for Event-based Perception,https://iclr.cc/virtual/2023/oral/12562,2023," We propose $\textit{EventFormer}$, a computationally efficient event-based representation learning framework for asynchronously processing event camera data. EventFormer treats sparse input events as a spatially unordered set and models their spatial interactions using self-attention mechanism. An associative memory-augmented recurrent module is used to correlate with the stored representation computed from past events. A memory addressing mechanism is proposed to store and retrieve the latent states only $\textit{where}$ these events occur and update them only $\textit{when}$ they occur. The representation learning shift from input space to the latent memory space resulting in reduced computation cost for processing each event. We show that EventFormer achieves 0.5$\%$ and 9$\%$ better accuracy with 30000$\times$ and 200$\times$ less computation compared to the state-of-the-art dense and event-based method, respectively, on event-based object recognition datasets.",Oral 2 Track 6: Applications & Social Aspects of Machine Learning,https://openreview.net/pdf?id=ZCStthyW-TD,
"['Xingchao Liu', 'Lemeng Wu', 'Mao Ye', 'Qiang Liu']",ICLR,Learning Diffusion Bridges on Constrained Domains,https://iclr.cc/virtual/2023/oral/12625,2023," Diffusion models have achieved promising results on generative learning recently. However, because diffusion processes are most naturally applied  on the unconstrained Euclidean space $\mathrm{R}^d$, key challenges arise for developing diffusion based models for learning data on constrained and structured domains. We present a simple and unified framework to achieve this that can be easily adopted to various types of domains, including product spaces of any type (be it bounded/unbounded, continuous/discrete, categorical/ordinal, or  their mix). In our model, the diffusion process is driven by a drift force that is a sum of two terms: one singular force designed by $Doob's~ h$-$transform$ that ensures all outcomes of the process to belong to the desirable domain, and one non-singular neural force field that is trained to make sure the outcome follows the data distribution statistically. Experiments show that our methods perform superbly on generating tabular data, images, semantic segments and 3D point clouds.",Oral 3 Track 3: Generative models,https://openreview.net/pdf?id=WH1yCa0TbB,
"['David Klee', 'Ondrej Biza', 'Robert Platt', 'Robin Walters']",ICLR,Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction,https://iclr.cc/virtual/2023/oral/12715,2023," Predicting the pose of objects from a single image is an important but difficult computer vision problem. Methods that predict a single point estimate do not predict the pose of objects with symmetries well and cannot represent uncertainty. Alternatively, some works predict a distribution over orientations in $\mathrm{SO}(3)$. However, training such models can be computation- and sample-inefficient. Instead, we propose a novel mapping of features from the image domain to the 3D rotation manifold. Our method then leverages $\mathrm{SO}(3)$ equivariant layers, which are more sample efficient, and outputs a distribution over rotations that can be sampled at arbitrary resolution. We demonstrate the effectiveness of our method at object orientation prediction, and achieve state-of-the-art performance on the popular PASCAL3D+ dataset. Moreover, we show that our method can model complex object symmetries, without any modifications to the parameters or loss function.  Code is available at \url{https://dmklee.github.io/image2sphere}.",Oral 3 Track 2: Deep Learning and representational learning,https://openreview.net/pdf?id=_2bDpAtr7PI,
"['Lucio Dery', 'Paul Michel', 'Mikhail Khodak', 'Graham Neubig', 'Ameet Talwalkar']",ICLR,AANG : Automating Auxiliary Learning,https://iclr.cc/virtual/2023/oral/12590,2023," Auxiliary objectives, supplementary learning signals that are introduced to help aid learning on data-starved or highly complex end-tasks, are commonplace in machine learning. Whilst much work has been done to formulate useful auxiliary objectives, their construction is still an art which proceeds by slow and tedious hand-design. Intuition for how and when these objectives improve end-task performance has also had limited theoretical backing. In this work, we present an approach for automatically generating a suite of auxiliary objectives. We achieve this by deconstructing existing objectives within a novel unified taxonomy, identifying connections between them, and generating new ones based on the uncovered structure. Next, we theoretically formalize widely-held intuitions about how auxiliary learning improves generalization on the end-task. This leads us to a principled and efficient algorithm for searching the space of generated objectives to find those most useful to a specified end-task.With natural language processing (NLP) as our domain of study, we demonstrate that our automated auxiliary learning pipeline leads to strong improvements over competitive baselines across continued training experiments on a pre-trained model on 5 NLP end-tasks.",Oral 4 Track 1: Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=vtVDI3w_BLL,
"['Yuelin Wang', 'Kai Yi', 'Xinliang Liu', 'Yuguang Wang', 'Shi Jin']",ICLR,ACMP: Allen-Cahn Message Passing with Attractive and Repulsive Forces for Graph Neural Networks,https://iclr.cc/virtual/2023/oral/12636,2023, Neural message passing is a basic feature extraction unit for graph-structured data considering neighboring node features in network propagation from one layer to the next. We model such process by an interacting particle system with attractive and repulsive forces and the Allen-Cahn force arising in the modeling of phase transition. The dynamics of the system is a reaction-diffusion process which can separate particles without blowing up. This induces an Allen-Cahn message passing (ACMP) for graph neural networks where the numerical iteration for the particle system solution constitutes the message passing propagation. ACMP which has a simple implementation with a neural ODE solver can propel the network depth up to one hundred of layers with theoretically proven strictly positive lower bound of the Dirichlet energy. It thus provides a deep model of GNNs circumventing the common GNN problem of oversmoothing. GNNs with ACMP achieve state of the art performance for real-world node classification tasks on both homophilic and heterophilic datasets. Codes are available at https://github.com/ykiiiiii/ACMP,Oral 3 Track 5: Deep Learning and representational learning & Neuroscience and Cognitive Science,https://openreview.net/pdf?id=4fZc_79Lrqs,
"['Jean-Baptiste Gaya', 'Thang Doan', 'Lucas Caccia', 'Laure Soulier', 'Ludovic Denoyer', 'Roberta Raileanu']",ICLR,Building a Subspace of Policies for Scalable Continual Learning,https://iclr.cc/virtual/2023/oral/12549,2023," The ability to continuously acquire new knowledge and skills is crucial for autonomous agents. Existing methods are typically based on either fixed-size models that struggle to learn a large number of diverse behaviors, or growing-size models that scale poorly with the number of tasks. In this work, we aim to strike a better balance between scalability and performance by designing a method whose size grows adaptively depending on the task sequence. We introduce Continual Subspace of Policies (CSP), a new approach that incrementally builds a subspace of policies for training a reinforcement learning agent on a sequence of tasks. The subspace's high expressivity allows CSP to perform well for many different tasks while growing more slowly than the number of tasks. Our method does not suffer from forgetting and also displays positive transfer to new tasks. CSP outperforms a number of popular baselines on a wide range of scenarios from two challenging domains, Brax (locomotion) and Continual World (robotic manipulation). Interactive visualizations of the subspace can be found at https://share.streamlit.io/continual-subspace/policies/main.",Oral 4 Track 4: Reinforcement Learning II,https://openreview.net/pdf?id=UKr0MwZM6fL,
"['Daesol Cho', 'Seungjae Lee', 'H. Kim']",ICLR,Outcome-directed Reinforcement Learning by Uncertainty \& Temporal Distance-Aware Curriculum Goal Generation,https://iclr.cc/virtual/2023/oral/12534,2023," Current reinforcement learning (RL) often suffers when solving a challenging exploration problem where the desired outcomes or high rewards are rarely observed. Even though curriculum RL, a framework that solves complex tasks by proposing a sequence of surrogate tasks, shows reasonable results, most of the previous works still have difficulty in proposing curriculum due to the absence of a mechanism for obtaining calibrated guidance to the desired outcome state without any prior domain knowledge. To alleviate it, we propose an uncertainty \& temporal distance-aware curriculum goal generation method for the outcome-directed RL via solving a bipartite matching problem. It could not only provide precisely calibrated guidance of the curriculum to the desired outcome states but also bring much better sample efficiency and geometry-agnostic curriculum goal proposal capability compared to previous curriculum RL methods. We demonstrate that our algorithm significantly outperforms these prior methods in a variety of challenging navigation tasks and robotic manipulation tasks in a quantitative and qualitative way.",Oral 4 Track 3: Reinforcement Learning I,https://openreview.net/pdf?id=v69itrHLEu,
"['Thomas Möllenhoff', 'Mohammad Emtiyaz Khan']",ICLR,SAM as an Optimal Relaxation of Bayes,https://iclr.cc/virtual/2023/oral/12576,2023," Sharpness-aware minimization (SAM) and related adversarial deep-learning methods can drastically improve generalization, but their underlying mechanisms are not yet fully understood. Here, we establish SAM as a relaxation of the Bayes objective where the expected negative-loss is replaced by the optimal convex lower bound, obtained by using the so-called Fenchel biconjugate. The connection enables a new Adam-like extension of SAM to automatically obtain reasonable uncertainty estimates, while sometimes also improving its accuracy. By connecting adversarial and Bayesian methods, our work opens a new path to robustness.",Oral 4 Track 2: Probabilistic Methods,https://openreview.net/pdf?id=k4fevFqSQcX,
"['Shutong Wu', 'Sizhe Chen', 'Cihang Xie', 'Xiaolin Huang']",ICLR,One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks,https://iclr.cc/virtual/2023/oral/12603,2023," Unlearnable examples (ULEs) aim to protect data from unauthorized usage for training DNNs. Existing work adds $\ell_\infty$-bounded perturbations to the original sample so that the trained model generalizes poorly. Such perturbations, however, are easy to eliminate by adversarial training and data augmentations. In this paper, we resolve this problem from a novel perspective by perturbing only one pixel in each image. Interestingly, such a small modification could effectively degrade model accuracy to almost an untrained counterpart. Moreover, our produced \emph{One-Pixel Shortcut (OPS)} could not be erased by adversarial training and strong augmentations. To generate OPS, we perturb in-class images at the same position to the same target value that could mostly and stably deviate from all the original images. Since such generation is only based on images, OPS needs significantly less computation cost than the previous methods using DNN generators. Based on OPS, we introduce an unlearnable dataset called CIFAR-10-S, which is indistinguishable from CIFAR-10 by humans but induces the trained model to extremely low accuracy. Even under adversarial training, a ResNet-18 trained on CIFAR-10-S has only 10.61% accuracy, compared to 83.02% by the existing error-minimizing method.",Oral 4 Track 6: Deep Learning and representational learning- Reinforcement Learning,https://openreview.net/pdf?id=p7G8t5FVn2h,
"['Jan Schuchardt', 'Tom Wollschläger', 'Aleksandar Bojchevski', 'Stephan Günnemann']",ICLR,Localized Randomized Smoothing for Collective Robustness Certification,https://iclr.cc/virtual/2023/oral/12615,2023," Models for image segmentation, node classification and many other tasks map a single input to multiple labels. By perturbing this single shared input (e.g. the image) an adversary can manipulate several predictions (e.g. misclassify several pixels). Collective robustness certification is the task of provably bounding the number of robust predictions under this threat model. The only dedicated method that goes beyond certifying each output independently is limited to strictly local models, where each prediction is associated with a small receptive field. We propose a more general collective robustness certificate for all types of models. We further show that this approach is beneficial for the larger class of softly local models, where each output is dependent on the entire input but assigns different levels of importance to different input regions (e.g. based on their proximity in the image). The certificate is based on our novel localized randomized smoothing approach, where the random perturbation strength for different input regions is proportional to their importance for the outputs. Localized smoothing Pareto-dominates existing certificates on both image segmentation and node classification tasks, simultaneously offering higher accuracy and stronger certificates.",Oral 5 Track 1: Unsupervised and Self-supervised learning & Social Aspects of Machine Learning-,https://openreview.net/pdf?id=-k7Lvk0GpBl,
"['Yi Zhou', 'Parikshit Ram', 'Theodoros Salonidis', 'Nathalie Baracaldo', 'Horst Samulowitz', 'Heiko Ludwig']",ICLR,Single-shot General Hyper-parameter Optimization for Federated Learning,https://iclr.cc/virtual/2023/oral/12583,2023," We address the problem of hyper-parameter optimization (HPO) for federated learning (FL-HPO). We introduce Federated Loss SuRface Aggregation (FLoRA), a general FL-HPO solution framework that can address use cases of tabular data and any Machine Learning (ML) model including gradient boosting training algorithms, SVMs, neural networks, among others and thereby further expands the scope of FL-HPO. FLoRA enables single-shot FL-HPO: identifying a single set of good hyper-parameters that are subsequently used in a single FL training. Thus, it enables FL-HPO solutions with minimal additional communication overhead compared to FL training without HPO. Utilizing standard smoothness assumptions, we theoretically characterize the optimality gap of FLoRA for any convex and non-convex loss functions, which explicitly accounts for the heterogeneous nature of the parties' local data distributions, a dominant characteristic of FL systems. Our empirical evaluation of FLoRA for multiple FL algorithms on seven OpenML datasets demonstrates significant model accuracy improvements over the baselines, and robustness to increasing number of parties involved in FL-HPO training.",Oral 5 Track 2: Optimization,https://openreview.net/pdf?id=3RhuF8foyPW,
"['Laurence Midgley', 'Vincent Stimper', 'Gregor Simm', 'Bernhard Schoelkopf', 'José Miguel Hernández Lobato']",ICLR,Flow Annealed Importance Sampling Bootstrap,https://iclr.cc/virtual/2023/oral/12611,2023," Normalizing flows are tractable density models that can approximate complicated target distributions, e.g. Boltzmann distributions of physical systems. However, current methods for training flows either suffer from mode-seeking behavior, use samples from the target generated beforehand by expensive MCMC methods, or use stochastic losses that have high variance. To avoid these problems, we augment flows with annealed importance sampling (AIS) and minimize the mass-covering $\alpha$-divergence with $\alpha=2$, which minimizes importance weight variance. Our method, Flow AIS Bootstrap (FAB), uses AIS to generate samples in regions where the flow is a poor approximation of the target, facilitating the discovery of new modes. We apply FAB to multimodal targets and show that we can approximate them very accurately where previous methods fail. To the best of our knowledge, we are the first to learn the Boltzmann distribution of the alanine dipeptide molecule using only the unnormalized target density, without access to samples generated via Molecular Dynamics (MD) simulations: FAB produces better results than training via maximum likelihood on MD samples while using 100 times fewer target evaluations. After reweighting the samples, we obtain unbiased histograms of dihedral angles that are almost identical to the ground truth.",Oral 4 Track 5: Machine Learning for Sciences & Probabilistic Methods,https://openreview.net/pdf?id=XCTVFJwS9LJ,
"['Guangyi Chen', 'Weiran Yao', 'Xiangchen Song', 'Xinyue Li', 'Yongming Rao', 'Kun Zhang']",ICLR,PLOT: Prompt Learning with Optimal Transport for Vision-Language Models,https://iclr.cc/virtual/2023/oral/12579,2023," With the increasing attention to large vision-language models such as CLIP, there has been a significant amount of effort dedicated to building efficient prompts. Unlike conventional methods of only learning one single prompt, we propose to learn multiple comprehensive prompts to describe diverse characteristics of categories such as intrinsic attributes or extrinsic contexts. However, directly matching each prompt to the same visual feature is problematic, as it pushes the prompts to converge to one point. To solve this problem, we propose to apply optimal transport to match the vision and text modalities. Specifically, we first model images and the categories with visual and textual feature sets. Then, we apply a two-stage optimization strategy to learn the prompts. In the inner loop, we optimize the optimal transport distance to align visual features and prompts by the Sinkhorn algorithm, while in the outer loop, we learn the prompts by this distance from the supervised data. Extensive experiments are conducted on the few-shot recognition task and the improvement demonstrates the superiority of our method. The code is available at https://github.com/CHENGY12/PLOT.",Oral 5 Track 5: Deep Learning and representational learning & Reinforcement Learning,https://openreview.net/pdf?id=zqwryBoXYnh,
"['Luca Moschella', 'Valentino Maiorca', 'Marco Fumero', 'Antonio Norelli', 'Francesco Locatello', 'Emanuele Rodolà']",ICLR,Relative representations enable zero-shot latent space communication,https://iclr.cc/virtual/2023/oral/12532,2023," Neural networks embed the geometric structure of a data manifold lying in a high-dimensional space into latent representations. Ideally, the distribution of the data points in the latent space should depend only on the task, the data, the loss, and other architecture-specific constraints. However, factors such as the random weights initialization, training hyperparameters, or other sources of randomness in the training phase may induce incoherent latent spaces that hinder any form of reuse. Nevertheless, we empirically observe that, under the same data and modeling choices, the angles between the encodings within distinct latent spaces do not change. In this work, we propose the latent similarity between each sample and a fixed set of anchors as an alternative data representation, demonstrating that it can enforce the desired invariances without any additional training. We show how neural architectures can leverage these relative representations to guarantee, in practice, invariance to latent isometries and rescalings, effectively enabling latent space communication: from zero-shot model stitching to latent space comparison between diverse settings. We extensively validate the generalization capability of our approach on different datasets, spanning various modalities (images, text, graphs), tasks (e.g., classification, reconstruction) and architectures (e.g., CNNs, GCNs, transformers).",Oral 5 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=SrC-nwieGJ,
"['Kangjie Chen', 'Xiaoxuan Lou', 'Guowen Xu', 'Jiwei Li', 'Tianwei Zhang']",ICLR,Clean-image Backdoor: Attacking Multi-label Models with Poisoned Labels Only,https://iclr.cc/virtual/2023/oral/12575,2023," Multi-label models have been widely used in various applications including image annotation and object detection. The fly in the ointment is its inherent vulnerability to backdoor attacks due to the adoption of deep learning techniques. However, all existing backdoor attacks exclusively require to modify training inputs (e.g., images), which may be impractical in real-world applications. In this paper, we aim to break this wall and propose the first clean-image backdoor attack, which only poisons the training labels without touching the training samples. Our key insight is that in a multi-label learning task, the adversary can just manipulate the annotations of training samples consisting of a specific set of classes to activate the backdoor. We design a novel trigger exploration method to find convert and effective triggers to enhance the attack performance. We also propose three target label selection strategies to achieve different goals. Experimental results indicate that our clean-image backdoor can achieve a 98% attack success rate while preserving the model's functionality on the benign inputs. Besides, the proposed clean-image backdoor can evade existing state-of-the-art defenses.",Oral 5 Track 4: Applications & Optimization,https://openreview.net/pdf?id=rFQfjDC9Mt,
"['Zhen Liu', 'Yao Feng', 'Michael J Black', 'Derek Nowrouzezahrai', 'Liam Paull', 'Weiyang Liu']",ICLR,MeshDiffusion: Score-based Generative 3D Mesh Modeling,https://iclr.cc/virtual/2023/oral/12552,2023," We consider the task of generating realistic 3D shapes, which is useful for a variety of applications such as automatic scene generation and physical simulation. Compared to other 3D representations like voxels and point clouds, meshes are more desirable in practice, because (1) they enable easy and arbitrary manipulation of shapes for relighting and simulation, and (2) they can fully leverage the power of modern graphics pipelines which are mostly optimized for meshes. Previous scalable methods for generating meshes typically rely on sub-optimal post-processing, and they tend to produce overly-smooth or noisy surfaces without fine-grained geometric details. To overcome these shortcomings, we take advantage of the graph structure of meshes and use a simple yet very effective generative modeling method to generate 3D meshes. Specifically, we represent meshes with deformable tetrahedral grids, and then train a diffusion model on this direct parameterization. We demonstrate the effectiveness of our model on multiple generative tasks.",Oral 6 Track 4: Applications & Social Aspects of Machine Learning & General Machine Learning,https://openreview.net/pdf?id=0cpM2ApF9p6,
"['Amir Hertz', 'Ron Mokady', 'Jay Tenenbaum', 'Kfir Aberman', 'Yael Pritch', 'Daniel Cohen-Or']",ICLR,Prompt-to-Prompt Image Editing with Cross-Attention Control,https://iclr.cc/virtual/2023/oral/12535,2023," Recent large-scale text-driven synthesis diffusion models have attracted much attention thanks to their remarkable capabilities of generating highly diverse images that follow given text prompts. Therefore, it is only natural to build upon these synthesis models to provide text-driven image editing capabilities. However, Editing is challenging for these generative models, since an innate property of an editing technique is to preserve some content from the original image, while in the text-based models, even a small modification of the text prompt often leads to a completely different outcome. State-of-the-art methods mitigate this by requiring the users to provide a spatial mask to localize the edit, hence, ignoring the original structure and content within the masked region. In this paper, we pursue an intuitive prompt-to-prompt editing framework, where the edits are controlled by text only. We analyze a text-conditioned model in depth and observe that the cross-attention layers are the key to controlling the relation between the spatial layout of the image to each word in the prompt. With this observation, we propose to control the attention maps along the diffusion process. Our approach enables us to monitor the synthesis process by editing the textual prompt only, paving the way to a myriad of caption-based editing applications such as localized editing by replacing a word, global editing by adding a specification, and even controlling the extent to which a word is reflected in the image. We present our results over diverse images and prompts with different text-to-image models, demonstrating high-quality synthesis and fidelity to the edited prompts.",Oral 2 Track 3: Generative models,https://openreview.net/pdf?id=_CDixzkzeyb,
"['Fivos Kalogiannis', 'Ioannis Anagnostides', 'Ioannis Panageas', 'Emmanouil-Vasileios Vlatakis-Gkaragkounis', 'Vaggos Chatziafratis', 'Stelios Stavroulakis']",ICLR,Efficiently Computing Nash Equilibria in Adversarial Team Markov Games,https://iclr.cc/virtual/2023/oral/12660,2023," Computing Nash equilibrium policies is a central problem in multi-agent reinforcement learning that has received extensive attention both in theory and in practice. However, in light of computational intractability barriers in general-sum games, provable guarantees have been thus far either limited to fully competitive or cooperative scenarios or impose strong assumptions that are difficult to meet in most practical applications.        In this work, we depart from those prior results by investigating infinite-horizon \emph{adversarial team Markov games}, a natural and well-motivated class of games in which a team of identically-interested players---in the absence of any explicit coordination or communication---is competing against an adversarial player. This setting allows for a unifying treatment of zero-sum Markov games and Markov potential games, and serves as a step to model more realistic strategic interactions that feature both competing and cooperative interests. Our main contribution is the first algorithm for computing stationary $\epsilon$-approximate Nash equilibria in adversarial team Markov games with computational complexity that is polynomial in all the natural parameters of the game, as well as $1/\epsilon$.        The proposed algorithm is based on performing independent policy gradient steps for each player in the team, in tandem with best responses from the side of the adversary; in turn, the policy for the adversary is then obtained by solving a carefully constructed linear program. Our analysis leverages non-standard techniques to establish the KKT optimality conditions for a nonlinear program with nonconvex constraints, thereby leading to a natural interpretation of the induced Lagrange multipliers.",Oral 6 Track 1: Theory,https://openreview.net/pdf?id=mjzm6btqgV,
"['Sang Choe', 'Willie Neiswanger', 'Pengtao Xie', 'Eric Xing']",ICLR,Betty: An Automatic Differentiation Library for Multilevel Optimization,https://iclr.cc/virtual/2023/oral/12635,2023," Gradient-based multilevel optimization (MLO) has gained attention as a framework for studying numerous problems, ranging from hyperparameter optimization and meta-learning to neural architecture search and reinforcement learning. However, gradients in MLO, which are obtained by composing best-response Jacobians via the chain rule, are notoriously difficult to implement and memory/compute intensive. We take an initial step towards closing this gap by introducing Betty, a software library for large-scale MLO. At its core, we devise a novel dataflow graph for MLO, which allows us to (1) develop efficient automatic differentiation for MLO that reduces the computational complexity from $\mathcal{O}(d^3)$ to $\mathcal{O}(d^2)$, (2) incorporate systems support such as mixed-precision and data-parallel training for scalability, and (3) facilitate implementation of MLO programs of arbitrary complexity while allowing a modular interface for diverse algorithmic and systems design choices. We empirically demonstrate that Betty can be used to implement an array of MLO programs, while also observing up to 11% increase in test accuracy, 14% decrease in GPU memory usage, and 20% decrease in training wall time over existing implementations on multiple benchmarks. We also showcase that Betty enables scaling MLO to models with hundreds of millions of parameters. We open-source the code at https://github.com/leopard-ai/betty.",Oral 6 Track 2: Infrastructure & Social Aspects of Machine Learning,https://openreview.net/pdf?id=LV_MeMS38Q9,
"['Daniel Barzilai', 'Amnon Geifman', 'Meirav Galun', 'Ronen Basri']",ICLR,A Kernel Perspective of Skip Connections in Convolutional Networks,https://iclr.cc/virtual/2023/oral/12602,2023," Over-parameterized residual networks (ResNets) are amongst the most successful convolutional neural architectures for image processing. Here we study their properties through their Gaussian Process and Neural Tangent kernels. We derive explicit formulas for these kernels, analyze their spectra, and provide bounds on their implied condition numbers. Our results indicate that (1) with ReLU activation, the eigenvalues of these residual kernels decay polynomially at a similar rate compared to the same kernels when skip connections are not used, thus maintaining a similar frequency bias; (2) however, residual kernels are more locally biased. Our analysis further shows that the matrices obtained by these residual kernels yield favorable condition numbers at finite depths than those obtained without the skip connections, enabling therefore faster convergence of training with gradient descent.",Oral 6 Track 6: Deep Learning,https://openreview.net/pdf?id=6H_uOfcwiVh,
"['Josua Sassen', 'Klaus Hildebrandt', 'Martin Rumpf', 'Benedikt Wirth']",ICLR,Parametrizing Product Shape Manifolds by Composite Networks,https://iclr.cc/virtual/2023/oral/12550,2023," Parametrizations of data manifolds in shape spaces can be computed using the rich toolbox of Riemannian geometry. This, however, often comes with high computational costs, which raises the question if one can learn an efficient neural network approximation. We show that this is indeed possible for shape spaces with a special product structure, namely those smoothly approximable by a direct sum of low-dimensional manifolds. Our proposed architecture leverages this structure by separately learning approximations for the low-dimensional factors and a subsequent combination. After developing the approach as a general framework, we apply it to a shape space of triangular surfaces. Here, typical examples of data manifolds are given through datasets of articulated models and can be factorized, for example, by a Sparse Principal Geodesic Analysis (SPGA). We demonstrate the effectiveness of our proposed approach with experiments on synthetic data as well as manifolds extracted from data via SPGA.",Oral 6 Track 5: Applications- & Deep Learning and representational learning,https://openreview.net/pdf?id=F_EhNDSamN,
"['Marius-Constantin Dinu', 'Markus Holzleitner', 'Maximilian Beck', 'Hoan Nguyen', 'Andrea Huber', 'Hamid Eghbalzadeh', 'Bernhard A. Moser', 'Sergei Pereverzyev', 'Sepp Hochreiter', 'Werner Zellinger']",ICLR,Addressing Parameter Choice Issues in Unsupervised Domain Adaptation by Aggregation,https://iclr.cc/virtual/2023/oral/12613,2023," We study the problem of choosing algorithm hyper-parameters in unsupervised domain adaptation, i.e., with labeled data in a source domain and unlabeled data in a target domain, drawn from a different input distribution. We follow the strategy to compute several models using different hyper-parameters, and, to subsequently compute a linear aggregation of the models. While several heuristics exist that follow this strategy, methods are still missing that rely on thorough theories for bounding the target error. In this turn, we propose a method that extends weighted least squares to vector-valued functions, e.g., deep neural networks. We show that the target error of the proposed algorithm is asymptotically not worse than twice the error of the unknown optimal aggregation. We also perform a large scale empirical comparative study on several datasets, including text, images, electroencephalogram, body sensor signals and signals from mobile phones. Our method outperforms deep embedded validation (DEV) and importance weighted validation (IWV) on all datasets, setting a new state-of-the-art performance for solving parameter choice issues in unsupervised domain adaptation with theoretical error guarantees. We further study several competitive heuristics, all outperforming IWV and DEV on at least five datasets. However, our method outperforms each heuristic on at least five of seven datasets.",Oral 6 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=M95oDwJXayG,
"['Thomas Sutter', 'Laura Manduchi', 'Alain Ryser', 'Julia E Vogt']",ICLR,Learning Group Importance using the Differentiable Hypergeometric Distribution,https://iclr.cc/virtual/2023/oral/12587,2023," Partitioning a set of elements into subsets of a priori unknown sizes is essential in many applications. These subset sizes are rarely explicitly learned - be it the cluster sizes in clustering applications or the number of shared versus independent generative latent factors in weakly-supervised learning. Probability distributions over correct combinations of subset sizes are non-differentiable due to hard constraints, which prohibit gradient-based optimization. In this work, we propose the differentiable hypergeometric distribution. The hypergeometric distribution models the probability of different group sizes based on their relative importance. We introduce reparameterizable gradients to learn the importance between groups and highlight the advantage of explicitly learning the size of subsets in two typical applications: weakly-supervised learning and clustering. In both applications, we outperform previous approaches, which rely on suboptimal heuristics to model the unknown size of groups.",Oral 1 Track 1: Deep Learning and representational learning I,https://openreview.net/pdf?id=75O7S_L4oY,
"['Rui Wen', 'Zhengyu Zhao', 'Zhuoran Liu', 'Michael Backes', 'Tianhao Wang', 'Yang Zhang']",ICLR,Is Adversarial Training Really a Silver Bullet for Mitigating Data Poisoning?,https://iclr.cc/virtual/2023/oral/12684,2023," Indiscriminate data poisoning can decrease the clean test accuracy of a deep learning model by slightly perturbing its training samples.There is a consensus that such poisons can hardly harm adversarially-trained (AT) models when the adversarial training budget is no less than the poison budget, i.e., $\epsilon_\mathrm{adv}\geq\epsilon_\mathrm{poi}$. This consensus, however, is challenged in this paper based on our new attack strategy that induces \textit{entangled features} (EntF). The existence of entangled features makes the poisoned data become less useful for training a model, no matter if AT is applied or not. We demonstrate that for attacking a CIFAR-10 AT model under a reasonable setting with $\epsilon_\mathrm{adv}=\epsilon_\mathrm{poi}=8/255$, our EntF yields an accuracy drop of $13.31\%$, which is $7\times$ better than existing methods and equal to discarding $83\%$ training data. We further show the generalizability of EntF to more challenging settings, e.g., higher AT budgets, partial poisoning, unseen model architectures, and stronger (ensemble or adaptive) defenses. We finally provide new insights into the distinct roles of non-robust vs. robust features in poisoning standard vs. AT models and demonstrate the possibility of using a hybrid attack to poison standard and AT models simultaneously. Our code is available at~\url{https://github.com/WenRuiUSTC/EntF}.",Oral 1 Track 4: Social Aspects of Machine Learning,https://openreview.net/pdf?id=zKvm1ETDOq,
"['James Whittington', 'Will Dorrell', 'Surya Ganguli', 'Timothy Behrens']",ICLR,Disentanglement with Biological Constraints: A Theory of Functional Cell Types,https://iclr.cc/virtual/2023/oral/12755,2023," Neurons in the brain are often finely tuned for specific task variables. Moreover, such disentangled representations are highly sought after in machine learning. Here we mathematically prove that simple biological constraints on neurons, namely nonnegativity and energy efficiency in both activity and weights, promote such sought after disentangled representations by enforcing neurons to become selective for single factors of task variation. We demonstrate these constraints lead to disentanglement in a variety of tasks and architectures, including variational autoencoders. We also use this theory to explain why the brain partitions its cells into distinct cell types such as grid and object-vector cells, and also explain when the brain instead entangles representations in response to entangled task factors. Overall, this work provides a mathematical understanding of why single neurons in the brain often represent single human-interpretable factors, and steps towards an understanding task structure shapes the structure of brain representation.",Oral 1 Track 3: Neuroscience and Cognitive Science & General Machine Learning,https://openreview.net/pdf?id=9Z_GfhZnGH,
"['Langwen Huang', 'Torsten Hoefler']",ICLR,Compressing multidimensional weather and climate data into neural networks,https://iclr.cc/virtual/2023/oral/12656,2023," Weather and climate simulations produce petabytes of high-resolution data that are later analyzed by researchers in order to understand climate change or severe weather. We propose a new method of compressing this multidimensional weather and climate data: a coordinate-based neural network is trained to overfit the data, and the resulting parameters are taken as a compact representation of the original grid-based data. While compression ratios range from 300x to more than 3,000x, our method outperforms the state-of-the-art compressor SZ3 in terms of weighted RMSE, MAE. It can faithfully preserve important large scale atmosphere structures and does not introduce significant artifacts.When using the resulting neural network as a 790x compressed dataloader to train the WeatherBench forecasting model, its RMSE increases by less than 2%. The three orders of magnitude compression democratizes access to high-resolution climate data and enables numerous new research directions.",Oral 1 Track 2: Machine Learning for Sciences,https://openreview.net/pdf?id=Y5SEe3dfniJ,
"['Jivat Neet Kaur', 'Emre Kiciman', 'Amit Sharma']",ICLR,Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization,https://iclr.cc/virtual/2023/oral/12672,2023," Recent empirical studies on domain generalization (DG) have shown that DG algorithms that perform well on some distribution shifts fail on others, and no state-of-the-art DG algorithm performs consistently well on all shifts. Moreover, real-world data often has multiple distribution shifts over different attributes; hence we introduce multi-attribute distribution shift datasets and find that the accuracy of existing DG algorithms falls even further. To explain these results, we provide a formal characterization of generalization under multi-attribute shifts using a canonical causal graph. Based on the relationship between spurious attributes and the classification label, we obtain realizations of the canonical causal graph that characterize common distribution shifts and show that each shift entails different independence constraints over observed variables. As a result, we prove that any algorithm based on a single, fixed constraint cannot work well across all shifts, providing theoretical evidence for mixed empirical results on DG algorithms. Based on this insight, we develop Causally Adaptive Constraint Minimization (CACM), an algorithm that uses knowledge about the data-generating process to adaptively identify and apply the correct independence constraints for regularization. Results on fully synthetic, MNIST, small NORB, and Waterbirds datasets, covering binary and multi-valued attributes and labels, show that adaptive dataset-dependent constraints lead to the highest accuracy on unseen domains whereas incorrect constraints fail to do so. Our results demonstrate the importance of modeling the causal relationships inherent in the data-generating process.",Oral 1 Track 6: Deep Learning and representational learning II,https://openreview.net/pdf?id=uyqks-LILZX,
"['Erik Wijmans', 'Manolis Savva', 'Irfan Essa', 'Stefan Lee', 'Ari Morcos', 'Dhruv Batra']",ICLR,Emergence of Maps in the Memories of Blind Navigation Agents,https://iclr.cc/virtual/2023/oral/12560,2023," Animal navigation research posits that organisms build and maintain internal spa- tial representations, or maps, of their environment. We ask if machines – specifically, artificial intelligence (AI) navigation agents – also build implicit (or ‘mental’) maps. A positive answer to this question would (a) explain the surprising phenomenon in recent literature of ostensibly map-free neural-networks achieving strong performance, and (b) strengthen the evidence of mapping as a fundamental mechanism for navigation by intelligent embodied agents, whether they be biological or artificial. Unlike animal navigation, we can judiciously design the agent’s perceptual system and control the learning paradigm to nullify alternative navigation mechanisms. Specifically, we train ‘blind’ agents – with sensing limited to only egomotion and no other sensing of any kind – to perform PointGoal navigation (‘go to $\Delta$x, $\Delta$y’) via reinforcement learning. Our agents are composed of navigation-agnostic components (fully-connected and recurrent neural networks), and our experimental setup provides no inductive bias towards mapping. Despite these harsh conditions, we find that blind agents are (1) surprisingly effective navigators in new environments (∼95% success); (2) they utilize memory over long horizons (remembering ∼1,000 steps of past experience in an episode); (3) this memory enables them to exhibit intelligent behavior (following walls, detecting collisions, taking shortcuts); (4) there is emergence of maps and collision detection neurons in the representations of the environment built by a blind agent as it navigates; and (5) the emergent maps are selective and task dependent (e.g. the agent ‘forgets’ exploratory detours). Overall, this paper presents no new techniques for the AI audience, but a surprising finding, an insight, and an explanation.",Oral 1 Track 5: Reinforcement Learning,https://openreview.net/pdf?id=lTt4KjHSsyl,
"['Hiroki Furuta', 'Yusuke Iwasawa', 'Yutaka Matsuo', 'Shixiang Gu']",ICLR,A System for Morphology-Task Generalization via Unified Representation and Behavior Distillation,https://iclr.cc/virtual/2023/oral/12619,2023," The rise of generalist large-scale models in natural language and vision has made us expect that a massive data-driven approach could achieve broader generalization in other domains such as continuous control. In this work, we explore a method for learning a single policy that manipulates various forms of agents to solve various tasks by distilling a large amount of proficient behavioral data. In order to align input-output (IO) interface among multiple tasks and diverse agent morphologies while preserving essential 3D geometric relations, we introduce morphology-task graph, which treats observations, actions and goals/task in a unified graph representation. We also develop MxT-Bench for fast large-scale behavior generation, which supports procedural generation of diverse morphology-task combinations with a minimal blueprint and hardware-accelerated simulator. Through efficient representation and architecture selection on MxT-Bench, we find out that a morphology-task graph representation coupled with Transformer architecture improves the multi-task performances compared to other baselines including recent discrete tokenization, and provides better prior knowledge for zero-shot transfer or sample efficiency in downstream multi-task imitation learning. Our work suggests large diverse offline datasets, unified IO representation, and policy representation and architecture selection through supervised learning form a promising approach for studying and advancing morphology-task generalization.",Oral 2 Track 4: Reinforcement Learning,https://openreview.net/pdf?id=HcUf-QwZeFh,
"['Renhao Wang', 'Jiayuan Mao', 'Joy Hsu', 'Hang Zhao', 'Jiajun Wu', 'Yang Gao']",ICLR,"Programmatically Grounded, Compositionally Generalizable Robotic Manipulation",https://iclr.cc/virtual/2023/oral/12730,2023," Robots operating in the real world require both rich manipulation skills as well as the ability to semantically reason about when to apply those skills. Towards this goal, recent works have integrated semantic representations from large-scale pretrained vision-language (VL) models into manipulation models, imparting them with more general reasoning capabilities. However, we show that the conventional {\it pretraining-finetuning} pipeline for integrating such representations entangles the learning of domain-specific action information and domain-general visual information, leading to less data-efficient training and poor generalization to unseen objects and tasks. To this end, we propose \ours, a {\it modular} approach to better leverage pretrained VL models by exploiting the syntactic and semantic structures of language instructions. Our framework uses a semantic parser to recover an executable program, composed of functional modules grounded on vision and action across different modalities. Each functional module is realized as a combination of deterministic computation and learnable neural networks. Program execution produces parameters to general manipulation primitives for a robotic end-effector. The entire modular network can be trained with end-to-end imitation learning objectives. Experiments show that our model successfully disentangles action and perception, translating to improved zero-shot and compositional generalization in a variety of manipulation behaviors. Project webpage at: \url{https://progport.github.io}.",Oral 3 Track 1: Reinforcement Learning,https://openreview.net/pdf?id=rZ-wylY5VI,
"['Shaokun Zhang', 'Feiran Jia', 'Chi Wang', 'Qingyun Wu']",ICLR,Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives,https://iclr.cc/virtual/2023/oral/12646,2023," Motivated by various practical applications, we propose a novel and general formulation of targeted multi-objective hyperparameter optimization. Our formulation allows a clear specification of an automatable optimization goal using lexicographic preference over multiple objectives. We then propose a randomized directed search method named LexiFlow to solve this problem. We demonstrate the strong empirical performance of the proposed algorithm in multiple hyperparameter optimization tasks.",Oral 2 Track 2: General Machine Learning,https://openreview.net/pdf?id=0Ij9_q567Ma,
"['Guy Tevet', 'Sigal Raab', 'Brian Gordon', 'Yonatan Shafir', 'Daniel Cohen-Or', 'Amit Bermano']",ICLR,Human Motion Diffusion Model,https://iclr.cc/virtual/2023/oral/12654,2023," Natural and expressive human motion generation is the holy grail of computer animation.It is a challenging task, due to the diversity of possible motion, human perceptual sensitivity to it, and the difficulty of accurately describing it. Therefore, current generative solutions are either low-quality or limited in expressiveness. Diffusion models are promising candidates for the human motion domain since theyhave already shown remarkable generative capabilities in other domains, and their many-to-many nature. In this paper, we introduce Motion Diffusion Model (MDM), a carefully adapted classifier-free diffusion-based generative model for human motion data.  MDM is transformer-based, combining insights from motion generation literature. A notable design-choice is that it predicts the sample itself rather than the noise in each step to facilitate the use of established geometric losses on the locations and velocities of the motion, such as the foot contact loss. As we demonstrate, MDM is a generic approach, enabling different modes of conditioning, and different generation tasks. We show that our model is trained with lightweight resources and yet achieves state-of-the-art results on leading benchmarks for text-to-motion, action-to-motion, and unconditioned motion generation.",Oral 2 Track 1: Applications,https://openreview.net/pdf?id=SJ1kSyO2jwu,
"['Aseem Baranwal', 'Kimon Fountoulakis', 'Aukosh Jagannath']",ICLR,Effects of Graph Convolutions in Multi-layer Networks,https://iclr.cc/virtual/2023/oral/12554,2023," Graph Convolutional Networks (GCNs) are one of the most popular architectures that are used to solve classification problems accompanied by graphical information. We present a rigorous theoretical understanding of the effects of graph convolutions in multi-layer networks. We study these effects through the node classification problem of a non-linearly separable Gaussian mixture model coupled with a stochastic block model. First, we show that a single graph convolution expands the regime of the distance between the means where multi-layer networks can classify the data by a factor of at least $1/\sqrt[4]{\rm deg}$, where ${\rm deg}$ denotes the expected degree of a node. Second, we show that with a slightly stronger graph density, two graph convolutions improve this factor to at least $1/\sqrt[4]{n}$, where $n$ is the number of nodes in the graph. Finally, we provide both theoretical and empirical insights into the performance of graph convolutions placed in different combinations among the layers of a neural network, concluding that the performance is mutually similar for all combinations of the placement. We present extensive experiments on both synthetic and real-world data that illustrate our results.",Oral 2 Track 5: Generative models & Theory,https://openreview.net/pdf?id=P-73JPgRs0R,
"['Bencheng Liao', 'Shaoyu Chen', 'Xinggang Wang', 'Tianheng Cheng', 'Qian Zhang', 'Wenyu Liu', 'Chang Huang']",ICLR,MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction,https://iclr.cc/virtual/2023/oral/12564,2023," High-definition (HD) map provides abundant and precise environmental information of the driving scene, serving as a fundamental and indispensable component for planning in autonomous driving system. We present MapTR, a structured end-to-end Transformer for efficient online vectorized HD map construction. We propose a unified permutation-equivalent modeling approach, i.e., modeling map element as a point set with a group of equivalent permutations, which accurately describes the shape of map element and stabilizes the learning process. We design a hierarchical query embedding scheme to flexibly encode structured map information and perform hierarchical bipartite matching for map element learning. MapTR achieves the best performance and efficiency with only camera input among existing vectorized map construction approaches on nuScenes dataset. In particular, MapTR-nano runs at real-time inference speed ($25.1$ FPS) on RTX 3090, $8\times$ faster than the existing state-of-the-art camera-based method while achieving $5.0$ higher mAP. Even compared with the existing state-of-the-art multi-modality method, MapTR-nano achieves $0.7$ higher mAP and $8\times$ faster inference speed, and MapTR-tiny achieves $13.5$ higher mAP and $3\times$ faster inference speed. Abundant qualitative results show that MapTR maintains stable and robust map construction quality in complex and various driving scenes. MapTR is of great application value in autonomous driving. Code and more demos are available at https://github.com/hustvl/MapTR.",Oral 2 Track 6: Applications & Social Aspects of Machine Learning,https://openreview.net/pdf?id=k7p_YAO7yE,
"['Ziming Liu', 'Eric Michaud', 'Max Tegmark']",ICLR,Omnigrok: Grokking Beyond Algorithmic Data,https://iclr.cc/virtual/2023/oral/12716,2023," Grokking, the unusual phenomenon for algorithmic datasets where generalization happens long after overfitting the training data, has remained elusive. We aim to understand grokking by analyzing the loss landscapes of neural networks, identifying the mismatch between training and test losses as the cause for grokking. We refer to this as the ""LU mechanism"" because training and test losses (against model weight norm) typically resemble ""L"" and ""U"", respectively. This simple mechanism can nicely explain many aspects of grokking: data size dependence, weight decay dependence, the emergence of representations, etc. Guided by the intuitive picture, we are able to induce grokking on tasks involving images, language and molecules, although the grokking signals are sometimes less dramatic. We attribute the dramatic nature of grokking for algorithmic datasets to representation learning.",Oral 3 Track 2: Deep Learning and representational learning,https://openreview.net/pdf?id=zDiHoIWa0q1,
"['Zhenmei Shi', 'Jiefeng Chen', 'Kunyang Li', 'Jayaram Raghuram', 'Xi Wu', 'Yingyu Liang', 'Somesh Jha']",ICLR,The Trade-off between Universality and Label Efficiency of Representations from Contrastive Learning,https://iclr.cc/virtual/2023/oral/12598,2023," Pre-training representations (a.k.a. foundation models) has recently become a prevalent learning paradigm, where one first pre-trains a representation using large-scale unlabeled data, and then learns simple predictors on top of the representation using small labeled data from the downstream tasks. There are two key desiderata for the representation: label efficiency (the ability to learn an accurate classifier on top of the representation with a small amount of labeled data) and universality (usefulness across a wide range of downstream tasks). In this paper, we focus on one of the most popular instantiations of this paradigm: contrastive learning with linear probing, i.e., learning a linear predictor on the representation pre-trained by contrastive learning. We show that there exists a trade-off between the two desiderata so that one may not be able to achieve both simultaneously. Specifically, we provide analysis using a theoretical data model and show that,  while more diverse pre-training data result in more diverse features for different tasks (improving universality), it puts less emphasis on task-specific features, giving rise to larger sample complexity for down-stream supervised tasks, and thus worse prediction performance. Guided by this analysis, we propose a contrastive regularization method to improve the trade-off. We validate our analysis and method empirically with systematic experiments using real-world datasets and foundation models.",Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=rvsbw2YthH_,
"['Jaehyun Nam', 'Jihoon Tack', 'Kyungmin Lee', 'Hankook Lee', 'Jinwoo Shin']",ICLR,STUNT: Few-shot Tabular Learning with Self-generated Tasks from Unlabeled Tables,https://iclr.cc/virtual/2023/oral/12594,2023," Learning with few labeled tabular samples is often an essential requirement for industrial machine learning applications as varieties of tabular data suffer from high annotation costs or have difficulties in collecting new samples for novel tasks. Despite the utter importance, such a problem is quite under-explored in the field of tabular learning, and existing few-shot learning schemes from other domains are not straightforward to apply, mainly due to the heterogeneous characteristics of tabular data. In this paper, we propose a simple yet effective framework for few-shot semi-supervised tabular learning, coined Self-generated Tasks from UNlabeled Tables (STUNT). Our key idea is to self-generate diverse few-shot tasks by treating randomly chosen columns as a target label. We then employ a meta-learning scheme to learn generalizable knowledge with the constructed tasks. Moreover, we introduce an unsupervised validation scheme for hyperparameter search (and early stopping) by generating a pseudo-validation set using STUNT from unlabeled data. Our experimental results demonstrate that our simple framework brings significant performance gain under various tabular few-shot learning benchmarks, compared to prior semi- and self-supervised baselines. Code is available at https://github.com/jaehyun513/STUNT.",Oral 4 Track 1: Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=_xlsjehDvlY,
"['Kenneth Li', 'Aspen Hopkins', 'David Bau', 'Fernanda Viégas', 'Hanspeter Pfister', 'Martin Wattenberg']",ICLR,Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task,https://iclr.cc/virtual/2023/oral/12641,2023," Language models show a surprising range of capabilities, but the source of their apparent competence is unclear. Do these networks just memorize a collection of surface statistics, or do they rely on internal representations of the process that generates the sequences they see? We investigate this question by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network and create ""latent saliency maps"" that can help explain predictions in human terms.",Oral 3 Track 5: Deep Learning and representational learning & Neuroscience and Cognitive Science,https://openreview.net/pdf?id=DeG07_TcZvT,
"['Zhuo Li', 'Derui Zhu', 'Yujing Hu', 'Xiaofei Xie', 'Lei Ma', 'YAN ZHENG', 'Yan Song', 'Yingfeng Chen', 'Jianjun Zhao']",ICLR,Neural Episodic Control with State Abstraction,https://iclr.cc/virtual/2023/oral/12557,2023," Existing Deep Reinforcement Learning (DRL) algorithms suffer from sample inefficiency. Generally, episodic control-based approaches are solutions that leverage highly rewarded past experiences to improve sample efficiency of DRL algorithms. However, previous episodic control-based approaches fail to utilize the latent information from the historical behaviors (\eg, state transitions, topological similarities, \etc) and lack scalability during DRL training. This work introduces Neural Episodic Control with State Abstraction (NECSA), a simple but effective state abstraction-based episodic control containing a more comprehensive episodic memory, a novel state evaluation, and a multi-step state analysis. We evaluate our approach to the MuJoCo and Atari tasks in OpenAI gym domains. The experimental results indicate that NECSA achieves higher sample efficiency than the state-of-the-art episodic control-based approaches. Our data and code are available at the project website\footnote{\url{https://sites.google.com/view/drl-necsa}}.",Oral 4 Track 4: Reinforcement Learning II,https://openreview.net/pdf?id=C2fsSj3ZGiU,
"['Onno Eberhard', 'Jakob Hollenstein', 'Cristina Pinneri', 'Georg Martius']",ICLR,Pink Noise Is All You Need: Colored Noise Exploration in Deep Reinforcement Learning,https://iclr.cc/virtual/2023/oral/12540,2023," In off-policy deep reinforcement learning with continuous action spaces, exploration is often implemented by injecting action noise into the action selection process. Popular algorithms based on stochastic policies, such as SAC or MPO, inject white noise by sampling actions from uncorrelated Gaussian distributions. In many tasks, however, white noise does not provide sufficient exploration, and temporally correlated noise is used instead. A common choice is Ornstein-Uhlenbeck (OU) noise, which is closely related to Brownian motion (red noise). Both red noise and white noise belong to the broad family of colored noise. In this work, we perform a comprehensive experimental evaluation on MPO and SAC to explore the effectiveness of other colors of noise as action noise. We find that pink noise, which is halfway between white and red noise, significantly outperforms white noise, OU noise, and other alternatives on a wide range of environments. Thus, we recommend it as the default choice for action noise in continuous control.",Oral 4 Track 3: Reinforcement Learning I,https://openreview.net/pdf?id=hQ9V5QN27eS,
"['Ling Pan', 'Dinghuai Zhang', 'Aaron Courville', 'Longbo Huang', 'Yoshua Bengio']",ICLR,Generative Augmented Flow Networks,https://iclr.cc/virtual/2023/oral/12623,2023," The Generative Flow Network is a probabilistic framework where an agent learns a stochastic policy for object generation, such that the probability of generating an object is proportional to a given reward function. Its effectiveness has been shown in discovering high-quality and diverse solutions, compared to reward-maximizing reinforcement learning-based methods. Nonetheless, GFlowNets only learn from rewards of the terminal states, which can limit its applicability. Indeed, intermediate rewards play a critical role in learning, for example from intrinsic motivation to provide intermediate feedback even in particularly challenging sparse reward tasks. Inspired by this, we propose Generative Augmented Flow Networks (GAFlowNets), a novel learning framework to incorporate intermediate rewards into GFlowNets. We specify intermediate rewards by intrinsic motivation to tackle the exploration problem in sparse reward environments. GAFlowNets can leverage edge-based and state-based intrinsic rewards in a joint way to improve exploration. Based on extensive experiments on the GridWorld task, we demonstrate the effectiveness and efficiency of GAFlowNet in terms of convergence, performance, and diversity of solutions. We further show that GAFlowNet is scalable to a more complex and large-scale molecule generation domain, where it achieves consistent and significant performance improvement.",Oral 4 Track 2: Probabilistic Methods,https://openreview.net/pdf?id=urF_CBK5XC0,
"['Xingchao Liu', 'Chengyue Gong', 'Qiang Liu']",ICLR,Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow,https://iclr.cc/virtual/2023/oral/12626,2023," We present rectified flow, a simple approach to learning (neural) ordinary differential equation (ODE) models to transport between two empirically observed distributions $\pi_0$ and $\pi_1$, hence providing a unified solution to generative modeling and domain transfer, among various other tasks involving distribution transport. The idea of rectified flow is to learn the ODE to follow the straight paths connecting the points drawn from $\pi_0$ and $\pi_1$ as much as possible. This is  achieved by solving a straightforward nonlinear least squares optimization problem, which can be easily scaled to large models without introducing extra parameters beyond standard supervised learning. The straight paths are the shortest paths between two points, and can be simulated exactly without time discretization and hence yield computationally efficient models. We show that, by learning a rectified flow from data, we effectively turn an arbitrary coupling of $\pi_0$ and $\pi_1$ to a  new deterministic coupling with provably non-increasing convex transport costs. In addition, with a ``reflow"" procedure that iteratively learns a new rectified flow from the data bootstrapped from the previous one, we obtain a sequence of flows with increasingly straight paths, which can be simulated accurately with coarse time discretization in the inference phase. In empirical studies, we show that rectified flow performs superbly on image generation, image-to-image translation, and domain adaptation. In particular, on image generation and translation, our method yields nearly straight flows that give high quality results even with \emph{a single Euler discretization step}. Code is available at \url{https://github.com/gnobitab/RectifiedFlow}.",Oral 3 Track 3: Generative models,https://openreview.net/pdf?id=XVjTT1nw5z,
"['Eoin Kenny', 'Mycal Tucker', 'Julie Shah']",ICLR,Towards Interpretable Deep Reinforcement Learning with Human-Friendly Prototypes,https://iclr.cc/virtual/2023/oral/12596,2023," Despite recent success of deep learning models in research settings, their application in sensitive domains remains limited because of their opaque decision-making processes. Taking to this challenge, people have proposed various eXplainable AI (XAI) techniques designed to calibrate trust and understandability of black-box models, with the vast majority of work focused on supervised learning. Here, we focus on making an ""interpretable-by-design"" deep reinforcement learning agent which is forced to use human-friendly prototypes in its decisions, thus making its reasoning process clear. Our proposed method, dubbed Prototype-Wrapper Network (PW-Net), wraps around any neural agent backbone, and results indicate that it does not worsen performance relative to black-box models. Most importantly, we found in a user study that PW-Nets supported better trust calibration and task performance relative to standard interpretability approaches and black-boxes.",Oral 5 Track 1: Unsupervised and Self-supervised learning & Social Aspects of Machine Learning-,https://openreview.net/pdf?id=hWwY_Jq0xsN,
"['Tong Yang', 'Michael Jordan', 'Tatjana Chavdarova']",ICLR,Solving Constrained Variational Inequalities via a First-order Interior Point-based Method,https://iclr.cc/virtual/2023/oral/12629,2023," We develop an interior-point approach to solve constrained variational inequality (cVI) problems. Inspired by the efficacy of the alternating direction method of multipliers (ADMM) method in the single-objective context, we generalize ADMM to derive a first-order method for cVIs, that we refer to as ADMM-based interior-point method for constrained VIs (ACVI). We provide convergence guarantees for ACVI in two general classes of problems: (i) when the operator is $\xi$-monotone, and (ii) when it is monotone, some constraints are active and the game is not purely rotational. When the operator is in addition L-Lipschitz for the latter case, we match known lower bounds on rates for the gap function of $\mathcal{O}(1/\sqrt{K})$ and $\mathcal{O}(1/K)$ for the last and average iterate, respectively. To the best of our knowledge, this is the first presentation of a first-order interior-point method for the general cVI problem that has a global convergence guarantee. Moreover, unlike previous work in this setting, ACVI provides a means to solve cVIs when the constraints are nontrivial. Empirical analyses demonstrate clear advantages of ACVI over common first-order methods. In particular, (i) cyclical behavior is notably reduced as our methods approach the solution from the analytic center, and (ii) unlike projection-based methods that zigzag when near a constraint, ACVI efficiently handles the constraints.",Oral 5 Track 2: Optimization,https://openreview.net/pdf?id=RQY2AXFMRiu,
"['Deval Shah', 'Tor Aamodt']",ICLR,Learning Label Encodings for Deep Regression,https://iclr.cc/virtual/2023/oral/12604,2023," Deep regression networks are widely used to tackle the problem of predicting a continuous value for a given input. Task-specialized approaches for training regression networks have shown significant improvement over generic approaches, such as direct regression. More recently, a generic approach based on regression by binary classification using binary-encoded labels has shown significant improvement over direct regression. The space of label encodings for regression is large. Lacking heretofore have been automated approaches to find a good label encoding for a given application. This paper introduces Regularized Label Encoding Learning (RLEL) for end-to-end training of an entire network and its label encoding. RLEL provides a generic approach for tackling regression. Underlying RLEL is our observation that the search space of label encodings can be constrained and efficiently explored by using a continuous search space of real-valued label encodings combined with a regularization function designed to encourage encodings with certain properties. These properties balance the probability of classification error in individual bits against error correction capability. Label encodings found by RLEL result in lower or comparable errors to manually designed label encodings. Applying RLEL results in 10.9% and 12.4% improvement in Mean Absolute Error (MAE) over direct regression and multiclass classification, respectively. Our evaluation demonstrates that RLEL can be combined with off-the-shelf feature extractors and is suitable across different architectures, datasets, and tasks. Code is available at https://github.com/ubc-aamodt-group/RLEL_regression.",Oral 4 Track 6: Deep Learning and representational learning- Reinforcement Learning,https://openreview.net/pdf?id=k60XE_b0Ix6,
"['Aleksandar Pavlović', 'Emanuel Sallinger']",ICLR,ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion,https://iclr.cc/virtual/2023/oral/12536,2023," Knowledge graphs are inherently incomplete. Therefore substantial research has been directed toward knowledge graph completion (KGC), i.e., predicting missing triples from the information represented in the knowledge graph (KG). KG embedding models (KGEs) have yielded promising results for KGC, yet any current KGE is incapable of: (1) fully capturing vital inference patterns (e.g., composition), (2) capturing prominent patterns jointly (e.g., hierarchy and composition), and (3) providing an intuitive interpretation of captured patterns. In this work, we propose ExpressivE, a fully expressive spatio-functional KGE that solves all these challenges simultaneously. ExpressivE embeds pairs of entities as points and relations as hyper-parallelograms in the virtual triple space $\mathbb{R}^{2d}$. This model design allows ExpressivE not only to capture a rich set of inference patterns jointly but additionally to display any supported inference pattern through the spatial relation of hyper-parallelograms, offering an intuitive and consistent geometric interpretation of ExpressivE embeddings and their captured patterns. Experimental results on standard KGC benchmarks reveal that ExpressivE is competitive with state-of-the-art KGEs and even significantly outperforms them on WN18RR.",Oral 5 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=xkev3_np08z,
"['Tailin Wu', 'Takashi Maruyama', 'Qingqing Zhao', 'Gordon Wetzstein', 'Jure Leskovec']",ICLR,Learning Controllable Adaptive Simulation for Multi-resolution Physics,https://iclr.cc/virtual/2023/oral/12539,2023," Simulating the time evolution of physical systems is pivotal in many scientific and engineering problems. An open challenge in simulating such systems is their multi-resolution dynamics: a small fraction of the system is extremely dynamic, and requires very fine-grained resolution, while a majority of the system is changing slowly and can be modeled by coarser spatial scales. Typical learning-based surrogate models use a uniform spatial scale, which needs to resolve to the finest required scale and can waste a huge compute to achieve required accuracy. In this work, we introduce Learning controllable Adaptive simulation for Multi-resolution Physics (LAMP) as the first full deep learning-based surrogate model that jointly learns the evolution model and optimizes appropriate spatial resolutions that devote more compute to the highly dynamic regions. LAMP consists of a Graph Neural Network (GNN) for learning the forward evolution, and a GNN-based actor-critic for learning the policy of spatial refinement and coarsening. We introduce learning techniques that optimizes LAMP with weighted sum of error and computational cost as objective, allowing LAMP to adapt to varying relative importance of error vs. computation tradeoff at inference time. We evaluate our method in a 1D benchmark of nonlinear PDEs and a challenging 2D mesh-based simulation. We demonstrate that our LAMP outperforms state-of-the-art deep learning surrogate models, and can adaptively trade-off computation to improve long-term prediction error: it achieves an average of 33.7% error reduction for 1D nonlinear PDEs, and outperforms  MeshGraphNets + classical Adaptive Mesh Refinement (AMR) in 2D mesh-based simulations. Project website with data and code can be found at: http://snap.stanford.edu/lamp.",Oral 4 Track 5: Machine Learning for Sciences & Probabilistic Methods,https://openreview.net/pdf?id=PbfgkZ2HdbE,
"['Zihui Xue', 'Zhengqi Gao', 'Sucheng Ren', 'Hang Zhao']",ICLR,The Modality Focusing Hypothesis: Towards Understanding Crossmodal Knowledge Distillation,https://iclr.cc/virtual/2023/oral/12608,2023," Crossmodal knowledge distillation (KD) extends traditional knowledge distillation to the area of multimodal learning and demonstrates great success in various applications. To achieve knowledge transfer across modalities, a pretrained network from one modality is adopted as the teacher to provide supervision signals to a student network learning from the other modality. In contrast to the empirical success reported in prior works, the working mechanism of crossmodal KD remains a mystery. In this paper, we present a thorough understanding of crossmodal KD. We begin by providing two failure cases and demonstrate that KD is not a universal cure in crossmodal knowledge transfer. We then present the modality Venn diagram to understand modality relationships and the modality focusing hypothesis revealing the decisive factor in the efficacy of crossmodal KD. Experimental results on 6 multimodal datasets help justify our hypothesis, diagnose failure cases, and point directions to improve crossmodal knowledge transfer in the future.",Oral 6 Track 4: Applications & Social Aspects of Machine Learning & General Machine Learning,https://openreview.net/pdf?id=w0QXrZ3N-s,
"['Shuyan Zhou', 'Uri Alon', 'Frank F Xu', 'Zhengbao Jiang', 'Graham Neubig']",ICLR,DocPrompting: Generating Code by Retrieving the Docs,https://iclr.cc/virtual/2023/oral/12584,2023," Publicly available source-code libraries are continuously growing and changing. This makes it impossible for models of codeto keep current with all available APIs by simply training these models on existing code repositories. Thus, existing models inherently cannot generalize to using unseen functions and libraries, because these would never appear in the training data. In contrast, when human programmers use functions and libraries for the first time, they frequently refer to textual resources such as code manuals and documentation, to explore and understand the available functionality. Inspired by this observation, we introduce DocPrompting: a natural-language-to-code generation approach that explicitly leverages documentation by (1) retrieving the relevant documentation pieces given an NL intent, and (2) generating code based on the NL intent and the retrieved documentation. DocPrompting is general: it can be applied to any programming language and is agnostic to the underlying neural model. We demonstrate that DocPrompting consistently improves NL-to-code models: DocPrompting improves strong base models such as CodeT5 by 2.85% in pass@1 (52% relative gain) and 4.39% in pass@10 (30% relative gain) in execution-based evaluation on the popular Python CoNaLa benchmark; on a new Bash dataset tldr, DocPrompting improves CodeT5 and GPT-Neo1.3B by up to absolute 6.9% exact match.",Oral 5 Track 4: Applications & Optimization,https://openreview.net/pdf?id=ZTCxT2t2Ru,
"['Zeyuan Allen-Zhu', 'Yuanzhi Li']",ICLR,"Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning",https://iclr.cc/virtual/2023/oral/12664,2023," We formally study how \emph{ensemble} of deep learning models can improve test accuracy, and how the superior performance of ensemble can be distilled into a single model using \emph{knowledge distillation}. We consider the challenging case where the ensemble is simply an average of the outputs of a few independently trained neural networks with the \emph{same} architecture, trained using the \emph{same} algorithm on the \emph{same} data set, and they only differ by the random seeds used in the initialization.We show that ensemble/knowledge distillation in \emph{deep learning} works very differently from traditional learning theory (such as boosting or NTKs). We develop a theory showing that when data has a structure we refer to as multi-view'', then ensemble of independently trained neural networks can provably improve test accuracy, and such superior test accuracy can also be provably distilled into a single model. Our result sheds light on how ensemble works in deep learning in a way that is completely different from traditional theorems, and how the dark knowledge'' is hidden in the outputs of the ensemble and can be used in distillation.",Oral 6 Track 1: Theory,https://openreview.net/pdf?id=Uuf2q9TfXGA,
"['Xiajun Jiang', 'Ryan Missel', 'Zhiyuan Li', 'Linwei Wang']",ICLR,Sequential Latent Variable Models for Few-Shot High-Dimensional Time-Series Forecasting,https://iclr.cc/virtual/2023/oral/12551,2023," Modern applications increasingly require learning and forecasting latent dynamics from high-dimensional time-series. Compared to univariate time-series forecasting, this adds a new challenge of reasoning about the latent dynamics of an unobserved abstract state. Sequential latent variable models (LVMs) present an attractive solution, although existing works either struggle with long-term forecasting or have difficulty learning across diverse dynamics. In this paper, we first present a conceptual framework of sequential LVMs to unify existing works, contrast their fundamental limitations, and identify an intuitive solution to long-term forecasting for diverse dynamics via meta-learning. We then present the first framework of few-shot forecasting for high-dimensional time-series: instead of learning a single dynamic function, we leverage data of diverse dynamics and learn to adapt latent dynamic functions to few-shot support series. This is realized via Bayesian meta-learning underpinned by: 1) a latent dynamic function conditioned on knowledge derived from few-shot support series, and 2) a meta-model that learns to extract such dynamic-specific knowledge via feed-forward embedding of support set. We compared the presented framework with a comprehensive set of baseline models trained 1) globally on the large meta-training set with diverse dynamics, and 2) individually on single dynamics, both with and without fine-tuning to k-shot support series used by the meta-models. We demonstrated that the presented framework is agnostic to the latent dynamic function of choice and, at meta-test time, is able to forecast for new dynamics given variable-shot of support series.",Oral 2 Track 3: Generative models,https://openreview.net/pdf?id=7C9aRX2nBf2,
"['Matthew Ho', 'Aditya Sharma', 'Justin Chang', 'Michael Saxon', 'Sharon Levy', 'Yujie Lu', 'William Wang']",ICLR,WikiWhy: Answering and Explaining Cause-and-Effect Questions,https://iclr.cc/virtual/2023/oral/12691,2023," As large language models (LLMs) grow larger and more sophisticated, assessing their ""reasoning"" capabilities in natural language grows more challenging. Recent question answering (QA) benchmarks that attempt to assess reasoning are often limited by a narrow scope of covered situations and subject matters. We introduce WikiWhy, a QA dataset built around a novel auxiliary task: explaining why an answer is true in natural language. WikiWhy contains over 9,000 ""why"" question-answer-rationale triples, grounded on Wikipedia facts across a diverse set of topics. Each rationale is a set of supporting statements connecting the question to the answer. WikiWhy serves as a benchmark for the reasoning capabilities of LLMs because it demands rigorous explicit rationales for each answer to demonstrate the acquisition of implicit commonsense knowledge, which is unlikely to be easily memorized. GPT-3 baselines achieve only 38.7% human-evaluated correctness in the end-to-end answer & explain condition, leaving significant room for future improvements.",Oral 6 Track 2: Infrastructure & Social Aspects of Machine Learning,https://openreview.net/pdf?id=vaxnu-Utr4l,
"['Shunyu Yao', 'Jeffrey Zhao', 'Dian Yu', 'Nan Du', 'Izhak Shafran', 'Karthik Narasimhan', 'Yuan Cao']",ICLR,ReAct: Synergizing Reasoning and Acting in Language Models,https://iclr.cc/virtual/2023/oral/12647,2023," While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples.",Oral 6 Track 6: Deep Learning,https://openreview.net/pdf?id=WE_vluYUL-X,
"['Joel Dapello', 'Kohitij Kar', 'Martin Schrimpf', 'Robert Geary', 'Michael Ferguson', 'David Cox', 'James DiCarlo']",ICLR,Aligning Model and Macaque Inferior Temporal Cortex Representations Improves Model-to-Human Behavioral Alignment and Adversarial Robustness,https://iclr.cc/virtual/2023/oral/12582,2023," While some state-of-the-art artificial neural network systems in computer vision are strikingly accurate models of the corresponding primate visual processing, there are still many discrepancies between these models and the behavior of primates on object recognition tasks. Many current models suffer from extreme sensitivity to adversarial attacks and often do not align well with the image-by-image behavioral error patterns observed in humans. Previous research has provided strong evidence that primate object recognition behavior can be very accurately predicted by neural population activity in the inferior temporal (IT) cortex, a brain area in the late stages of the visual processing hierarchy. Therefore, here we directly test whether making the late stage representations of models more similar to that of macaque IT produces new models that exhibit more robust, primate-like behavior. We conducted chronic, large-scale multi-electrode recordings  across the IT cortex in six non-human primates (rhesus macaques). We then use these data to fine-tune (end-to-end) the model ""IT"" representations such that they are more aligned with the biological IT representations, while preserving accuracy on object recognition tasks. We generate a cohort of models with a range of IT similarity scores validated on held-out animals across two image sets with distinct statistics. Across a battery of optimization conditions, we observed a strong correlation between the models' IT-likeness and alignment with human behavior, as well as an increase in its adversarial robustness. We further assessed the limitations of this approach and find that the improvements in behavioral alignment and adversarial robustness generalize across different image statistics, but not to object categories outside of those covered in our IT training set. Taken together, our results demonstrate that building models that are more aligned with the primate brain leads to more robust and human-like behavior, and call for larger neural data-sets to further augment these gains.",Oral 5 Track 5: Deep Learning and representational learning & Reinforcement Learning,https://openreview.net/pdf?id=SMYdcXjJh1q,
"['Badr Youbi Idrissi', 'Diane Bouchacourt', 'Randall Balestriero', 'Ivan Evtimov', 'Caner Hazirbas', 'Nicolas Ballas', 'Pascal Vincent', 'Michal Drozdzal', 'David Lopez-Paz', 'Mark Ibrahim']",ICLR,ImageNet-X: Understanding Model Mistakes with Factor of Variation Annotations,https://iclr.cc/virtual/2023/oral/12558,2023," Deep learning vision systems are widely deployed across applications where reliability is critical. However, even today's best models can fail to recognize an object when its pose, lighting, or background varies. While existing benchmarks surface examples challenging for models, they do not explain why such mistakes arise. To address this need, we introduce ImageNet-X—a set of sixteen human annotations of factors such as pose, background, or lighting the entire ImageNet-1k validation set as well as a random subset of 12k training images. Equipped with ImageNet-X, we investigate 2,200 current recognition models and study the types of mistakes as a function of model’s (1) architecture, e.g. transformer vs. convolutional, (2) learning paradigm, e.g. supervised vs. self-supervised, and (3) training procedures, e.g., data augmentation. Regardless of these choices, we find models have consistent failure modes across ImageNet-X categories. We also find that while data augmentation can improve robustness to certain factors, they induce spill-over effects to other factors. For example, color-jitter augmentation improves robustness to color and brightness, but surprisingly hurts robustness to pose. Together, these insights suggest to advance the robustness of modern vision models, future research should focus on collecting additional data and understanding data augmentation schemes. Along with these insights, we release a toolkit based on ImageNet-X to spur further study into the mistakes image recognition systems make.",Oral 6 Track 5: Applications- & Deep Learning and representational learning,https://openreview.net/pdf?id=HXz7Vcm3VgM,
"['Feiqing Huang', 'Kexin Lu', 'Yuxi Cai', 'Zhen Qin', 'Yanwen Fang', 'Guangjian Tian', 'Guodong Li']",ICLR,Encoding Recurrence into Transformers,https://iclr.cc/virtual/2023/oral/12649,2023," This paper novelly breaks down with ignorable loss an RNN layer into a sequence of simple RNNs, each of which can be further rewritten into a lightweight positional encoding matrix of a self-attention, named the Recurrence Encoding Matrix (REM). Thus, recurrent dynamics introduced by the RNN layer can be encapsulated into the positional encodings of a multihead self-attention, and this makes it possible to seamlessly incorporate these recurrent dynamics into a Transformer, leading to a new module, Self-Attention with Recurrence (RSA). The proposed module can leverage the recurrent inductive bias of REMs to achieve a better sample efficiency than its corresponding baseline Transformer, while the self-attention is used to model the remaining non-recurrent signals. The relative proportions of these two components are controlled by a data-driven gated mechanism, and the effectiveness of RSA modules are demonstrated by four sequential learning tasks.",Oral 6 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=7YfHla7IxBJ,
"['Takashi Ishida', 'Ikko Yamane', 'Nontawat Charoenphakdee', 'Gang Niu', 'Masashi Sugiyama']",ICLR,Is the Performance of My Deep Network Too Good to Be True? A Direct Approach to Estimating the Bayes Error in Binary Classification,https://iclr.cc/virtual/2023/oral/12692,2023," There is a fundamental limitation in the prediction performance that a machine learning model can achieve due to the inevitable uncertainty of the prediction target. In classification problems, this can be characterized by the Bayes error, which is the best achievable error with any classifier. The Bayes error can be used as a criterion to evaluate classifiers with state-of-the-art performance and can be used to detect test set overfitting. We propose a simple and direct Bayes error estimator, where we just take the mean of the labels that show \emph{uncertainty} of the class assignments. Our flexible approach enables us to perform Bayes error estimation even for weakly supervised data. In contrast to others, our method is model-free and even instance-free. Moreover, it has no hyperparameters and gives a more accurate estimate of the Bayes error than several baselines empirically. Experiments using our method suggest that recently proposed deep networks such as the Vision Transformer may have reached, or is about to reach, the Bayes error for benchmark datasets. Finally, we discuss how we can study the inherent difficulty of the acceptance/rejection decision for scientific articles, by estimating the Bayes error of the ICLR papers from 2017 to 2023.",Oral 1 Track 4: Social Aspects of Machine Learning,https://openreview.net/pdf?id=FZdJQgy05rz,
"['Gregoire Deletang', 'Anian Ruoss', 'Jordi Grau-Moya', 'Tim Genewein', 'Li Kevin Wenliang', 'Elliot Catt', 'Chris Cundy', 'Marcus Hutter', 'Shane Legg', 'Joel Veness', 'Pedro Ortega']",ICLR,Neural Networks and the Chomsky Hierarchy,https://iclr.cc/virtual/2023/oral/12616,2023," Reliable generalization lies at the heart of safe ML and AI. However, understanding when and how neural networks generalize remains one of the most important unsolved problems in the field. In this work, we conduct an extensive empirical study (20'910 models, 15 tasks) to investigate whether insights from the theory of computation can predict the limits of neural network generalization in practice. We demonstrate that grouping tasks according to the Chomsky hierarchy allows us to forecast whether certain architectures will be able to generalize to out-of-distribution inputs. This includes negative results where even extensive amounts of data and training time never lead to any non-trivial generalization, despite models having sufficient capacity to fit the training data perfectly. Our results show that, for our subset of tasks, RNNs and Transformers fail to generalize on non-regular tasks, LSTMs can solve regular and counter-language tasks, and only networks augmented with structured memory (such as a stack or memory tape) can successfully generalize on context-free and context-sensitive tasks.",Oral 1 Track 1: Deep Learning and representational learning I,https://openreview.net/pdf?id=WbxHAzkeQcn,
"['Tianbo Li', 'Min Lin', 'Zheyuan Hu', 'Kunhao Zheng', 'Giovanni Vignale', 'Kenji Kawaguchi', 'A. Castro Neto', 'Kostya Novoselov', 'shuicheng YAN']",ICLR,D4FT: A Deep Learning Approach to Kohn-Sham Density Functional Theory,https://iclr.cc/virtual/2023/oral/12668,2023," Kohn-Sham Density Functional Theory (KS-DFT) has been traditionally solved by the Self-Consistent Field (SCF) method. Behind the SCF loop is the physics intuition of solving a system of non-interactive single-electron wave functions under an effective potential. In this work, we propose a deep learning approach to KS-DFT. First, in contrast to the conventional SCF loop, we propose to directly minimize the total energy by reparameterizing the orthogonal constraint as a feed-forward computation. We prove that such an approach has the same expressivity as the SCF method, yet reduces the computational complexity from O(N^4) to O(N^3). Second, the numerical integration which involves a summation over the quadrature grids can be amortized to the optimization steps. At each step, stochastic gradient descent (SGD) is performed with a sampled minibatch of the grids. Extensive experiments are carried out to demonstrate the advantage of our approach in terms of efficiency and stability. In addition, we show that our approach enables us to explore more complex neural-based wave functions.",Oral 1 Track 2: Machine Learning for Sciences,https://openreview.net/pdf?id=aBWnqqsuot7,
"['Ahmed Touati', 'Jérémy Rapin', 'Yann Ollivier']",ICLR,Does Zero-Shot Reinforcement Learning Exist?,https://iclr.cc/virtual/2023/oral/12581,2023," A zero-shot RL agent is an agent that can solve any RL task in a given environment, instantly with no additional planning or learning, after an initial reward-free learning phase. This marks a shift from the reward-centric RL paradigm towards controllable agents that can follow arbitrary instructions in an environment. Current RL agents can solve families of related tasks at best, or require planning anew for each task. Strategies for approximate zero-shot RL have been suggested using successor features (SFs) (Borsa et al., 2018) or forward-backward (FB) representations (Touati & Ollivier, 2021), but testing has been limited. After clarifying the relationships between these schemes, we introduce improved losses and new SF models, and test the viability of zero-shot RL schemes systematically on tasks from the Unsupervised RL benchmark (Laskin et al., 2021). To disentangle universal representation learning from exploration, we work in an offline setting and repeat the tests on several existing replay buffers.SFs appear to suffer from the choice of the elementary state features. SFs with Laplacian eigenfunctions do well, while SFs based on auto-encoders, inverse curiosity, transition models, low-rank transition matrix, contrastive learning, or diversity (APS),  perform unconsistently. In contrast, FB representations jointly learn the elementary and successor features from a single, principled criterion. They perform best and consistently across the board, reaching $85\%$ of supervised RL performance with a good replay buffer, in a zero-shot manner.",Oral 1 Track 5: Reinforcement Learning,https://openreview.net/pdf?id=MYEap_OcQI,
"[""Pierluca D'Oro"", 'Max Schwarzer', 'Evgenii Nikishin', 'Pierre-Luc Bacon', 'Marc G Bellemare', 'Aaron Courville']",ICLR,Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier,https://iclr.cc/virtual/2023/oral/12655,2023," Increasing the replay ratio, the number of updates of an agent's parameters per environment interaction, is an appealing strategy for improving the sample efficiency of deep reinforcement learning algorithms. In this work, we show that fully or partially resetting the parameters of deep reinforcement learning agents causes better replay ratio scaling capabilities to emerge. We push the limits of the sample efficiency of carefully-modified algorithms by training them using an order of magnitude more updates than usual, significantly improving their performance in the Atari 100k and DeepMind Control Suite benchmarks. We then provide an analysis of the design choices required for favorable replay ratio scaling to be possible and discuss inherent limits and tradeoffs.",Oral 2 Track 4: Reinforcement Learning,https://openreview.net/pdf?id=OpC-9aBBVJe,
"['Hayeon Lee', 'Sohyun An', 'Minseon Kim', 'Sung Ju Hwang']",ICLR,Meta-prediction Model for Distillation-Aware NAS on Unseen Datasets,https://iclr.cc/virtual/2023/oral/12673,2023," Distillation-aware Network Architecture Search (DaNAS) aims to search for an optimal student architecture that obtains the best performance and/or efficiency when distilling the knowledge from a given teacher model. Previous DaNAS methods have mostly tackled the search for the network architecture for fixed source/target tasks and the teacher, which are not generalized well on a new task, thus need to perform a costly search for any new combination of the domains and the teachers. For standard NAS tasks without KD, meta-learning-based computationally efficient NAS methods have been proposed, which learn the generalized search process over multiple tasks and transfer the knowledge obtained over those tasks to a new task. However, since they assume learning from scratch without KD from a teacher, they might not be ideal for DaNAS scenarios, which could significantly affect the final performances of the architectures obtained from the search. To eliminate the excessive computational cost of DaNAS methods and the sub-optimality of rapid NASmethods, we propose a distillation-aware meta accuracy prediction model, DaSS (Distillation-aware Student Search), which can predict a given architecture’s final performances on a dataset when performing KD with a given teacher, without having actually to train it on the target task. The experimental results demonstrate that our proposed meta-prediction model successfully generalizes to multiple unseen datasets for DaNAS tasks, largely outperforming existing meta-NAS methods and rapid NAS baselines. Code is available at https://github.com/CownowAn/DaSS.",Oral 1 Track 6: Deep Learning and representational learning II,https://openreview.net/pdf?id=SEh5SfEQtqB,
"['Hoang Anh Just', 'Feiyang Kang', 'Tianhao Wang', 'Yi Zeng', 'Myeongseob Ko', 'Ming Jin', 'Ruoxi Jia']",ICLR,LAVA: Data Valuation without Pre-Specified Learning Algorithms,https://iclr.cc/virtual/2023/oral/12671,2023," Traditionally, data valuation is posed as a problem of equitably splitting the validation performance of a learning algorithm among the training data. As a result, the calculated data values depend on many design choices of the underlying learning algorithm. However, this dependence is undesirable for many use cases of data valuation, such as setting priorities over different data sources in a data acquisition process and informing pricing mechanisms in a data marketplace. In these scenarios, data needs to be valued before the actual analysis and the choice of the learning algorithm is still undetermined then. Another side-effect of the dependence is that to assess the value of individual points, one needs to re-run the learning algorithm with and without a point, which incurs a large computation burden. This work leapfrogs over the current limits of data valuation methods by introducing a new framework that can value training data in a way that is oblivious to the downstream learning algorithm. Our main results are as follows. $\textbf{(1)}$ We develop a proxy for the validation performance associated with a training set based on a non-conventional $\textit{class-wise}$ $\textit{Wasserstein distance}$ between the training and the validation set. We show that the distance characterizes the upper bound of the validation performance for any given model under certain Lipschitz conditions. $\textbf{(2)}$ We develop a novel method to value individual data based on the sensitivity analysis of the $\textit{class-wise}$ Wasserstein distance. Importantly, these values can be directly obtained $\textit{for free}$ from the output of off-the-shelf optimization solvers once the Wasserstein distance is computed. $\textbf{(3) }$We evaluate our new data valuation framework over various use cases related to detecting low-quality dataand show that, surprisingly, the learning-agnostic feature of our framework enables a $\textit{significant improvement}$ over the state-of-the-art performance while being $\textit{orders of magnitude faster.}$",Oral 2 Track 2: General Machine Learning,https://openreview.net/pdf?id=JJuP86nBl4q,
"['Joey Hong', 'Kush Bhatia', 'Anca Dragan']",ICLR,On the Sensitivity of Reward Inference to Misspecified Human Models,https://iclr.cc/virtual/2023/oral/12738,2023," Inferring reward functions from human behavior is at the center of value alignment – aligning AI objectives with what we, humans, actually want. But doing so relies on models of how humans behave given their objectives. After decades of research in cognitive science, neuroscience, and behavioral economics, obtaining accurate human models remains an open research topic. This begs the question: how accurate do these models need to be in order for the reward inference to be accurate? On the one hand, if small errors in the model can lead to catastrophic error in inference, the entire framework of reward learning seems ill-fated, as we will never have perfect models of human behavior. On the other hand, if as our models improve, we can have a guarantee that reward accuracy also improves, this would show the benefit of more work on the modeling side. We study this question both theoretically and empirically. We do show that it is unfortunately possible to construct small adversarial biases in behavior that lead to arbitrarily large errors in the inferred reward. However, and arguably more importantly, we are also able to identify reasonable assumptions under which the reward inference error can be bounded linearly in the error in the human model. Finally, we verify our theoretical insights in discrete and continuous control tasks with simulated and human data.",Oral 3 Track 1: Reinforcement Learning,https://openreview.net/pdf?id=hJqGbUpDGV,
"['Adrien Journé', 'Hector Garcia Rodriguez', 'Qinghai Guo', 'Timoleon Moraitis']",ICLR,Hebbian Deep Learning Without Feedback,https://iclr.cc/virtual/2023/oral/12759,2023," Recent approximations to backpropagation (BP) have mitigated many of BP's computational inefficiencies and incompatibilities with biology, but important limitations still remain. Moreover, the approximations significantly decrease accuracy in benchmarks, suggesting that an entirely different approach may be more fruitful. Here, grounded on recent theory for Hebbian learning in soft winner-take-all networks, we present multilayer SoftHebb, i.e. an algorithm that trains deep neural networks, without any feedback, target, or error signals. As a result, it achieves efficiency by avoiding weight transport, non-local plasticity, time-locking of layer updates, iterative equilibria, and (self-) supervisory or other feedback signals – which were necessary in other approaches. Its increased efficiency and biological compatibility do not trade off accuracy compared to state-of-the-art bio-plausible learning, but rather improve it. With up to five hidden layers and an added linear classifier, accuracies on MNIST, CIFAR-10, STL-10, and ImageNet, respectively reach 99.4%, 80.3%, 76.2%, and 27.3%. In conclusion, SoftHebb shows with a radically different approach from BP that Deep Learning over few layers may be plausible in the brain and increases the accuracy of bio-plausible machine learning. Code is available at https://github.com/NeuromorphicComputing/SoftHebb.",Oral 1 Track 3: Neuroscience and Cognitive Science & General Machine Learning,https://openreview.net/pdf?id=8gd4M-_Rj1,
"['Jiri Hron', 'Karl Krauth', 'Michael Jordan', 'Niki Kilbertus', 'Sarah Dean']",ICLR,Modeling content creator incentives on algorithm-curated platforms,https://iclr.cc/virtual/2023/oral/12766,2023," Content creators compete for user attention. Their reach crucially depends on algorithmic choices made by developers on online platforms. To maximize exposure, many creators adapt strategically, as evidenced by examples like the sprawling search engine optimization industry. This begets competition for the finite user attention pool. We formalize these dynamics in what we call an exposure game, a model of incentives induced by modern algorithms including factorization and (deep) two-tower architectures. We prove that seemingly innocuous algorithmic choices—e.g., non-negative vs. unconstrained factorization—significantly affect the existence and character of (Nash) equilibria in exposure games. We proffer use of creator behavior models like ours for an (ex-ante) pre-deployment audit. Such an audit can identify misalignment between desirable and incentivized content, and thus complement post-hoc measures like content filtering and moderation. To this end, we propose tools for numerically finding equilibria in exposure games, and illustrate results of an audit on the MovieLens and LastFM datasets. Among else, we find that the strategically produced content exhibits strong dependence between algorithmic exploration and content diversity, and between model expressivity and bias towards gender-based user and creator groups.",Oral 2 Track 5: Generative models & Theory,https://openreview.net/pdf?id=l6CpxixmUg,
"['Olga Golovneva', 'Moya Chen', 'spencer poff', 'Martin Corredor', 'Luke Zettlemoyer', 'Maryam Fazel-Zarandi', 'Asli Celikyilmaz']",ICLR,ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning,https://iclr.cc/virtual/2023/oral/12565,2023," Large language models show improved downstream task performance when prompted to generate step-by-step reasoning to justify their final answers. These reasoning steps greatly improve model interpretability and verification, but objectively studying their correctness (independent of the final answer) is difficult without reliable methods for automatic evaluation. We simply do not know how often the stated reasoning steps actually support the final end task predictions. In this work, we present ROSCOE, a suite of interpretable, unsupervised automatic scores that improve and extend previous text generation evaluation metrics. To evaluate ROSCOE against baseline metrics, we design a typology of reasoning errors and collect synthetic and human evaluation scores on commonly used reasoning datasets. In contrast with existing metrics, ROSCOE can measure semantic consistency, logicality, informativeness, fluency, and factuality — among other traits — by leveraging properties of step-by-step rationales. We empirically verify the strength of our metrics on five human annotated and six programmatically perturbed diagnostics datasets - covering a diverse set of tasks that require reasoning skills and show that ROSCOE can consistently outperform baseline metrics.",Oral 2 Track 6: Applications & Social Aspects of Machine Learning,https://openreview.net/pdf?id=xYlJRpzZtsY,
"['Tianlong Chen', 'Zhenyu Zhang', 'AJAY JAISWAL', 'Shiwei Liu', 'Zhangyang Wang']",ICLR,Sparse MoE as the New Dropout: Scaling Dense and Self-Slimmable Transformers,https://iclr.cc/virtual/2023/oral/12718,2023," Despite their remarkable achievement, gigantic transformers encounter significant drawbacks, including exorbitant computational and memory footprints during training, as well as severe collapse evidenced by a high degree of parameter redundancy. Sparsely-activated Mixture-of-Experts (SMoEs) have shown promise to mitigate the issue of training efficiency, yet they are prone to (1) $\textit{redundant experts}$ due to representational collapse; and (2) $\textit{poor expert scalability for inference and downstream fine-tuning}$, primarily due to overfitting of the learned routing policy to the number of activated experts during training. As recent research efforts are predominantly focused on improving routing policies to encourage expert specializations, this work focuses on $\textit{exploring the overlooked scalability bottleneck of SMoEs}$ and leveraging it to effectively $\textbf{scale dense transformers}$. To this end, we propose a new plug-and-play training framework, $\textbf{SMoE-Dropout}$, to enable scaling transformers to better accuracy in their full capacity without collapse. Specifically, SMoE-Dropout consists of a $\textit{randomly initialized and fixed}$ router network to activate experts and gradually increases the activated expert number as training progresses over time. Transformers trained by SMoE-Dropout naturally exhibit a $\textbf{``self-slimmable”}$ property subject to resource availability, offering smooth and consistent performance boosts with an increase in activated experts during inference or fine-tuning. Our extensive experiments across diverse transformer architectures on a variety of tasks demonstrate the superior performance and substantial computation savings of SMoE-Dropout, compared to dense training baselines with equivalent parameter counts. In particular, our trained BERT outperforms its densely trained counterpart with consistent improvements of {$1.03\%$, $0.78\%$, $1.09\%$} on challenging reasoning tasks {$\texttt{ASDiv-A}$, $\texttt{MAWPS}$, $\texttt{SVAMP}$}, respectively. Codes and models are available in https://github.com/VITA-Group/Random-MoE-as-Dropout.",Oral 3 Track 2: Deep Learning and representational learning,https://openreview.net/pdf?id=w1hwFUb_81,
"['Ruiqi Ni', 'Ahmed Qureshi']",ICLR,NTFields: Neural Time Fields for Physics-Informed Robot Motion Planning,https://iclr.cc/virtual/2023/oral/12669,2023," Neural Motion Planners (NMPs) have emerged as a promising tool for solving robot navigation tasks in complex environments. However, these methods often require expert data for learning, which limits their application to scenarios where data generation is time-consuming. Recent developments have also led to physics-informed deep neural models capable of representing complex dynamical Partial Differential Equations (PDEs). Inspired by these developments, we propose Neural Time Fields (NTFields) for robot motion planning in cluttered scenarios. Our framework represents a wave propagation model generating continuous arrival time to find path solutions informed by a nonlinear first-order PDE called Eikonal Equation. We evaluate our method in various cluttered 3D environments, including the Gibson dataset, and demonstrate its ability to solve motion planning problems for 4-DOF and 6-DOF robot manipulators where the traditional grid-based Eikonal planners often face the curse of dimensionality. Furthermore, the results show that our method exhibits high success rates and significantly lower computational times than the state-of-the-art methods, including NMPs that require training data from classical planners.",Oral 2 Track 1: Applications,https://openreview.net/pdf?id=ApF0dmi1_9K,
"['Léon Zheng', 'Gilles Puy', 'Elisa Riccietti', 'Patrick Perez', 'Rémi Gribonval']",ICLR,Self-supervised learning with rotation-invariant kernels,https://iclr.cc/virtual/2023/oral/12685,2023," We introduce a regularization loss based on kernel mean embeddings with rotation-invariant kernels on the hypersphere (also known as dot-product kernels) for self-supervised learning of image representations. Besides being fully competitive with the state of the art, our method significantly reduces time and memory complexity for self-supervised training, making it implementable for very large embedding dimensions on existing devices and more easily adjustable than previous methods to settings with limited resources. Our work follows the major paradigm where the model learns to be invariant to some predefined image transformations (cropping, blurring, color jittering, etc.), while avoiding a degenerate solution by regularizing the embedding distribution. Our particular contribution is to propose a loss family promoting the embedding distribution to be close to the uniform distribution on the hypersphere, with respect to the maximum mean discrepancy pseudometric. We demonstrate that this family encompasses several regularizers of former methods, including uniformity-based and information-maximization methods, which are variants of our flexible regularization loss with different kernels. Beyond its practical consequences for state of the art self-supervised learning with limited resources, the proposed generic regularization approach opens perspectives to leverage more widely the literature on kernel methods in order to improve self-supervised learning methods.",Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=8uu6JStuYm,
"['Zhili LIU', 'Kai Chen', 'Jianhua Han', 'Lanqing HONG', 'Hang Xu', 'Zhenguo Li', 'James Kwok']",ICLR,Task-customized Masked Autoencoder via Mixture of Cluster-conditional Experts,https://iclr.cc/virtual/2023/oral/12640,2023," Masked Autoencoder (MAE) is a prevailing self-supervised learning method that achieves promising results in model pre-training. However, when the various downstream tasks have data distributions different from the pre-training data, the semantically irrelevant pre-training information might result in negative transfer, impeding MAE’s scalability. To address this issue, we propose a novel MAE-based pre-training paradigm, Mixture of Cluster-conditional Experts (MoCE), which can be trained once but provides customized pre-training models for diverse downstream tasks. Different from the mixture of experts (MoE), our MoCE trains each expert only with semantically relevant images by using cluster-conditional gates. Thus, each downstream task can be allocated to its customized model pre-trained with data most similar to the downstream data. Experiments on a collection of 11 downstream tasks show that MoCE outperforms the vanilla MAE by 2.45\% on average. It also obtains new state-of-the-art self-supervised learning results on detection and segmentation.",Oral 4 Track 1: Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=j8IiQUM33s,
"['Jiajun Fan', 'Yuzheng Zhuang', 'Yuecheng Liu', 'Jianye HAO', 'Bin Wang', 'Jiangcheng Zhu', 'Hao Wang', 'Shu-Tao Xia']",ICLR,Learnable Behavior Control: Breaking Atari Human World Records via Sample-Efficient Behavior Selection,https://iclr.cc/virtual/2023/oral/12618,2023," The exploration problem is one of the main challenges in deep reinforcement learning (RL). Recent promising works tried to handle the problem with population-based methods, which collect samples with diverse behaviors derived from a population of different exploratory policies. Adaptive policy selection has been adopted for behavior control. However, the behavior selection space is largely limited by the predefined policy population, which further limits behavior diversity.  In this paper, we propose a general framework called Learnable Behavioral Control (LBC) to address the limitation, which a) enables a significantly enlarged behavior selection space via formulating a hybrid behavior mapping from all policies; b) constructs a unified learnable process for behavior selection. We introduce LBC into distributed off-policy actor-critic methods and achieve behavior control via optimizing the selection of the behavior mappings with bandit-based meta-controllers. Our agents have achieved 10077.52% mean human normalized score and surpassed 24 human world records within 1B training frames in the Arcade Learning Environment, which demonstrates our significant state-of-the-art (SOTA) performance without degrading the sample efficiency.",Oral 4 Track 4: Reinforcement Learning II,https://openreview.net/pdf?id=FeWvD0L_a4,
"['Marcel Seelbach Benkner', 'Maximilian Krahn', 'Edith Tretschk', 'Zorah Lähner', 'Michael Moeller', 'Vladislav Golyanik']",ICLR,QuAnt: Quantum Annealing with Learnt Couplings,https://iclr.cc/virtual/2023/oral/12642,2023," Modern quantum annealers can find high-quality solutions to combinatorial optimisation objectives given as quadratic unconstrained binary optimisation (QUBO) problems. Unfortunately, obtaining suitable QUBO forms in computer vision remains challenging and currently requires problem-specific analytical derivations. Moreover, such explicit formulations impose tangible constraints on solution encodings. In stark contrast to prior work, this paper proposes to learn QUBO forms from data through gradient backpropagation instead of deriving them. As a result, the solution encodings can be  chosen flexibly and compactly. Furthermore, our methodology is general and virtually independent of the specifics of the target problem type. We demonstrate the advantages of learnt  QUBOs on the diverse problem types of graph matching, 2D point cloud alignment and 3D rotation estimation. Our results are competitive with the previous quantum state of the art while requiring much fewer logical and physical qubits, enabling our method to scale to larger problems. The code and the new dataset are available at https://4dqv.mpi-inf.mpg.de/QuAnt/.",Oral 3 Track 5: Deep Learning and representational learning & Neuroscience and Cognitive Science,https://openreview.net/pdf?id=isiQ5KIXbjj,
"['Nico Gürtler', 'Sebastian Blaes', 'Pavel Kolev', 'Felix Widmaier', 'Manuel Wuthrich', 'Stefan Bauer', 'Bernhard Schoelkopf', 'Georg Martius']",ICLR,Benchmarking Offline Reinforcement Learning on Real-Robot Hardware,https://iclr.cc/virtual/2023/oral/12548,2023," Learning policies from previously recorded data is a promising direction for real-world robotics tasks, as online learning is often infeasible. Dexterous manipulation in particular remains an open problem in its general form. The combination of offline reinforcement learning with large diverse datasets, however, has the potential to lead to a breakthrough in this challenging domain analogously to the rapid progress made in supervised learning in recent years. To coordinate the efforts of the research community toward tackling this problem, we propose a benchmark including: i) a large collection of data for offline learning from a dexterous manipulation platform on two tasks, obtained with capable RL agents trained in simulation; ii) the option to execute learned policies on a real-world robotic system and a simulation for efficient debugging. We evaluate prominent open-sourced offline reinforcement learning algorithms on the datasets and provide a reproducible experimental setup for offline reinforcement learning on real systems.",Oral 4 Track 3: Reinforcement Learning I,https://openreview.net/pdf?id=3k5CUGDLNdd,
"['Yingda Yin', 'Yang Wang', 'He Wang', 'Baoquan Chen']",ICLR,A Laplace-inspired Distribution on SO(3) for Probabilistic Rotation Estimation,https://iclr.cc/virtual/2023/oral/12627,2023," Estimating the 3DoF rotation from a single RGB image is an important yet challenging problem. Probabilistic rotation regression has raised more and more attention with the benefit of expressing uncertainty information along with the prediction. Though modeling noise using Gaussian-resembling Bingham distribution and matrix Fisher distribution is natural, they are shown to be sensitive to outliers for the nature of quadratic punishment to deviations. In this paper, we draw inspiration from multivariate Laplace distribution and propose a novel Rotation Laplace distribution on SO(3). Rotation Laplace distribution is robust to the disturbance of outliers and enforces much gradient to the low-error region, resulting in a better convergence. Our extensive experiments show that our proposed distribution achieves state-of-the-art performance for rotation regression tasks over both probabilistic and non-probabilistic baselines. Our project page is at pku-epic.github.io/RotationLaplace.",Oral 4 Track 2: Probabilistic Methods,https://openreview.net/pdf?id=Mvetq8DO05O,
"['Zahra Kadkhodaie', 'Florentin Guth', 'Stéphane Mallat', 'Eero Simoncelli']",ICLR,Learning multi-scale local conditional probability models of images,https://iclr.cc/virtual/2023/oral/12697,2023," Deep neural networks can learn powerful prior probability models for images, as evidenced by the high-quality generations obtained with recent score-based diffusion methods. But the means by which these networks capture complex global statistical structure, apparently without suffering from the curse of dimensionality, remain a mystery. To study this, we incorporate diffusion methods into a multi-scale decomposition, reducing dimensionality by assuming a stationary local Markov model for wavelet coefficients conditioned on coarser-scale coefficients. We instantiate this model using convolutional neural networks (CNNs) with local receptive fields, which enforce both the stationarity and Markov properties. Global structures are captured using a CNN with receptive fields covering the entire (but small) low-pass image. We test this model on a dataset of face images, which are highly non-stationary and contain large-scale geometric structures.Remarkably, denoising, super-resolution, and image synthesis results all demonstrate that these structures can be captured with significantly smaller conditioning neighborhoods than required by a Markov model implemented in the pixel domain. Our results show that score estimation for large complex images can be reduced to low-dimensional Markov conditional models across scales,  alleviating the curse of dimensionality.",Oral 3 Track 3: Generative models,https://openreview.net/pdf?id=VZX2I_VVJKH,
"['Divyansh Jhunjhunwala', 'Shiqiang Wang', 'Gauri Joshi']",ICLR,FedExP: Speeding Up Federated Averaging via Extrapolation,https://iclr.cc/virtual/2023/oral/12638,2023," Federated Averaging (FedAvg) remains the most popular algorithm for Federated Learning (FL) optimization due to its simple implementation, stateless nature, and privacy guarantees combined with secure aggregation. Recent work has sought to generalize the vanilla averaging in FedAvg to a generalized gradient descent step by treating client updates as pseudo-gradients and using a server step size. While the use of a server step size has been shown to provide performance improvement theoretically, the practical benefit of the server step size has not been seen in most existing works. In this work, we present FedExP, a method to adaptively determine the server step size in FL based on dynamically varying pseudo-gradients throughout the FL process. We begin by considering the overparameterized convex regime, where we reveal an interesting similarity between FedAvg and the Projection Onto Convex Sets (POCS) algorithm. We then show how FedExP can be motivated as a novel extension to the extrapolation mechanism that is used to speed up POCS. Our theoretical analysis later also discusses the implications of FedExP in underparameterized and non-convex settings. Experimental results show that FedExP consistently converges faster than FedAvg and competing baselines on a range of realistic FL datasets.",Oral 5 Track 2: Optimization,https://openreview.net/pdf?id=IPrzNbddXV,
"['Nimrod Berman', 'Ilan Naiman', 'Omri Azencot']",ICLR,Multifactor Sequential Disentanglement via Structured Koopman Autoencoders,https://iclr.cc/virtual/2023/oral/12605,2023," Disentangling complex data to its latent factors of variation is a fundamental task in representation learning. Existing work on sequential disentanglement mostly provides two factor representations, i.e., it separates the data to time-varying and time-invariant factors. In contrast, we consider multifactor disentanglement in which multiple (more than two) semantic disentangled components are generated. Key to our approach is a strong inductive bias where we assume that the underlying dynamics can be represented linearly in the latent space. Under this assumption, it becomes natural to exploit the recently introduced Koopman autoencoder models. However, disentangled representations are not guaranteed in Koopman approaches, and thus we propose a novel spectral loss term which leads to structured Koopman matrices and disentanglement. Overall, we propose a simple and easy to code new deep model that is fully unsupervised and it supports multifactor disentanglement. We showcase new disentangling abilities such as swapping of individual static factors between characters, and an incremental swap of disentangled factors from the source to the target. Moreover, we evaluate our method extensively on two factor standard benchmark tasks where we significantly improve over competing unsupervised approaches, and we perform competitively in comparison to weakly- and self-supervised state-of-the-art approaches. The code is available at https://github.com/azencot-group/SKD.",Oral 4 Track 6: Deep Learning and representational learning- Reinforcement Learning,https://openreview.net/pdf?id=6fuPIe9tbnC,
"['Saachi Jain', 'Hannah Lawrence', 'Ankur Moitra', 'Aleksander Madry']",ICLR,Distilling Model Failures as Directions in Latent Space,https://iclr.cc/virtual/2023/oral/12544,2023," Existing methods for isolating hard subpopulations and spurious correlations in datasets often require human intervention. This can make these methods labor-intensive and dataset-specific. To address these shortcomings, we present a scalable method for automatically distilling a model's failure modes. Specifically, we harness linear classifiers to identify consistent error patterns, and, in turn, induce a natural representation of these failure modes as directions within the feature space. We demonstrate that this framework allows us to discover and automatically caption challenging subpopulations within the training dataset. Moreover, by combining our framework with off-the-shelf diffusion models, we can generate images that are especially challenging for the analyzed model, and thus can be used to perform synthetic data augmentation that helps remedy the model's failure modes.",Oral 5 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=99RpBVpLiX,
"['Jikai Jin', 'Yiping Lu', 'Jose Blanchet', 'Lexing Ying']",ICLR,Minimax Optimal Kernel Operator Learning via Multilevel Training,https://iclr.cc/virtual/2023/oral/12553,2023," Learning mappings between infinite-dimensional function spaces have achieved empirical success in many disciplines of machine learning, including generative modeling, functional data analysis, causal inference, and multi-agent reinforcement learning. In this paper, we study the statistical limit of learning a Hilbert-Schmidt operator between two infinite-dimensional Sobolev reproducing kernel Hilbert spaces. We establish the information-theoretic lower bound in terms of the Sobolev Hilbert-Schmidt norm and show that a regularization that learns the spectral components below the bias contour and ignores the ones above the variance contour can achieve the optimal learning rate. At the same time, the spectral components between the bias and variance contours give us flexibility in designing computationally feasible machine learning algorithms. Based on this observation, we develop a multilevel kernel operator learning algorithm that is optimal when learning linear operators between infinite-dimensional function spaces.",Oral 4 Track 5: Machine Learning for Sciences & Probabilistic Methods,https://openreview.net/pdf?id=zEn1BhaNYsC,
"['Zizhao Zhang', 'Xin Wang', 'Chaoyu Guan', 'Ziwei Zhang', 'Haoyang Li', 'Wenwu Zhu']",ICLR,AutoGT: Automated Graph Transformer Architecture Search,https://iclr.cc/virtual/2023/oral/12707,2023," Although Transformer architectures have been successfully applied to graph data with the advent of Graph Transformer, current design of Graph Transformer still heavily relies on human labor and expertise knowledge to decide proper neural architectures and suitable graph encoding strategies at each Transformer layer. In literature, there have been some works on automated design of Transformers focusing on non-graph data such as texts and images without considering graph encoding strategies, which fail to handle the non-euclidean graph data. In this paper, we study the problem of automated graph Transformer, for the first time. However, solving these problems poses the following challenges: i) how can we design a unified search space for graph Transformer, and ii) how to deal with the coupling relations between Transformer architectures and the graph encodings of each Transformer layer. To address these challenges, we propose Automated Graph Transformer (AutoGT), a neural architecture search framework that can automatically discover the optimal graph Transformer architectures by joint optimization of Transformer architecture and graph encoding strategies. Specifically, we first propose a unified graph Transformer formulation that can represent most of state-of-the-art graph Transformer architectures. Based upon the unified formulation, we further design the graph Transformer search space that includes both candidate architectures and various graph encodings. To handle the coupling relations, we propose a novel encoding-aware performance estimation strategy by gradually training and splitting the supernets according to the correlations between graph encodings and architectures. The proposed strategy can provide a more consistent and fine-grained performance prediction when evaluating the jointly optimized graph encodings and architectures. Extensive experiments and ablation studies show that our proposed AutoGT gains sufficient improvement over state-of-the-art hand-crafted baselines on all datasets, demonstrating its effectiveness and wide applicability.",Oral 6 Track 4: Applications & Social Aspects of Machine Learning & General Machine Learning,https://openreview.net/pdf?id=GcM7qfl5zY,
"['Frederic Koehler', 'Alexander Heckett', 'Andrej Risteski']",ICLR,Statistical Efficiency of Score Matching: The View from Isoperimetry,https://iclr.cc/virtual/2023/oral/12712,2023," Deep generative models parametrized up to a normalizing constant (e.g. energy-based models) are difficult to train by maximizing the likelihood of the data because the likelihood and/or gradients thereof cannot be explicitly or efficiently written down. Score matching is a training method, whereby instead of fitting the likelihood $\log p(x)$ for the training data, we instead fit the score function $\nabla_x \log p(x)$ --- obviating the need to evaluate the partition function. Though this estimator is known to be consistent, its unclear whether (and when) its statistical efficiency is comparable to that of maximum likelihood --- which is known to be (asymptotically) optimal. We initiate this line of inquiry in this paper, and show a tight connection between statistical efficiency of score matching and the isoperimetric properties of the distribution being estimated --- i.e. the Poincar\'e, log-Sobolev and isoperimetric constant --- quantities which govern the mixing time of Markov processes like Langevin dynamics. Roughly, we show that the score matching estimator is statistically comparable to the maximum likelihood when the  distribution has a small isoperimetric constant. Conversely, if the distribution has a large isoperimetric constant --- even for simple families of distributions like exponential families with rich enough sufficient statistics --- score matching will be substantially less efficient than maximum likelihood. We suitably formalize these results both in the finite sample regime, and in the asymptotic regime. Finally, we identify a direct parallel in the discrete setting, where we connect the statistical properties of pseudolikelihood estimation with approximate tensorization of entropy and the Glauber dynamics.",Oral 6 Track 1: Theory,https://openreview.net/pdf?id=TD7AnQjNzR6,
"['Tuomas Oikarinen', 'Tsui-Wei Weng']",ICLR,CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks,https://iclr.cc/virtual/2023/oral/12723,2023," In this paper, we propose CLIP-Dissect, a new technique to automatically describe the function of individual hidden neurons inside vision networks. CLIP-Dissect leverages recent advances in multimodal vision/language models to label internal neurons with open-ended concepts without the need for any labeled data or human examples. We show that CLIP-Dissect provides more accurate descriptions than existing methods for last layer neurons where the ground-truth is available as well as qualitatively good descriptions for hidden layer neurons. In addition, our method is very flexible: it is model agnostic, can easily handle new concepts and can be extended to take advantage of better multimodal models in the future. Finally CLIP-Dissect is computationally efficient and can label all neurons from five layers of ResNet-50 in just 4 minutes, which is more than 10$\times$ faster than existing methods. Our code is available at https://github.com/Trustworthy-ML-Lab/CLIP-dissect.",Oral 5 Track 1: Unsupervised and Self-supervised learning & Social Aspects of Machine Learning-,https://openreview.net/pdf?id=iPWiwWHc1V,
"['Yongshuo Zong', 'Yongxin Yang', 'Timothy Hospedales']",ICLR,MEDFAIR: Benchmarking Fairness for Medical Imaging,https://iclr.cc/virtual/2023/oral/12546,2023," A multitude of work has shown that machine learning-based medical diagnosis systems can be biased against certain subgroups of people. This has motivated a growing number of bias mitigation algorithms that aim to address fairness issues in machine learning. However, it is difficult to compare their effectiveness in medical imaging for two reasons. First, there is little consensus on the criteria to assess fairness. Second, existing bias mitigation algorithms are developed under different settings, e.g., datasets, model selection strategies, backbones, and fairness metrics, making a direct comparison and evaluation based on existing results impossible. In this work, we introduce MEDFAIR, a framework to benchmark the fairness of machine learning models for medical imaging. MEDFAIR covers eleven algorithms from various categories, ten datasets from different imaging modalities, and three model selection criteria. Through extensive experiments, we find that the under-studied issue of model selection criterion can have a significant impact on fairness outcomes; while in contrast, state-of-the-art bias mitigation algorithms do not significantly improve fairness outcomes over empirical risk minimization (ERM) in both in-distribution and out-of-distribution settings. We evaluate fairness from various perspectives and make recommendations for different medical application scenarios that require different ethical principles. Our framework provides a reproducible and easy-to-use entry point for the development and evaluation of future bias mitigation algorithms in deep learning. Code is available at https://github.com/ys-zong/MEDFAIR.",Oral 6 Track 2: Infrastructure & Social Aspects of Machine Learning,https://openreview.net/pdf?id=6ve2CkeQe5S,
"['Ido Galil', 'Mohammed Dabbah', 'Ran El-Yaniv']",ICLR,A framework for benchmarking Class-out-of-distribution detection and its application to ImageNet,https://iclr.cc/virtual/2023/oral/12531,2023," When deployed for risk-sensitive tasks, deep neural networks must be able to detect instances with labels from outside the distribution for which they were trained.In this paper we present a novel framework to benchmark the ability of image classifiers to detect class-out-of-distribution instances(i.e., instances whose true labels do not appear in the training distribution) at various levels of detection difficulty.We apply this technique to ImageNet, and benchmark 525 pretrained, publicly available, ImageNet-1k classifiers. The code for generating a benchmark for any ImageNet-1k classifier, along with the benchmarks prepared for the above-mentioned 525 models is available at https://github.com/mdabbah/COOD_benchmarking.The usefulness of the proposed framework and its advantage over alternative existing benchmarks is demonstrated by analyzing the results obtained for these models, which reveals numerous novel observations including:(1) knowledge distillation consistently improves class-out-of-distribution (C-OOD) detection performance; (2) a subset of ViTs performs better C-OOD detection than any other model; (3) the language–-vision CLIP model achieves good zero-shot detection performance, with its best instance outperforming 96% of all other models evaluated; (4) accuracy and in-distribution ranking are positively correlated to C-OOD detection; and (5) we compare various confidence functions for C-OOD detection.Our companion paper, also published in ICLR 2023 (What Can We Learn From The Selective Prediction And Uncertainty Estimation Performance Of 523 Imagenet Classifiers), examines the uncertainty estimation performance (ranking, calibration, and selective prediction performance) of these classifiers in an in-distribution setting.",Oral 6 Track 6: Deep Learning,https://openreview.net/pdf?id=Iuubb9W6Jtk,
"['Yiming Zuo', 'Jia Deng']",ICLR,View Synthesis with Sculpted Neural Points,https://iclr.cc/virtual/2023/oral/12591,2023," We address the task of view synthesis, generating novel views of a scene given a set of images as input. In many recent works such as NeRF (Mildenhall et al., 2020), the scene geometry is parameterized using neural implicit representations (i.e., MLPs). Implicit neural representations have achieved impressive visual quality but have drawbacks in computational efficiency. In this work, we propose a new approach that performs view synthesis using point clouds. It is the first point-based method that achieves better visual quality than NeRF while being 100× faster in rendering speed. Our approach builds on existing works on differentiable point-based rendering but introduces a novel technique we call “Sculpted Neural Points (SNP)”, which significantly improves the robustness to errors and holes in the reconstructed point cloud. We further propose to use view-dependent point features based on spherical harmonics to capture non-Lambertian surfaces, and new designs in the point-based rendering pipeline that further boost the performance. Finally, we show that our system supports fine-grained scene editing. Code is available at https://github.com/princeton-vl/SNP.",Oral 5 Track 4: Applications & Optimization,https://openreview.net/pdf?id=0ypGZvm0er0,
"['Avrajit Ghosh', 'HE LYU', 'Xitong Zhang', 'Rongrong Wang']",ICLR,Implicit regularization in Heavy-ball momentum accelerated stochastic gradient descent,https://iclr.cc/virtual/2023/oral/12593,2023," It is well known that the finite step-size ($h$) in Gradient descent (GD) implicitly regularizes solutions to flatter minimas. A natural question to ask is \textit{Does the momentum parameter $\beta$ (say) play a role in implicit regularization in Heavy-ball (H.B) momentum accelerated gradient descent (GD+M)?}. To answer this question, first, we show that  the trajectory traced by discrete H.B momentum update (GD+M) is $O(h^2)$ close to a continuous trajectory induced by a modified loss, which consists of an original loss and an implicit regularizer. This implicit regularizer for (GD+M) is indeed stronger than that of (GD) by factor of $(\frac{1+\beta}{1-\beta})$, thus explaining why (GD+M) shows better generalization performance and higher test accuracy than (GD). Furthermore, we extend our analysis to stochastic version of gradient descent with momentum (SGD+M) and propose a deterministic continuous trajectory that is $O(h^2)$ close to the discrete update of (SGD+M) in a strong approximation sense. We explore the implicit regularization in (SGD+M) and (GD+M) through a series of experiments validating our theory.",Oral 5 Track 5: Deep Learning and representational learning & Reinforcement Learning,https://openreview.net/pdf?id=ZzdBhtEH9yB,
"['Mingi Kwon', 'Jaeseok Jeong', 'Youngjung Uh']",ICLR,Diffusion Models Already Have A Semantic Latent Space,https://iclr.cc/virtual/2023/oral/12589,2023," Diffusion models achieve outstanding generative performance in various domains. Despite their great success, they lack semantic latent space which is essential for controlling the generative process. To address the problem, we propose asymmetric reverse process (Asyrp) which discovers the semantic latent space in frozen pretrained diffusion models. Our semantic latent space, named h-space, has nice properties for accommodating semantic image manipulation: homogeneity, linearity, robustness, and consistency across timesteps. In addition, we measure editing strength and quality deficiency of a generative process at timesteps to provide a principled design of the process for versatility and quality improvements. Our method is applicable to various architectures (DDPM++, iDDPM, and ADM) and datasets (CelebA-HQ, AFHQ-dog, LSUN-church, LSUN-bedroom, and METFACES).",Oral 2 Track 3: Generative models,https://openreview.net/pdf?id=pd1P2eUBVfq,
"['Eric Qu', 'Xufang Luo', 'Dongsheng Li']",ICLR,Data Continuity Matters: Improving Sequence Modeling with Lipschitz Regularizer,https://iclr.cc/virtual/2023/oral/12563,2023," Sequence modeling is a core problem in machine learning, and various neural networks have been designed to process different types of sequence data. However, few attempts have been made to understand the inherent data property of sequence data, neglecting the critical factor that may significantly affect the performance of sequence modeling. In this paper, we theoretically and empirically analyze a generic property of sequence data, i.e., continuity, and connect this property with the performance of deep models. First, we empirically observe that different kinds of models for sequence modeling prefer data with different continuity. Then, we theoretically analyze the continuity preference of different models in both time and frequency domains. To further utilize continuity to improve sequence modeling, we propose a simple yet effective Lipschitz Regularizer, that can flexibly adjust data continuity according to model preferences, and bring very little extra computational cost. Extensive experiments on various tasks demonstrate that altering data continuity via Lipschitz Regularizer can largely improve the performance of many deep models for sequence modeling.",Oral 6 Track 5: Applications- & Deep Learning and representational learning,https://openreview.net/pdf?id=27uBgHuoSQ,
"['Donggyun Kim', 'Jinwoo Kim', 'Seongwoong Cho', 'Chong Luo', 'Seunghoon Hong']",ICLR,Universal Few-shot Learning of Dense Prediction Tasks with Visual Token Matching,https://iclr.cc/virtual/2023/oral/12651,2023," Dense prediction tasks are a fundamental class of problems in computer vision. As supervised methods suffer from high pixel-wise labeling cost, a few-shot learning solution that can learn any dense task from a few labeled images is desired. Yet, current few-shot learning methods target a restricted set of tasks such as semantic segmentation, presumably due to challenges in designing a general and unified model that is able to flexibly and efficiently adapt to arbitrary tasks of unseen semantics. We propose Visual Token Matching (VTM), a universal few-shot learner for arbitrary dense prediction tasks. It employs non-parametric matching on patch-level embedded tokens of images and labels that encapsulates all tasks. Also, VTM flexibly adapts to any task with a tiny amount of task-specific parameters that modulate the matching algorithm. We implement VTM as a powerful hierarchical encoder-decoder architecture involving ViT backbones where token matching is performed at multiple feature hierarchies. We experiment VTM on a challenging variant of Taskonomy dataset and observe that it robustly few-shot learns various unseen dense prediction tasks. Surprisingly, it is competitive with fully supervised baselines using only 10 labeled examples of novel tasks ($0.004\%$ of full supervision) and sometimes outperforms using $0.1\%$ of full supervision. Codes are available at https://github.com/GitGyun/visual_token_matching.",Oral 6 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=88nT0j5jAn,
"['Jianan Zhao', 'Meng Qu', 'Chaozhuo Li', 'Hao Yan', 'Qian Liu', 'Rui Li', 'Xing Xie', 'Jian Tang']",ICLR,Learning on Large-scale Text-attributed Graphs via Variational Inference,https://iclr.cc/virtual/2023/oral/12630,2023," This paper studies learning on text-attributed graphs (TAGs), where each node is associated with a text description. An ideal solution for such a problem would be integrating both the text and graph structure information with large language models and graph neural networks (GNNs). However, the problem becomes very challenging when graphs are large due to the high computational complexity brought by training large language models and  GNNs together. In this paper, we propose an efficient and effective solution to learning on large text-attributed graphs by fusing graph structure and language learning with a variational Expectation-Maximization (EM) framework, called GLEM. Instead of simultaneously training large language models and GNNs on big graphs, GLEM proposes to alternatively update the two modules in the E-step and M-step. Such a procedure allows training the two modules separately while simultaneously allowing the two modules to interact and mutually enhance each other. Extensive experiments on multiple data sets demonstrate the efficiency and effectiveness of the proposed approach.",Oral 1 Track 1: Deep Learning and representational learning I,https://openreview.net/pdf?id=q0nmYciuuZN,
"['Xiangzhe Kong', 'Wenbing Huang', 'Yang Liu']",ICLR,Conditional Antibody Design as 3D Equivariant Graph Translation,https://iclr.cc/virtual/2023/oral/12683,2023," Antibody design is valuable for therapeutic usage and biological research. Existing deep-learning-based methods encounter several key issues: 1) incomplete context for Complementarity-Determining Regions (CDRs) generation; 2) incapability of capturing the entire 3D geometry of the input structure; 3) inefficient prediction of the CDR sequences in an autoregressive manner. In this paper, we propose Multi-channel Equivariant Attention Network (MEAN) to co-design 1D sequences and 3D structures of CDRs. To be specific, MEAN formulates antibody design as a conditional graph translation problem by importing extra components including the target antigen and the light chain of the antibody. Then, MEAN resorts to E(3)-equivariant message passing along with a proposed attention mechanism to better capture the geometrical correlation between different components. Finally, it outputs both the 1D sequences and 3D structure via a multi-round progressive full-shot scheme, which enjoys more efficiency and precision against previous autoregressive approaches. Our method significantly surpasses state-of-the-art models in sequence and structure modeling, antigen-binding CDR design, and binding affinity optimization. Specifically, the relative improvement to baselines is about 23\% in antigen-binding CDR design and 34\% for affinity optimization.",Oral 1 Track 2: Machine Learning for Sciences,https://openreview.net/pdf?id=LFHFQbjxIiP,
"['Zhenting Wang', 'Kai Mei', 'Juan Zhai', 'Shiqing Ma']",ICLR,UNICORN: A Unified Backdoor Trigger Inversion Framework,https://iclr.cc/virtual/2023/oral/12724,2023," The backdoor attack, where the adversary uses inputs stamped with triggers (e.g., a patch) to activate pre-planted malicious behaviors, is a severe threat to Deep Neural Network (DNN) models. Trigger inversion is an effective way of identifying backdoor models and understanding embedded adversarial behaviors. A challenge of trigger inversion is that there are many ways of constructing the trigger. Existing methods cannot generalize to various types of triggers by making certain assumptions or attack-specific constraints. The fundamental reason is that existing work does not formally define the trigger and the inversion problem. This work formally defines and analyzes the trigger and the inversion problem. Then, it proposes a unified framework to invert backdoor triggers based on the formalization of triggers and the identified inner behaviors of backdoor models from our analysis. Our prototype UNICORN is general and effective in inverting backdoor triggers in DNNs. The code can be found at https://github.com/RU-System-Software-and-Security/UNICORN.",Oral 1 Track 4: Social Aspects of Machine Learning,https://openreview.net/pdf?id=Mj7K4lglGyj,
"['Kevin Frans', 'Phillip Isola']",ICLR,Powderworld: A Platform for Understanding Generalization via Rich Task Distributions,https://iclr.cc/virtual/2023/oral/12662,2023," One of the grand challenges of reinforcement learning is the ability to generalize to new tasks. However, general agents require a set of rich, diverse tasks to train on. Designing a `foundation environment' for such tasks is tricky -- the ideal environment would support a range of emergent phenomena, an expressive task space, and fast runtime. To take a step towards addressing this research bottleneck, this work presents Powderworld, a lightweight yet expressive simulation environment running directly on the GPU. Within Powderworld, two motivating task distributions are presented, one for world-modelling and one for reinforcement learning. Each contains hand-designed test tasks to examine generalization. Experiments indicate that increasing the environment's complexity improves generalization for world models, yet causes reinforcement learning agents to struggle. Powderworld aims to support the study of generalization by providing a source of diverse tasks arising from the same core rules.",Oral 2 Track 4: Reinforcement Learning,https://openreview.net/pdf?id=AWZgXGmsbA,
"['Maor Ashkenazi', 'Zohar Rimon', 'Ron Vainshtein', 'Shir Levi', 'Elad Richardson', 'Pinchas Mintz', 'Eran Treister']",ICLR,NeRN: Learning Neural Representations for Neural Networks,https://iclr.cc/virtual/2023/oral/12674,2023," Neural Representations have recently been shown to effectively reconstruct a wide range of signals from 3D meshes and shapes to images and videos. We show that, when adapted correctly, neural representations can be used to directly represent the weights of a pre-trained convolutional neural network, resulting in a Neural Representation for Neural Networks (NeRN). Inspired by coordinate inputs of previous neural representation methods, we assign a coordinate to each convolutional kernel in our network based on its position in the architecture, and optimize a predictor network to map coordinates to their corresponding weights. Similarly to the spatial smoothness of visual scenes, we show that incorporating a smoothness constraint over the original network's weights aids NeRN towards a better reconstruction. In addition, since slight perturbations in pre-trained model weights can result in a considerable accuracy loss, we employ techniques from the field of knowledge distillation to stabilize the learning process. We demonstrate the effectiveness of NeRN in reconstructing widely used architectures on CIFAR-10, CIFAR-100, and ImageNet. Finally, we present two applications using NeRN, demonstrating the capabilities of the learned representations.",Oral 1 Track 6: Deep Learning and representational learning II,https://openreview.net/pdf?id=9gfir3fSy3J,
"['Ashish Gaurav', 'Kasra Rezaee', 'Guiliang Liu', 'Pascal Poupart']",ICLR,Learning Soft Constraints From Constrained Expert Demonstrations,https://iclr.cc/virtual/2023/oral/12699,2023," Inverse reinforcement learning (IRL) methods assume that the expert data is generated by an agent optimizing some reward function. However, in many settings, the agent may optimize a reward function subject to some constraints, where the constraints induce behaviors that may be otherwise difficult to express with just a reward function. We consider the setting where the reward function is given, and the constraints are unknown, and propose a method that is able to recover these constraints satisfactorily from the expert data. While previous work has focused on recovering hard constraints, our method can recover cumulative soft constraints that the agent satisfies on average per episode. In IRL fashion, our method solves this problem by adjusting the constraint function iteratively through a constrained optimization procedure, until the agent behavior matches the expert behavior. We demonstrate our approach on synthetic environments, robotics environments and real world highway driving scenarios.",Oral 1 Track 5: Reinforcement Learning,https://openreview.net/pdf?id=8sSnD78NqTN,
"['Liyao Li', 'Haobo Wang', 'Liangyu Zha', 'Qingyi Huang', 'Sai Wu', 'Gang Chen', 'Junbo Zhao']",ICLR,Learning a Data-Driven Policy Network for Pre-Training Automated Feature Engineering,https://iclr.cc/virtual/2023/oral/12727,2023," Feature engineering is widely acknowledged to be pivotal in tabular data analysis and prediction. Automated feature engineering (AutoFE) emerged to automate this process managed by experienced data scientists and engineers conventionally. In this area, most — if not all — prior work adopted an identical framework from the neural architecture search (NAS) method. While feasible, we posit that the NAS framework very much contradicts the way how human experts cope with the data since the inherent Markov decision process (MDP) setup differs. We point out that its data-unobserved setup consequentially results in an incapability to generalize across different datasets as well as also high computational cost. This paper proposes a novel AutoFE framework Feature Set Data-Driven Search (FETCH), a pipeline mainly for feature generation and selection. Notably, FETCH is built on a brand-new data-driven MDP setup using the tabular dataset as the state fed into the policy network. Further, we posit that the crucial merit of FETCH is its transferability where the yielded policy network trained on a variety of datasets is indeed capable to enact feature engineering on unseen data, without requiring additional exploration. To the best of our knowledge, this is a pioneer attempt to build a tabular data pre-training paradigm via AutoFE. Extensive experiments show that FETCH systematically surpasses the current state-of-the-art AutoFE methods and validates the transferability of AutoFE pre-training.",Oral 2 Track 2: General Machine Learning,https://openreview.net/pdf?id=688hNNMigVX,
"['Hyungu Kahng', 'Hyungrok Do', 'Judy Zhong']",ICLR,Domain Generalization via Heckman-type Selection Models,https://iclr.cc/virtual/2023/oral/12545,2023," The domain generalization (DG) setup considers the problem where models are trained on data sampled from multiple domains and evaluated on test domains unseen during training. In this paper, we formulate DG as a sample selection problem where each domain is sampled from a common underlying population through non-random sampling probabilities that correlate with both the features and the outcome. Under this setting, the fundamental iid assumption of the empirical risk minimization (ERM) is violated, so it often performs worse on test domains whose non-random sampling probabilities differ from the domains in the training dataset. We propose a Selection-Guided DG (SGDG) framework to learn the selection probability of each domain and the joint distribution of the outcome and domain selection variables. The proposed SGDG is domain generalizable as it intends to minimize the risk under the population distribution. We theoretically proved that, under certain regular conditions, SGDG can achieve smaller risk than ERM. Furthermore, we present a class of parametric SGDG (HeckmanDG) estimators applicable to continuous, binary, and multinomial outcomes. We also demonstrated its efficacy empirically through simulations and experiments on a set of benchmark datasets comparing with other well-known DG methods.",Oral 1 Track 3: Neuroscience and Cognitive Science & General Machine Learning,https://openreview.net/pdf?id=fk7RbGibe1,
"['Kuno Kim', 'Stefano Ermon']",ICLR,Understanding and Adopting Rational Behavior by Bellman Score Estimation,https://iclr.cc/virtual/2023/oral/12741,2023," We are interested in solving a class of problems that seek to understand and adopt rational behavior from demonstrations. We may broadly classify these problems into four categories of reward identification, counterfactual analysis, behavior imitation, and behavior transfer. In this work, we make a key observation that knowing how changes in the underlying rewards affect the optimal behavior allows one to solve a variety of aforementioned problems. To a local approximation, this quantity is precisely captured by what we term the Bellman score, i.e gradient of log probabilities of the optimal policy with respect to the reward. We introduce the Bellman score operator which provably converges to the gradient of the infinite-horizon optimal Q-values with respect to the reward which can then be used to directly estimate the score. Guided by our theory, we derive a practical score-learning algorithm which can be used for score estimation in high-dimensional state-actions spaces. We show that score-learning can be used to reliably identify rewards, perform counterfactual predictions, achieve state-of-the-art behavior imitation, and transfer policies across environments.",Oral 3 Track 1: Reinforcement Learning,https://openreview.net/pdf?id=WzGdBqcBicl,
"['Yicheng Luo', 'Zhengyao Jiang', 'samuel cohen', 'Edward Grefenstette', 'Marc Deisenroth']",ICLR,Optimal Transport for Offline Imitation Learning,https://iclr.cc/virtual/2023/oral/12580,2023," With the advent of large datasets, offline reinforcement learning is a promising framework for learning good decision-making policies without the need to interact with the real environment.However, offline RL requires the dataset to be reward-annotated, which presents practical challenges when reward engineering is difficult or when obtaining reward annotations is labor-intensive.In this paper, we introduce Optimal Transport Relabeling (OTR), an imitation learning algorithm that can automatically relabel offline data of mixed and unknown quality with rewards from a few good demonstrations. OTR's key idea is to use optimal transport to compute an optimal alignment between an unlabeled trajectory in the dataset and an expert demonstration to obtain a similarity measure that can be interpreted as a reward, which can then be used by an offline RL algorithm to learn the policy. OTR is easy to implement and computationally efficient. On D4RL benchmarks, we demonstrate that OTR with a single demonstration can consistently match the performance of offline RL with ground-truth rewards.",Oral 2 Track 5: Generative models & Theory,https://openreview.net/pdf?id=MhuFzFsrfvH,
"['Juhan Bae', 'Michael Zhang', 'Michael Ruan', 'Duanyang Wang', 'So Hasegawa', 'Jimmy Ba', 'Roger Grosse']",ICLR,"Multi-Rate VAE: Train Once, Get the Full Rate-Distortion Curve",https://iclr.cc/virtual/2023/oral/12720,2023," Variational autoencoders (VAEs) are powerful tools for learning latent representations of data used in a wide range of applications. In practice, VAEs usually require multiple training rounds to choose the amount of information the latent variable should retain. This trade-off between the reconstruction error (distortion) and the KL divergence (rate) is typically parameterized by a hyperparameter $\beta$. In this paper, we introduce Multi-Rate VAE (MR-VAE), a computationally efficient framework for learning optimal parameters corresponding to various $\beta$ in a single training run. The key idea is to explicitly formulate a response function using hypernetworks that maps $\beta$ to the optimal parameters. MR-VAEs construct a compact response hypernetwork where the pre-activations are conditionally gated based on $\beta$. We justify the proposed architecture by analyzing linear VAEs and showing that it can represent response functions exactly for linear VAEs. With the learned hypernetwork, MR-VAEs can construct the rate-distortion curve without additional training and can be deployed with significantly less hyperparameter tuning. Empirically, our approach is competitive and often exceeds the performance of multiple $\beta$-VAEs training with minimal computation and memory overheads.",Oral 3 Track 2: Deep Learning and representational learning,https://openreview.net/pdf?id=OJ8aSjCaMNK,
"['Simran Arora', 'Avanika Narayan', 'Mayee Chen', 'Laurel Orr', 'Neel Guha', 'Kush Bhatia', 'Ines Chami', 'Christopher Re']",ICLR,Ask Me Anything: A simple strategy for prompting language models,https://iclr.cc/virtual/2023/oral/12566,2023," Large language models (LLMs) transfer well to new tasks out-of-the-box simply given a natural language prompt that demonstrates how to perform the task and no additional training. Prompting is a brittle process wherein small modifications to the prompt can cause large variations in the model predictions, and therefore significant effort is dedicated towards designing a painstakingly crafted ""perfect prompt"" for a task. To mitigate the high degree of effort, we instead ask whether collecting multiple decent, yet imperfect, prompts and aggregating them can lead to a high quality prompting strategy. Our observations motivate our proposed method, Ask Me Anything (AMA). We first develop an understanding of the effective prompt formats, finding question-answering (QA) prompts, which encourage open-ended generation (""Who went to the park?"") tend to outperform those that restrict the model outputs (""John went to the park. True or False?""). AMA recursively uses the LLM to transform task inputs to the effective QA format. AM generates multiple questions per input and applies these prompts to collect several noisy ""votes"" for the input's true label. We find the prompts have varying accuracies and dependencies and thus propose to use weak supervision, a procedure for combining the noisy predictions, to produce the final predictions. We evaluate AMA across open-source model families (EleutherAI, BLOOM, OPT, and T0) and sizes (125M-175B parameters), demonstrating an average performance lift of 10.2\% over the few-shot baseline. This simple strategy enables the open-source GPT-J-6B model to match and exceed the performance of few-shot GPT3-175B  on 15 of 20 popular benchmarks. Averaged across these tasks, the GPT-J-6B model outperforms few-shot GPT3-175B. We release our code here: https://github.com/HazyResearch/ama_prompting.",Oral 2 Track 6: Applications & Social Aspects of Machine Learning,https://openreview.net/pdf?id=bhUPJnS2g0X,
"['Jiasen Lu', 'Christopher Clark', 'Rowan Zellers', 'Roozbeh Mottaghi', 'Aniruddha Kembhavi']",ICLR,"UNIFIED-IO: A Unified Model for Vision, Language, and Multi-modal Tasks",https://iclr.cc/virtual/2023/oral/12725,2023," We propose Unified-IO, a model that performs a large variety of AI tasks spanning classical computer vision tasks, including pose estimation, object detection, depth estimation and image generation, vision-and-language tasks such as region captioning and referring expression, to natural language processing tasks such as question answering and paraphrasing. Developing a single unified model for such a large variety of tasks poses unique challenges due to the heterogeneous inputs and outputs pertaining to each task, including RGB images, per-pixel maps, binary masks, bounding boxes, and language. We achieve this unification by homogenizing every supported input and output into a sequence of discrete vocabulary tokens. This common representation across all tasks allows us to train a single transformer-based architecture, jointly on over 90 diverse datasets in the vision and language fields. Unified-IO is the first model capable of performing all 7 tasks on the GRIT benchmark and produces strong results across 16 diverse benchmarks like NYUv2-Depth, ImageNet, VQA2.0, OK-VQA, Swig, VizWizGround, BoolQ, and SciTail, with no task-specific fine-tuning. Code and pre-trained models will be made publicly available.",Oral 2 Track 1: Applications,https://openreview.net/pdf?id=E01k9048soZ,
"['Hariprasath Govindarajan', 'Per Sidén', 'Jacob Roll', 'Fredrik Lindsten']",ICLR,DINO as a von Mises-Fisher mixture model,https://iclr.cc/virtual/2023/oral/12762,2023," Self-distillation methods using Siamese networks are popular for self-supervised pre-training. DINO is one such method based on a cross-entropy loss between $K$-dimensional probability vectors, obtained by applying a softmax function to the dot product between representations and learnt prototypes. Given the fact that the learned representations are $L^2$-normalized, we show that DINO and its derivatives, such as iBOT, can be interpreted as a mixture model of von Mises-Fisher components. With this interpretation, DINO assumes equal precision for all components when the prototypes are also $L^2$-normalized. Using this insight we propose DINO-vMF, that adds appropriate normalization constants when computing the cluster assignment probabilities. Unlike DINO, DINO-vMF is stable also for the larger ViT-Base model with unnormalized prototypes. We show that the added flexibility of the mixture model is beneficial in terms of better image representations. The DINO-vMF pre-trained model consistently performs better than DINO on a range of downstream tasks. We obtain similar improvements for iBOT-vMF vs iBOT and thereby show the relevance of our proposed modification also for other methods derived from DINO.",Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=cMJo1FTwBTQ,
"['Li Yi', 'Gezheng Xu', 'Pengcheng Xu', 'Jiaqi Li', 'Ruizhi Pu', 'Charles Ling', 'Ian McLeod', 'Boyu Wang']",ICLR,When Source-Free Domain Adaptation Meets Learning with Noisy Labels,https://iclr.cc/virtual/2023/oral/12670,2023," Recent state-of-the-art source-free domain adaptation (SFDA) methods have focused on learning meaningful cluster structures in the feature space, which have succeeded in adapting the knowledge from source domain to unlabeled target domain without accessing the private source data. However, existing methods rely on the pseudo-labels generated by source models that can be noisy due to domain shift. In this paper, we study SFDA from the perspective of learning with label noise (LLN). Unlike the label noise in the conventional LLN scenario, we prove that the label noise in SFDA follows a different distribution assumption. We also prove that such a difference makes existing LLN methods that rely on their distribution assumptions unable to address the label noise in SFDA. Empirical evidence suggests that only marginal improvements are achieved when applying the existing LLN methods to solve the SFDA problem. On the other hand, although there exists a fundamental difference between the label noise in the two scenarios, we demonstrate theoretically that the early-time training phenomenon (ETP), which has been previously observed in conventional label noise settings, can also be observed in the SFDA problem. Extensive experiments demonstrate significant improvements to existing SFDA algorithms by leveraging ETP to address the label noise in SFDA.",Oral 4 Track 1: Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=u2Pd6x794I,
"['Haoran Xu', 'Li Jiang', 'Jianxiong Li', 'Zhuoran Yang', 'Zhaoran Wang', 'Wai Chan', 'Xianyuan Zhan']",ICLR,Offline RL with No OOD Actions: In-Sample Learning via Implicit Value Regularization,https://iclr.cc/virtual/2023/oral/12693,2023," Most offline reinforcement learning (RL) methods suffer from the trade-off between improving the policy to surpass the behavior policy and constraining the policy to limit the deviation from the behavior policy as computing $Q$-values using out-of-distribution (OOD) actions will suffer from errors due to distributional shift. The recent proposed \textit{In-sample Learning} paradigm (i.e., IQL), which improves the policy by quantile regression using only data samples, shows great promise because it learns an optimal policy without querying the value function of any unseen actions. However, it remains unclear how this type of method handles the distributional shift in learning the value function. In this work, we make a key finding that the in-sample learning paradigm arises under the \textit{Implicit Value Regularization} (IVR) framework. This gives a deeper understanding of why the in-sample learning paradigm works, i.e., it applies implicit value regularization to the policy. Based on the IVR framework, we further propose two practical algorithms, Sparse $Q$-learning (SQL) and Exponential $Q$-learning (EQL), which adopt the same value regularization used in existing works, but in a complete in-sample manner. Compared with IQL, we find that our algorithms introduce sparsity in learning the value function, making them more robust in noisy data regimes. We also verify the effectiveness of SQL and EQL on D4RL benchmark datasets and show the benefits of in-sample learning by comparing them with CQL in small data regimes. Code is available at \url{https://github.com/ryanxhr/SQL}.",Oral 4 Track 4: Reinforcement Learning II,https://openreview.net/pdf?id=ueYYgo2pSSU,
"['Mansheej Paul', 'Feng Chen', 'Brett Larsen', 'Jonathan Frankle', 'Surya Ganguli', 'Gintare Karolina Dziugaite']",ICLR,Unmasking the Lottery Ticket Hypothesis: What's Encoded in a Winning Ticket's Mask?,https://iclr.cc/virtual/2023/oral/12645,2023," Modern deep learning involves training costly, highly overparameterized networks, thus motivating the search for sparser networks that require less compute and memory but can still be trained to the same accuracy as the full network (i.e. matching). Iterative magnitude pruning (IMP) is a state of the art algorithm that can find such highly sparse matching subnetworks, known as winning tickets. IMP operates by iterative cycles of training, masking a fraction of smallest magnitude weights, rewinding unmasked weights back to an early training point, and repeating. Despite its simplicity, the underlying principles for when and how IMP finds winning tickets remain elusive. In particular, what useful information does an IMP mask found at the end of training convey to a rewound network near the beginning of training? How does SGD allow the network to extract this information? And why is iterative pruning needed, i.e. why can't we prune to very high sparsities in one shot? We develop answers to these questions in terms of the geometry of the error landscape. First, we find that—at higher sparsities—pairs of pruned networks at successive pruning iterations are connected by a linear path with zero error barrier if and only if they are matching. This indicates that masks found at the end of training convey to the rewind point the identity of an axial subspace that intersects a desired linearly connected mode of a matching sublevel set. Second, we show SGD can exploit this information due to a strong form of robustness: it can return to this mode despite  strong perturbations early in training. Third, we show how the flatness of the error landscape at the end of training determines a limit on the fraction of weights that can be pruned at each iteration of IMP. This analysis yields a new quantitative link between IMP performance and the Hessian eigenspectrum. Finally, we show that the role of retraining in IMP is to find a network with new small weights to prune. Overall, these results make progress toward demystifying the existence of winning tickets by revealing the fundamental role of error landscape geometry in the algorithms used to find them.",Oral 3 Track 5: Deep Learning and representational learning & Neuroscience and Cognitive Science,https://openreview.net/pdf?id=xSsW2Am-ukZ,
"['Zihao Xu', 'Guang-Yuan Hao', 'Hao He', 'Hao Wang']",ICLR,Domain-Indexing Variational Bayes: Interpretable Domain Index for Domain Adaptation,https://iclr.cc/virtual/2023/oral/12653,2023," Previous studies have shown that leveraging ""domain index"" can significantly boost domain adaptation performance (Wang et al., 2020; Xu et al., 2022). However, such domain indices are not always available. To address this challenge, we first provide a formal definition of domain index from the probabilistic perspective, and then propose an adversarial variational Bayesian framework that infers domain indices from multi-domain data, thereby providing additional insight on domain relations and improving domain adaptation performance. Our theoretical analysis shows that our adversarial variational Bayesian framework finds the optimal domain index at equilibrium. Empirical results on both synthetic and real data verify that our model can produce interpretable domain indices which enable us to achieve superior performance compared to state-of-the-art domain adaptation methods. Code is available at https://github.com/Wang-ML-Lab/VDI.",Oral 4 Track 2: Probabilistic Methods,https://openreview.net/pdf?id=pxStyaf2oJ5,
"['Pietro Mazzaglia', 'Tim Verbelen', 'Bart Dhoedt', 'Alexandre Lacoste', 'Sai Rajeswar']",ICLR,Choreographer: Learning and Adapting Skills in Imagination,https://iclr.cc/virtual/2023/oral/12667,2023," Unsupervised skill learning aims to learn a rich repertoire of behaviors without external supervision, providing artificial agents with the ability to control and influence the environment. However, without appropriate knowledge and exploration, skills may provide control only over a restricted area of the environment, limiting their applicability. Furthermore, it is unclear how to leverage the learned skill behaviors for adapting to downstream tasks in a data-efficient manner. We present Choreographer, a model-based agent that exploits its world model to learn and adapt skills in imagination. Our method decouples the exploration and skill learning processes, being able to discover skills in the latent state space of the model. During adaptation, the agent uses a meta-controller to evaluate and adapt the learned skills efficiently by deploying them in parallel in imagination. Choreographer is able to learn skills both from offline data, and by collecting data simultaneously with an exploration policy. The skills can be used to effectively adapt to downstream tasks, as we show in the URL benchmark, where we outperform previous approaches from both pixels and states inputs. The skills also explore the environment thoroughly, finding sparse rewards more frequently, as shown in goal-reaching tasks from the DMC Suite and Meta-World. Project website: https://skillchoreographer.github.io/",Oral 4 Track 3: Reinforcement Learning I,https://openreview.net/pdf?id=PhkWyijGi5b,
"['Zhihao Shi', 'Xize Liang', 'Jie Wang']",ICLR,LMC: Fast Training of GNNs via Subgraph Sampling with Provable Convergence,https://iclr.cc/virtual/2023/oral/12648,2023," The message passing-based graph neural networks (GNNs) have achieved great success in many real-world applications.However, training GNNs on large-scale graphs suffers from the well-known neighbor explosion problem, i.e., the exponentially increasing dependencies of nodes with the number of message passing layers. Subgraph-wise sampling methods---a promising class of mini-batch training techniques---discard messages outside the mini-batches in backward passes to avoid the neighbor explosion problem at the expense of gradient estimation accuracy. This poses significant challenges to their convergence analysis and convergence speeds, which seriously limits their reliable real-world applications. To address this challenge, we propose a novel subgraph-wise sampling method with a convergence guarantee, namely Local Message Compensation (LMC). To the best of our knowledge, LMC is the {\it first} subgraph-wise sampling method with provable convergence. The key idea of LMC is to retrieve the discarded messages in backward passes based on a message passing formulation of backward passes. By efficient and effective compensations for the discarded messages in both forward and backward passes, LMC computes accurate mini-batch gradients and thus accelerates convergence. We further show that LMC converges to first-order stationary points of GNNs. Experiments on large-scale benchmark tasks demonstrate that LMC significantly outperforms state-of-the-art subgraph-wise sampling methods in terms of efficiency.",Oral 5 Track 2: Optimization,https://openreview.net/pdf?id=5VBBA91N6n,
"['Rinon Gal', 'Yuval Alaluf', 'Yuval Atzmon', 'Or Patashnik', 'Amit Bermano', 'Gal Chechik', 'Daniel Cohen-Or']",ICLR,An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion,https://iclr.cc/virtual/2023/oral/12700,2023," Text-to-image models offer unprecedented freedom to guide creation through natural language. Yet, it is unclear how such freedom can be exercised to generate images of specific unique concepts, modify their appearance, or compose them in new roles and novel scenes.In other words, we ask: how can we use language-guided models to turn *our* cat into a painting, or imagine a new product based on *our* favorite toy? Here we present a simple approach that allows such creative freedom. Using only $3$-$5$ images of a user-provided concept, like an object or a style, we learn to represent it through new ``words"" in the embedding space of a frozen text-to-image model.These ``words"" can be composed into natural language sentences, guiding *personalized* creation in an intuitive way.Notably, we find evidence that a *single* word embedding is sufficient for capturing unique and varied concepts. We compare our approach to a wide range of baselines, and demonstrate that it can more faithfully portray the concepts across a range of applications and tasks. Our code, data and new words will be available.",Oral 3 Track 3: Generative models,https://openreview.net/pdf?id=NAQvF08TcyG,
"['Benjamin Chamberlain', 'Sergey Shirobokov', 'Emanuele Rossi', 'Fabrizio Frasca', 'Thomas Markovich', 'Nils Hammerla', 'Michael Bronstein', 'Max Hansmire']",ICLR,Graph Neural Networks for Link Prediction with Subgraph Sketching,https://iclr.cc/virtual/2023/oral/12595,2023," Many Graph Neural Networks (GNNs) perform poorly compared to simple heuristics on Link Prediction (LP) tasks. This is due to limitations in expressive power such as the inability to count triangles (the backbone of most LP heuristics) and because they can not distinguish automorphic nodes (those having identical structural roles). Both expressiveness issues can be alleviated by learning link (rather than node) representations and incorporating structural features such as triangle counts. Since explicit link representations are often prohibitively expensive, recent works resorted to subgraph-based methods, which have achieved state-of-the-art performance for LP, but suffer from poor efficiency due to high levels of redundancy between subgraphs. We analyze the components of subgraph GNN (SGNN) methods for link prediction. Based on our analysis, we propose a novel full-graph GNN called ELPH (Efficient Link Prediction with Hashing) that passes subgraph sketches as messages to approximate the key components of SGNNs without explicit subgraph construction. ELPH is provably more expressive than Message Passing GNNs (MPNNs).  It outperforms existing SGNN models on many standard LP benchmarks while being orders of magnitude faster. However, it shares the common GNN limitation that it is only efficient when the dataset fits in GPU memory. Accordingly, we develop a highly scalable model, called BUDDY, which uses feature precomputation to circumvent this limitation without sacrificing predictive performance. Our experiments show that BUDDY also outperforms SGNNs on standard LP benchmarks while being highly scalable and faster than ELPH.",Oral 5 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=m1oqEOAozQU,
"['Alexandre Araujo', 'Aaron Havens', 'Blaise Delattre', 'Alexandre Allauzen', 'Bin Hu']",ICLR,A Unified Algebraic Perspective on Lipschitz Neural Networks,https://iclr.cc/virtual/2023/oral/12631,2023," Important research efforts have focused on the design and training of neural networks with a controlled Lipschitz constant. The goal is to increase and sometimes guarantee the robustness against adversarial attacks. Recent promising techniques draw inspirations from different backgrounds to design 1-Lipschitz neural networks, just to name a few: convex potential layers derive from the discretization of continuous dynamical systems, Almost-Orthogonal-Layer proposes a tailored method for matrix rescaling. However, it is today important to consider the recent and promising contributions in the field under a common theoretical lens to better design new and improved layers. This paper introduces a novel algebraic perspective unifying various types of 1-Lipschitz neural networks, including the ones previously mentioned, along with methods based on orthogonality and spectral methods. Interestingly, we show that many existing techniques can be derived and generalized via finding analytical solutions of a common semidefinite programming (SDP) condition.  We also prove that AOL biases the scaled weight to the ones which are close to the set of orthogonal matrices in a certain mathematical manner. Moreover, our algebraic condition, combined with the Gershgorin circle theorem, readily leads to new and diverse parameterizations for 1-Lipschitz network layers. Our approach, called SDP-based Lipschitz Layers (SLL), allows us to design non-trivial yet efficient generalization of convex potential layers.  Finally, the comprehensive set of experiments on image classification shows that SLLs outperform previous approaches on certified robust accuracy. Code is available at https://github.com/araujoalexandre/Lipschitz-SLL-Networks.",Oral 4 Track 6: Deep Learning and representational learning- Reinforcement Learning,https://openreview.net/pdf?id=k71IGLC8cfc,
"['Yinhuai Wang', 'Jiwen Yu', 'Jian Zhang']",ICLR,Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model,https://iclr.cc/virtual/2023/oral/12622,2023," Most existing Image Restoration (IR) models are task-specific, which can not be generalized to different degradation operators. In this work, we propose the Denoising Diffusion Null-Space Model (DDNM), a novel zero-shot framework for arbitrary linear IR problems, including but not limited to image super-resolution, colorization, inpainting, compressed sensing, and deblurring. DDNM only needs a pre-trained off-the-shelf diffusion model as the generative prior, without any extra training or network modifications. By refining only the null-space contents during the reverse diffusion process, we can yield diverse results satisfying both data consistency and realness. We further propose an enhanced and robust version, dubbed DDNM+, to support noisy restoration and improve restoration quality for hard tasks. Our experiments on several IR tasks reveal that DDNM outperforms other state-of-the-art zero-shot IR methods. We also demonstrate that DDNM+ can solve complex real-world applications, e.g., old photo restoration.",Oral 6 Track 4: Applications & Social Aspects of Machine Learning & General Machine Learning,https://openreview.net/pdf?id=mRieQgMtNTQ,
"['Takeshi Koshizuka', 'Issei Sato']",ICLR,"Neural Lagrangian Schr\""{o}dinger Bridge: Diffusion Modeling for Population Dynamics",https://iclr.cc/virtual/2023/oral/12561,2023," Population dynamics is the study of temporal and spatial variation in the size of populations of organisms and is a major part of population ecology. One of the main difficulties in analyzing population dynamics is that we can only obtain observation data with coarse time intervals from fixed-point observations due to experimental costs or measurement constraints. Recently, modeling population dynamics by using continuous normalizing flows (CNFs) and dynamic optimal transport has been proposed to infer the sample trajectories from a fixed-point observed population. While the sample behavior in CNFs is deterministic, the actual sample in biological systems moves in an essentially random yet directional manner. Moreover, when a sample moves from point A to point B in dynamical systems, its trajectory typically follows the principle of least action in which the corresponding action has the smallest possible value. To satisfy these requirements of the sample trajectories, we formulate the Lagrangian Schrödinger bridge (LSB) problem and propose to solve it approximately by modeling the advection-diffusion process with regularized neural SDE. We also develop a model architecture that enables faster computation of the loss function. Experimental results show that the proposed method can efficiently approximate the population-level dynamics even for high-dimensional data and that using the prior knowledge introduced by the Lagrangian enables us to estimate the sample-level dynamics with stochastic behavior.",Oral 4 Track 5: Machine Learning for Sciences & Probabilistic Methods,https://openreview.net/pdf?id=d3QNWD_pcFv,
"['Ainesh Bakshi', 'Piotr Indyk', 'Praneeth Kacham', 'Sandeep Silwal', 'Samson Zhou']",ICLR,Subquadratic Algorithms for Kernel Matrices via Kernel Density Estimation,https://iclr.cc/virtual/2023/oral/12713,2023," Kernel matrices, as well as weighted graphs represented by them, are ubiquitous objects in machine learning, statistics and other related fields. The main drawback of using kernel methods (learning and inference using kernel matrices) is efficiency -- given $n$ input points, most kernel-based algorithms need to materialize the full $n \times n$ kernel matrix before performing any subsequent computation, thus incurring $\Omega(n^2)$ runtime. Breaking this quadratic barrier for various problems has therefore, been a subject of extensive research efforts. We break the quadratic barrier and obtain \emph{subquadratic} time  algorithms for several fundamental linear-algebraic and graph processing primitives, including approximating the top eigenvalue and eigenvector, spectral sparsification, solving linear systems, local clustering, low-rank approximation, arboricity estimation and counting weighted triangles. We build on the recently developed Kernel Density Estimation framework, which (after preprocessing in time subquadratic in $n$) can return estimates of row/column sums of the kernel matrix. In particular, we develop efficient reductions from \emph{weighted vertex} and \emph{weighted edge sampling} on kernel graphs, \emph{simulating random walks} on kernel graphs, and \emph{importance sampling} on matrices to Kernel Density Estimation and show that we can generate samples from these distributions in \emph{sublinear} (in the support of the distribution) time. Our reductions are the central ingredient in each of our applications and we believe they may be of independent interest. We empirically demonstrate the efficacy of our algorithms on low-rank approximation (LRA) and spectral sparsification, where we observe a $\textbf{9x}$ decrease in the number of kernel evaluations over baselines for LRA and a $\textbf{41x}$ reduction in the graph size for spectral sparsification.",Oral 6 Track 1: Theory,https://openreview.net/pdf?id=74A-FDAyiL,
"['Scott Sussex', 'Anastasia Makarova', 'Andreas Krause']",ICLR,Model-based Causal Bayesian Optimization,https://iclr.cc/virtual/2023/oral/14239,2023," How should we intervene on an unknown structural equation model to maximize a downstream variable of interest? This setting, also known as causal Bayesian optimization (CBO), has important applications in medicine, ecology, and manufacturing. Standard Bayesian optimization algorithms fail to effectively leverage the underlying causal structure. Existing CBO approaches assume noiseless measurements and do not come with guarantees. We propose the {\em model-based causal Bayesian optimization algorithm (MCBO)} that learns a full system model instead of only modeling intervention-reward pairs. MCBO propagates epistemic uncertainty about the causal mechanisms through the graph and trades off exploration and exploitation via the optimism principle. We bound its cumulative regret, and obtain the first non-asymptotic bounds for CBO. Unlike in standard Bayesian optimization, our acquisition function cannot be evaluated in closed form, so we show how the reparameterization trick can be used to apply gradient-based optimizers. The resulting practical implementation of MCBO compares favorably with state-of-the-art approaches empirically.",Oral 5 Track 1: Unsupervised and Self-supervised learning & Social Aspects of Machine Learning-,https://openreview.net/pdf?id=Vk-34OQ7rFo,
"['Lorenz Kuhn', 'Yarin Gal', 'Sebastian Farquhar']",ICLR,Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation,https://iclr.cc/virtual/2023/oral/12609,2023," We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of ""semantic equivalence""—different sentences can mean the same thing. To overcome these challenges we introduce semantic entropy—an entropy which incorporates linguistic invariances created by shared meanings. Our method is unsupervised, uses only a single model, and requires no modifications to off-the-shelf language models. In comprehensive ablation studies we show that the semantic entropy is more predictive of model accuracy on question answering data sets than comparable baselines.",Oral 6 Track 2: Infrastructure & Social Aspects of Machine Learning,https://openreview.net/pdf?id=VD-AYtP0dve,
"['Olivier Laurent', 'Adrien Lafage', 'Enzo Tartaglione', 'Geoffrey Daniel', 'Jean-marc Martinez', 'Andrei Bursuc', 'Gianni Franchi']",ICLR,Packed Ensembles for efficient uncertainty estimation,https://iclr.cc/virtual/2023/oral/12701,2023," Deep Ensembles (DE) are a prominent approach for achieving excellent performance on key metrics such as accuracy, calibration, uncertainty estimation, and out-of-distribution detection. However, hardware limitations of real-world systems constrain to smaller ensembles and lower-capacity networks, significantly deteriorating their performance and properties. We introduce Packed-Ensembles (PE), a strategy to design and train lightweight structured ensembles by carefully modulating the dimension of their encoding space. We leverage grouped convolutions to parallelize the ensemble into a single shared backbone and forward pass to improve training and inference speeds. PE is designed to operate within the memory limits of a standard neural network. Our extensive research indicates that PE accurately preserves the properties of DE, such as diversity, and performs equally well in terms of accuracy, calibration, out-of-distribution detection, and robustness to distribution shift. We make our code available at https://github.com/ENSTA-U2IS/torch-uncertainty.",Oral 6 Track 6: Deep Learning,https://openreview.net/pdf?id=XXTyv1zD9zD,
"['Ce Liu', 'Suryansh Kumar', 'Shuhang Gu', 'Radu Timofte', 'Luc Van Gool']",ICLR,VA-DepthNet: A Variational Approach to Single Image Depth Prediction,https://iclr.cc/virtual/2023/oral/12606,2023," We introduce VA-DepthNet, a simple, effective, and accurate deep neural network approach for the single-image depth prediction (SIDP) problem. The proposed approach advocates using classical first-order variational constraints for this problem. While state-of-the-art deep neural network methods for SIDP learn the scene depth from images in a supervised setting, they often overlook the invaluable invariances and priors in the rigid scene space, such as the regularity of the scene. The paper's main contribution is to reveal the benefit of classical and well-founded variational constraints in the neural network design for the SIDP task. It is shown that imposing first-order variational constraints in the scene space together with popular encoder-decoder-based network architecture design provides excellent results for the supervised SIDP task. The imposed first-order variational constraint makes the network aware of the depth gradient in the scene space, i.e., regularity. The paper demonstrates the usefulness of the proposed approach via extensive evaluation and ablation analysis over several benchmark datasets, such as KITTI, NYU Depth V2, and SUN RGB-D. The VA-DepthNet at test time shows considerable improvements in depth prediction accuracy compared to the prior art and is accurate also at high-frequency regions in the scene space.  At the time of writing this paper, our method---labeled as VA-DepthNet, when tested on the KITTI depth-prediction evaluation set benchmarks, shows state-of-the-art results, and is the top-performing published approach.",Oral 5 Track 4: Applications & Optimization,https://openreview.net/pdf?id=xjxUjHa_Wpa,
"['TAN NGUYEN', 'Tam Nguyen', 'Nhat Ho', 'Andrea Bertozzi', 'Richard Baraniuk', 'Stanley J Osher']",ICLR,A Primal-Dual Framework for Transformers and Neural Networks,https://iclr.cc/virtual/2023/oral/12628,2023," Self-attention is key to the remarkable success of transformers in sequence modeling tasks including many applications in natural language processing and computer vision. Like neural network layers, these attention mechanisms are often developed by heuristics and experience. To provide a principled framework for constructing attention layers in transformers, we show that the self-attention corresponds to the support vector expansion derived from a support vector regression problem, whose primal formulation has the form of a neural network layer. Using our framework, we derive popular attention layers used in practice and propose two new attentions: 1) the Batch Normalized Attention (Attention-BN) derived from the batch normalization layer and 2)  the Attention with Scaled Head (Attention-SH) derived from using less training data to fit the SVR model. We empirically demonstrate the advantages of the Attention-BN and Attention-SH in reducing head redundancy, increasing the model's accuracy, and improving the model's efficiency in a variety of practical applications including image and time-series classification.",Oral 5 Track 5: Deep Learning and representational learning & Reinforcement Learning,https://openreview.net/pdf?id=U_T8-5hClV,
"['Ben Poole', 'Ajay Jain', 'Jonathan T. Barron', 'Ben Mildenhall']",ICLR,DreamFusion: Text-to-3D using 2D Diffusion,https://iclr.cc/virtual/2023/oral/12607,2023," Recent breakthroughs in text-to-image synthesis have been driven by diffusion models trained on billions of image-text pairs. Adapting this approach to 3D synthesis would require large-scale datasets of labeled 3D or multiview data and efficient architectures for denoising 3D data, neither of which currently exist. In this work, we circumvent these limitations by using a pretrained 2D text-to-image diffusion model to perform text-to-3D synthesis. We introduce a loss based on probability density distillation that enables the use of a 2D diffusion model as a prior for optimization of a parametric image generator. Using this loss in a DeepDream-like procedure, we optimize a randomly-initialized 3D model (a Neural Radiance Field, or NeRF) via gradient descent such that its 2D renderings from random angles achieve a low loss. The resulting 3D model of the given text can be viewed from any angle, relit by arbitrary illumination, or composited into any 3D environment. Our approach requires no 3D training data and no modifications to the image diffusion model, demonstrating the effectiveness of pretrained image diffusion models as priors.",Oral 2 Track 3: Generative models,https://openreview.net/pdf?id=FjNys5c7VyY,
"['Danilo Numeroso', 'Davide Bacciu', 'Petar Veličković']",ICLR,Dual Algorithmic Reasoning,https://iclr.cc/virtual/2023/oral/12592,2023," Neural Algorithmic Reasoning is an emerging area of machine learning which seeks to infuse algorithmic computation in neural networks, typically by training neural models to approximate steps of classical algorithms. In this context, much of the current work has focused on learning reachability and shortest path graph algorithms, showing that joint learning on similar algorithms is beneficial for generalisation. However, when targeting more complex problems, such ""similar"" algorithms become more difficult to find. Here, we propose to learn algorithms by exploiting duality of the underlying algorithmic problem. Many algorithms solve optimisation problems. We demonstrate that simultaneously learning the dual definition of these optimisation problems in algorithmic learning allows for better learning and qualitatively better solutions. Specifically, we exploit the max-flow min-cut theorem to simultaneously learn these two algorithms over synthetically generated graphs, demonstrating the effectiveness of the proposed approach. We then validate the real-world utility of our dual algorithmic reasoner by deploying it on a challenging brain vessel classification task, which likely depends on the vessels’ flow properties. We demonstrate a clear performance gain when using our model within such a context, and empirically show that learning the max-flow and min-cut algorithms together is critical for achieving such a result.",Oral 6 Track 5: Applications- & Deep Learning and representational learning,https://openreview.net/pdf?id=hhvkdRdWt1F,
"['Yuxin Wen', 'Arpit Bansal', 'hamid kazemi', 'Eitan Borgnia', 'Micah Goldblum', 'Jonas Geiping', 'Tom Goldstein']",ICLR,Canary in a Coalmine: Better Membership Inference with Ensembled Adversarial Queries,https://iclr.cc/virtual/2023/oral/12737,2023," As industrial applications are increasingly automated by machine learning models, enforcing personal data ownership and intellectual property rights requires tracing training data back to their rightful owners. Membership inference algorithms approach this problem by using statistical techniques to discern whether a target sample was included in a model's training set. However, existing methods only utilize the unaltered target sample or simple augmentations of the target to compute statistics. Such a sparse sampling of the model's behavior carries little information, leading to poor inference capabilities. In this work, we use adversarial tools to directly optimize for queries that are discriminative and diverse. Our improvements achieve significantly more accurate membership inference than existing methods, especially in offline scenarios and in the low false-positive regime which is critical in legal settings.",Oral 1 Track 4: Social Aspects of Machine Learning,https://openreview.net/pdf?id=b7SBTEBFnC,
"['Yi-Lun Liao', 'Tess Smidt']",ICLR,Equiformer: Equivariant Graph Attention Transformer for 3D Atomistic Graphs,https://iclr.cc/virtual/2023/oral/12753,2023," Despite their widespread success in various domains, Transformer networks have yet to perform well across datasets in the domain of 3D atomistic graphs such as molecules even when 3D-related inductive biases like translational invariance and rotational equivariance are considered. In this paper, we demonstrate that Transformers can generalize well to 3D atomistic graphs and present Equiformer, a graph neural network leveraging the strength of Transformer architectures and incorporating SE(3)/E(3)-equivariant features based on irreducible representations (irreps). First, we propose a simple and effective architecture by only replacing original operations in Transformers with their equivariant counterparts and including tensor products. Using equivariant operations enables encoding equivariant information in channels of irreps features without complicating graph structures. With minimal modifications to Transformers, this architecture has already achieved strong empirical results. Second, we propose a novel attention mechanism called equivariant graph attention, which improves upon typical attention in Transformers through replacing dot product attention with multi-layer perceptron attention and including non-linear message passing. With these two innovations, Equiformer achieves competitive results to previous models on QM9, MD17 and OC20 datasets.",Oral 1 Track 2: Machine Learning for Sciences,https://openreview.net/pdf?id=KwmPfARgOTD,
"['Jimmy Smith', 'andrew warrington', 'Scott Linderman']",ICLR,Simplified State Space Layers for Sequence Modeling,https://iclr.cc/virtual/2023/oral/12657,2023," Models using structured state space sequence (S4) layers have achieved state-of-the-art performance on long-range sequence modeling tasks. An S4 layer combines linear state space models (SSMs), the HiPPO framework, and deep learning to achieve high performance. We build on the design of the S4 layer and introduce a new state space layer, the S5 layer.  Whereas an S4 layer uses many independent single-input, single-output SSMs, the S5 layer uses one multi-input, multi-output SSM.  We establish a connection between S5 and S4, and use this to develop the initialization and parameterization used by the S5 model.  The result is a state space layer that can leverage efficient and widely implemented parallel scans, allowing S5 to match the computational efficiency of S4, while also achieving state-of-the-art performance on several long-range sequence modeling tasks.  S5 averages $87.4\%$ on the long range arena benchmark, and $98.5\%$ on the most difficult Path-X task.",Oral 6 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=Ai8Hw3AXqks,
"['Xiang Li', 'Viraj Mehta', 'Johannes Kirschner', 'Ian Char', 'Willie Neiswanger', 'Jeff Schneider', 'Andreas Krause', 'Ilija Bogunovic']",ICLR,Near-optimal Policy Identification in Active Reinforcement Learning,https://iclr.cc/virtual/2023/oral/12706,2023," Many real-world reinforcement learning tasks require control of complex dynamical systems that involve both costly data acquisition processes and large state spaces. In cases where the expensive transition dynamics can be readily evaluated at specified states (e.g., via a simulator), agents can operate in what is often referred to as planning with a \emph{generative model}. We propose the AE-LSVI algorithm for best policy identification, a novel variant of the kernelized least-squares value iteration (LSVI) algorithm that combines optimism with pessimism for active exploration (AE). AE-LSVI provably identifies a near-optimal policy \emph{uniformly} over an entire state space and achieves polynomial sample complexity guarantees that are independent of the number of states. When specialized to the recently introduced offline contextual Bayesian optimization setting, our algorithm achieves improved sample complexity bounds. Experimentally, we demonstrate that AE-LSVI outperforms other RL algorithms in a variety of environments when robustness to the initial state is required.",Oral 2 Track 4: Reinforcement Learning,https://openreview.net/pdf?id=3OR2tbtnYC-,
"['Aviral Kumar', 'Rishabh Agarwal', 'Xinyang Geng', 'George Tucker', 'Sergey Levine']",ICLR,Offline Q-learning on Diverse Multi-Task Data Both Scales And Generalizes,https://iclr.cc/virtual/2023/oral/12708,2023," The potential of offline reinforcement learning (RL) is that high-capacity models trained on large, heterogeneous datasets can lead to agents that generalize broadly, analogously to similar advances in vision and NLP. However, recent works argue that offline RL methods encounter unique challenges to scaling up model capacity. Drawing on the learnings from these works, we re-examine previous design choices and find that with appropriate choices: ResNets, cross-entropy based distributional backups, and feature normalization, offline Q-learning algorithms exhibit strong performance that scales with model capacity. Using multi-task Atari as a testbed for scaling and generalization, we train a single policy on 40 games with near-human performance using up-to 80 million parameter networks, finding that model performance scales favorably with capacity. In contrast to prior work, we extrapolate beyond dataset performance even when trained entirely on a large (400M transitions) but highly suboptimal dataset (51% human-level performance). Compared to return-conditioned supervised approaches, offline Q-learning scales similarly with model capacity and has better performance, especially when the dataset is suboptimal. Finally, we show that offline Q-learning with a diverse dataset is sufficient to learn powerful representations that facilitate rapid transfer to novel games and fast online learning on new variations of a training game, improving over existing state-of-the-art representation learning approaches.",Oral 1 Track 5: Reinforcement Learning,https://openreview.net/pdf?id=4-k7kUavAj,
"['JIANFEI YANG', 'Xiangyu Peng', 'Kai Wang', 'Zheng Zhu', 'Jiashi Feng', 'Lihua Xie', 'Yang You']",ICLR,Divide to Adapt: Mitigating Confirmation Bias for Domain Adaptation of Black-Box Predictors,https://iclr.cc/virtual/2023/oral/12702,2023," Domain Adaptation of Black-box Predictors (DABP) aims to learn a model on an unlabeled target domain supervised by a black-box predictor trained on a source domain. It does not require access to both the source-domain data and the predictor parameters, thus addressing the data privacy and portability issues of standard domain adaptation methods. Existing DABP approaches mostly rely on knowledge distillation (KD) from the black-box predictor, i.e., training the model with its noisy target-domain predictions, which however inevitably introduces the confirmation bias accumulated from the prediction noises and leads to degrading performance. To mitigate such bias, we propose a new strategy, \textit{divide-to-adapt}, that purifies cross-domain knowledge distillation by proper domain division. This is inspired by an observation we make for the first time in domain adaptation: the target domain usually contains easy-to-adapt and hard-to-adapt samples that have different levels of domain discrepancy w.r.t. the source domain, and deep models tend to fit easy-to-adapt samples first. Leveraging easy-to-adapt samples with less noise can help KD alleviate the negative effect of prediction noises from black-box predictors. In this sense, the target domain can be divided into an easy-to-adapt subdomain with less noise and a hard-to-adapt subdomain at the early stage of training. Then the adaptation is achieved by semi-supervised learning. We further reduce distribution discrepancy between subdomains and develop weak-strong augmentation strategy to filter the predictor errors progressively. As such, our method is a simple yet effective solution to reduce error accumulation in cross-domain knowledge distillation for DABP. Moreover, we prove that the target error of DABP is bounded by the noise ratio of two subdomains, i.e., the confirmation bias, which provides the theoretical justifications for our method. Extensive experiments demonstrate our method achieves state of the art on all DABP benchmarks, outperforming the existing best approach by 7.0\% on VisDA-17, and is even comparable with the standard domain adaptation methods that use the source-domain data.",Oral 1 Track 6: Deep Learning and representational learning II,https://openreview.net/pdf?id=hVrXUps3LFA,
"['Cristina Cornelio', 'Jan Stuehmer', 'Xu Hu', 'Timothy Hospedales']",ICLR,Learning where and when to reason in neuro-symbolic inference,https://iclr.cc/virtual/2023/oral/12732,2023," The integration of hard constraints on neural network outputs is a very desirable capability. This allows to instill trust in AI by guaranteeing the sanity of that neural network predictions with respect to domain knowledge. Recently, this topic has received a lot of attention. However, all the existing methods usually either impose the constraints in a ""weak"" form at training time, with no guarantees at inference, or fail to provide a general framework that supports different tasks and constraint types. We tackle this open problem from a neuro-symbolic perspective. Our pipeline enhances a conventional neural predictor with (1) a symbolic reasoning module capable of correcting structured prediction errors and (2) a neural attention module that learns to direct the reasoning effort to focus on potential prediction errors, while keeping other outputs unchanged. This framework provides an appealing trade-off between the efficiency of constraint-free neural inference and the prohibitive cost of exhaustive reasoning at inference time. We show that our method outperforms the state of the art on visual-Sudoku, and can also benefit visual scene graph prediction. Furthermore, it can improve the performance of existing neuro-symbolic systems that lack our explicit reasoning during inference.",Oral 2 Track 2: General Machine Learning,https://openreview.net/pdf?id=en9V5F8PR-,
"['Yanchao Sun', 'shuang ma', 'Ratnesh Madaan', 'Rogerio Bonatti', 'Furong Huang', 'Ashish Kapoor']",ICLR,SMART: Self-supervised Multi-task pretrAining with contRol Transformers,https://iclr.cc/virtual/2023/oral/12742,2023," Self-supervised pretraining has been extensively studied in language and vision domains, where a unified model can be easily adapted to various downstream tasks by pretraining representations without explicit labels. When it comes to sequential decision-making tasks, however, it is difficult to properly design such a pretraining approach that can cope with both high-dimensional perceptual information and the complexity of sequential control over long interaction horizons. The challenge becomes combinatorially more complex if we want to pretrain representations amenable to a large variety of tasks. To tackle this problem, in this work, we formulate a general pretraining-finetuning pipeline for sequential decision making, under which we propose a generic pretraining framework \textit{Self-supervised Multi-task pretrAining with contRol Transformer (SMART)}. By systematically investigating pretraining regimes, we carefully design a Control Transformer (CT) coupled with a novel control-centric pretraining objective in a self-supervised manner. SMART encourages the representation to capture the common essential information relevant to short-term control and long-term control, which is transferrable across tasks. We show by extensive experiments in DeepMind Control Suite that SMART significantly improves the learning efficiency among seen and unseen downstream tasks and domains under different learning scenarios including Imitation Learning (IL) and Reinforcement Learning (RL). Benefiting from the proposed control-centric objective, SMART is resilient to distribution shift between pretraining and finetuning, and even works well with low-quality pretraining datasets that are randomly collected. The codebase, pretrained models and datasets are provided at https://github.com/microsoft/smart.",Oral 3 Track 1: Reinforcement Learning,https://openreview.net/pdf?id=9piH3Hg8QEf,
"['Ben Athiwaratkun', 'Sanjay Krishna Gouda', 'Zijian Wang', 'Xiaopeng Li', 'YUCHEN TIAN', 'Ming Tan', 'Wasi Ahmad', 'Shiqi Wang', 'Qing Sun', 'Mingyue Shang', 'Sujan Kumar Gonugondla', 'Hantian Ding', 'Varun Kumar', 'Nathan Fulton', 'Arash Farahani', 'Siddhartha Jain', 'Robert Giaquinto', 'Haifeng Qian', 'Murali Krishna Ramanathan', 'Ramesh Nallapati', 'Baishakhi Ray', 'Parminder Bhatia', 'Sudipta Sengupta', 'Dan Roth', 'Bing Xiang']",ICLR,Multi-lingual Evaluation of Code Generation Models,https://iclr.cc/virtual/2023/oral/12722,2023," We present two new benchmarks, MBXP and Multilingual HumanEval, designed to evaluate code completion models in over 10 programming languages. These datasets are generated using a conversion framework that transpiles prompts and test cases from the original MBPP and HumanEval datasets into the corresponding data in the target language. By using these benchmarks, we are able to assess the performance of code generation models in a multi-lingual fashion, and discovered generalization ability of language models on out-of-domain languages, advantages of multi-lingual models over mono-lingual, the ability of  few-shot prompting to teach the model new languages, and zero-shot translation abilities. In addition, we use our code generation model to perform large-scale bootstrapping to obtain synthetic canonical solutions in several languages, which can be used for other code-related evaluations such as code insertion, robustness, or summarization tasks.",Oral 3 Track 2: Deep Learning and representational learning,https://openreview.net/pdf?id=Bo7eeXm6An8,
"['Kevin Meng', 'Arnab Sen Sharma', 'Alex J Andonian', 'Yonatan Belinkov', 'David Bau']",ICLR,Mass-Editing Memory in a Transformer,https://iclr.cc/virtual/2023/oral/12726,2023," Recent work has shown exciting promise in updating large language models with new memories, so as to replace obsolete information or add specialized knowledge. However, this line of work is predominantly limited to updating single associations. We develop MEMIT, a method for directly updating a language model with many memories, demonstrating experimentally that it can scale up to thousands of associations for GPT-J (6B) and GPT-NeoX (20B), exceeding prior work by an order of magnitude. Our code and data will be open-sourced upon publication.",Oral 2 Track 1: Applications,https://openreview.net/pdf?id=MkbcAHIYgyS,
"['Shuaicheng Niu', 'Jiaxiang Wu', 'Yifan Zhang', 'Zhiquan Wen', 'Yaofo Chen', 'Peilin Zhao', 'Mingkui Tan']",ICLR,Towards Stable Test-time Adaptation in Dynamic Wild World,https://iclr.cc/virtual/2023/oral/12676,2023," Test-time adaptation (TTA) has shown to be effective at tackling distribution shifts between training and testing data by adapting a given model on test samples. However, the online model updating of TTA may be unstable and this is often a key obstacle preventing existing TTA methods from being deployed in the real world. Specifically, TTA may fail to improve or even harm the model performance when test data have: 1) mixed distribution shifts, 2) small batch sizes, and 3) online imbalanced label distribution shifts, which are quite common in practice. In this paper, we investigate the unstable reasons and find that the batch norm layer is a crucial factor hindering TTA stability. Conversely, TTA can perform more stably with batch-agnostic norm layers, i.e., group or layer norm. However, we observe that TTA with group and layer norms does not always succeed and still suffers many failure cases. By digging into the failure cases, we find that certain noisy test samples with large gradients may disturb the model adaption and result in collapsed trivial solutions, i.e., assigning the same class label for all samples. To address the above collapse issue, we propose a sharpness-aware and reliable entropy minimization method, called SAR, for further stabilizing TTA from two aspects: 1) remove partial noisy samples with large gradients, 2) encourage model weights to go to a flat minimum so that the model is robust to the remaining noisy samples. Promising results demonstrate that SAR performs more stably than prior methods and is computationally efficient under the above wild test scenarios.",Oral 4 Track 1: Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=g2YraF75Tj,
"['Marc Szafraniec', 'Baptiste Roziere', 'Hugh Leather', 'Patrick Labatut', 'François Charton', 'Gabriel Synnaeve']",ICLR,Code Translation with Compiler Representations,https://iclr.cc/virtual/2023/oral/12614,2023," In this paper, we leverage low-level compiler intermediate representations (IR) code translation. Traditional transpilers rely on syntactic information and handcrafted rules, which limits their applicability and produces unnatural-looking code. Applying neural machine translation (NMT) approaches to code has successfully broadened the set of programs on which one can get a natural-looking translation. However, they treat the code as sequences of text tokens, and still do not differentiate well enough between similar pieces of code which have different semantics in different languages. The consequence is low quality translation, reducing the practicality of NMT, and stressing the need for an approach significantly increasing its accuracy. Here we propose to augment code translation with IRs, specifically LLVM IR, with results on the C++, Java, Rust, and Go languages. Our method improves upon the state of the art for unsupervised code translation, increasing the number of correct translations by 11% on average, and up to 79% for the Java → Rust pair with greedy decoding. With beam search, it increases the number of correct translations by 5.5% in average. We extend previous test sets for code translation, by adding hundreds of Go and Rust functions. Additionally, we train models with high performance on the problem of IR decompilation, generating programming source code from IR, and study using IRs as intermediary pivot for translation.",Oral 2 Track 6: Applications & Social Aspects of Machine Learning,https://openreview.net/pdf?id=XomEU3eNeSQ,
"['Ping-yeh Chiang', 'Renkun Ni', 'David Y. Miller', 'Arpit Bansal', 'Jonas Geiping', 'Micah Goldblum', 'Tom Goldstein']",ICLR,Loss Landscapes are All You Need: Neural Network Generalization Can Be Explained Without the Implicit Bias of Gradient Descent,https://iclr.cc/virtual/2023/oral/12746,2023," It is commonly believed that the implicit regularization of optimizers is needed for neural networks to generalize in the overparameterized regime. In this paper, we observe experimentally that this implicit regularization behavior is {\em generic}, i.e. it does not depend strongly on the choice of optimizer. We demonstrate this by training neural networks using several gradient-free optimizers, which do not benefit from properties that are often attributed to gradient-based optimizers.   This includes a guess-and-check optimizer that generates uniformly random parameter vectors until finding one that happens to achieve perfect train accuracy, and a zeroth-order Pattern Search optimizer that uses no gradient computations. In the low sample and few-shot regimes, where zeroth order optimizers are most computationally tractable, we find that these non-gradient optimizers achieve test accuracy comparable to SGD. The code to reproduce results can be found at https://github.com/Ping-C/optimizer .",Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=QC10RmRbZy9,
"['Anurag Ajay', 'Yilun Du', 'Abhi Gupta', 'Joshua B Tenenbaum', 'Tommi Jaakkola', 'Pulkit Agrawal']",ICLR,Is Conditional Generative Modeling all you need for Decision Making?,https://iclr.cc/virtual/2023/oral/12696,2023," Recent improvements in conditional generative modeling have made it possible to generate high-quality images from language descriptions alone. We investigate whether these methods can directly address the problem of sequential decision-making. We view decision-making not through the lens of reinforcement learning (RL), but rather through conditional generative modeling. To our surprise, we find that our formulation leads to policies that can outperform existing offline RL approaches across standard benchmarks. By modeling a policy as a return-conditional generative model, we avoid the need for dynamic programming and subsequently eliminate many of the complexities that come with traditional offline RL. We further demonstrate the advantages of modeling policies as conditional generative models by considering two other conditioning variables: constraints and skills. Conditioning on a single constraint or skill during training leads to behaviors at test-time that can satisfy several constraints together or demonstrate a composition of skills. Our results illustrate that conditional generative modeling is a powerful tool for decision-making.",Oral 4 Track 4: Reinforcement Learning II,https://openreview.net/pdf?id=sP1fo2K9DFG,
"['Daniel Kunin', 'Atsushi Yamamura', 'Chao Ma', 'Surya Ganguli']",ICLR,The Asymmetric Maximum Margin Bias of Quasi-Homogeneous Neural Networks,https://iclr.cc/virtual/2023/oral/12690,2023," In this work, we explore the maximum-margin bias of quasi-homogeneous neural networks trained with gradient flow on an exponential loss and past a point of separability. We introduce the class of quasi-homogeneous models, which is expressive enough to describe nearly all neural networks with homogeneous activations, even those with biases, residual connections, and normalization layers, while structured enough to enable geometric analysis of its gradient dynamics. Using this analysis, we generalize the existing results of maximum-margin bias for homogeneous networks to this richer class of models. We find that gradient flow implicitly favors a subset of the parameters, unlike in the case of a homogeneous model where all parameters are treated equally. We demonstrate through simple examples how this strong favoritism toward minimizing an asymmetric norm can degrade the robustness of quasi-homogeneous models. On the other hand, we conjecture that this norm-minimization discards, when possible, unnecessary higher-order parameters, reducing the model to a sparser parameterization. Lastly, by applying our theorem to sufficiently expressive neural networks with normalization layers, we reveal a universal mechanism behind the empirical phenomenon of Neural Collapse.",Oral 3 Track 5: Deep Learning and representational learning & Neuroscience and Cognitive Science,https://openreview.net/pdf?id=IM4xp7kGI5V,
"['Mohammadsajad Abavisani', 'David Danks', 'Sergey Plis']",ICLR,GRACE-C: Generalized Rate Agnostic Causal Estimation via Constraints,https://iclr.cc/virtual/2023/oral/12717,2023," Graphical structures estimated by causal learning algorithms from time series data can provide highly misleading causal information if the causal timescale of the generating process fails to match the measurement timescale of the data. Existing algorithms provide limited resources to respond to this challenge, and so researchers must either use models that they know are likely misleading, or else forego causal learning entirely. Existing methods face up-to-four distinct shortfalls, as they might a) require that the difference between causal and measurement timescales is known; b) only handle very small number of random variables when the timescale difference is unknown; c) only apply to pairs of variables (albeit with fewer assumptions about prior knowledge); or d) be unable to find a solution given statistical noise in the data. This paper aims to address these challenges. We present an approach that combines constraint programming with both theoretical insights into the problem structure and prior information about admissible causal interactions to achieve speed up of multiple orders of magnitude. The resulting system scales to significantly larger sets of random variables ($>100$) without knowledge of the timescale difference while maintaining  theoretical guarantees. This method is also robust to edge misidentification and can use parametric connection strengths, while optionally finding the optimal among many possible solutions.",Oral 4 Track 2: Probabilistic Methods,https://openreview.net/pdf?id=B_pCIsX8KL_,
"['Jiyan Jiang', 'Wenpeng Zhang', 'Shiji Zhou', 'Lihong Gu', 'Xiaodong Zeng', 'Wenwu Zhu']",ICLR,Multi-Objective Online Learning,https://iclr.cc/virtual/2023/oral/12729,2023," This paper presents a systematic study of multi-objective online learning. We first formulate the framework of Multi-Objective Online Convex Optimization, which encompasses a novel multi-objective regret. This regret is built upon a sequence-wise extension of the commonly used discrepancy metric Pareto suboptimality gap in zero-order multi-objective bandits. We then derive an equivalent form of the regret, making it amenable to be optimized via first-order iterative methods. To motivate the algorithm design, we give an explicit example in which equipping OMD with the vanilla min-norm solver for gradient composition will incur a linear regret, which shows that merely regularizing the iterates, as in single-objective online learning, is not enough to guarantee sublinear regrets in the multi-objective setting. To resolve this issue, we propose a novel min-regularized-norm solver that regularizes the composite weights. Combining min-regularized-norm with OMD results in the Doubly Regularized Online Mirror Multiple Descent algorithm. We further derive the multi-objective regret bound for the proposed algorithm, which matches the optimal bound in the single-objective setting. Extensive experiments on real-world datasets verify the effectiveness of the proposed algorithm.",Oral 5 Track 2: Optimization,https://openreview.net/pdf?id=dKkMnCWfVmm,
"['Jiyeon Han', 'Hwanil Choi', 'Yunjey Choi', 'Junho Kim', 'Jung-Woo Ha', 'Jaesik Choi']",ICLR,Rarity Score : A New Metric to Evaluate the Uncommonness of Synthesized Images,https://iclr.cc/virtual/2023/oral/12703,2023," Evaluation metrics in image synthesis play a key role to measure performances of generative models. However, most metrics mainly focus on image fidelity. Existing diversity metrics are derived by comparing distributions, and thus they cannot quantify the diversity or rarity degree of each generated image. In this work, we propose a new evaluation metric, called `rarity score', to measure both image-wise uncommonness and model-wise diversified generation performance.   We first show empirical observation that typical samples are close to each other and distinctive samples are far from each other in nearest-neighbor distances on latent spaces represented by feature extractor networks such as VGG16. We then show that one can effectively filter typical or distinctive samples with the proposed metric. We also use our metric to demonstrate that the extent to which different generative models produce rare images can be effectively compared. Further, our metric can be used to compare rarities between datasets that share the same concept such as CelebA-HQ and FFHQ. Finally, we analyze the use of metrics in different designs of feature extractors to better understand the relationship between feature spaces and resulting high-rarity images. Code will be publicly available for the research community.",Oral 3 Track 3: Generative models,https://openreview.net/pdf?id=JTGimap_-F,
"['Blake Bordelon', 'Cengiz Pehlevan']",ICLR,The Influence of Learning Rule on Representation Dynamics in Wide Neural Networks,https://iclr.cc/virtual/2023/oral/12632,2023," It is unclear how changing the learning rule of a deep neural network alters its learning dynamics and representations. To gain insight into the relationship between learned features, function approximation, and the learning rule, we analyze infinite-width deep networks trained with gradient descent (GD) and biologically-plausible alternatives including feedback alignment (FA), direct feedback alignment (DFA), and error modulated Hebbian learning (Hebb), as well as gated linear networks (GLN). We show that, for each of these learning rules, the evolution of the output function at infinite width is governed by a time varying effective neural tangent kernel (eNTK). In the lazy training limit, this eNTK is static and does not evolve, while in the rich mean-field regime this kernel's evolution can be determined self-consistently with dynamical mean field theory (DMFT). This DMFT enables comparisons of the feature and prediction dynamics induced by each of these learning rules. In the lazy limit, we find that DFA and Hebb can only learn using the last layer features, while full FA can utilize earlier layers with a scale determined by the initial correlation between feedforward and feedback weight matrices. In the rich regime, DFA and FA utilize a temporally evolving and depth-dependent NTK. Counterintuitively, we find that FA networks trained in the rich regime exhibit more feature learning if initialized with smaller correlation between the forward and backward pass weights. GLNs admit a very simple formula for their lazy limit kernel and preserve conditional Gaussianity of their preactivations under gating functions. Error modulated Hebb rules show very small task-relevant alignment of their kernels and perform most task relevant learning in the last layer.",Oral 5 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=nZ2NtpolC5-,
"['Vanshaj Khattar', 'Yuhao Ding', 'Bilgehan Sel', 'Javad Lavaei', 'Ming Jin']",ICLR,A CMDP-within-online framework for Meta-Safe Reinforcement Learning,https://iclr.cc/virtual/2023/oral/12687,2023," Meta-reinforcement learning has widely been used as a learning-to-learn framework to solve unseen tasks with limited experience. However, the aspect of constraint violations has not been adequately addressed in the existing works, making their application restricted in real-world settings. In this paper, we study the problem of meta-safe reinforcement learning (meta-SRL) through the CMDP-within-online framework. We obtain task-averaged regret guarantees for the reward maximization (optimality gap) and constraint violations using gradient-based meta-learning and show that the task-averaged optimality gap and constraint satisfaction improve with task-similarity in the static environment, or task-relatedness in the changing environment. Several technical challenges arise when making this framework practical while still having strong theoretical guarantees. To address these challenges, we propose a meta-algorithm that performs inexact online learning on the upper bounds of intra-task optimality gap and constraint violations estimated by off-policy stationary distribution corrections. Furthermore, we enable the learning rates to be adapted for every task and extend our approach to settings with the dynamically changing task environments. Finally, experiments are conducted to demonstrate the effectiveness of our approach. The proposed theoretical framework is the first to handle the nonconvexity and stochastic nature of within-task CMDPs, while exploiting inter-task dependency for multi-task safe learning.",Oral 4 Track 3: Reinforcement Learning I,https://openreview.net/pdf?id=mbxz9Cjehr,
"['Zichen Jeff Cui', 'Yibin Wang', 'Nur Muhammad Shafiullah', 'Lerrel Pinto']",ICLR,From Play to Policy: Conditional Behavior Generation from Uncurated Robot Data,https://iclr.cc/virtual/2023/oral/12686,2023," While large-scale sequence modelling from offline data has led to impressive performance gains in natural language generation and image generation, directly translating such ideas to robotics has been challenging. One critical reason for this is that uncurated robot demonstration data, i.e. play data, collected from non-expert human demonstrators are often noisy, diverse, and distributionally multi-modal. This makes extracting useful, task-centric behaviors from such data a difficult generative modelling problem. In this work, we present Conditional Behavior Transformers (C-BeT), a method that combines the multi-modal generation ability of Behavior Transformer with future-conditioned goal specification. On a suite of simulated benchmark tasks, we find that C-BeT improves upon prior state-of-the-art work in learning from play data by an average of 45.7%. Further, we demonstrate for the first time that useful task-centric behaviors can be learned on a real-world robot purely from play data without any task labels or reward information. Robot videos are best viewed on our project website: play-to-policy.github.io",Oral 4 Track 6: Deep Learning and representational learning- Reinforcement Learning,https://openreview.net/pdf?id=c7rM7F7jQjN,
"['Xuheng Cai', 'Chao Huang', 'Lianghao Xia', 'Xubin Ren']",ICLR,LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation,https://iclr.cc/virtual/2023/oral/12748,2023," Graph neural network (GNN) is a powerful learning approach for graph-based recommender systems. Recently, GNNs integrated with contrastive learning have shown superior performance in recommendation with their data augmentation schemes, aiming at dealing with highly sparse data. Despite their success, most existing graph contrastive learning methods either perform stochastic augmentation (e.g., node/edge perturbation) on the user-item interaction graph, or rely on the heuristic-based augmentation techniques (e.g., user clustering) for generating contrastive views. We argue that these methods cannot well preserve the intrinsic semantic structures and are easily biased by the noise perturbation. In this paper, we propose a simple yet effective graph contrastive learning paradigm LightGCL that mitigates these issues impairing the generality and robustness of CL-based recommenders. Our model exclusively utilizes singular value decomposition for contrastive augmentation, which enables the unconstrained structural refinement with global collaborative relation modeling. Experiments conducted on several benchmark datasets demonstrate the significant improvement in performance of our model over the state-of-the-arts. Further analyses demonstrate the superiority of LightGCL's robustness against data sparsity and popularity bias. The source code of our model is available at https://github.com/HKUDS/LightGCL.",Oral 6 Track 4: Applications & Social Aspects of Machine Learning & General Machine Learning,https://openreview.net/pdf?id=FKXVK9dyMM,
"['Sheheryar Zaidi', 'Michael Schaarschmidt', 'James Martens', 'Hyunjik Kim', 'Yee Whye Teh', 'Alvaro Sanchez Gonzalez', 'Peter Battaglia', 'Razvan Pascanu', 'Jonathan Godwin']",ICLR,Pre-training via Denoising for Molecular Property Prediction,https://iclr.cc/virtual/2023/oral/12772,2023," Many important problems involving molecular property prediction from 3D structures have limited data, posing a generalization challenge for neural networks. In this paper, we describe a pre-training technique based on denoising that achieves a new state-of-the-art in molecular property prediction by utilizing large datasets of 3D molecular structures at equilibrium to learn meaningful representations for downstream tasks. Relying on the well-known link between denoising autoencoders and score-matching, we show that the denoising objective corresponds to learning a molecular force field -- arising from approximating the Boltzmann distribution with a mixture of Gaussians -- directly from equilibrium structures. Our experiments demonstrate that using this pre-training objective significantly improves performance on multiple benchmarks, achieving a new state-of-the-art on the majority of targets in the widely used QM9 dataset. Our analysis then provides practical insights into the effects of different factors -- dataset sizes, model size and architecture, and the choice of upstream and downstream datasets -- on pre-training.",Oral 4 Track 5: Machine Learning for Sciences & Probabilistic Methods,https://openreview.net/pdf?id=tYIMtogyee,
"['Yunwei Ren', 'Mo Zhou', 'Rong Ge']",ICLR,Depth Separation with Multilayer Mean-Field Networks,https://iclr.cc/virtual/2023/oral/12736,2023," Depth separation—why a deeper network is more powerful than a shallow one—has been a major problem in deep learning theory. Previous results often focus on representation power, for example, Safran et al. (2019) constructed a function that is easy to approximate using a 3-layer network but not approximable by any 2-layer network. In this paper, we show that this separation is in fact algorithmic: one can learn the function constructed by Safran et al. (2019) using an overparametrized network with polynomially many neurons efﬁciently. Our result relies on a new way of extending the mean-ﬁeld limit to multilayer networks, and a decomposition of loss that factors out the error introduced by the discretization of inﬁnite-width mean-ﬁeld networks.",Oral 6 Track 1: Theory,https://openreview.net/pdf?id=uzFQpkEzOo,
"['Yuxin Fang', 'Li Dong', 'Hangbo Bao', 'Xinggang Wang', 'Furu Wei']",ICLR,Corrupted Image Modeling for Self-Supervised Visual Pre-Training,https://iclr.cc/virtual/2023/oral/12571,2023," We introduce Corrupted Image Modeling (CIM) for self-supervised visual pre-training. CIM uses an auxiliary generator with a small trainable BEiT to corrupt the input image instead of using artificial [MASK] tokens, where some patches are randomly selected and replaced with plausible alternatives sampled from the BEiT output distribution. Given this corrupted image, an enhancer network learns to either recover all the original image pixels, or predict whether each visual token is replaced by a generator sample or not. The generator and the enhancer are simultaneously trained and synergistically updated. After pre-training, the enhancer can be used as a high-capacity visual encoder for downstream tasks. CIM is a general and flexible visual pre-training framework that is suitable for various network architectures. For the first time, CIM demonstrates that both ViT and CNN can learn rich visual representations using a unified, non-Siamese framework. Experimental results show that our approach achieves compelling results in vision benchmarks, such as ImageNet classification and ADE20K semantic segmentation.",Oral 5 Track 1: Unsupervised and Self-supervised learning & Social Aspects of Machine Learning-,https://openreview.net/pdf?id=09hVcSDkea,
"['Ali Shahin Shamsabadi', 'Sierra Wyllie', 'Nicholas Franzese', 'Natalie Dullerud', 'Sébastien Gambs', 'Nicolas Papernot', 'Xiao Wang', 'Adrian Weller']",ICLR,Confidential-PROFITT: Confidential PROof of FaIr Training of Trees,https://iclr.cc/virtual/2023/oral/12661,2023," Post hoc auditing of model fairness suffers from potential drawbacks: (1) auditing may be highly sensitive to the test samples chosen; (2) the model and/or its training data may need to be shared with an auditor thereby breaking confidentiality. We address these issues by instead providing a certificate that demonstrates that the learning algorithm itself is fair, and hence, as a consequence, so too is the trained model. We introduce a method to provide a confidential proof of fairness for training, in the context of widely used decision trees, which we term Confidential-PROFITT. We propose novel fair decision tree learning algorithms along with customized zero-knowledge proof protocols to obtain a proof of fairness that can be audited by a third party. Using zero-knowledge proofs enables us to guarantee confidentiality of both the model and its training data. We show empirically that bounding the information gain of each node with respect to the sensitive attributes reduces the unfairness of the final tree. In extensive experiments on the COMPAS, Communities and Crime, Default Credit, and Adult datasets, we demonstrate that a company can use Confidential-PROFITT to certify the fairness of their decision tree to an auditor in less than 2 minutes, thus indicating the applicability of our approach. This is true for both the demographic parity and equalized odds definitions of fairness. Finally, we extend Confidential-PROFITT to apply to ensembles of trees.",Oral 6 Track 2: Infrastructure & Social Aspects of Machine Learning,https://openreview.net/pdf?id=iIfDQVyuFD,
"['Sachit Menon', 'Carl Vondrick']",ICLR,Visual Classification via Description from Large Language Models,https://iclr.cc/virtual/2023/oral/12774,2023," Vision-language models such as CLIP have shown promising performance on a variety of recognition tasks using the standard zero-shot classification procedure -- computing similarity between the query image and the embedded words for each category. By only using the category name, they neglect to make use of the rich context of additional information that language affords. The procedure gives no intermediate understanding of why a category is chosen, and furthermore provides no mechanism for adjusting the criteria used towards this decision. We present an alternative framework for classification with VLMs, which we call classification by description. We ask VLMs to check for descriptive features rather than broad categories: to find a tiger, look for its stripes; its claws; and more. By basing decisions on these descriptors, we can provide additional cues that encourage using the features we want to be used. In the process, we can get a clear idea of what the model ``thinks"" it is seeing to make its decision; it gains some level of inherent explainability. We query large language models (e.g., GPT-3) for these descriptors to obtain them in a scalable way. Extensive experiments show our framework has numerous advantages past interpretability. We show improvements in accuracy on ImageNet across distribution shifts; demonstrate the ability to adapt VLMs to recognize concepts unseen during training; and illustrate how descriptors can be edited to effectively mitigate bias compared to the baseline.",Oral 5 Track 4: Applications & Optimization,https://openreview.net/pdf?id=jlAjNL8z5cs,
"['Zenan Li', 'Zehua Liu', 'Yuan Yao', 'Jingwei Xu', 'Taolue Chen', 'Xiaoxing Ma', 'Jian Lu']",ICLR,Learning with Logical Constraints but without Shortcut Satisfaction,https://iclr.cc/virtual/2023/oral/12682,2023," Recent studies have started to explore the integration of logical knowledge into deep learning via encoding logical constraints as an additional loss function. However, existing approaches tend to vacuously satisfy logical constraints through shortcuts, failing to fully exploit the knowledge. In this paper, we present a new framework for learning with logical constraints. Specifically, we address the shortcut satisfaction issue by introducing dual variables for logical connectives, encoding how the constraint is satisfied. We further propose a variational framework where the encoded logical constraint is expressed as a distributional loss that is compatible with the model's original training loss. The theoretical analysis shows that the proposed approach bears some nice properties, and the experimental evaluations demonstrate its superior performance in both model generalizability and constraint satisfaction.",Oral 5 Track 5: Deep Learning and representational learning & Reinforcement Learning,https://openreview.net/pdf?id=M2unceRvqhh,
"['Sitan Chen', 'Sinho Chewi', 'Jerry Li', 'Yuanzhi Li', 'Adil Salim', 'Anru Zhang']",ICLR,Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions,https://iclr.cc/virtual/2023/oral/12680,2023," We provide theoretical convergence guarantees for score-based generative models (SGMs) such as denoising diffusion probabilistic models (DDPMs), which constitute the backbone of large-scale real-world generative models such as DALL$\cdot$E 2. Our main result is that, assuming accurate score estimates, such SGMs can efficiently sample from essentially any realistic data distribution. In contrast to prior works, our results (1) hold for an $L^2$-accurate score estimate (rather than $L^\infty$-accurate); (2) do not require restrictive functional inequality conditions that preclude substantial non-log-concavity; (3) scale polynomially in all relevant problem parameters; and (4) match state-of-the-art complexity guarantees for discretization of the Langevin diffusion, provided that the score error is sufficiently small. We view this as strong theoretical justification for the empirical success of SGMs. We also examine SGMs based on the critically damped Langevin diffusion (CLD). Contrary to conventional wisdom, we provide evidence that the use of the CLD does *not* reduce the complexity of SGMs.",Oral 2 Track 3: Generative models,https://openreview.net/pdf?id=zyLVMgsZ0U_,
"['Qitian Wu', 'Chenxiao Yang', 'Wentao Zhao', 'Yixuan He', 'David Wipf', 'Junchi Yan']",ICLR,DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion,https://iclr.cc/virtual/2023/oral/12621,2023," Real-world data generation often involves complex inter-dependencies among instances, violating the IID-data hypothesis of standard learning paradigms and posing a challenge for uncovering the geometric structures for learning desired instance representations. To this end, we introduce an energy constrained diffusion model which encodes a batch of instances from a dataset into evolutionary states that progressively incorporate other instances' information by their interactions. The diffusion process is constrained by descent criteria w.r.t. a principled energy function that characterizes the global consistency of instance representations over latent structures. We provide rigorous theory that implies closed-form optimal estimates for the pairwise diffusion strength among arbitrary instance pairs, which gives rise to a new class of neural encoders, dubbed as DIFFormer (diffusion-based Transformers), with two instantiations: a simple version with linear complexity for prohibitive instance numbers, and an advanced version for learning complex structures. Experiments highlight the wide applicability of our model as a general-purpose encoder backbone with superior performance in various tasks, such as node classification on large graphs, semi-supervised image/text classification, and spatial-temporal dynamics prediction. The codes are available at https://github.com/qitianwu/DIFFormer.",Oral 6 Track 5: Applications- & Deep Learning and representational learning,https://openreview.net/pdf?id=j6zUzrapY3L,
"['Ian Covert', 'Chanwoo Kim', 'Su-In Lee']",ICLR,Learning to Estimate Shapley Values with Vision Transformers,https://iclr.cc/virtual/2023/oral/12745,2023," Transformers have become a default architecture in computer vision, but understanding what drives their predictions remains a challenging problem. Current explanation approaches rely on attention values or input gradients, but these provide a limited view of a model’s dependencies. Shapley values offer a theoretically sound alternative, but their computational cost makes them impractical for large, high-dimensional models. In this work, we aim to make Shapley values practical for vision transformers (ViTs). To do so, we first leverage an attention masking approach to evaluate ViTs with partial information, and we then develop a procedure to generate Shapley value explanations via a separate, learned explainer model. Our experiments compare Shapley values to many baseline methods (e.g., attention rollout, GradCAM, LRP), and we find that our approach provides more accurate explanations than existing methods for ViTs.",Oral 1 Track 4: Social Aspects of Machine Learning,https://openreview.net/pdf?id=5ktFNz_pJLK,
"['Peter Yichen Chen', 'Jinxu Xiang', 'Dong Heon Cho', 'Yue Chang', 'G Pershing', 'Henrique Maia', 'Maurizio Chiaramonte', 'Kevin Carlberg', 'Eitan Grinspun']",ICLR,CROM: Continuous Reduced-Order Modeling of PDEs Using Implicit Neural Representations,https://iclr.cc/virtual/2023/oral/12769,2023," The long runtime of high-fidelity partial differential equation (PDE) solvers makes them unsuitable for time-critical applications. We propose to accelerate PDE solvers using reduced-order modeling (ROM). Whereas prior ROM approaches reduce the dimensionality of discretized vector fields, our continuous reduced-order modeling (CROM) approach builds a low-dimensional embedding of the continuous vector fields themselves, not their discretization. We represent this reduced manifold using continuously differentiable neural fields, which may train on any and all available numerical solutions of the continuous system, even when they are obtained using diverse methods or discretizations. We validate our approach on an extensive range of PDEs with training data from voxel grids, meshes, and point clouds. Compared to prior discretization-dependent ROM methods, such as linear subspace proper orthogonal decomposition (POD) and nonlinear manifold neural-network-based autoencoders, CROM features higher accuracy, lower memory consumption, dynamically adaptive resolutions, and applicability to any discretization. For equal latent space dimension, CROM exhibits 79$\times$ and 49$\times$ better accuracy, and 39$\times$ and 132$\times$ smaller memory footprint, than POD and autoencoder methods, respectively. Experiments demonstrate 109$\times$ and 89$\times$ wall-clock speedups over unreduced models on CPUs and GPUs, respectively. Videos and codes are available on the project page: https://crom-pde.github.io",Oral 1 Track 2: Machine Learning for Sciences,https://openreview.net/pdf?id=FUORz1tG8Og,
"['Cameron Diao', 'Ricky Loynd']",ICLR,Relational Attention: Generalizing Transformers for Graph-Structured Tasks,https://iclr.cc/virtual/2023/oral/12688,2023," Transformers flexibly operate over sets of real-valued vectors representing task-specific entities and their attributes, where each vector might encode one word-piece token and its position in a sequence, or some piece of information that carries no position at all. As set processors, transformers are at a disadvantage in reasoning over more general graph-structured data where nodes represent entities and edges represent relations between entities. To address this shortcoming, we generalize transformer attention to consider and update edge vectors in each transformer layer. We evaluate this relational transformer on a diverse array of graph-structured tasks, including the large and challenging CLRS Algorithmic Reasoning Benchmark. There, it dramatically outperforms state-of-the-art graph neural networks expressly designed to reason over graph-structured data. Our analysis demonstrates that these gains are attributable to relational attention's inherent ability to leverage the greater expressivity of graphs over sets.",Oral 6 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=cFuMmbWiN6,
"['Yecheng Jason Ma', 'Shagun Sodhani', 'Dinesh Jayaraman', 'Osbert Bastani', 'Vikash Kumar', 'Amy Zhang']",ICLR,VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training,https://iclr.cc/virtual/2023/oral/12735,2023," Reward and representation learning are two long-standing challenges for learning an expanding set of robot manipulation skills from sensory observations. Given the inherent cost and scarcity of in-domain, task-specific robot data, learning from large, diverse, offline human videos has emerged as a promising path towards acquiring a generally useful visual representation for control; however, how these human videos can be used for general-purpose reward learning remains an open question. We introduce $\textbf{V}$alue-$\textbf{I}$mplicit $\textbf{P}$re-training (VIP), a self-supervised pre-trained visual representation capable of generating dense and smooth reward functions for unseen robotic tasks. VIP casts representation learning from human videos as an offline goal-conditioned reinforcement learning problem and derives a self-supervised dual goal-conditioned value-function objective that does not depend on actions, enabling pre-training on unlabeled human videos. Theoretically, VIP can be understood as a novel implicit time contrastive objective that generates a temporally smooth embedding, enabling the value function to be implicitly defined via the embedding distance, which can then be used to construct the reward for any goal-image specified downstream task. Trained on large-scale Ego4D human videos and without any fine-tuning on in-domain, task-specific data, VIP can provide dense visual reward for an extensive set of simulated and $\textbf{real-robot}$ tasks, enabling diverse reward-based visual control methods and significantly outperforming all prior pre-trained representations. Notably, VIP can enable simple, few-shot offline RL on a suite of real-world robot tasks with as few as 20 trajectories.",Oral 1 Track 5: Reinforcement Learning,https://openreview.net/pdf?id=YJ7o2wetJ2,
"['Andrew Szot', 'Amy Zhang', 'Dhruv Batra', 'Zsolt Kira', 'Franziska Meier']",ICLR,BC-IRL: Learning Generalizable Reward Functions from Demonstrations,https://iclr.cc/virtual/2023/oral/12714,2023," How well do reward functions learned with inverse reinforcement learning (IRL) generalize? We illustrate that state-of-the-art IRL algorithms, which maximize a maximum-entropy objective, learn rewards that overfit to the demonstrations. Such rewards struggle to provide meaningful rewards for states not covered by the demonstrations, a major detriment when using the reward to learn policies in new situations. We introduce BC-IRL a new inverse reinforcement learning method that learns reward functions that generalize better when compared to maximum-entropy IRL approaches. In contrast to the MaxEnt framework, which learns to maximize rewards around demonstrations, BC-IRL updates reward parameters such that the policy trained with the new reward matches the expert demonstrations better. We show that BC-IRL learns rewards that generalize better on an illustrative simple task and two continuous robotic control tasks, achieving over twice the success rate of baselines in challenging generalization settings.",Oral 2 Track 4: Reinforcement Learning,https://openreview.net/pdf?id=Ovnwe_sDQW,
"['Zhiyuan Li', 'Xiajun Jiang', 'Ryan Missel', 'Prashnna Gyawali', 'Nilesh Kumar', 'Linwei Wang']",ICLR,Continual Unsupervised Disentangling of Self-Organizing Representations,https://iclr.cc/virtual/2023/oral/12760,2023," Limited progress has been made in continual unsupervised learning of representations, especially in reusing, expanding, and continually disentangling learned semantic factors across data environments. We argue that this is because existing approaches treat continually-arrived data independently, without considering how they are related based on the underlying semantic factors. We address this by a new generative model describing a topologically-connected mixture of spike-and-slab distributions in the latent space, learned end-to-end in a continual fashion via principled variational inference. The learned mixture is able to automatically discover the active semantic factors underlying each data environment and to accumulate their relational structure based on that. This distilled knowledge of different data environments can further be used for generative replay and guiding continual disentangling of new semantic factors. We tested the presented method on a split version of 3DShapes to provide the first quantitative disentanglement evaluation of continually learned representations, and further demonstrated its ability to continually disentangle new representations in benchmark datasets.",Oral 1 Track 6: Deep Learning and representational learning II,https://openreview.net/pdf?id=ih0uFRFhaZZ,
"['Sherry Yang', 'Dale Schuurmans', 'Pieter Abbeel', 'Ofir Nachum']",ICLR,Dichotomy of Control: Separating What You Can Control from What You Cannot,https://iclr.cc/virtual/2023/oral/12750,2023," Future- or return-conditioned supervised learning is an emerging paradigm for offline reinforcement learning (RL), in which the future outcome (i.e., return) associated with a sequence of actions in an offline dataset is used as input to a policy trained to imitate those same actions. While return-conditioning is at the heart of popular algorithms such as decision transformer (DT), these methods tend to perform poorly in highly stochastic environments, where an occasional high return associated with a sequence of actions may be due more to the randomness of the environment than to the actions themselves. Such situations can lead to a learned policy that is inconsistent with its conditioning inputs; i.e., using the policy – while conditioned on a specific desired return – to act in the environment can lead to a distribution of real returns that is wildly different than desired. In this work, we propose the dichotomy of control (DoC), a future-conditioned supervised learning framework that separates mechanisms within a policy’s control (actions) from those outside of a policy’s control (environment stochasticity). We achieve this by conditioning the policy on a latent variable representation of the future and designing a mutual information constraint that removes any future information from the latent variable that is only due to randomness of the environment. Theoretically, we show that DoC yields policies that are consistent with their conditioning inputs, ensuring that conditioning a learned policy on a desired high-return future outcome will correctly induce high-return behavior. Empirically, we show that DoC is able to achieve significantly better performance than DT on environments with highly stochastic rewards (e.g., Bandit) and transitions (e.g., FrozenLake).",Oral 3 Track 1: Reinforcement Learning,https://openreview.net/pdf?id=DEGjDDV22pI,
"['Bohang Zhang', 'Shengjie Luo', 'Liwei Wang', 'Di He']",ICLR,Rethinking the Expressive Power of GNNs via Graph Biconnectivity,https://iclr.cc/virtual/2023/oral/12728,2023," Designing expressive Graph Neural Networks (GNNs) is a central topic in learning graph-structured data. While numerous approaches have been proposed to improve GNNs with respect to the Weisfeiler-Lehman (WL) test, for most of them, there is still a lack of deep understanding of what additional power they can systematically and provably gain. In this paper, we take a fundamentally different perspective to study the expressive power of GNNs beyond the WL test. Specifically, we introduce a novel class of expressivity metrics via graph biconnectivity and highlight their importance in both theory and practice. As biconnectivity can be easily calculated using simple algorithms that have linear computational costs, it is natural to expect that popular GNNs can learn it easily as well. However, after a thorough review of prior GNN architectures, we surprisingly find that most of them are not expressive for any of these metrics. The only exception is the ESAN framework (Bevilacqua et al., 2022), for which we give a theoretical justification of its power. We proceed to introduce a principled and more efficient approach, called the Generalized Distance Weisfeiler-Lehman (GD-WL), which is provably expressive for all biconnectivity metrics. Practically, we show GD-WL can be implemented by a Transformer-like architecture that preserves expressiveness and enjoys full parallelizability. A set of experiments on both synthetic and real datasets demonstrates that our approach can consistently outperform prior GNN architectures.",Oral 3 Track 2: Deep Learning and representational learning,https://openreview.net/pdf?id=r9hNv76KoT3,
"['Quentin Bouniot', 'Romaric Audigier', 'Angelique Loesch', 'Amaury Habrard']",ICLR,Proposal-Contrastive Pretraining for Object Detection from Fewer Data,https://iclr.cc/virtual/2023/oral/12677,2023," The use of pretrained deep neural networks represents an attractive way to achieve strong results with few data available. When specialized in dense problems such as object detection, learning local rather than global information in images has proven to be more efficient. However, for unsupervised pretraining, the popular contrastive learning requires a large batch size and, therefore, a lot of resources. To address this problem, we are interested in transformer-based object detectors that have recently gained traction in the community with good performance and with the particularity of generating many diverse object proposals.     In this work, we present Proposal Selection Contrast (ProSeCo), a novel unsupervised overall pretraining approach that leverages this property. ProSeCo uses the large number of object proposals generated by the detector for contrastive learning, which allows the use of a smaller batch size, combined with object-level features to learn local information in the images. To improve the effectiveness of the contrastive loss, we introduce the object location information in the selection of positive examples to take into account multiple overlapping object proposals. When reusing pretrained backbone, we advocate for consistency in learning local information between the backbone and the detection head.     We show that our method outperforms state of the art in unsupervised pretraining for object detection on standard and novel benchmarks in learning with fewer data.",Oral 4 Track 1: Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=gm0VZ-h-hPy,
"['Tiago Pimentel', 'Clara Meister', 'Ryan Cotterell']",ICLR,"On the Usefulness of Embeddings, Clusters and Strings for Text Generation Evaluation",https://iclr.cc/virtual/2023/oral/12733,2023," A good automatic evaluation metric for language generation ideally correlates highly with human judgements of text quality.  Yet, there is a dearth of such metrics, which inhibits the rapid and efficient progress of language generators. One exception is  the recently proposed Mauve. In theory, Mauve measures an information-theoretic divergence between two probability distributions over strings: one representing the language generator under evaluation; the other representing the true natural language distribution. Mauve's authors argue that its success comes from the qualitative properties of their proposed divergence.  Yet in practice, as this divergence is uncomputable, Mauve approximates it by measuring the divergence between multinomial distributions over clusters instead, where cluster assignments are attained by grouping strings based on a pretrained language model's embeddings. As we show, however, this is not a tight approximation---in either theory or practice. This begs the question: why does Mauve work so well? In this work, we show that \mauve was right for the wrong reasons, and that its newly proposed divergence is not necessary for its high performance. In fact, classical divergences paired with its proposed cluster-based approximation may actually serve as better evaluation metrics. We finish the paper with a probing analysis; this analysis leads us to conclude that---by encoding syntactic- and coherence-level features of text, while ignoring surface-level features---such cluster-based approximations to string distributions may simply be better for evaluating state-of-the-art language generators.",Oral 2 Track 1: Applications,https://openreview.net/pdf?id=bvpkw7UIRdU,
"['Ronak Mehta', 'Jeffery Kline', 'Vishnu Lokhande', 'Glenn Fung', 'Vikas Singh']",ICLR,Efficient Discrete Multi Marginal Optimal Transport Regularization,https://iclr.cc/virtual/2023/oral/12599,2023," Optimal transport has emerged as a powerful tool for a variety of problems in machine learning, and it is frequently used to enforce distributional constraints. In this context, existing methods often use either a Wasserstein metric, or else they apply concurrent barycenter approaches when more than two distributions are considered. In this paper, we  leverage multi-marginal optimal transport (MMOT), where we take advantage of a procedure that computes a generalized earth mover's distance as a sub-routine. We show that not only is our algorithm computationally more efficient compared to other barycentric-based distance methods, but it has the additional advantage that gradients used for backpropagation can be efficiently computed during the forward pass computation itself, which leads to substantially faster model training. We provide technical details about this new regularization term and its properties, and we present experimental demonstrations of faster runtimes when compared to standard Wasserstein-style methods. Finally, on a range of experiments designed to assess effectiveness at enforcing fairness, we demonstrate our method compares well with alternatives.",Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=R98ZfMt-jE,
"['Shaolei Zhang', 'Yang Feng']",ICLR,Hidden Markov Transformer for Simultaneous Machine Translation,https://iclr.cc/virtual/2023/oral/13383,2023," Simultaneous machine translation (SiMT) outputs the target sequence while receiving the source sequence, and hence learning when to start translating each target token is the core challenge for SiMT task. However, it is non-trivial to learn the optimal moment among many possible moments of starting translating, as the moments of starting translating always hide inside the model and can only be supervised with the observed target sequence. In this paper, we propose a Hidden Markov Transformer (HMT), which treats the moments of starting translating as hidden events and the target sequence as the corresponding observed events, thereby organizing them as a hidden Markov model. HMT explicitly models multiple moments of starting translating as the candidate hidden events, and then selects one to generate the target token. During training, by maximizing the marginal likelihood of the target sequence over multiple moments of starting translating, HMT learns to start translating at the moments that target tokens can be generated more accurately. Experiments on multiple SiMT benchmarks show that HMT outperforms strong baselines and achieves state-of-the-art performance.",Oral 2 Track 6: Applications & Social Aspects of Machine Learning,https://openreview.net/pdf?id=9y0HFvaAYD6,
"['Yiqin Tan', 'Pihe Hu', 'Ling Pan', 'Jiatai Huang', 'Longbo Huang']",ICLR,RLx2: Training a Sparse Deep Reinforcement Learning Model from Scratch,https://iclr.cc/virtual/2023/oral/12747,2023," Training deep reinforcement learning (DRL) models usually requires high computation costs. Therefore, compressing DRL models possesses immense potential for training acceleration and model deployment. However, existing methods that generate small models mainly adopt the knowledge distillation-based approach by iteratively training a dense network. As a result, the training process still demands massive computing resources. Indeed, sparse training from scratch in DRL has not been well explored and is particularly challenging due to non-stationarity in bootstrap training. In this work, we propose a novel sparse DRL training framework, “the Rigged Reinforcement Learning Lottery” (RLx2), which builds upon gradient-based topology evolution and is capable of training a sparse DRL model based entirely on a sparse network. Specifically, RLx2 introduces a novel multi-step TD target mechanism with a dynamic-capacity replay buffer to achieve robust value learning and efficient topology exploration in sparse models. It also reaches state-of-the-art sparse training performance in several tasks, showing $7.5\times$-$20\times$ model compression with less than $3\%$ performance degradation and up to $20\times$ and $50\times$ FLOPs reduction for training and inference, respectively.",Oral 4 Track 4: Reinforcement Learning II,https://openreview.net/pdf?id=DJEEqoAq7to,
"['Nate Gruver', 'Marc A Finzi', 'Micah Goldblum', 'Andrew Wilson']",ICLR,The Lie Derivative for Measuring Learned Equivariance,https://iclr.cc/virtual/2023/oral/12763,2023," Equivariance guarantees that a model's predictions capture key symmetries in data. When an image is translated or rotated, an equivariant model's representation of that image will translate or rotate accordingly. The success of convolutional neural networks has historically been tied to translation equivariance directly encoded in their architecture. The rising success of vision transformers, which have no explicit architectural bias towards equivariance, challenges this narrative and suggests that augmentations and training data might also play a significant role in their performance. In order to better understand the role of equivariance in recent vision models, we apply the Lie derivative, a method for measuring equivariance with strong mathematical foundations and minimal hyperparameters. Using the Lie derivative, we study the equivariance properties of hundreds of pretrained models, spanning CNNs, transformers, and Mixer architectures. The scale of our analysis allows us to separate the impact of architecture from other factors like model size or training method. Surprisingly, we find that many violations of equivariance can be linked to spatial aliasing in ubiquitous network layers, such as pointwise non-linearities, and that as models get larger and more accurate they tend to display more equivariance, regardless of architecture. For example, transformers can be more equivariant than convolutional neural networks after training.",Oral 3 Track 5: Deep Learning and representational learning & Neuroscience and Cognitive Science,https://openreview.net/pdf?id=JL7Va5Vy15J,
"['Wenbo Gong', 'Joel Jennings', 'Cheng Zhang', 'Nick Pawlowski']",ICLR,Rhino: Deep Causal Temporal Relationship Learning with History-dependent Noise,https://iclr.cc/virtual/2023/oral/12768,2023," Discovering causal relationships between different variables from time series data has been a long-standing challenge for many domains. For example, in stock markets, the announcement of acquisitions from leading companies may have immediate effects on stock prices and increase the uncertainty of the future market due to this past action. To discover causal relations in such case, the model needs to consider non-linear relations between variables, instantaneous effect and the change of noise distribution due to past actions. We name the latter as history-dependent noise. However, previous works do not offer a solution addressing all these problems together. In this paper, we propose a structural equation model, called Rhino, which combines vector auto-regression, deep learning and variational inference to model non-linear relationships with instantaneous effects while allowing the noise distribution to be modulated by history observations. Theoretically, we prove the structural identifiability of Rhino. Our empirical results from extensive synthetic experiments and two real-world benchmarks demonstrate better discovery performance compared to relevant baselines, with ablation studies revealing its robustness under model misspecification.",Oral 4 Track 2: Probabilistic Methods,https://openreview.net/pdf?id=i_1rbq8yFWC,
"['Yuan Yin', 'Matthieu Kirchmeyer', 'Jean-Yves Franceschi', 'alain rakotomamonjy', 'patrick gallinari']",ICLR,Continuous PDE Dynamics Forecasting with Implicit Neural Representations,https://iclr.cc/virtual/2023/oral/12771,2023," Effective data-driven PDE forecasting methods often rely on fixed spatial and / or temporal discretizations. This raises limitations in real-world applications like weather prediction where flexible extrapolation at arbitrary spatiotemporal locations is required. We address this problem by introducing a new data-driven approach, DINo, that models a PDE's flow with continuous-time dynamics of spatially continuous functions. This is achieved by embedding spatial observations independently of their discretization via Implicit Neural Representations in a small latent space temporally driven by a learned ODE. This separate and flexible treatment of time and space makes DINo the first data-driven model to combine the following advantages. It extrapolates at arbitrary spatial and temporal locations; it can learn from sparse irregular grids or manifolds; at test time, it generalizes to new grids or resolutions. DINo outperforms alternative neural PDE forecasters in a variety of challenging generalization scenarios on representative PDE systems.",Oral 5 Track 2: Optimization,https://openreview.net/pdf?id=B73niNjbPs,
"['Gianluigi Silvestri', 'Daan Roos', 'Luca Ambrogioni']",ICLR,Deterministic training of generative autoencoders using invertible layers,https://iclr.cc/virtual/2023/oral/12731,2023," In this work, we provide a deterministic alternative to the stochastic variational training of generative autoencoders. We refer to these new generative autoencoders as AutoEncoders within Flows (AEF), since the encoder and decoder are defined as affine layers of an overall invertible architecture. This results in a deterministic encoding of the data, as opposed to the stochastic encoding of VAEs. The paper introduces two related families of AEFs. The first family relies on a partition of the ambient space and is trained by exact maximum-likelihood. The second family exploits a deterministic expansion of the ambient space and is trained by maximizing the log-probability in this extended space. This latter case leaves complete freedom in the choice of encoder, decoder and prior architectures, making it a drop-in replacement for the training of existing VAEs and VAE-style models. We show that these AEFs can have strikingly higher performance than architecturally identical VAEs in terms of log-likelihood and sample quality, especially for low dimensional latent spaces. Importantly, we show that AEF samples are substantially sharper than VAE samples.",Oral 3 Track 3: Generative models,https://openreview.net/pdf?id=g8wBdhnstYz,
"['Duc Hoang', 'Shiwei Liu', 'Radu Marculescu', 'Zhangyang Wang']",ICLR,REVISITING PRUNING AT INITIALIZATION THROUGH THE LENS OF RAMANUJAN GRAPH,https://iclr.cc/virtual/2023/oral/12695,2023," Pruning neural networks at initialization (PaI) has received an upsurge of interest due to its end-to-end saving potential. PaI is able to find sparse subnetworks at initialization that can achieve comparable performance to the full networks. These methods can surpass the trivial baseline of random pruning but suffer from a significant performance gap compared to post-training pruning. Previous approaches firmly rely on weights, gradients, and sanity checks as primary signals when conducting PaI analysis. To better understand the underlying mechanism of PaI, we propose to interpret it through the lens of the Ramanujan Graph - a class of expander graphs that are sparse while being highly connected. It is often believed there should be a strong correlation between the Ramanujan graph and PaI since both are about finding sparse and well-connected neural networks. However, the finer-grained link relating highly sparse and connected networks to their relative performance (i.e., ranking of difference sparse structures at the same specific global sparsity) is still missing. We observe that not only the Ramanujan property for sparse networks shows no significant relationship to PaI’s relative performance, but maximizing it can also lead to the formation of pseudo-random graphs with no structural meanings. We reveal the underlying cause to be Ramanujan Graph’s strong assumption on the upper bound of the largest nontrivial eigenvalue (µˆ) of layers belonging to highly sparse networks. We hence propose Iterative Mean Difference of Bound (IMDB) as a mean to relax the µˆ upper bound. Likewise, we also show there exists a lower bound for µˆ, which we call the Normalized Random Coefficient (NaRC), that gives us an accurate assessment for when sparse but highly connected structure degenerates into naive randomness. Finally, we systematically analyze the behavior of various PaI methods and demonstrate the utility of our proposed metrics in characterizing PaI performance. We show that subnetworks preserving better the IMDB property correlate higher in performance, while NaRC provides us with a possible mean to locate the region where highly connected, highly sparse, and non-trivial Ramanujan expanders exist. Our code is available at: https://github.com/VITA-Group/ramanujan-on-pai.",Oral 5 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=uVcDssQff_,
"['Samuel Ainsworth', 'Jonathan Hayase', 'Siddhartha Srinivasa']",ICLR,Git Re-Basin: Merging Models modulo Permutation Symmetries,https://iclr.cc/virtual/2023/oral/12764,2023," The success of deep learning is due in large part to our ability to solve certain massive non-convex optimization problems with relative ease. Though non-convex optimization is NP-hard, simple algorithms -- often variants of stochastic gradient descent -- exhibit surprising effectiveness in fitting large neural networks in practice. We argue that neural network loss landscapes often contain (nearly) a single basin after accounting for all possible permutation symmetries of hidden units a la Entezari et al. 2021. We introduce three algorithms to permute the units of one model to bring them into alignment with a reference model in order to merge the two models in weight space. This transformation produces a functionally equivalent set of weights that lie in an approximately convex basin near the reference model. Experimentally, we demonstrate the single basin phenomenon across a variety of model architectures and datasets, including the first (to our knowledge) demonstration of zero-barrier linear mode connectivity between independently trained ResNet models on CIFAR-10. Additionally, we identify intriguing phenomena relating model width and training time to mode connectivity. Finally, we discuss shortcomings of the linear mode connectivity hypothesis, including a counterexample to the single basin theory.",Oral 4 Track 6: Deep Learning and representational learning- Reinforcement Learning,https://openreview.net/pdf?id=CQsmMYmlP5T,
"['Joey Hong', 'Aviral Kumar', 'Sergey Levine']",ICLR,Confidence-Conditioned Value Functions for Offline Reinforcement Learning,https://iclr.cc/virtual/2023/oral/12739,2023," Offline reinforcement learning (RL) promises the ability to learn effective policies solely using existing, static datasets, without any costly online interaction. To do so, offline RL methods must handle distributional shift between the dataset and the learned policy. The most common approach is to learn conservative, or lower-bound, value functions, which underestimate the return of OOD actions. However, such methods exhibit one notable drawback: policies optimized on such value functions can only behave according to a fixed, possibly suboptimal, degree of conservatism. However, this can be alleviated if we instead are able to learn policies for varying degrees of conservatism at training time and devise a method to dynamically choose one of them during evaluation. To do so, in this work, we propose learning value functions that additionally condition on the degree of conservatism, which we dub confidence-conditioned value functions. We derive a new form of a Bellman backup that simultaneously learns Q-values for any degree of confidence with high probability. By conditioning on confidence, our value functions enable adaptive strategies during online evaluation by controlling for confidence level using the history of observations thus far. This approach can be implemented in practice by conditioning the Q-function from existing conservative algorithms on the confidence. We theoretically show that our learned value functions produce conservative estimates of the true value at any desired confidence. Finally, we empirically show that our algorithm outperforms existing conservative offline RL algorithms on multiple discrete control domains.",Oral 4 Track 3: Reinforcement Learning I,https://openreview.net/pdf?id=Zeb5mTuqT5,
"['Mark N Müller', 'Franziska Eckert', 'Marc Fischer', 'Martin Vechev']",ICLR,Certified Training: Small Boxes are All You Need,https://iclr.cc/virtual/2023/oral/12588,2023," To obtain, deterministic guarantees of adversarial robustness, specialized training methods are used. We propose, SABR, a novel such certified training method, based on the key insight that propagating interval bounds for a small but carefully selected subset of the adversarial input region is sufficient to approximate the worst-case loss over the whole region while significantly reducing approximation errors. We show in an extensive empirical evaluation that SABR outperforms existing certified defenses in terms of both standard and certifiable accuracies across perturbation magnitudes and datasets, pointing to a new class of certified training methods promising to alleviate the robustness-accuracy trade-off.",Oral 6 Track 4: Applications & Social Aspects of Machine Learning & General Machine Learning,https://openreview.net/pdf?id=7oFuxtJtUMH,
"['Kruno Lehman', 'Jonas Rothfuss', 'Andreas Krause']",ICLR,MARS: Meta-learning as Score Matching in the Function Space,https://iclr.cc/virtual/2023/oral/12709,2023," Meta-learning aims to extract useful inductive biases from a set of related datasets. In Bayesian meta-learning, this is typically achieved by constructing a prior distribution over neural network parameters. However, specifying families of computationally viable prior distributions over the high-dimensional neural network parameters is difficult. As a result, existing approaches resort to meta-learning restrictive diagonal Gaussian priors, severely limiting their expressiveness and performance. To circumvent these issues, we approach meta-learning through the lens of functional Bayesian neural network inference which views the prior as a stochastic process and performs inference in the function space. Specifically, we view the meta-training tasks as samples from the data-generating process and formalize meta-learning as empirically estimating the law of this stochastic process. Our approach can seamlessly acquire and represent complex prior knowledge by meta-learning the score function of the data-generating process marginals instead of parameter space priors. In a comprehensive benchmark, we demonstrate that our method achieves state-of-the-art performance in terms of predictive accuracy and substantial improvements in the quality of uncertainty estimates.",Oral 4 Track 5: Machine Learning for Sciences & Probabilistic Methods,https://openreview.net/pdf?id=WAgXmT8BeRj,
"['Carles Domingo i Enrich', 'Yair Schiff', 'Youssef Mroueh']",ICLR,Learning with Stochastic Orders,https://iclr.cc/virtual/2023/oral/12744,2023," Learning high-dimensional distributions is often done with explicit likelihood modeling or implicit modeling via minimizing integral probability metrics (IPMs). In this paper, we expand this learning paradigm to stochastic orders, namely, the convex or Choquet order between probability measures. Towards this end, exploiting the relation between convex orders and optimal transport, we introduce the Choquet-Toland distance between probability measures, that can be used as a drop-in replacement for IPMs. We also introduce the Variational Dominance Criterion (VDC) to learn probability measures with dominance constraints, that encode the desired stochastic order between the learned measure and a known baseline. We analyze both quantities and show that they suffer from the curse of dimensionality and propose surrogates via input convex maxout networks (ICMNs), that enjoy parametric rates. We provide a min-max framework for learning with stochastic orders and validate it experimentally on synthetic and high-dimensional image generation, with promising results. Finally, our ICMNs class of convex functions and its derived Rademacher Complexity are of independent interest beyond their application in convex orders. Code to reproduce experimental results is available at https://github.com/yair-schiff/stochastic-orders-ICMN.",Oral 6 Track 1: Theory,https://openreview.net/pdf?id=P3PJokAqGW,
"['Maria Esipova', 'Atiyeh Ashari Ghomi', 'Yaqiao Luo', 'Jesse Cresswell']",ICLR,Disparate Impact in Differential Privacy from Gradient Misalignment,https://iclr.cc/virtual/2023/oral/12689,2023," As machine learning becomes more widespread throughout society, aspects including data privacy and fairness must be carefully considered, and are crucial for deployment in highly regulated industries. Unfortunately, the application of privacy enhancing technologies can worsen unfair tendencies in models. In particular, one of the most widely used techniques for private model training, differentially private stochastic gradient descent (DPSGD), frequently intensifies disparate impact on groups within data. In this work we study the fine-grained causes of unfairness in DPSGD and identify gradient misalignment due to inequitable gradient clipping as the most significant source. This observation leads us to a new method for reducing unfairness by preventing gradient misalignment in DPSGD.",Oral 6 Track 2: Infrastructure & Social Aspects of Machine Learning,https://openreview.net/pdf?id=qLOaeRvteqbx,
"['Yuzhe Yang', 'Xin Liu', 'Jiang Wu', 'Silviu Borac', 'Dina Katabi', 'Ming-Zher Poh', 'Daniel McDuff']",ICLR,SimPer: Simple Self-Supervised Learning of Periodic Targets,https://iclr.cc/virtual/2023/oral/12765,2023," From human physiology to environmental evolution, important processes in nature often exhibit meaningful and strong periodic or quasi-periodic changes. Due to their inherent label scarcity, learning useful representations for periodic tasks with limited or no supervision is of great benefit. Yet, existing self-supervised learning (SSL) methods overlook the intrinsic periodicity in data, and fail to learn representations that capture periodic or frequency attributes. In this paper, we present SimPer, a simple contrastive SSL regime for learning periodic information in data. To exploit the periodic inductive bias, SimPer introduces customized augmentations, feature similarity measures, and a generalized contrastive loss for learning efficient and robust periodic representations. Extensive experiments on common real-world tasks in human behavior analysis, environmental sensing, and healthcare domains verify the superior performance of SimPer compared to state-of-the-art SSL methods, highlighting its intriguing properties including better data efficiency, robustness to spurious correlations, and generalization to distribution shifts.",Oral 5 Track 1: Unsupervised and Self-supervised learning & Social Aspects of Machine Learning-,https://openreview.net/pdf?id=EKpMeEV0hOo,
"['Heshan Fernando', 'Han Shen', 'Miao Liu', 'Subhajit Chaudhury', 'Keerthiram Murugesan', 'Tianyi Chen']",ICLR,Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Approach,https://iclr.cc/virtual/2023/oral/12639,2023," Many machine learning problems today have multiple objective functions. They appear either in learning with multiple criteria where learning has to make a trade-off between multiple performance metrics such as fairness, safety and accuracy; or, in multi-task learning where multiple tasks are optimized jointly, sharing inductive bias between them. This problems are often tackled by the multi-objective optimization framework. However, existing stochastic multi-objective gradient methods and its variants (e.g., MGDA, PCGrad, CAGrad, etc.) all adopt a biased noisy gradient direction, which leads to degraded empirical performance. To this end, we develop a stochastic multi-objective gradient correction (MoCo) method for multi-objective optimization. The unique feature of our method is that it can guarantee convergence without increasing the batch size even in the nonconvex setting. Simulations on multi-task supervised and reinforcement learning demonstrate the effectiveness of our method relative to the state-of-the-art methods.",Oral 5 Track 4: Applications & Optimization,https://openreview.net/pdf?id=dLAYGdKTi2,
"['Mert Bulent Sariyildiz', 'Yannis Kalantidis', 'Karteek Alahari', 'Diane Larlus']",ICLR,No Reason for No Supervision: Improved Generalization in Supervised Models,https://iclr.cc/virtual/2023/oral/12767,2023," We consider the problem of training a deep neural network on a given classification task, e.g., ImageNet-1K (IN1K), so that it excels at both the training task as well as at other (future) transfer tasks. These two seemingly contradictory properties impose a trade-off between improving the model’s generalization and maintaining its performance on the original task. Models trained with self-supervised learning tend to generalize better than their supervised counterparts for transfer learning; yet, they still lag behind supervised models on IN1K. In this paper, we propose a supervised learning setup that leverages the best of both worlds. We extensively analyze supervised training using multi-scale crops for data augmentation and an expendable projector head, and reveal that the design of the projector allows us to control the trade-off between performance on the training task and transferability. We further replace the last layer of class weights with class prototypes computed on the fly using a memory bank and derive two models: t-ReX that achieves a new state of the art for transfer learning and outperforms top methods such as DINO and PAWS on IN1K, and t-ReX* that matches the highly optimized RSB-A1 model on IN1K while performing better on transfer tasks.Code and pretrained models: https://europe.naverlabs.com/t-rex",Oral 5 Track 5: Deep Learning and representational learning & Reinforcement Learning,https://openreview.net/pdf?id=3Y5Uhf5KgGK,
"['Do-Yeon Kim', 'Dong-Jun Han', 'Jun Seo', 'Jaekyun Moon']",ICLR,Warping the Space: Weight Space Rotation for Class-Incremental Few-Shot Learning,https://iclr.cc/virtual/2023/oral/12681,2023," Class-incremental few-shot learning, where new sets of classes are provided sequentially with only a few training samples, presents a great challenge due to catastrophic forgetting of old knowledge and overfitting caused by lack of data. During finetuning on new classes, the performance on previous classes deteriorates quickly even when only a small fraction of parameters are updated, since the previous knowledge is broadly associated with most of the model parameters in the original parameter space. In this paper, we introduce WaRP, the \textit{weight space rotation process}, which transforms the original parameter space into a new space so that we can push most of the previous knowledge compactly into only a few important parameters. By properly identifying and freezing these key parameters in the new weight space, we can finetune the remaining parameters without affecting the knowledge of previous classes. As a result, WaRP provides an additional room for the model to effectively learn new classes in future incremental sessions. Experimental results confirm the effectiveness of our solution and show the improved performance over the state-of-the-art methods.",Oral 6 Track 5: Applications- & Deep Learning and representational learning,https://openreview.net/pdf?id=kPLzOfPfA2l,
"['Bo Li', 'Yifei Shen', 'Jingkang Yang', 'Yezhen Wang', 'Jiawei Ren', 'Tong Che', 'Jun Zhang', 'Ziwei Liu']",ICLR,Sparse Mixture-of-Experts are Domain Generalizable Learners,https://iclr.cc/virtual/2023/oral/12704,2023," Human visual perception can easily generalize to out-of-distributed visual data, which is far beyond the capability of modern machine learning models. Domain generalization (DG) aims to close this gap, with existing DG methods mainly focusing on the loss function design. In this paper, we propose to explore an orthogonal direction, i.e., the design of the backbone architecture. It is motivated by an empirical finding that transformer-based models trained with empirical risk minimization (ERM) outperform CNN-based models employing state-of-the-art (SOTA) DG algorithms on multiple DG datasets. We develop a formal framework to characterize a network's robustness to distribution shifts by studying its architecture's alignment with the correlations in the dataset. This analysis guides us to propose a novel DG model built upon vision transformers, namely \emph{Generalizable Mixture-of-Experts (GMoE)}. Extensive experiments on DomainBed demonstrate that GMoE trained with ERM outperforms SOTA DG baselines by a large margin. Moreover, GMoE is complementary to existing DG methods and its performance is substantially improved when trained with DG algorithms.",Oral 6 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=RecZ9nB9Q4,
"['Michał Zawalski', 'Michał Tyrolski', 'Konrad Czechowski', 'Tomasz Odrzygóźdź', 'Damian Stachura', 'Piotr Piękos', 'Yuhuai Wu', 'Łukasz Kuciński', 'Piotr Miłoś']",ICLR,Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal Search,https://iclr.cc/virtual/2023/oral/12758,2023," Complex reasoning problems contain states that vary in the computational cost required to determine the right action plan. To take advantage of this property, we propose Adaptive Subgoal Search (AdaSubS), a search method that adaptively adjusts the planning horizon. To this end, AdaSubS generates diverse sets of subgoals at different distances. A verification mechanism is employed to filter out unreachable subgoals swiftly, making it possible to focus on feasible further subgoals. In this way, AdaSubS benefits from the efficiency of planning with longer-term subgoals and the fine control with shorter-term ones, and thus scales well to difficult planning problems. We show that AdaSubS significantly surpasses hierarchical planning algorithms on three complex reasoning tasks: Sokoban, the Rubik’s Cube, and the inequality-proving benchmark INT.",Oral 3 Track 1: Reinforcement Learning,https://openreview.net/pdf?id=7JsGYvjE88d,
"['Rem Yang', 'Jacob Laurel', 'Sasa Misailovic', 'Gagandeep Singh']",ICLR,Provable Defense Against Geometric Transformations,https://iclr.cc/virtual/2023/oral/12754,2023," Geometric image transformations that arise in the real world, such as scaling and rotation, have been shown to easily deceive deep neural networks (DNNs). Hence, training DNNs to be certifiably robust to these perturbations is critical. However, no prior work has been able to incorporate the objective of deterministic certified robustness against geometric transformations into the training procedure, as existing verifiers are exceedingly slow. To address these challenges, we propose the first provable defense for deterministic certified geometric robustness. Our framework leverages a novel GPU-optimized verifier that can certify images between 60$\times$ to 42,600$\times$ faster than existing geometric robustness verifiers, and thus unlike existing works, is fast enough for use in training. Across multiple datasets, our results show that networks trained via our framework consistently achieve state-of-the-art deterministic certified geometric robustness and clean accuracy. Furthermore, for the first time, we verify the geometric robustness of a neural network for the challenging, real-world setting of autonomous driving.",Oral 1 Track 4: Social Aspects of Machine Learning,https://openreview.net/pdf?id=ThXqBsRI-cY,
"['Jake Bruce', 'Ankit Anand', 'Bogdan Mazoure', 'Rob Fergus']",ICLR,Learning About Progress From Experts,https://iclr.cc/virtual/2023/oral/12756,2023," Many important tasks involve some notion of long-term progress in multiple phases: e.g. to clean a shelf it must be cleared of items, cleaning products applied, and then the items placed back on the shelf. In this work, we explore the use of expert demonstrations in long-horizon tasks to learn a monotonically increasing function that summarizes progress. This function can then be used to aid agent exploration in environments with sparse rewards. As a case study we consider the NetHack environment, which requires long-term progress at a variety of scales and is far from being solved by existing approaches. In this environment, we demonstrate that by learning a model of long-term progress from expert data containing only observations, we can achieve efficient exploration in challenging sparse tasks, well beyond what is possible with current state-of-the-art approaches. We have made the curated gameplay dataset used in this work available at https://github.com/deepmind/nao_top10.",Oral 2 Track 4: Reinforcement Learning,https://openreview.net/pdf?id=sKc6fgce1zs,
"['Edoardo Cetin', 'Benjamin Chamberlain', 'Michael Bronstein', 'Jonathan J Hunt']",ICLR,Hyperbolic Deep Reinforcement Learning,https://iclr.cc/virtual/2023/oral/12525,2023," In deep reinforcement learning (RL), useful information about the state is inherently tied to its possible future successors. Consequently, encoding features that capture the hierarchical relationships between states into the model's latent representations is often conducive to recovering effective policies. In this work, we study a new class of deep RL algorithms that promote encoding such relationships by using hyperbolic space to model latent representations. However, we find that a naive application of existing methodology from the hyperbolic deep learning literature leads to fatal instabilities due to the non-stationarity and variance characterizing common gradient estimators in RL. Hence, we design a new general method that directly addresses such optimization challenges and enables stable end-to-end learning with deep hyperbolic representations. We empirically validate our framework by applying it to popular on-policy and off-policy RL algorithms on the Procgen and Atari 100K benchmarks, attaining near universal performance and generalization benefits. Given its natural fit, we hope this work will inspire future RL research to consider hyperbolic representations as a standard tool.",Oral 3 Track 2: Deep Learning and representational learning,https://openreview.net/pdf?id=TfBHFLgv77,
"['Andrii Zadaianchuk', 'Matthäus Kleindessner', 'Yi Zhu', 'Francesco Locatello', 'Thomas Brox']",ICLR,Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations,https://iclr.cc/virtual/2023/oral/12740,2023," In this paper, we show that recent advances in self-supervised representation learning enable unsupervised object discovery and semantic segmentation with a performance that matches the state of the field on supervised semantic segmentation 10 years ago. We propose a methodology based on unsupervised saliency masks and self-supervised feature clustering to kickstart object discovery followed by training a semantic segmentation network on pseudo-labels to bootstrap the system on images with multiple objects. We show that while being conceptually simple our proposed baseline is surprisingly strong. We present results on PASCAL VOC that go far beyond the current state of the art (50.0 mIoU), and we report for the first time results on MS COCO for the whole set of 81 classes: our method discovers 34 categories with more than 20% IoU, while obtaining an average IoU of 19.6 for all 81 categories.",Oral 4 Track 1: Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=1_jFneF07YC,
"['Tianlin Liu', 'Joan Puigcerver', 'Mathieu Blondel']",ICLR,Sparsity-Constrained Optimal Transport,https://iclr.cc/virtual/2023/oral/12752,2023," Regularized optimal transport (OT) is now increasingly used as a loss or as a matching layer in neural networks. Entropy-regularized OT can be computed using the Sinkhorn algorithm but it leads to fully-dense transportation plans, meaning that all sources are (fractionally) matched with all targets. To address this issue, several works have investigated quadratic regularization instead. This regularization preserves sparsity and leads to unconstrained and smooth (semi) dual objectives, that can be solved with off-the-shelf gradient methods. Unfortunately, quadratic regularization does not give direct control over the cardinality (number of nonzeros) of the transportation plan. We propose in this paper a new approach for OT with explicit cardinality constraints on the transportation plan. Our work is motivated by an application to sparse mixture of experts, where OT can be used to match input tokens such as image patches with expert models such as neural networks. Cardinality constraints ensure that at most $k$ tokens are matched with an expert, which is crucial for computational performance reasons. Despite the nonconvexity of cardinality constraints, we show that the corresponding (semi) dual problems are tractable and can be solved with first-order gradient methods. Our method can be thought as a middle ground between unregularized OT (recovered in the limit case $k=1$) and quadratically-regularized OT (recovered when $k$ is large enough). The smoothness of the objectives increases as $k$ increases, giving rise to a trade-off between convergence speed and sparsity of the optimal plan.",Oral 3 Track 4: General Machine Learning & Unsupervised and Self-supervised learning,https://openreview.net/pdf?id=yHY9NbQJ5BP,
"['Antonia Creswell', 'Murray Shanahan', 'Irina Higgins']",ICLR,Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning,https://iclr.cc/virtual/2023/oral/12542,2023," Large language models (LLMs) have been shown to be capable of impressive few-shot generalisation to new tasks. However, they still tend to perform poorly on multi-step logical reasoning problems. Here we carry out a comprehensive evaluation of LLMs on 46 tasks that probe different aspects of logical reasoning. We show that language models tend to perform fairly well at single step inference or entailment tasks, but struggle to chain together multiple reasoning steps to solve more complex problems. In light of this, we propose a Selection-Inference (SI) framework that exploits pre-trained LLMs as general processing modules, and alternates between selection and inference to generate a series of interpretable, casual reasoning steps leading to the final answer. We show that a 7B parameter LLM used within the SI framework in a 5-shot generalisation setting, with no fine-tuning, yields a performance improvement of over 100% compared to an equivalent vanilla baseline on a suite of 10 logical reasoning tasks. The same model in the same setting even outperforms a significantly larger 280B parameter baseline on the same suite of tasks. Moreover, answers produced by the SI framework are accompanied by a causal natural-language-based reasoning trace, which has important implications for the safety and trustworthiness of the system.",Oral 2 Track 6: Applications & Social Aspects of Machine Learning,https://openreview.net/pdf?id=3Pf3Wg6o-A4,
"['Khai Loong Aw', 'Mariya Toneva']",ICLR,Training language models to summarize narratives improves brain alignment,https://iclr.cc/virtual/2023/oral/12698,2023," Building systems that achieve a deeper understanding of language is one of the central goals of natural language processing (NLP). Towards this goal, recent works have begun to train language models on narrative datasets which require extracting the most critical information by integrating across long contexts. However, it is still an open question whether these models are learning a deeper understanding of the text, or if the models are simply learning a heuristic to complete the task. This work investigates this further by turning to the one language processing system that truly understands complex language: the human brain. We show that training language models for deeper narrative understanding results in richer representations that have improved alignment to human brain activity. We further find that the improvements in brain alignment are larger for character names than for other discourse features, which indicates that these models are learning important narrative elements. Taken together, these results suggest that this type of training can indeed lead to deeper language understanding. These findings have consequences both for cognitive neuroscience by revealing some of the significant factors behind brain-NLP alignment, and for NLP by highlighting that understanding of long-range context can be improved beyond language modeling.",Oral 3 Track 5: Deep Learning and representational learning & Neuroscience and Cognitive Science,https://openreview.net/pdf?id=KzkLAE49H9b,
"['Yiming Gao', 'Feiyu Liu', 'Liang Wang', 'Zhenjie Lian', 'Weixuan Wang', 'Siqin Li', 'Xianliang Wang', 'Xianhan Zeng', 'Rundong Wang', 'jiawei wang', 'QIANG FU', 'Yang Wei', 'Lanxiao Huang', 'Wei Liu']",ICLR,Towards Effective and Interpretable Human-Agent Collaboration in MOBA Games: A Communication Perspective,https://iclr.cc/virtual/2023/oral/12770,2023," MOBA games, e.g., Dota2 and Honor of Kings, have been actively used as the testbed for the recent AI research on games, and various AI systems have been developed at the human level so far. However, these AI systems mainly focus on how to compete with humans, less on exploring how to collaborate with humans. To this end, this paper makes the first attempt to investigate human-agent collaboration in MOBA games. In this paper, we propose to enable humans and agents to collaborate through explicit communication by designing an efficient and interpretable Meta-Command Communication-based framework, dubbed MCC, for accomplishing effective human-agent collaboration in MOBA games. The MCC framework consists of two pivotal modules: 1) an interpretable communication protocol, i.e., the Meta-Command, to bridge the communication gap between humans and agents; 2) a meta-command value estimator, i.e., the Meta-Command Selector, to select a valuable meta-command for each agent to achieve effective human-agent collaboration. Experimental results in Honor of Kings demonstrate that MCC agents can collaborate reasonably well with human teammates and even generalize to collaborate with different levels and numbers of human teammates. Videos are available at https://sites.google.com/view/mcc-demo.",Oral 4 Track 4: Reinforcement Learning II,https://openreview.net/pdf?id=q3F0UBAruO,
"['Ivan Skorokhodov', 'Aliaksandr Siarohin', 'Yinghao Xu', 'Jian Ren', 'Hsin-Ying Lee', 'Peter Wonka', 'Sergey Tulyakov']",ICLR,3D generation on ImageNet,https://iclr.cc/virtual/2023/oral/12734,2023," All existing 3D-from-2D generators are designed for well-curated single-category datasets, where all the objects have (approximately) the same scale, 3D location, and orientation, and the camera always points to the center of the scene. This makes them inapplicable to diverse, in-the-wild datasets of non-alignable scenes rendered from arbitrary camera poses. In this work, we develop a 3D generator with Generic Priors (3DGP): a 3D synthesis framework with more general assumptions about the training data, and show that it scales to very challenging datasets, like ImageNet. Our model is based on three new ideas. First, we incorporate an inaccurate off-the-shelf depth estimator into 3D GAN training via a special depth adaptation module to handle the imprecision. Then, we create a flexible camera model and a regularization strategy for it to learn its distribution parameters during training. Finally, we extend the recent ideas of transferring knowledge from pretrained classifiers into GANs for patch-wise trained models by employing a simple distillation-based technique on top of the discriminator. It achieves more stable training than the existing methods and speeds up the convergence by at least 40%. We explore our model on four datasets: SDIP Dogs $256^2$, SDIP Elephants $256^2$, LSUN Horses $256^2$, and ImageNet $256^2$ and demonstrate that 3DGP outperforms the recent state-of-the-art in terms of both texture and geometry quality. Code and visualizations: https://snap-research.github.io/3dgp.",Oral 3 Track 3: Generative models,https://openreview.net/pdf?id=U2WjB9xxZ9q,
"['Puja Trivedi', 'Danai Koutra', 'Jayaraman J. Thiagarajan']",ICLR,A Closer Look at Model Adaptation using Feature Distortion and Simplicity Bias,https://iclr.cc/virtual/2023/oral/12719,2023," Advances in the expressivity of pretrained models have increased interest in the design of adaptation protocols which enable safe and effective transfer learning. Going beyond conventional linear probing (LP) and fine tuning (FT) strategies, protocols that can effectively control feature distortion, i.e., the failure to update features orthogonal to the in-distribution, have been found to achieve improved out-of-distribution generalization (OOD). In order to limit this distortion, the LP+FT protocol, which first learns a linear probe and then uses this initialization for subsequent FT, was proposed. However, in this paper, we find when adaptation protocols (LP, FT, LP+FT) are also evaluated on a variety of safety objectives (e.g., calibration, robustness, etc.), a complementary perspective to feature distortion is helpful to explain protocol behavior. To this end, we study the susceptibility of protocols to simplicity bias (SB), i.e. the well-known propensity of deep neural networks to rely upon simple features, as SB has recently been shown to underlie several problems in robust generalization. Using a synthetic dataset, we demonstrate the susceptibility of existing protocols to SB. Given the strong effectiveness of LP+FT, we then propose modified linear probes that help mitigate SB, and lead to better initializations for subsequent FT. We verify the effectiveness of the proposed LP+FT variants for decreasing SB in a controlled setting, and their ability to improve OOD generalization and safety on three adaptation datasets.",Oral 5 Track 3: Deep Learning and representational learning,https://openreview.net/pdf?id=wkg_b4-IwTZ,
"['Michael Laskin', 'Luyu Wang', 'Junhyuk Oh', 'Emilio Parisotto', 'Stephen Spencer', 'Richie Steigerwald', 'DJ Strouse', 'Steven Hansen', 'Angelos Filos', 'Ethan Brooks', 'Maxime Gazeau', 'Himanshu Sahni', 'Satinder Singh', 'Volodymyr Mnih']",ICLR,In-context Reinforcement Learning with Algorithm Distillation,https://iclr.cc/virtual/2023/oral/12612,2023," We propose Algorithm Distillation (AD), a method for distilling reinforcement learning (RL) algorithms into neural networks by modeling their training histories with a causal sequence model. Algorithm Distillation treats learning to reinforcement learn as an across-episode sequential prediction problem. A dataset of learning histories is generated by a source RL algorithm, and then a causal transformer is trained by autoregressively predicting actions given their preceding learning histories as context. Unlike sequential policy prediction architectures that distill post-learning or expert sequences, AD is able to improve its policy entirely in-context without updating its network parameters. We demonstrate that AD can reinforcement learn in-context in a variety of environments with sparse rewards, combinatorial task structure, and pixel-based observations, and find that AD learns a more data-efficient RL algorithm than the one that generated the source data.",Oral 4 Track 6: Deep Learning and representational learning- Reinforcement Learning,https://openreview.net/pdf?id=hy0a5MMPUv,
"['Divyansh Garg', 'Joey Hejna', 'Matthieu Geist', 'Stefano Ermon']",ICLR,Extreme Q-Learning: MaxEnt RL without Entropy,https://iclr.cc/virtual/2023/oral/12751,2023," Modern Deep Reinforcement Learning (RL) algorithms require estimates of the maximal Q-value, which are difficult to compute in continuous domains with an infinite number of possible actions. In this work, we introduce a new update rule for online and offline RL which directly models the maximal value using Extreme Value Theory (EVT), drawing inspiration from economics. By doing so, we avoid computing Q-values using out-of-distribution actions which is often a substantial source of error. Our key insight is to introduce an objective that directly estimates the optimal soft-value functions (LogSumExp) in the maximum entropy RL setting without needing to sample from a policy. Using EVT, we derive our \emph{Extreme Q-Learning} framework and consequently online and, for the first time, offline MaxEnt Q-learning algorithms, that do not explicitly require access to a policy or its entropy. Our method obtains consistently strong performance in the D4RL benchmark, outperforming prior works by \emph{10+ points} on the challenging Franka Kitchen tasks while offering moderate improvements over SAC and TD3 on online DM Control tasks. Visualizations and code can be found on our website.",Oral 4 Track 3: Reinforcement Learning I,https://openreview.net/pdf?id=SJ0Lde3tRL,
"['Ranjie Duan', 'YueFeng Chen', 'Yao Zhu', 'Xiaojun Jia', 'Rong Zhang', ""Hui Xue'""]",ICLR,"Inequality phenomenon in $l_{\infty}$-adversarial training, and its unrealized threats",https://iclr.cc/virtual/2023/oral/12663,2023," The appearance of adversarial examples raises attention from both academia and industry. Along with the attack-defense arms race, adversarial training is the most effective against adversarial examples.However, we find inequality phenomena occur during the $l_{\infty}$-adversarial training, that few features dominate the prediction made by the adversarially trained model. We systematically evaluate such inequality phenomena by extensive experiments and find such phenomena become more obvious when performing adversarial training with increasing adversarial strength (evaluated by $\epsilon$). We hypothesize such inequality phenomena make $l_{\infty}$-adversarially trained model less reliable than the standard trained model when few ``important features"" are influenced. To validate our hypothesis, we proposed two simple attacks that either perturb or replace important features with noise or occlusion. Experiments show that $l_{\infty}$-adversarially trained model can be easily attacked when the few important features are influenced. Our work shed light on the limitation of the practicality of $l_{\infty}$-adversarial training.",Oral 6 Track 4: Applications & Social Aspects of Machine Learning & General Machine Learning,https://openreview.net/pdf?id=4t9q35BxGr,
"['Samuel Lanthaler', 'Roberto Molinaro', 'Patrik Hadorn', 'Siddhartha Mishra']",ICLR,Nonlinear Reconstruction for Operator Learning of PDEs with Discontinuities,https://iclr.cc/virtual/2023/oral/12757,2023," Discontinuous solutions arise in a large class of hyperbolic and advection-dominated PDEs. This paper investigates, both theoretically and empirically, the operator learning of PDEs with discontinuous solutions. We rigorously prove, in terms of lower approximation bounds, that methods which entail a linear reconstruction step (e.g. DeepONets or PCA-Nets) fail to efficiently approximate the solution operator of such PDEs. In contrast, we show that certain methods employing a non-linear reconstruction mechanism can overcome these fundamental lower bounds and approximate the underlying operator efficiently. The latter class includes Fourier Neural Operators and a novel extension of DeepONets termed shift-DeepONets. Our theoretical findings are confirmed by empirical results for advection equations, inviscid Burgers’ equation and the compressible Euler equations of gas dynamics.",Oral 6 Track 1: Theory,https://openreview.net/pdf?id=CrfhZAsJDsZ,
"['Samuel Lavoie', 'Christos Tsirigotis', 'Max Schwarzer', 'Ankit Vani', 'Mikhail Noukhovitch', 'Kenji Kawaguchi', 'Aaron Courville']",ICLR,Simplicial Embeddings in Self-Supervised Learning and Downstream Classification,https://iclr.cc/virtual/2023/oral/12601,2023," Simplicial Embeddings (SEM) are representations learned through self-supervised learning (SSL), wherein a representation is projected into $L$ simplices of $V$ dimensions each using a \texttt{softmax} operation. This procedure conditions the representation onto a constrained space during pretraining and imparts an inductive bias for group sparsity. For downstream classification, we formally prove that the SEM representation leads to better generalization than an unnormalized representation.Furthermore, we empirically demonstrate that SSL methods trained with SEMs have improved generalization on natural image datasets such as CIFAR-100 and ImageNet. Finally, when used in a downstream classification task, we show that SEM features exhibit emergent semantic coherence where small groups of learned features are distinctly predictive of semantically-relevant classes.",Oral 5 Track 1: Unsupervised and Self-supervised learning & Social Aspects of Machine Learning-,https://openreview.net/pdf?id=RWtGreRpovS,
"['Rujikorn Charakorn', 'Poramate Manoonpong', 'Nat Dilokthanakul']",ICLR,Generating Diverse Cooperative Agents by Learning Incompatible Policies,https://iclr.cc/virtual/2023/oral/12527,2023," Training a robust cooperative agent requires diverse partner agents. However, obtaining those agents is difficult. Previous works aim to learn diverse behaviors by changing the state-action distribution of agents. But, without information about the task's goal, the diversified agents are not guided to find other important, albeit sub-optimal, solutions: the agents might learn only variations of the same solution. In this work, we propose to learn diverse behaviors via policy compatibility. Conceptually, policy compatibility measures whether policies of interest can coordinate effectively. We theoretically show that incompatible policies are not similar. Thus, policy compatibility—which has been used exclusively as a measure of robustness—can be used as a proxy for learning diverse behaviors. Then, we incorporate the proposed objective into a population-based training scheme to allow concurrent training of multiple agents. Additionally, we use state-action information to induce local variations of each policy. Empirically, the proposed method consistently discovers more solutions than baseline methods across various multi-goal cooperative environments. Finally, in multi-recipe Overcooked, we show that our method produces populations of behaviorally diverse agents, which enables generalist agents trained with such a population to be more robust.See our project page at https://bit.ly/marl-lipo",Oral 5 Track 5: Deep Learning and representational learning & Reinforcement Learning,https://openreview.net/pdf?id=UkU05GOH7_6,
"['Polina Kirichenko', 'Pavel Izmailov', 'Andrew Wilson']",ICLR,Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations,https://iclr.cc/virtual/2023/oral/12773,2023," Neural network classifiers can largely rely on simple spurious features, such as image backgrounds, to make predictions. However, even in these cases, we show that they still often learn core features associated with the desired attributes of the data, contrary to recent findings. Inspired by this insight, we demonstrate that simple last layer retraining can match or outperform state-of-the-art approaches on spurious correlation benchmarks, but with profoundly lower complexity and computational expenses. Moreover, we show that last layer retraining on large ImageNet-trained models can also significantly reduce reliance on background and texture information, improving robustness to covariate shift, after only minutes of training on a single GPU.",Oral 6 Track 5: Applications- & Deep Learning and representational learning,https://openreview.net/pdf?id=Zb6c8A-Fghk,
