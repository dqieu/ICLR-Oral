author,publisher,title,url,year,abstract,session,pdf_url,openreview_url
"['Tianyu He', 'Darshil Doshi', 'Aritra Das', 'Andrey Gromov']",NeurIPS,Learning to grok_ Emergence of in-context learning and skill composition in modular arithmetic tasks,https://neurips.cc/virtual/2024/oral/97968,2024," Large language models can solve tasks that were not present in the training set. This capability is believed to be due to in-context learning and skill composition. In this work, we study the emergence of in-context learning and skill composition in a collection of modular arithmetic tasks. Specifically, we consider a finite collection of linear modular functions $z = a  x + b  y \text{ mod } p$ labeled by the vector $(a, b) \in \mathbb{Z}_p^2$. We use some of these tasks for pre-training and the rest for out-of-distribution testing. We empirically show that a GPT-style transformer exhibits a transition from in-distribution to out-of-distribution generalization as the number of pre-training tasks increases. We find that the smallest model capable of out-of-distribution generalization requires two transformer blocks, while for deeper models, the out-of-distribution generalization phase is *transient*, necessitating early stopping. Finally, we perform an interpretability study of the pre-trained models, revealing highly structured representations in both attention heads and MLPs; and discuss the learned algorithms. Notably, we find an algorithmic shift in deeper models, as we go from few to many in-context examples.",Oral Session 1A: Neuroscience and Intepretability,https://openreview.net/pdf?id=aVh9KRZdRk,https://openreview.net/forum?id=aVh9KRZdRk
"['Jin Zhang', 'Ze Liu', 'Defu Lian', 'Enhong Chen']",NeurIPS,Generalization Error Bounds for Two-stage Recommender Systems with Tree Structure,https://neurips.cc/virtual/2024/oral/97958,2024," Two-stage recommender systems play a crucial role in efficiently identifying relevant items and personalizing recommendations from a vast array of options. This paper, based on an error decomposition framework, analyzes the generalization error for two-stage recommender systems with a tree structure, which consist of an efficient tree-based retriever and a more precise yet time-consuming ranker. We use the Rademacher complexity to establish the generalization upper bound for various tree-based retrievers using beam search, as well as for different ranker models under a shifted training distribution. Both theoretical insights and practical experiments on real-world datasets indicate that increasing the branches in tree-based retrievers and harmonizing distributions across stages can enhance the generalization performance of two-stage recommender systems.",Oral Session 1D: Learning Theory,https://openreview.net/pdf?id=m1a4CrRJR7,https://openreview.net/forum?id=m1a4CrRJR7
"['Aaron Defazio', 'Xingyu Yang', 'Ahmed Khaled', 'Konstantin Mishchenko', 'Harsh Mehta', 'Ashok Cutkosky']",NeurIPS,The Road Less Scheduled,https://neurips.cc/virtual/2024/oral/98003,2024," Existing learning rate schedules that do not require specification of the optimization stopping step $T$ are greatly out-performed by learning rate schedules that depend on $T$. We propose an approach that avoids the need for this stopping time by eschewing the use of schedules entirely, while exhibiting state-of-the-art performance compared to schedules across a wide family of problems ranging from convex problems to large-scale deep learning problems. Our Schedule-Free approach introduces no additional hyper-parameters over standard optimizers with momentum. Our method is a direct consequence of a new theory we develop that unifies scheduling and iterate averaging. An open source implementation of our method is available at https://github.com/facebookresearch/schedule_free. Schedule-Free AdamW is the core algorithm behind our winning entry to the MLCommons 2024 AlgoPerf Algorithmic Efficiency Challenge Self-Tuning track.",Oral Session 1C: Optimization and Learning Theory,https://openreview.net/pdf?id=0XeNkkENuI,https://openreview.net/forum?id=0XeNkkENuI
"['Rohan Alur', 'Manish Raghavan', 'Devavrat Shah']",NeurIPS,Human Expertise in Algorithmic Prediction,https://neurips.cc/virtual/2024/oral/97946,2024," We introduce a novel framework for incorporating human expertise into algorithmic predictions. Our approach leverages human judgment to distinguish inputs which are algorithmically indistinguishable , or ""look the same"" to predictive algorithms.  We argue that this framing clarifies the problem of human-AI collaboration in prediction tasks, as experts often form judgments by drawing on information which is not encoded in an algorithm's training data. Algorithmic indistinguishability yields a natural test for assessing whether experts incorporate this kind of ""side information"", and further provides a simple but principled method for selectively incorporating human feedback into algorithmic predictions. We show that this method provably improves the performance of any feasible algorithmic predictor and precisely quantify this improvement.  We find empirically that although algorithms often outperform their human counterparts on average , human judgment can improve algorithmic predictions on specific instances (which can be identified ex-ante). In an X-ray classification task, we find that this subset constitutes nearly 30% of the patient population. Our approach provides a natural way of uncovering this heterogeneity and thus enabling effective human-AI collaboration.",Oral Session 1B: Human-AI Interaction,https://openreview.net/pdf?id=wpGJ2AX6SZ,https://openreview.net/forum?id=wpGJ2AX6SZ
"['Shen Li', 'Yuyang Zhang', 'Zhaolin Ren', 'Claire Liang', 'Na Li', 'Julie A Shah']",NeurIPS,Enhancing Preference-based Linear Bandits via Human Response Time,https://neurips.cc/virtual/2024/oral/97969,2024," Interactive preference learning systems infer human preferences by presenting queries as pairs of options and collecting binary choices. Although binary choices are simple and widely used, they provide limited information about preference strength. To address this, we leverage human response times, which are inversely related to preference strength, as an additional signal. We propose a computationally efficient method that combines choices and response times to estimate human utility functions, grounded in the EZ diffusion model from psychology. Theoretical and empirical analyses show that for queries with strong preferences, response times complement choices by providing extra information about preference strength, leading to significantly improved utility estimation. We incorporate this estimator into preference-based linear bandits for fixed-budget best-arm identification. Simulations on three real-world datasets demonstrate that using response times significantly accelerates preference learning compared to choice-only approaches. Additional materials, such as code, slides, and talk video, are available at https://shenlirobot.github.io/pages/NeurIPS24.html.",Oral Session 2A: Agents,https://openreview.net/pdf?id=aIPwlkdOut,https://openreview.net/forum?id=aIPwlkdOut
"['Jayden Teoh', 'Wenjun Li', 'Pradeep Varakantham']",NeurIPS,Improving Environment Novelty Quantification for Effective Unsupervised Environment Design,https://neurips.cc/virtual/2024/oral/97974,2024," Unsupervised Environment Design (UED) formalizes the problem of autocurricula through interactive training between a teacher agent and a student agent. The teacher generates new training environments with high learning potential, curating an adaptive curriculum that strengthens the student's ability to handle unseen scenarios. Existing UED methods mainly rely on regret , a metric that measures the difference between the agent's optimal and actual performance, to guide curriculum design. Regret-driven methods generate curricula that progressively increase environment complexity for the student but overlook environment novelty — a critical element for enhancing an agent's generalizability. Measuring environment novelty is especially challenging due to the underspecified nature of environment parameters in UED, and existing approaches face significant limitations. To address this, this paper introduces the Coverage-based Evaluation of Novelty In Environment (CENIE) framework. CENIE proposes a scalable, domain-agnostic, and curriculum-aware approach to quantifying environment novelty by leveraging the student's state-action space coverage from previous curriculum experiences. We then propose an implementation of CENIE that models this coverage and measures environment novelty using Gaussian Mixture Models. By integrating both regret and novelty as complementary objectives for curriculum design, CENIE facilitates effective exploration across the state-action space while progressively increasing curriculum complexity. Empirical evaluations demonstrate that augmenting existing regret-based UED algorithms with CENIE achieves state-of-the-art performance across multiple benchmarks, underscoring the effectiveness of novelty-driven autocurricula for robust generalization.",Oral Session 2B: Reinforcement Learning,https://openreview.net/pdf?id=UdxpjKO2F9,https://openreview.net/forum?id=UdxpjKO2F9
"['Shaoteng Liu', 'Haoqi Yuan', 'Minda Hu', 'Yanwei Li', 'Yukang Chen', 'Shu Liu', 'Zongqing Lu', 'Jiaya Jia']",NeurIPS,RL-GPT_ Integrating Reinforcement Learning and Code-as-policy,https://neurips.cc/virtual/2024/oral/97985,2024," Large Language Models (LLMs) have demonstrated proficiency in utilizing various tools by coding, yet they face limitations in handling intricate logic and precise control. In embodied tasks, high-level planning is amenable to direct coding, while low-level actions often necessitate task-specific refinement, such as Reinforcement Learning (RL). To seamlessly integrate both modalities, we introduce a two-level hierarchical framework, RL-GPT, comprising a slow agent and a fast agent. The slow agent analyzes actions suitable for coding, while the fast agent executes coding tasks. This decomposition effectively focuses each agent on specific tasks, proving highly efficient within our pipeline. Our approach outperforms traditional RL methods and existing GPT agents, demonstrating superior efficiency. In the Minecraft game, it rapidly obtains diamonds within a single day on an RTX3090. Additionally, it achieves SOTA performance across all designated MineDojo tasks.",Oral Session 2C: Reinforcement Learning,https://openreview.net/pdf?id=LEzx6QRkRH,https://openreview.net/forum?id=LEzx6QRkRH
"['Matthew Zurek', 'Yudong Chen']",NeurIPS,Span-Based Optimal Sample Complexity for Weakly Communicating and General Average Reward MDPs,https://neurips.cc/virtual/2024/oral/97954,2024," We study the sample complexity of learning an $\varepsilon$-optimal policy in an average-reward Markov decision process (MDP) under a generative model. For weakly communicating MDPs, we establish the complexity bound $\widetilde{O}\left(SA\frac{\mathsf{H}}{\varepsilon^2} \right)$, where $\mathsf{H}$ is the span of the bias function of the optimal policy and $SA$ is the cardinality of the state-action space. Our result is the first that is minimax optimal (up to log factors) in all parameters $S,A,\mathsf{H}$, and $\varepsilon$, improving on existing work that either assumes uniformly bounded mixing times for all policies or has suboptimal dependence on the parameters. We also initiate the study of sample complexity in general (multichain) average-reward MDPs. We argue a new transient time parameter $\mathsf{B}$ is necessary, establish an $\widetilde{O}\left(SA\frac{\mathsf{B} + \mathsf{H}}{\varepsilon^2} \right)$ complexity bound, and prove a matching (up to log factors) minimax lower bound. Both results are based on reducing the average-reward MDP to a discounted MDP, which requires new ideas in the general setting. To optimally analyze this reduction, we develop improved bounds for $\gamma$-discounted MDPs, showing that $\widetilde{O}\left(SA\frac{\mathsf{H}}{(1-\gamma)^2\varepsilon^2} \right)$ and $\widetilde{O}\left(SA\frac{\mathsf{B} + \mathsf{H}}{(1-\gamma)^2\varepsilon^2} \right)$ samples suffice to learn $\varepsilon$-optimal policies in weakly communicating and in general MDPs, respectively. Both these results circumvent the well-known minimax lower bound of $\widetilde{\Omega}\left(SA\frac{1}{(1-\gamma)^3\varepsilon^2} \right)$ for $\gamma$-discounted MDPs, and establish a quadratic rather than cubic horizon dependence for a fixed MDP instance.",Oral Session 2D: Generative Models,https://openreview.net/pdf?id=pGEY8JQ3qx,https://openreview.net/forum?id=pGEY8JQ3qx
"['Zhenghao Lin', 'Zhibin Gou', 'Yeyun Gong', 'Xiao Liu', 'yelong shen', 'Ruochen Xu', 'Chen Lin', 'Yujiu Yang', 'Jian Jiao', 'Nan Duan', 'Weizhu Chen']",NeurIPS,Not All Tokens Are What You Need for Pretraining,https://neurips.cc/virtual/2024/oral/98004,2024," Previous language model pre-training methods have uniformly applied a next-token prediction loss to all training tokens. Challenging this norm, we posit that ''Not all tokens in a corpus are equally important for language model training''. Our initial analysis examines token-level training dynamics of language model, revealing distinct loss patterns for different tokens. Leveraging these insights, we introduce a new language model called Rho-1. Unlike traditional LMs that learn to predict every next token in a corpus, Rho-1 employs Selective Language Modeling (SLM), which selectively trains on useful tokens that aligned with the desired distribution. This approach involves scoring training tokens using a reference model, and then training the language model with a focused loss on tokens with higher scores. When continual continual pretraining on 15B OpenWebMath corpus, Rho-1 yields an absolute improvement in few-shot accuracy of up to 30% in 9 math tasks. After fine-tuning, Rho-1-1B and 7B achieved state-of-the-art results of 40.6% and 51.8% on MATH dataset, respectively - matching DeepSeekMath with only 3% of the pretraining tokens. Furthermore, when continual pretraining on 80B general tokens, Rho-1 achieves 6.8% average enhancement across 15 diverse tasks, increasing both data efficiency and performance of the language model pre-training.",Oral Session 3A: Generative Models,https://openreview.net/pdf?id=0NMzBwqaAJ,https://openreview.net/forum?id=0NMzBwqaAJ
"['Zhe Hu', 'Tuo Liang', 'Jing Li', 'Yiren Lu', 'Yunlai Zhou', 'Yiran Qiao', 'Jing Ma', 'Yu Yin']",NeurIPS,Cracking the Code of Juxtaposition_ Can AI Models Understand the Humorous Contradictions,https://neurips.cc/virtual/2024/oral/97967,2024," Recent advancements in large vision language models have demonstrated remarkable proficiency across a wide range of tasks. Yet, these models still struggle with understanding the nuances of human humor through juxtaposition, particularly when it involves nonlinear narratives that underpin many jokes and humor cues.  This paper investigates this challenge by focusing on comics with contradictory narratives, where each comic consists of two panels that create a humorous contradiction. We introduce the YesBut benchmark, which comprises tasks of varying difficulty aimed at assessing AI's capabilities in recognizing and interpreting these comics, ranging from literal content comprehension to deep narrative reasoning. Through extensive experimentation and analysis of recent commercial or open-sourced large vision language models, we assess their capability to comprehend the complex interplay of the narrative humor inherent in these comics. Our results show that even the state-of-the-art models still struggle with this task. Our findings offer insights into the current limitations and potential improvements for AI in understanding human creative expressions.",Oral Session 3B: Natural Language Processing,https://openreview.net/pdf?id=bCMpdaQCNW,https://openreview.net/forum?id=bCMpdaQCNW
"['Vladimir Malinovskii', 'Denis Mazur', 'Ivan Ilin', 'Denis Kuznedelev', 'Konstantin Burlachenko', 'Kai Yi', 'Dan Alistarh', 'Peter Richtarik']",NeurIPS,PV-Tuning_ Beyond Straight-Through Estimation for Extreme LLM Compression,https://neurips.cc/virtual/2024/oral/97970,2024," There has been significant interest in ""extreme"" compression of large language models (LLMs), i.e. to 1-2 bits per parameter, which allows such models to be executed efficiently on resource-constrained devices.  Existing work focused on improved one-shot quantization techniques and weight representations; yet, purely post-training  approaches are reaching diminishing returns in terms of the accuracy-vs-bit-width trade-off. State-of-the-art quantization methods such as QuIP# and AQLM include fine-tuning (part of) the compressed parameters over a limited amount of calibration data; however, such fine-tuning techniques over compressed weights often make exclusive use of straight-through estimators (STE), whose performance is not well-understood in this setting. In this work, we question the use of STE for extreme LLM compression, showing that it can be sub-optimal, and perform a systematic study of quantization-aware fine-tuning strategies for LLMs.We propose PV-Tuning - a representation-agnostic framework that generalizes and improves upon existing fine-tuning strategies, and provides convergence guarantees in restricted cases.On the practical side, when used for 1-2 bit vector quantization, PV-Tuning outperforms prior techniques for highly-performant models such as Llama and Mistral. Using PV-Tuning, we achieve the first Pareto-optimal quantization for Llama-2 family models at  2 bits per parameter.",Oral Session 3C: Natural Language Processing,https://openreview.net/pdf?id=YvA8UF0I37,https://openreview.net/forum?id=YvA8UF0I37
"['Jingchang Chen', 'Hongxuan Tang', 'Zheng Chu', 'Qianglong Chen', 'Zekun Wang', 'Ming Liu', 'Bing Qin']",NeurIPS,Divide-and-Conquer Meets Consensus_ Unleashing the Power of Functions in Code Generation,https://neurips.cc/virtual/2024/oral/97965,2024," Despite recent progress made by large language models in code generation, they still struggle with programs that meet complex requirements. Recent work utilizes plan-and-solve decomposition to decrease the complexity and leverage self-tests to refine the generated program. Yet, planning deep-inside requirements in advance can be challenging, and the tests need to be accurate to accomplish self-improvement. To this end, we propose FunCoder, a code generation framework incorporating the divide-and-conquer strategy with functional consensus. Specifically, FunCoder recursively branches off sub-functions as smaller goals during code generation, represented by a tree hierarchy. These sub-functions are then composited to attain more complex objectives. Additionally, we designate functions via a consensus formed by identifying similarities in program behavior, mitigating error propagation. FunCoder outperforms state-of-the-art methods by +9.8% on average in HumanEval, MBPP, xCodeEval and MATH with GPT-3.5 and GPT-4. Moreover, our method demonstrates superiority on smaller models: With FunCoder, StableCode-3b surpasses GPT-3.5 by +18.6% and achieves 97.7% of GPT-4's performance on HumanEval. Further analysis reveals that our proposed dynamic function decomposition is capable of handling complex requirements, and the functional consensus prevails over self-testing in correctness evaluation.",Oral Session 3D: Natural Language Processing,https://openreview.net/pdf?id=cFqAANINgW,https://openreview.net/forum?id=cFqAANINgW
"['Ruiqi Gao', 'Aleksander Holynski', 'Philipp Henzler', 'Arthur Brussee', 'Ricardo Martin Brualla', 'Pratul Srinivasan', 'Jonathan Barron', 'Ben Poole']",NeurIPS,CAT3D_ Create Anything in 3D with Multi-View Diffusion Models,https://neurips.cc/virtual/2024/oral/97975,2024," Advances in 3D reconstruction have enabled high-quality 3D capture, but require a user to collect hundreds to thousands of images to create a 3D scene. We present CAT3D, a method for creating anything in 3D by simulating this real-world capture process with a multi-view diffusion model. Given any number of input images and a set of target novel viewpoints, our model generates highly consistent novel views of a scene. These generated views can be used as input to robust 3D reconstruction techniques to produce 3D representations that can be rendered from any viewpoint in real-time. CAT3D can create entire 3D scenes in as little as one minute, and outperforms existing methods for single image and few-view 3D scene creation.",Oral Session 4B: Diffusion-based Models,https://openreview.net/pdf?id=TFZlFRl9Ks,https://openreview.net/forum?id=TFZlFRl9Ks
"['zhengrui Xu', 'Guan&#x27;an Wang', 'Xiaowen Huang', 'Jitao Sang']",NeurIPS,DenoiseRep_ Denoising Model for Representation Learning,https://neurips.cc/virtual/2024/oral/97982,2024," The denoising model has been proven a powerful generative model but has little exploration of discriminative tasks. Representation learning is important in discriminative tasks, which is defined as ""learning representations (or features) of the data that make it easier to extract useful information when building classifiers or other predictors"" . In this paper, we propose a novel Denoising Model for Representation Learning ( DenoiseRep ) to improve feature discrimination with joint feature extraction and denoising. DenoiseRep views each embedding layer in a backbone as a denoising layer, processing the cascaded embedding layers as if we are recursively denoise features step-by-step. This unifies the frameworks of feature extraction and denoising, where the former progressively embeds features from low-level to high-level, and the latter recursively denoises features step-by-step. After that, DenoiseRep fuses the parameters of feature extraction and denoising layers, and theoretically demonstrates its equivalence before and after the fusion, thus making feature denoising computation-free. DenoiseRep is a label-free algorithm that incrementally improves features but also complementary to the label if available. Experimental results on various discriminative vision tasks, including re-identification (Market-1501, DukeMTMC-reID, MSMT17, CUHK-03, vehicleID), image classification (ImageNet, UB200, Oxford-Pet, Flowers), object detection (COCO), image segmentation (ADE20K) show stability and impressive improvements. We also validate its effectiveness on the CNN (ResNet) and Transformer (ViT, Swin, Vmamda) architectures.","Oral Session 4C: Diffusion-based Models, Mathematics",https://openreview.net/pdf?id=OycU0bAus6,https://openreview.net/forum?id=OycU0bAus6
"['Yulia Rubanova', 'Tatiana Lopez-Guevara', 'Kelsey Allen', 'Will Whitney', 'Kimberly Stachenfeld', 'Tobias Pfaff']",NeurIPS,Learning rigid-body simulators over implicit shapes for large-scale scenes and vision,https://neurips.cc/virtual/2024/oral/97980,2024," Simulating large scenes with many rigid objects is crucial for a variety of applications, such as robotics, engineering, film and video games. Rigid interactions are notoriously hard to model: small changes to the initial state or the simulation parameters can lead to large changes in the final state. Recently, learned simulators based on graph networks (GNNs) were developed as an alternative to hand-designed simulators like MuJoCo and Bullet. They are able to accurately capture dynamics of real objects directly from real-world observations. However, current state-of-the-art learned simulators operate on meshes and scale poorly to scenes with many objects or detailed shapes. Here we present SDF-Sim, the first learned rigid-body simulator designed for scale. We use learned signed-distance functions (SDFs) to represent the object shapes and to speed up distance computation. We design the simulator to leverage SDFs and avoid the fundamental bottleneck of the previous simulators associated with collision detection.For the first time in literature, we demonstrate that we can scale the GNN-based simulators to scenes with hundreds of objects and up to 1.1 million nodes, where mesh-based approaches run out of memory. Finally, we show that SDF-Sim can be applied to real world scenes by extracting SDFs from multi-view images.",Oral Session 5A: Graph Neural Networks,https://openreview.net/pdf?id=QDYts5dYgq,https://openreview.net/forum?id=QDYts5dYgq
"['Junhao Cai', 'Yuji Yang', 'Weihao Yuan', 'Yisheng HE', 'Zilong Dong', 'Liefeng Bo', 'Hui Cheng', 'Qifeng Chen']",NeurIPS,GIC_ Gaussian-Informed Continuum for Physical Property Identification and Simulation,https://neurips.cc/virtual/2024/oral/97976,2024," This paper studies the problem of estimating physical properties (system identification) through visual observations. To facilitate geometry-aware guidance in physical property estimation, we introduce a novel hybrid framework that leverages 3D Gaussian representation to not only capture explicit shapes but also enable the simulated continuum to render object masks as 2D shape surrogates during training. We propose a new dynamic 3D Gaussian framework based on motion factorization to recover the object as 3D Gaussian point sets across different time states. Furthermore, we develop a coarse-to-fine filling strategy to generate the density fields of the object from the Gaussian reconstruction, allowing for the extraction of object continuums along with their surfaces and the integration of Gaussian attributes into these continuum. In addition to the extracted object surfaces, the Gaussian-informed continuum also enables the rendering of object masks during simulations, serving as 2D-shape guidance for physical property estimation. Extensive experimental evaluations demonstrate that our pipeline achieves state-of-the-art performance across multiple benchmarks and metrics. Additionally, we illustrate the effectiveness of the proposed method through real-world demonstrations, showcasing its practical utility. Our project page is at  https://jukgei.github.io/project/gic.",Oral Session 4D: Machine Vision,https://openreview.net/pdf?id=SSCtCq2MH2,https://openreview.net/forum?id=SSCtCq2MH2
"['Dongxiao He', 'Lianze Shan', 'Jitao Zhao', 'Hengrui Zhang', 'Zhen Wang', 'Weixiong Zhang']",NeurIPS,Exploitation of a Latent Mechanism in Graph Contrastive Learning_ Representation Scattering,https://neurips.cc/virtual/2024/oral/97979,2024," Graph Contrastive Learning (GCL) has emerged as a powerful approach for generating graph representations without the need for manual annotation. Most advanced GCL methods fall into three main frameworks: node discrimination, group discrimination, and bootstrapping schemes, all of which achieve comparable performance. However, the underlying mechanisms and factors that contribute to their effectiveness are not yet fully understood. In this paper, we revisit these frameworks and reveal a common mechanism—representation scattering—that significantly enhances their performance. Our discovery highlights an essential feature of GCL and unifies these seemingly disparate methods under the concept of representation scattering. To leverage this insight, we introduce Scattering Graph Representation Learning (SGRL), a novel framework that incorporates a new representation scattering mechanism designed to enhance representation diversity through a center-away strategy. Additionally, consider the interconnected nature of graphs, we develop a topology-based constraint  mechanism that integrates graph structural properties with representation scattering to prevent excessive scattering. We extensively evaluate SGRL across various downstream tasks on benchmark datasets, demonstrating its efficacy and superiority over existing GCL methods. Our findings underscore the significance of representation scattering in GCL and provide a structured framework for harnessing this mechanism to advance graph representation learning. The code of SGRL is at https://github.com/hedongxiao-tju/SGRL.","Oral Session 5B: Graph Neural Networks, Causal Inference",https://openreview.net/pdf?id=R8SolCx62K,https://openreview.net/forum?id=R8SolCx62K
"['Haonan Lin', 'Wenbin An', 'Jiahao Wang', 'Yan Chen', 'Feng Tian', 'Mengmeng Wang', 'QianYing Wang', 'Guang Dai', 'Jingdong Wang']",NeurIPS,Flipped Classroom_ Aligning Teacher Attention with Student in Generalized Category Discovery,https://neurips.cc/virtual/2024/oral/97990,2024," Recent advancements have shown promise in applying traditional Semi-Supervised Learning strategies to the task of Generalized Category Discovery (GCD). Typically, this involves a teacher-student framework in which the teacher imparts knowledge to the student to classify categories, even in the absence of explicit labels. Nevertheless, GCD presents unique challenges, particularly the absence of priors for new classes, which can lead to the teacher's misguidance and unsynchronized learning with the student, culminating in suboptimal outcomes. In our work, we delve into why traditional teacher-student designs falter in generalized category discovery as compared to their success in closed-world semi-supervised learning. We identify inconsistent pattern learning as the crux of this issue and introduce FlipClass—a method that dynamically updates the teacher to align with the student's attention, instead of maintaining a static teacher reference. Our teacher-attention-update strategy refines the teacher's focus based on student feedback, promoting consistent pattern recognition and synchronized learning across old and new classes. Extensive experiments on a spectrum of benchmarks affirm that FlipClass significantly surpasses contemporary GCD methods, establishing new standards for the field.",Oral Session 5C: Machine Vision,https://openreview.net/pdf?id=C4NbtYnyQg,https://openreview.net/forum?id=C4NbtYnyQg
"['Zhongchao Yi', 'Zhengyang Zhou', 'Qihe Huang', 'Yanjiang Chen', 'Liheng Yu', 'Xu Wang', 'Yang Wang']",NeurIPS,Get Rid of Isolation_ A Continuous Multi-task Spatio-Temporal Learning Framework,https://neurips.cc/virtual/2024/oral/97948,2024," Spatiotemporal learning has become a pivotal technique to enable urban intelligence. Traditional spatiotemporal models mostly focus on a specific task by assuming a same distribution between training and testing sets. However, given that urban systems are usually dynamic, multi-sourced with imbalanced data distributions, current specific task-specific models fail to generalize to new urban conditions and adapt to new domains without explicitly modeling interdependencies across various dimensions and types of urban data. To this end, we argue that there is an essential to propose a Continuous Multi-task Spatio-Temporal learning framework (CMuST) to empower  collective urban intelligence, which  reforms the urban spatiotemporal learning from single-domain  to cooperatively multi-dimensional and multi-task learning. Specifically, CMuST proposes a new multi-dimensional spatiotemporal interaction network (MSTI) to allow cross-interactions between context and main observations as well as  self-interactions within spatial and temporal aspects  to be  exposed, which is also the core for capturing task-level commonality and personalization. To ensure continuous task learning, a novel Rolling Adaptation training scheme (RoAda) is devised, which not only preserves task uniqueness by constructing data summarization-driven task prompts, but also harnesses correlated patterns among tasks  by iterative model behavior modeling. We further establish a benchmark of three cities for multi-task spatiotemporal learning, and empirically demonstrate the superiority of CMuST via extensive evaluations on these datasets. The impressive improvements on both few-shot streaming data and new domain tasks against existing SOAT methods are achieved. Code is available at https://github.com/DILab-USTCSZ/CMuST.",Oral Session 5D: Machine Learning and Science,https://openreview.net/pdf?id=tnh4LK72yj,https://openreview.net/forum?id=tnh4LK72yj
"['Nicholas Gao', 'Stephan Günnemann']",NeurIPS,Neural Pfaffians_ Solving Many Many-Electron Schrödinger Equations,https://neurips.cc/virtual/2024/oral/97987,2024," Neural wave functions accomplished unprecedented accuracies in approximating the ground state of many-electron systems, though at a high computational cost. Recent works proposed amortizing the cost by learning generalized wave functions across different structures and compounds instead of solving each problem independently. Enforcing the permutation antisymmetry of electrons in such generalized neural wave functions remained challenging as existing methods require discrete orbital selection via non-learnable hand-crafted algorithms. This work tackles the problem by defining overparametrized, fully learnable neural wave functions suitable for generalization across molecules. We achieve this by relying on Pfaffians rather than Slater determinants. The Pfaffian allows us to enforce the antisymmetry on arbitrary electronic systems without any constraint on electronic spin configurations or molecular structure. Our empirical evaluation finds that a single neural Pfaffian calculates the ground state and ionization energies with chemical accuracy across various systems. On the TinyMol dataset, we outperform the `gold-standard' CCSD(T) CBS reference energies by 1.9m$E_h$ and reduce energy errors compared to previous generalized neural wave functions by up to an order of magnitude.","Oral Session 6A: Machine Learning and Science, Safety",https://openreview.net/pdf?id=HRkniCWM3E,https://openreview.net/forum?id=HRkniCWM3E
"['Jiaming Ji', 'Boyuan Chen', 'Hantao Lou', 'Donghai Hong', 'Borong Zhang', 'Xuehai Pan', 'Tianyi (Alex) Qiu', 'Juntao Dai', 'Yaodong Yang']",NeurIPS,Aligner_ Efficient Alignment by Learning to Correct,https://neurips.cc/virtual/2024/oral/97959,2024," With the rapid development of large language models (LLMs) and ever-evolving practical requirements, finding an efficient and effective alignment method has never been more critical. However, the tension between the complexity of current alignment methods and the need for rapid iteration in deployment scenarios necessitates the development of a model-agnostic alignment approach that can operate under these constraints. In this paper, we introduce Aligner, a novel and simple alignment paradigm that learns the correctional residuals between preferred and dispreferred answers using a small model. Designed as a model-agnostic, plug-and-play module, Aligner can be directly applied to various open-source and API-based models with only one-off training, making it suitable for rapid iteration. Notably, Aligner can be applied to any powerful, large-scale upstream models. Moreover, it can even iteratively bootstrap the upstream models using corrected responses as synthetic human preference data, breaking through the model's performance ceiling. Our experiments demonstrate performance improvements by deploying the same Aligner model across 11 different LLMs, evaluated on the 3H dimensions (helpfulness, harmlessness, and honesty). Specifically, Aligner-7B has achieved an average improvement of 68.9% in helpfulness and 22.8% in harmlessness across the tested LLMs while also effectively reducing hallucination. In the Alpaca-Eval leaderboard, stacking Aligner-2B on GPT-4 Turbo improved its LC Win Rate from 55.0% to 58.3%, surpassing GPT-4 Omni's 57.5% Win Rate (community report).","Oral Session 6B: Safety, New Data",https://openreview.net/pdf?id=kq166jACVP,https://openreview.net/forum?id=kq166jACVP
"['Yongzhe Jia', 'Xuyun Zhang', 'Hongsheng Hu', 'Kim-Kwang Raymond Choo', 'Lianyong Qi', 'Xiaolong Xu', 'Amin Beheshti', 'Wanchun Dou']",NeurIPS,DapperFL_ Domain Adaptive Federated Learning with Model Fusion Pruning for Edge Devices,https://neurips.cc/virtual/2024/oral/97981,2024," Federated learning (FL) has emerged as a prominent machine learning paradigm in edge computing environments, enabling edge devices to collaboratively optimize a global model without sharing their private data. However, existing FL frameworks suffer from efficacy deterioration due to the system heterogeneity inherent in edge computing, especially in the presence of domain shifts across local data. In this paper, we propose a heterogeneous FL framework DapperFL, to enhance model performance across multiple domains. In DapperFL, we introduce a dedicated Model Fusion Pruning (MFP) module to produce personalized compact local models for clients to address the system heterogeneity challenges. The MFP module prunes local models with fused knowledge obtained from both local and remaining domains, ensuring robustness to domain shifts. Additionally, we design a Domain Adaptive Regularization (DAR) module to further improve the overall performance of DapperFL. The DAR module employs regularization generated by the pruned model, aiming to learn robust representations across domains. Furthermore, we introduce a specific aggregation algorithm for aggregating heterogeneous local models with tailored architectures and weights. We implement DapperFL on a real-world FL platform with heterogeneous clients. Experimental results on benchmark datasets with multiple domains demonstrate that DapperFL outperforms several state-of-the-art FL frameworks by up to 2.28%, while significantly achieving model volume reductions ranging from 20% to 80%. Our code is available at: https://github.com/jyzgh/DapperFL.","Oral Session 6D: Deep Learning Architecture, Infrastructure",https://openreview.net/pdf?id=Pezt0xttae,https://openreview.net/forum?id=Pezt0xttae
"['Spencer Rooke', 'Zhaoze Wang', 'Ronald Di Tullio', 'Vijay Balasubramanian']",NeurIPS,Trading Place for Space_ Increasing Location Resolution Reduces Contextual Capacity in Hippocampal Codes,https://neurips.cc/virtual/2024/oral/97978,2024," Many animals learn cognitive maps of their environment - a simultaneous representation of context, experience, and position.  Place cells in the hippocampus, named for their explicit encoding of position, are believed to be a neural substrate of these maps, with place cell ""remapping"" explaining how this system can represent different contexts. Briefly, place cells alter their firing properties, or ""remap"", in response to changes in experiential or sensory cues. Substantial sensory changes, produced, e.g., by moving between environments, cause large subpopulations of place cells to change their tuning entirely. While many studies have looked at the physiological basis of remapping, we lack explicit calculations of how the contextual capacity of the place cell system changes as a function of place field firing properties. Here, we propose a geometric approach to understanding population level activity of place cells.  Using known firing field statistics, we investigate how changes to place cell firing properties affect the distances between representations of different environments within firing rate space.  Using this approach, we find that the number of contexts storable by the hippocampus grows exponentially with the number of place cells, and calculate this exponent for environments of different sizes. We identify a fundamental trade-off between high resolution encoding of position and the number of storable contexts. This trade-off is tuned by place cell width, which might explain the change in firing field scale along the dorsal-ventral axis of the hippocampus. We demonstrate that clustering of place cells near likely points of confusion, such as boundaries, increases the contextual capacity of the place system within our framework and conclude by discussing how our geometric approach could be extended to include other cell types and abstract spaces.",Oral Session 1A: Neuroscience and Intepretability,https://openreview.net/pdf?id=REIK4SZMJt,https://openreview.net/forum?id=REIK4SZMJt
"['Arthur da Cunha', 'Mikael Møller Høgsgaard', 'Kasper Green Larsen']",NeurIPS,Optimal Parallelization of Boosting,https://neurips.cc/virtual/2024/oral/97950,2024," Recent works on the parallel complexity of Boosting have established strong lower bounds on the tradeoff between the number of training rounds $p$ and the total parallel work per round $t$.These works have also presented highly non-trivial parallel algorithms that shed light on different regions of this tradeoff.Despite these advancements, a significant gap persists between the theoretical lower bounds and the performance of these algorithms across much of the tradeoff space.In this work, we essentially close this gap by providing both improved lower bounds on the parallel complexity of weak-to-strong learners, and a parallel Boosting algorithm whose performance matches these bounds across the entire $p$ vs. $t$ compromise spectrum, up to logarithmic factors.Ultimately, this work settles the parallel complexity of Boosting algorithms that are nearly sample-optimal.",Oral Session 1D: Learning Theory,https://openreview.net/pdf?id=rtz4df9IF1,https://openreview.net/forum?id=rtz4df9IF1
"['Antonio Terpin', 'Nicolas Lanzetti', 'Martín Gadea', 'Florian Dorfler']",NeurIPS,Learning diffusion at lightspeed,https://neurips.cc/virtual/2024/oral/97944,2024," Diffusion regulates numerous natural processes and the dynamics of many successful generative models. Existing models to learn the diffusion terms from observational data rely on complex bilevel optimization problems and model only the drift of the system.We propose a new simple model, JKOnet , which bypasses the complexity of existing architectures while presenting significantly enhanced representational capabilities: JKOnet recovers the potential, interaction, and internal energy components of the underlying diffusion process. JKOnet* minimizes a simple quadratic loss and outperforms other baselines in terms of sample efficiency, computational complexity, and accuracy. Additionally, JKOnet* provides a closed-form optimal solution for linearly parametrized functionals, and, when applied to predict the evolution of cellular processes from real-world data, it achieves state-of-the-art accuracy at a fraction of the computational cost of all existing methods.Our methodology is based on the interpretation of diffusion processes as energy-minimizing trajectories in the probability space via the so-called JKO scheme, which we study via its first-order optimality conditions.",Oral Session 1C: Optimization and Learning Theory,https://openreview.net/pdf?id=y10avdRFNK,https://openreview.net/forum?id=y10avdRFNK
"['Changli Wu', 'qi chen', 'Jiayi Ji', 'Haowei Wang', 'Yiwei Ma', 'You Huang', 'Gen Luo', 'Hao Fei', 'Xiaoshuai Sun', 'Rongrong Ji']",NeurIPS,RG-SAN_ Rule-Guided Spatial Awareness Network for End-to-End 3D Referring Expression Segmentation,https://neurips.cc/virtual/2024/oral/97951,2024," 3D Referring Expression Segmentation (3D-RES) aims to segment 3D objects by correlating referring expressions with point clouds. However, traditional approaches frequently encounter issues like over-segmentation or mis-segmentation, due to insufficient emphasis on spatial information of instances. In this paper, we introduce a Rule-Guided Spatial Awareness Network (RG-SAN) by utilizing solely the spatial information of the target instance for supervision. This approach enables the network to accurately depict the spatial relationships among all entities described in the text, thus enhancing the reasoning capabilities. The RG-SAN consists of the Text-driven Localization Module (TLM) and the Rule-guided Weak Supervision (RWS) strategy. The TLM initially locates all mentioned instances and iteratively refines their positional information. The RWS strategy, acknowledging that only target objects have supervised positional information, employs dependency tree rules to precisely guide the core instance’s positioning. Extensive testing on the ScanRefer benchmark has shown that RG-SAN not only establishes new performance benchmarks, with an mIoU increase of 5.1 points, but also exhibits significant improvements in robustness when processing descriptions with spatial ambiguity. All codes are available at https://github.com/sosppxo/RG-SAN.",Oral Session 1B: Human-AI Interaction,https://openreview.net/pdf?id=r5spnrY6H3,https://openreview.net/forum?id=r5spnrY6H3
"['Sudeep Salgia', 'Yuejie Chi']",NeurIPS,The Sample-Communication Complexity Trade-off in Federated Q-Learning,https://neurips.cc/virtual/2024/oral/97994,2024," We consider the problem of Federated Q-learning, where $M$ agents aim to collaboratively learn the optimal Q-function of an unknown infinite horizon Markov Decision Process with finite state and action spaces. We investigate the trade-off between sample and communication complexity for the widely used class of intermittent communication algorithms. We first establish the converse result, where we show that any Federated Q-learning that offers a linear speedup with respect to number of agents in sample complexity needs to incur a communication cost of at least $\Omega(\frac{1}{1-\gamma})$, where $\gamma$ is the discount factor. We also propose a new Federated Q-learning algorithm, called Fed-DVR-Q, which is the first Federated Q-learning algorithm to simultaneously achieve order-optimal sample and communication complexities. Thus, together these results provide a complete characterization of the sample-communication complexity trade-off in Federated Q-learning.",Oral Session 2B: Reinforcement Learning,https://openreview.net/pdf?id=6YIpvnkjUK,https://openreview.net/forum?id=6YIpvnkjUK
"['Yang Peng', 'Liangyu Zhang', 'Zhihua Zhang']",NeurIPS,Statistical Efficiency of Distributional Temporal Difference Learning,https://neurips.cc/virtual/2024/oral/97962,2024," Distributional reinforcement learning (DRL) has achieved empirical success in various domains.One of the core tasks in the field of DRL is distributional policy evaluation, which involves estimating the return distribution $\eta^\pi$ for a given policy $\pi$.The distributional temporal difference learning has been accordingly proposed, whichis an extension of the temporal difference learning (TD) in the classic RL area.In the tabular case,  Rowland et al. [2018] and Rowland et al. [2023] proved the asymptotic convergence of two instances of distributional TD, namely categorical temporal difference learning (CTD) and quantile temporal difference learning (QTD), respectively.In this paper, we go a step further and analyze the finite-sample performance of distributional TD.To facilitate theoretical analysis, we propose a non-parametric distributional TD learning (NTD).For a $\gamma$-discounted infinite-horizon tabular Markov decision process,we show that for NTD we need $\widetilde O\left(\frac{1}{\varepsilon^{2p}(1-\gamma)^{2p+1}}\right)$ iterations to achieve an $\varepsilon$-optimal estimator with high probability, when the estimation error is measured by the $p$-Wasserstein distance.This sample complexity bound is minimax optimal (up to logarithmic factors) in the case of the $1$-Wasserstein distance.To achieve this, we establish a novel Freedman's inequality in Hilbert spaces, which would be of independent interest.In addition, we revisit CTD, showing that the same non-asymptotic convergence bounds hold for CTD in the case of the $p$-Wasserstein distance.",Oral Session 2C: Reinforcement Learning,https://openreview.net/pdf?id=eWUM5hRYgH,https://openreview.net/forum?id=eWUM5hRYgH
"['Shangzi Xue', 'Zhenya Huang', 'Jiayu Liu', 'Xin Lin', 'Yuting Ning', 'Binbin Jin', 'Xin Li', 'Qi Liu']",NeurIPS,"Decompose, Analyze and Rethink_ Solving Intricate Problems with Human-like Reasoning Cycle",https://neurips.cc/virtual/2024/oral/97984,2024," In this paper, we introduce DeAR ( Decompose-Analyze-Rethink ), a framework that iteratively builds a reasoning tree to tackle intricate problems within a single large language model (LLM). Unlike approaches that extend or search for rationales, DeAR is featured by 1) adopting a tree-based question decomposition manner to plan the organization of rationales, which mimics the logical planning inherentin human cognition; 2) globally updating the rationales at each reasoning step through natural language feedback. Specifically, the Decompose stage decomposes the question into simpler sub-questions, storing them as new nodes; the Analyze stage generates and self-checks rationales for sub-questions at each node evel; and the Rethink stage updates parent-node rationales based on feedback from their child nodes. By generating and updating the reasoning process from a more global perspective, DeAR constructs more adaptive and accurate logical structures for complex problems, facilitating timely error correction compared to rationale-extension and search-based approaches such as Tree-of-Thoughts (ToT) and Graph-of-Thoughts (GoT). We conduct extensive experiments on three reasoning benchmarks, including ScienceQA, StrategyQA, and GSM8K, which cover a variety of reasoning tasks, demonstrating that our approach significantly reduces logical errors and enhances performance across various LLMs. Furthermore, we validate that DeAR is an efficient method that achieves a superior trade-off between accuracy and reasoning time compared to ToT and GoT.",Oral Session 3B: Natural Language Processing,https://openreview.net/pdf?id=NPKZF1WDjZ,https://openreview.net/forum?id=NPKZF1WDjZ
"['Sicheng Xu', 'Guojun Chen', 'Yu-Xiao Guo', 'Jiaolong Yang', 'Chong Li', 'Zhenyu Zang', 'Yizhong Zhang', 'Xin Tong', 'Baining Guo']",NeurIPS,VASA-1_ Lifelike Audio-Driven Talking Faces Generated in Real Time,https://neurips.cc/virtual/2024/oral/97995,2024," We introduce VASA, a framework for generating lifelike talking faces with appealing visual affective skills (VAS) given a single static image and a speech audio clip. Our premiere model, VASA-1, is capable of not only generating lip movements that are exquisitely synchronized with the audio, but also producing a large spectrum of facial nuances and natural head motions that contribute to the perception of authenticity and liveliness. The core innovations include a diffusion-based holistic facial dynamics and head movement generation model that works in a face latent space, and the development of such an expressive and disentangled face latent space using videos.Through extensive experiments including evaluation on a set of new metrics, we show that our method significantly outperforms previous methods along various dimensions comprehensively. Our method delivers high video quality with realistic facial and head dynamics and also supports the online generation of 512$\times$512 videos at up to 40 FPS with negligible starting latency.It paves the way for real-time engagements with lifelike avatars that emulate human conversational behaviors.",Oral Session 2D: Generative Models,https://openreview.net/pdf?id=5zSCSE0k41,https://openreview.net/forum?id=5zSCSE0k41
"['Tianhong Li', 'Dina Katabi', 'Kaiming He']",NeurIPS,Return of Unconditional Generation_ A Self-supervised Representation Generation Method,https://neurips.cc/virtual/2024/oral/97963,2024," Unconditional generation -- the problem of modeling data distribution without relying on human-annotated labels -- is a long-standing and fundamental challenge in generative models, creating a potential of learning from large-scale unlabeled data. In the literature, the generation quality of an unconditional method has been much worse than that of its conditional counterpart. This gap can be attributed to the lack of semantic information provided by labels. In this work, we show that one can close this gap by generating semantic representations in the representation space produced by a self-supervised encoder. These representations can be used to condition the image generator. This framework, called Representation-Conditioned Generation (RCG), provides an effective solution to the unconditional generation problem without using labels. Through comprehensive experiments, we observe that RCG significantly improves unconditional generation quality: e.g., it achieves a new state-of-the-art FID of 2.15 on ImageNet 256x256, largely reducing the previous best of 5.91 by a relative 64%. Our unconditional results are situated in the same tier as the leading class-conditional ones. We hope these encouraging observations will attract the community's attention to the fundamental problem of unconditional generation. Code is available at https://github.com/LTH14/rcg .",Oral Session 3A: Generative Models,https://openreview.net/pdf?id=clTa4JFBML,https://openreview.net/forum?id=clTa4JFBML
"['Alvin Tan', 'Chunhua Yu', 'Bria Long', 'Wanjing Ma', 'Tonya Murray', 'Rebecca Silverman', 'Jason Yeatman', 'Michael C Frank']",NeurIPS,DevBench_ A multimodal developmental benchmark for language learning,https://neurips.cc/virtual/2024/oral/98016,2024," How (dis)similar are the learning trajectories of vision–language models and children? Recent modeling work has attempted to understand the gap between models’ and humans’ data efficiency by constructing models trained on less data, especially multimodal naturalistic data. However, such models are often evaluated on adult-level benchmarks, with limited breadth in language abilities tested, and without direct comparison to behavioral data. We introduce DevBench, a multimodal benchmark comprising seven language evaluation tasks spanning the domains of lexical, syntactic, and semantic ability, with behavioral data from both children and adults. We evaluate a set of vision–language models on these tasks, comparing models and humans on their response patterns, not their absolute performance. Across tasks, models exhibit variation in their closeness to human response patterns, and models that perform better on a task also more closely resemble human behavioral responses. We also examine the developmental trajectory of OpenCLIP over training, finding that greater training results in closer approximations to adult response patterns. DevBench thus provides a benchmark for comparing models to human language development. These comparisons highlight ways in which model and human language learning processes diverge, providing insight into entry points for improving language models.",Oral Session 4A: Natural Language Processing,https://arxiv.org/pdf/2406.10215,
"['Arjun Panickssery', 'Samuel Bowman', 'Shi Feng']",NeurIPS,LLM Evaluators Recognize and Favor Their Own Generations,https://neurips.cc/virtual/2024/oral/97998,2024," Self-evaluation using large language models (LLMs) has proven valuable not only in benchmarking but also methods like reward modeling, constitutional AI, and self-refinement. But new biases are introduced due to the same LLM acting as both the evaluator and the evaluatee. One such bias is self-preference, where an LLM evaluator scores its own outputs higher than others’ while human annotators consider them of equal quality. But do LLMs actually recognize their own outputs when they give those texts higher scores, or is it just a coincidence? In this paper, we investigate if self-recognition capability contributes to self-preference. We discover that, out of the box, LLMs such as GPT-4 and Llama 2 have non-trivial accuracy at distinguishing themselves from other LLMs and humans. By finetuning LLMs, we discover a linear correlation between self-recognition capability and the strength of self-preference bias; using controlled experiments, we show that the causal explanation resists straightforward confounders. We discuss how self-recognition can interfere with unbiased evaluations and AI safety more generally.",Oral Session 3C: Natural Language Processing,https://openreview.net/pdf?id=4NJBV6Wp0h,https://openreview.net/forum?id=4NJBV6Wp0h
"['Haokun Lin', 'Haobo Xu', 'Yichen WU', 'Jingzhi Cui', 'Yingtao Zhang', 'Linzhan Mou', 'Linqi Song', 'Zhenan Sun', 'Ying Wei']",NeurIPS,DuQuant_ Distributing Outliers via Dual Transformation Makes Stronger Quantized LLMs,https://neurips.cc/virtual/2024/oral/97956,2024," Quantization of large language models (LLMs) faces significant challenges, particularly due to the presence of outlier activations that impede efficient low-bit representation. Traditional approaches predominantly address Normal Outliers, which are activations across all tokens with relatively large magnitudes. However, these methods struggle with smoothing Massive Outliers that display significantly larger values, which leads to significant performance degradation in low-bit quantization. In this paper, we introduce DuQuant, a novel approach that utilizes rotation and permutation transformations to more effectively mitigate both massive and normal outliers. First, DuQuant starts by constructing the rotation matrix, using specific outlier dimensions as prior knowledge, to redistribute outliers to adjacent channels by block-wise rotation. Second, We further employ a zigzag permutation to balance the distribution of outliers across blocks, thereby reducing block-wise variance. A subsequent rotation further smooths the activation landscape, enhancing model performance. DuQuant simplifies the quantization process and excels in managing outliers, outperforming the state-of-the-art baselines across various sizes and types of LLMs on multiple tasks, even with 4-bit weight-activation quantization. Our code is available at https://github.com/Hsu1023/DuQuant.",Oral Session 3D: Natural Language Processing,https://openreview.net/pdf?id=mp8u2Pcmqz,https://openreview.net/forum?id=mp8u2Pcmqz
"['Michael Luo', 'Justin Wong', 'Brandon Trabucco', 'Yanping Huang', 'Joseph Gonzalez', 'zhifeng Chen', 'Ruslan Salakhutdinov', 'Ion Stoica']",NeurIPS,Stylus_ Automatic Adapter Selection for Diffusion Models,https://neurips.cc/virtual/2024/oral/98000,2024," Beyond scaling base models with more data or parameters, fine-tuned adapters provide an alternative way to generate high fidelity, custom images at reduced costs. As such, adapters have been widely adopted by open-source communities, accumulating a database of over 100K adapters—most of which are highly customized with insufficient descriptions. To generate high quality images, this paper explores the problem of matching the prompt to a Stylus of relevant adapters, built on recent work that highlight the performance gains of composing adapters. We introduce Stylus, which efficiently selects and automatically composes task-specific adapters based on a prompt's keywords. Stylus outlines a three-stage approach that first summarizes adapters with improved descriptions and embeddings, retrieves relevant adapters, and then further assembles adapters based on prompts' keywords by checking how well they fit the prompt. To evaluate Stylus, we developed StylusDocs, a curated dataset featuring 75K adapters with pre-computed adapter embeddings. In our evaluation on popular Stable Diffusion checkpoints, Stylus achieves greater CLIP/FID Pareto efficiency and is twice as preferred, with humans and multimodal models as evaluators, over the base model.",Oral Session 4B: Diffusion-based Models,https://openreview.net/pdf?id=3Odq2tGSpp,https://openreview.net/forum?id=3Odq2tGSpp
"['Tianwei Yin', 'Michaël Gharbi', 'Taesung Park', 'Richard Zhang', 'Eli Shechtman', 'Fredo Durand', 'Bill Freeman']",NeurIPS,Improved Distribution Matching Distillation for Fast Image Synthesis,https://neurips.cc/virtual/2024/oral/97949,2024," Recent approaches have shown promises distilling expensive diffusion models into efficient one-step generators.Amongst them, Distribution Matching Distillation (DMD) produces one-step generators that match their teacher in distribution, i.e., the distillation process does not enforce a one-to-one correspondence with the sampling trajectories of their teachers.However, to ensure stable training in practice, DMD requires an additional regression loss computed using a large set of noise--image pairs, generated by the teacher with many steps of a deterministic sampler.This is not only computationally expensive for large-scale text-to-image synthesis, but it also limits the student's quality, tying it too closely to the teacher's original sampling paths.We introduce DMD2, a set of techniques that lift this limitation and improve DMD training.First, we eliminate the regression loss and the need for expensive dataset construction.We show that the resulting instability is due to the ""fake"" critic not estimating the distribution of generated samples with sufficient accuracy and propose a two time-scale update rule as a remedy.Second, we integrate a GAN loss into the distillation procedure, discriminating between generated samples and real images.This lets us train the student model on real data, thus mitigating the imperfect ""real"" score estimation from the teacher model, and thereby enhancing quality.Third, we introduce a new training procedure that enables multi-step sampling in the student, andaddresses the training--inference input mismatch of previous work, by simulating inference-time generator samples during training. Taken together, our improvements set new benchmarks in one-step image generation, with FID scores of 1.28 on ImageNet-64×64 and 8.35 on zero-shot COCO 2014, surpassing the original teacher despite a 500X reduction in inference cost.Further, we show our approach can generate megapixel images by distilling SDXL, demonstrating exceptional visual quality among few-step methods, and surpassing the teacher. We release our code and pretrained models.","Oral Session 4C: Diffusion-based Models, Mathematics",https://openreview.net/pdf?id=tQukGCDaNT,https://openreview.net/forum?id=tQukGCDaNT
"['Raffaele Paolino', 'Sohir Maskey', 'Pascal Welke', 'Gitta Kutyniok']",NeurIPS,Weisfeiler and Leman Go Loopy_ A New Hierarchy for Graph Representational Learning,https://neurips.cc/virtual/2024/oral/97991,2024," We introduce $r$-loopy Weisfeiler-Leman ($r$-$\ell$WL), a novel hierarchy of graph isomorphism tests and a corresponding GNN framework, $r$-$\ell$MPNN, that can count cycles up to length $r{+}2$. Most notably, we show that $r$-$\ell$WL can count homomorphisms of cactus graphs. This extends 1-WL, which can only count homomorphisms of trees and, in fact, is incomparable to $k$-WL for any fixed $k$. We empirically validate the expressive and counting power of $r$-$\ell$MPNN on several synthetic datasets and demonstrate the scalability and strong performance on various real-world datasets, particularly on sparse graphs.",Oral Session 5A: Graph Neural Networks,https://openreview.net/pdf?id=9O2sVnEHor,https://openreview.net/forum?id=9O2sVnEHor
"['Minghua Liu', 'Chong Zeng', 'Xinyue Wei', 'Ruoxi Shi', 'Linghao Chen', 'Chao Xu', 'Mengqi Zhang', 'Zhaoning Wang', 'Xiaoshuai Zhang', 'Isabella Liu', 'Hongzhi Wu', 'Hao Su']",NeurIPS,MeshFormer _ High-Quality Mesh Generation with 3D-Guided Reconstruction Model,https://neurips.cc/virtual/2024/oral/97945,2024," Open-world 3D reconstruction models have recently garnered significant attention. However, without sufficient 3D inductive bias, existing methods typically entail expensive training costs and struggle to extract high-quality 3D meshes. In this work, we introduce MeshFormer, a sparse-view reconstruction model that explicitly leverages 3D native structure, input guidance, and training supervision. Specifically, instead of using a triplane representation, we store features in 3D sparse voxels and combine transformers with 3D convolutions to leverage an explicit 3D structure and projective bias. In addition to sparse-view RGB input, we require the network to take input and generate corresponding normal maps. The input normal maps can be predicted by 2D diffusion models, significantly aiding in the guidance and refinement of the geometry's learning. Moreover, by combining Signed Distance Function (SDF) supervision with surface rendering, we directly learn to generate high-quality meshes without the need for complex multi-stage training processes. By incorporating these explicit 3D biases, MeshFormer can be trained efficiently and deliver high-quality textured meshes with fine-grained geometric details. It can also be integrated with 2D diffusion models to enable fast single-image-to-3D and text-to-3D tasks. Videos are available at https://meshformer3d.github.io/",Oral Session 4D: Machine Vision,https://openreview.net/pdf?id=x7pjdDod6Z,https://openreview.net/forum?id=x7pjdDod6Z
"['Siyuan Guo', 'Chi Zhang', 'Karthika Mohan', 'Ferenc Huszar', 'Bernhard Schölkopf']",NeurIPS,Do Finetti_ On Causal Effects for Exchangeable Data,https://neurips.cc/virtual/2024/oral/97996,2024," We study causal effect estimation in a setting where the data are not i.i.d.$\ $(independent and identically distributed). We focus on exchangeable data satisfying an assumption of independent causal mechanisms. Traditional causal effect estimation frameworks, e.g., relying on structural causal models and do-calculus, are typically limited to i.i.d. data and do not extend to more general exchangeable generative processes, which naturally arise in multi-environment data. To address this gap, we develop a generalized framework for exchangeable data and introduce a truncated factorization formula that facilitates both the identification and estimation of causal effects in our setting. To illustrate potential applications, we introduce a causal Pólya urn model and demonstrate how intervention propagates effects in exchangeable data settings. Finally, we develop an algorithm that performs simultaneous causal discovery and effect estimation given multi-environment data.","Oral Session 5B: Graph Neural Networks, Causal Inference",https://openreview.net/pdf?id=4rCZeCZAON,https://openreview.net/forum?id=4rCZeCZAON
"['Felix Petersen', 'Hilde Kuehne', 'Christian Borgelt', 'Julian Welzel', 'Stefano Ermon']",NeurIPS,Convolutional Differentiable Logic Gate Networks,https://neurips.cc/virtual/2024/oral/97997,2024," With the increasing inference cost of machine learning models, there is a growing interest in models with fast and efficient inference. Recently, an approach for learning logic gate networks directly via a differentiable relaxation was proposed. Logic gate networks are faster than conventional neural network approaches because their inference only requires logic gate operators such as NAND, OR, and XOR, which are the underlying building blocks of current hardware and can be efficiently executed. We build on this idea, extending it by deep logic gate tree convolutions, logical OR pooling, and residual initializations. This allows scaling logic gate networks up by over one order of magnitude and utilizing the paradigm of convolution. On CIFAR-10, we achieve an accuracy of 86.29% using only 61 million logic gates, which improves over the SOTA while being 29x smaller.",Oral Session 5C: Machine Vision,https://openreview.net/pdf?id=4bKEFyUHT4,https://openreview.net/forum?id=4bKEFyUHT4
"['Yubin Kim', 'Chanwoo Park', 'Hyewon Jeong', 'Yik Siu Chan', 'Xuhai ""Orson"" Xu', 'Daniel McDuff', 'Hyeonhoon Lee', 'Marzyeh Ghassemi', 'Cynthia Breazeal', 'Hae Park']",NeurIPS,MDAgents_ An Adaptive Collaboration of LLMs for Medical Decision-Making,https://neurips.cc/virtual/2024/oral/97988,2024," Foundation models are becoming valuable tools in medicine. Yet despite their promise, the best way to leverage Large Language Models (LLMs) in complex medical tasks remains an open question. We introduce a novel multi-agent framework, named **M**edical **D**ecision-making **Agents** (**MDAgents**) that helps to address this gap by automatically assigning a collaboration structure to a team of LLMs. The assigned solo or group collaboration structure is tailored to the medical task at hand, a simple emulation inspired by the way real-world medical decision-making processes are adapted to tasks of different complexities. We evaluate our framework and baseline methods using state-of-the-art LLMs across a suite of real-world medical knowledge and clinical diagnosis benchmarks, including a comparison ofLLMs’ medical complexity classification against human physicians. MDAgents achieved the **best performance in seven out of ten** benchmarks on tasks requiring an understanding of medical knowledge and multi-modal reasoning, showing a significant **improvement of up to 4.2\%** ($p$ < 0.05) compared to previous methods' best performances. Ablation studies reveal that MDAgents effectively determines medical complexity to optimize for efficiency and accuracy across diverse medical tasks. Notably, the combination of moderator review and external medical knowledge in group collaboration resulted in an average accuracy **improvement of 11.8\%**. Our code can be found at https://github.com/mitmedialab/MDAgents.","Oral Session 6A: Machine Learning and Science, Safety",https://openreview.net/pdf?id=EKdk4vxKO4,https://openreview.net/forum?id=EKdk4vxKO4
"['Nikhil Khandekar', 'Qiao Jin', 'Guangzhi Xiong', 'Soren Dunn', 'Serina Applebaum', 'Zain Anwar', 'Maame Sarfo-Gyamfi', 'Conrad Safranek', 'Abid Anwar', 'Andrew Zhang', 'Aidan Gilson', 'Maxwell Singer', 'Amisha Dave', 'Anrew Taylor', 'Aidong Zhang', 'Qingyu Chen', 'Zhiyong Lu']",NeurIPS,MedCalc-Bench_ Evaluating Large Language Models for Medical Calculations,https://neurips.cc/virtual/2024/oral/98021,2024," Current benchmarks for evaluating large language models (LLMs) in medicine are primarily focused on question-answering involving domain knowledge and descriptive reasoning. While such qualitative capabilities are vital to medical diagnosis, in real-world scenarios, doctors frequently use clinical calculators that follow quantitative equations and rule-based reasoning paradigms for evidence-based decision support. To this end, we propose MedCalc-Bench, a first-of-its-kind dataset focused on evaluating the medical calculation capability of LLMs. MedCalc-Bench contains an evaluation set of over 1000 manually reviewed instances from 55 different medical calculation tasks. Each instance in MedCalc-Bench consists of a patient note, a question requesting to compute a specific medical value, a ground truth answer, and a step-by-step explanation showing how the answer is obtained. While our evaluation results show the potential of LLMs in this area, none of them are effective enough for clinical settings. Common issues include extracting the incorrect entities, not using the correct equation or rules for a calculation task, or incorrectly performing the arithmetic for the computation. We hope our study highlights the quantitative knowledge and reasoning gaps in LLMs within medical settings, encouraging future improvements of LLMs for various clinical calculation tasks. MedCalc-Bench is publicly available at: https://github.com/ncbi-nlp/MedCalc-Bench.",Oral Session 6C: New Data,https://arxiv.org/pdf/2406.12036,
"['Zekun Shi', 'Zheyuan Hu', 'Min Lin', 'Kenji Kawaguchi']",NeurIPS,Stochastic Taylor Derivative Estimator_ Efficient amortization for arbitrary differential operators,https://neurips.cc/virtual/2024/oral/97986,2024," Optimizing neural networks with loss that contain high-dimensional and high-order differential operators  is expensive to evaluate with back-propagation due to $\mathcal{O}(d^{k})$ scaling of the derivative tensor size and the $\mathcal{O}(2^{k-1}L)$ scaling in the computation graph, where $d$ is the dimension of the domain, $L$ is the number of ops in the forward computation graph, and $k$ is the derivative order. In previous works, the polynomial scaling in $d$ was addressed by amortizing the computation over the optimization process via randomization. Separately, the exponential scaling in $k$ for univariate functions ($d=1$) was addressed with high-order auto-differentiation (AD). In this work, we show how to efficiently perform arbitrary contraction of the derivative tensor of arbitrary order for multivariate functions, by properly constructing the input tangents to univariate high-order AD, which can be used to efficiently randomize any differential operator.  When applied to Physics-Informed Neural Networks (PINNs), our method provides >1000$\times$ speed-up and >30$\times$ memory reduction over randomization with first-order AD, and we can now solve 1-million-dimensional PDEs in 8 minutes on a single NVIDIA A100 GPU. This work opens the possibility of using high-order differential operators in large-scale problems.",Oral Session 5D: Machine Learning and Science,https://openreview.net/pdf?id=J2wI2rCG2u,https://openreview.net/forum?id=J2wI2rCG2u
"['Chengyi Cai', 'Zesheng Ye', 'Lei Feng', 'Jianzhong Qi', 'Feng Liu']",NeurIPS,Bayesian-guided Label Mapping for Visual Reprogramming,https://neurips.cc/virtual/2024/oral/98002,2024," Visual reprogramming (VR) leverages the intrinsic capabilities of pretrained vision models by adapting their input or output interfaces to solve downstream tasks whose labels (i.e., downstream labels) might be totally different from the labels associated with the pretrained models (i.e., pretrained labels). When adapting the output interface, label mapping methods transform the pretrained labels to downstream labels by establishing a gradient-free one-to-one correspondence between the two sets of labels.However, in this paper, we reveal that one-to-one mappings may overlook the complex relationship between pretrained and downstream labels. Motivated by this observation, we propose a B ayesian-guided L abel M apping (BLM) method. BLM constructs an iteratively-updated probabilistic label mapping matrix, with each element quantifying a pairwise relationship between pretrained and downstream labels.The assignment of values to the constructed matrix is guided by Bayesian conditional probability, considering the joint distribution of the downstream labels and the labels predicted by the pretrained model on downstream samples. Experiments conducted on both pretrained vision models (e.g., ResNeXt) and vision-language models (e.g., CLIP) demonstrate the superior performance of BLM over existing label mapping methods. The success of BLM also offers a probabilistic lens through which to understand and analyze the effectiveness of VR.Our code is available at https://github.com/tmlr-group/BayesianLM.","Oral Session 6B: Safety, New Data",https://openreview.net/pdf?id=135eKqDoRR,https://openreview.net/forum?id=135eKqDoRR
"['Zixuan Gong', 'Guangyin Bao', 'Qi Zhang', 'Zhongwei Wan', 'Duoqian Miao', 'Shoujin Wang', 'Lei Zhu', 'Changwei Wang', 'Rongtao Xu', 'Liang Hu', 'Ke Liu', 'Yu Zhang']",NeurIPS,NeuroClips_ Towards High-fidelity and Smooth fMRI-to-Video Reconstruction,https://neurips.cc/virtual/2024/oral/97992,2024," Reconstruction of static visual stimuli from non-invasion brain activity fMRI achieves great success, owning to advanced deep learning models such as CLIP and Stable Diffusion. However, the research on fMRI-to-video reconstruction remains limited since decoding the spatiotemporal perception of continuous visual experiences is formidably challenging. We contend that the key to addressing these challenges lies in accurately decoding both high-level semantics and low-level perception flows, as perceived by the brain in response to video stimuli. To the end, we propose NeuroClips, an innovative framework to decode high-fidelity and smooth video from fMRI. NeuroClips utilizes a semantics reconstructor to reconstruct video keyframes, guiding semantic accuracy and consistency, and employs a perception reconstructor to capture low-level perceptual details, ensuring video smoothness. During inference, it adopts a pre-trained T2V diffusion model injected with both keyframes and low-level perception flows for video reconstruction. Evaluated on a publicly available fMRI-video dataset, NeuroClips achieves smooth high-fidelity video reconstruction of up to 6s at 8FPS, gaining significant improvements over state-of-the-art models in various metrics, e.g., a 128% improvement in SSIM and an 81% improvement in spatiotemporal metrics. Our project is available at https://github.com/gongzix/NeuroClips.",Oral Session 1A: Neuroscience and Intepretability,https://openreview.net/pdf?id=8qu52Fl1Dt,https://openreview.net/forum?id=8qu52Fl1Dt
"['Yutao Sun', 'Li Dong', 'Yi Zhu', 'Shaohan Huang', 'Wenhui Wang', 'Shuming Ma', 'Quanlu Zhang', 'Jianyong Wang', 'Furu Wei']",NeurIPS,You Only Cache Once_ Decoder-Decoder Architectures for Language Models,https://neurips.cc/virtual/2024/oral/98001,2024," We introduce a decoder-decoder architecture, YOCO, for large language models, which only caches key-value pairs once. It consists of two components, i.e., a cross-decoder stacked upon a self-decoder. The self-decoder efficiently encodes global key-value (KV) caches that are reused by the cross-decoder via cross-attention. The overall model behaves like a decoder-only Transformer, although YOCO only caches once. The design substantially reduces GPU memory demands, yet retains global attention capability. Additionally, the computation flow enables prefilling to early exit without changing the final output, thereby significantly speeding up the prefill stage. Experimental results demonstrate that YOCO achieves favorable performance compared to Transformer in various settings of scaling up model size and number of training tokens. We also extend YOCO to 1M context length with near-perfect needle retrieval accuracy. The profiling results show that YOCO improves inference memory, prefill latency, and throughput by orders of magnitude across context lengths and model sizes.","Oral Session 6D: Deep Learning Architecture, Infrastructure",https://openreview.net/pdf?id=25Ioxw576r,https://openreview.net/forum?id=25Ioxw576r
"['Xin Chen', 'Anderson Ye Zhang']",NeurIPS,Achieving Optimal Clustering in Gaussian Mixture Models with Anisotropic Covariance Structures,https://neurips.cc/virtual/2024/oral/97961,2024," We study clustering under anisotropic Gaussian Mixture Models (GMMs), where covariance matrices from different clusters are unknown and are not necessarily the identity matrix. We analyze two anisotropic scenarios: homogeneous, with identical covariance matrices, and heterogeneous, with distinct matrices per cluster. For these models, we derive minimax lower bounds that illustrate the critical influence of covariance structures on clustering accuracy. To solve the clustering problem, we consider a variant of Lloyd's algorithm, adapted to estimate and utilize covariance information iteratively. We prove that the adjusted algorithm not only achieves the minimax optimality but also converges within a logarithmic number of iterations, thus bridging the gap between theoretical guarantees and practical efficiency.",Oral Session 1D: Learning Theory,https://openreview.net/pdf?id=ge8GZn8Gtu,https://openreview.net/forum?id=ge8GZn8Gtu
"['Manling Li', 'Shiyu Zhao', 'Qineng Wang', 'Kangrui Wang', 'Yu Zhou', 'Sanjana Srivastava', 'Cem Gokmen', 'Tony Lee', 'Erran Li Li', 'Ruohan Zhang', 'Weiyu Liu', 'Percy Liang', 'Fei-Fei Li', 'Jiayuan Mao', 'Jiajun Wu']",NeurIPS,Embodied Agent Interface_ Benchmarking LLMs for Embodied Decision Making,https://neurips.cc/virtual/2024/oral/98018,2024," We aim to evaluate Large Language Models (LLMs) for embodied decision making. While a significant body of work has been leveraging LLMs for decision making in embodied environments, we still lack a systematic understanding of their performance because they are usually applied in different domains, for different purposes, and built based on different inputs and outputs. Furthermore, existing evaluations tend to rely solely on a final success rate, making it difficult to pinpoint what ability is missing in LLMs and where the problem lies, which in turn blocks embodied agents from leveraging LLMs effectively and selectively. To address these limitations, we propose a generalized interface (Embodied Agent Interface) that supports the formalization of various types of tasks and input-output specifications of LLM-based modules. Specifically, it allows us to unify 1) a broad set of embodied decision-making tasks involving both state and temporally extended goals, 2) four commonly-used LLM-based modules for decision making: goal interpretation, subgoal decomposition, action sequencing, and transition modeling, and 3) a collection of fine-grained metrics that break down evaluation into error types, such as hallucination errors, affordance errors, and various types of planning errors. Overall, our benchmark offers a comprehensive assessment of LLMs’ performance for different subtasks, pinpointing the strengths and weaknesses in LLM-powered embodied AI systems and providing insights into the effective and selective use of LLMs in embodied decision making.",Oral Session 2A: Agents,https://arxiv.org/pdf/2410.07166,
"['Philip Amortila', 'Dylan J Foster', 'Nan Jiang', 'Akshay Krishnamurthy', 'Zak Mhammedi']",NeurIPS,Reinforcement Learning Under Latent Dynamics_ Toward Statistical and Algorithmic Modularity,https://neurips.cc/virtual/2024/oral/97952,2024," Real-world applications of reinforcement learning often involve  environments where agents operate on complex, high-dimensional observations, but the underlying (``latent'')  dynamics are comparatively simple. However, beyond restrictive settings  such as tabular latent dynamics,  the fundamental statistical requirements and algorithmic principles for reinforcement learning under latent dynamics are poorly  understood.  This paper addresses the question of reinforcement learning under general latent dynamics from a  statistical and algorithmic perspective.  On the statistical side, our main negativeresult shows that most well-studied settings for reinforcement learning with function approximation become intractable when composed with rich observations; we complement this with a positive result, identifying latent pushforward coverability as ageneral condition that enables statistical tractability. Algorithmically, we develop provably efficient observable-to-latent reductions ---that is, reductions that transform an arbitrary algorithm for the  latent MDP into an algorithm that can operate on rich observations--- in two settings: one where the agent has access to hindsightobservations of the latent dynamics (Lee et al., 2023) and onewhere the agent can estimate self-predictive latent models (Schwarzer et al., 2020). Together, our results serve as a  first step toward a unified statistical and algorithmic theory forreinforcement learning under latent dynamics.",Oral Session 1C: Optimization and Learning Theory,https://openreview.net/pdf?id=qf2uZAdy1N,https://openreview.net/forum?id=qf2uZAdy1N
"['Xiong-Hui Chen', 'Ziyan Wang', 'Yali Du', 'Shengyi Jiang', 'Meng Fang', 'Yang Yu', 'Jun Wang']",NeurIPS,"Policy Learning from Tutorial Books via Understanding, Rehearsing and Introspecting",https://neurips.cc/virtual/2024/oral/97989,2024," When humans need to learn a new skill, we can acquire knowledge through written books, including textbooks, tutorials, etc. However, current research for decision-making, like reinforcement learning (RL), has primarily required numerous real interactions with the target environment to learn a skill, while failing to utilize the existing knowledge already summarized in the text. The success of Large Language Models (LLMs) sheds light on utilizing such knowledge behind the books. In this paper, we discuss a new policy learning problem called Policy Learning from tutorial Books (PLfB) upon the shoulders of LLMs’ systems, which aims to leverage rich resources such as tutorial books to derive a policy network. Inspired by how humans learn from books, we solve the problem via a three-stage framework: Understanding, Rehearsing, and Introspecting (URI). In particular, it first rehearses decision-making trajectories based on the derived knowledge after understanding the books, then introspects in the imaginary dataset to distill a policy network.  We build two benchmarks for PLfB~based on Tic-Tac-Toe and Football games. In experiment, URI's policy achieves at least 44% net win rate against GPT-based agents without any real data; In Football game, which is a complex scenario, URI's policy beat the built-in AIs with a 37% while using GPT-based agent can only achieve a 6\% winning rate. The project page: https://plfb-football.github.io.",Oral Session 2B: Reinforcement Learning,https://openreview.net/pdf?id=Ddak3nSqQM,https://openreview.net/forum?id=Ddak3nSqQM
"['Dengwei Zhao', 'Shikui Tu', 'Lei Xu']",NeurIPS,SeeA__ Efficient Exploration-Enhanced A_ Search by Selective Sampling,https://neurips.cc/virtual/2024/oral/97957,2024," Monte-Carlo tree search (MCTS) and reinforcement learning contributed crucially to the success of AlphaGo and AlphaZero, and A$^*$ is a tree search algorithm among the most well-known ones in the classical AI literature. MCTS and  A$^*$ both perform heuristic search and are mutually beneficial. Efforts have been made to the renaissance of A$^*$ from three possible aspects, two of which have been confirmed by studies in recent years, while the third is about the OPEN list that consists of open nodes of A$^*$ search, but still lacks deep investigation. This paper aims at the third, i.e., developing the Sampling-exploration enhanced A$^*$ (SeeA$^*$) search by constructing a dynamic subset of OPEN through a selective sampling process, such that the node with the best heuristic value in this subset instead of in the OPEN is expanded. Nodes with the best heuristic values in OPEN are most probably picked into this subset, but sometimes may not be included, which enables SeeA$^*$ to explore other promising branches. Three sampling techniques are presented for comparative investigations. Moreover, under the assumption about the distribution of prediction errors, we have theoretically shown the superior efficiency of SeeA$^*$ over A$^*$ search, particularly when the accuracy of the guiding heuristic function is insufficient. Experimental results on retrosynthetic planning in organic chemistry, logic synthesis in integrated circuit design, and the classical Sokoban game empirically demonstrate the efficiency of SeeA$^*$, in comparison with the state-of-the-art heuristic search algorithms.",Oral Session 2C: Reinforcement Learning,https://openreview.net/pdf?id=mSaqxZVZW8,https://openreview.net/forum?id=mSaqxZVZW8
"['Ricardo Dominguez-Olmedo', 'Moritz Hardt', 'Celestine Mendler-Dünner']",NeurIPS,Questioning the Survey Responses of Large Language Models,https://neurips.cc/virtual/2024/oral/97983,2024," Surveys have recently gained popularity as a tool to study large language models. By comparing models’ survey responses to those of different human reference populations, researchers aim to infer the demographics, political opinions, or values best represented by current language models. In this work, we critically examine language models' survey responses on the basis of the well-established American Community Survey by the U.S. Census Bureau. Evaluating 43 different language models using de-facto standard prompting methodologies, we establish two dominant patterns. First, models' responses are governed by ordering and labeling biases, for example, towards survey responses labeled with the letter “A”. Second, when adjusting for these systematic biases through randomized answer ordering, models across the board trend towards uniformly random survey responses, irrespective of model size or training data. As a result, models consistently appear to better represent subgroups whose aggregate statistics are closest to uniform for the survey under consideration, leading to potentially misguided conclusions about model alignment.",Oral Session 3B: Natural Language Processing,https://openreview.net/pdf?id=Oo7dlLgqQX,https://openreview.net/forum?id=Oo7dlLgqQX
"['Keyu Tian', 'Yi Jiang', 'Zehuan Yuan', 'BINGYUE PENG', 'Liwei Wang']",NeurIPS,Visual Autoregressive Modeling_ Scalable Image Generation via Next-Scale Prediction,https://neurips.cc/virtual/2024/oral/97960,2024," We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine ""next-scale prediction"" or ""next-resolution prediction"", diverging from the standard raster-scan ""next-token prediction"". This simple, intuitive methodology allows autoregressive (AR) transformers to learn visual distributions fast and generalize well: VAR, for the first time, makes GPT-style AR models surpass diffusion transformers in image generation. On ImageNet 256x256 benchmark, VAR significantly improve AR baseline by improving Frechet inception distance (FID) from 18.65 to 1.73, inception score (IS) from 80.4 to 350.2, with around 20x faster inference speed. It is also empirically verified that VAR outperforms the Diffusion Transformer (DiT) in multiple dimensions including image quality, inference speed, data efficiency, and scalability. Scaling up VAR models exhibits clear power-law scaling laws similar to those observed in LLMs, with linear correlation coefficients near -0.998 as solid evidence. VAR further showcases zero-shot generalization ability in downstream tasks including image in-painting, out-painting, and editing. These results suggest VAR has initially emulated the two important properties of LLMs: Scaling Laws and zero-shot task generalization. We have released all models and codes to promote the exploration of AR/VAR models for visual generation and unified learning.",Oral Session 2D: Generative Models,https://openreview.net/pdf?id=gojL67CfS8,https://openreview.net/forum?id=gojL67CfS8
"['Chunlin Tian', 'Zhan Shi', 'Zhijiang Guo', 'Li Li', 'Cheng-Zhong Xu']",NeurIPS,HydraLoRA_ An Asymmetric LoRA Architecture for Efficient Fine-Tuning,https://neurips.cc/virtual/2024/oral/97953,2024," Adapting Large Language Models (LLMs) to new tasks through fine-tuning has been made more efficient by the introduction of Parameter-Efficient Fine-Tuning (PEFT) techniques, such as LoRA. However, these methods often underperform compared to full fine-tuning, particularly in scenarios involving complex datasets. This issue becomes even more pronounced in complex domains, highlighting the need for improved PEFT approaches that can achieve better performance. Through a series of experiments, we have uncovered two critical insights that shed light on the training and parameter inefficiency of LoRA. Building on these insights, we have developed HydraLoRA, a LoRA framework with an asymmetric structure that eliminates the need for domain expertise. Our experiments demonstrate that HydraLoRA outperforms other PEFT approaches, even those that rely on domain knowledge during the training and inference phases. Our anonymous codes are submitted with the paper and will be publicly available. Code is available: https://github.com/Clin0212/HydraLoRA.",Oral Session 3A: Generative Models,https://openreview.net/pdf?id=qEpi8uWX3N,https://openreview.net/forum?id=qEpi8uWX3N
"['Tero Karras', 'Miika Aittala', 'Tuomas Kynkäänniemi', 'Jaakko Lehtinen', 'Timo Aila', 'Samuli Laine']",NeurIPS,Guiding a Diffusion Model with a Bad Version of Itself,https://neurips.cc/virtual/2024/oral/97966,2024," The primary axes of interest in image-generating diffusion models are image quality, the amount of variation in the results, and how well the results align with a given condition, e.g., a class label or a text prompt. The popular classifier-free guidance approach uses an unconditional model to guide a conditional model, leading to simultaneously better prompt alignment and higher-quality images at the cost of reduced variation. These effects seem inherently entangled, and thus hard to control. We make the surprising observation that it is possible to obtain disentangled control over image quality without compromising the amount of variation by guiding generation using a smaller, less-trained version of the model itself rather than an unconditional model. This leads to significant improvements in ImageNet generation, setting record FIDs of 1.01 for 64x64 and 1.25 for 512x512, using publicly available networks. Furthermore, the method is also applicable to unconditional diffusion models, drastically improving their quality.",Oral Session 4B: Diffusion-based Models,https://openreview.net/pdf?id=bg6fVPVs3s,https://openreview.net/forum?id=bg6fVPVs3s
"['Qiguang Chen', 'Libo Qin', 'Jiaqi Wang', 'Jingxuan Zhou', 'Wanxiang Che']",NeurIPS,Unlocking the Capabilities of Thought_ A Reasoning Boundary Framework to Quantify and Optimize Chain-of-Thought,https://neurips.cc/virtual/2024/oral/97955,2024," Chain-of-Thought (CoT) reasoning has emerged as a promising approach for enhancing the performance of large language models (LLMs) on complex reasoning tasks. Recently, a series of studies attempt to explain the mechanisms underlying CoT, aiming to deepen the understanding of its efficacy. Nevertheless, the existing research faces two major challenges: (1) a lack of quantitative metrics to assess CoT capabilities and (2) a dearth of guidance on optimizing CoT performance. Motivated by this, in this work, we introduce a novel reasoning boundary framework (RBF) to address these challenges. To solve the lack of quantification, we first define a reasoning boundary (RB) to quantify the upper-bound of CoT and establish a combination law for RB, enabling a practical quantitative approach applicable to various real-world CoT tasks. To address the lack of optimization, we propose three categories of RBs. We further optimize these categories with combination laws focused on RB promotion and reasoning path optimization for CoT improvement. Through extensive experiments on 27 models and 5 tasks, the study validates the existence and rationality of the proposed framework. Furthermore, it explains the effectiveness of 10 CoT strategies and guides optimization from two perspectives. We hope this work can provide a comprehensive understanding of the boundaries and optimization strategies for reasoning in LLMs. Our code and data are available at https://github.com/LightChen233/reasoning-boundary.",Oral Session 3C: Natural Language Processing,https://openreview.net/pdf?id=pC44UMwy2v,https://openreview.net/forum?id=pC44UMwy2v
"['Sangwoong Yoon', 'Himchan Hwang', 'Dohyun Kwon', 'Yung-Kyun Noh', 'Frank Park']",NeurIPS,Maximum Entropy Inverse Reinforcement Learning of Diffusion Models with Energy-Based Models,https://neurips.cc/virtual/2024/oral/97973,2024," We present a maximum entropy inverse reinforcement learning (IRL) approach for improving the sample quality of diffusion generative models, especially when the number of generation time steps is small. Similar to how IRL trains a policy based on the reward function learned from expert demonstrations, we train (or fine-tune) a diffusion model using the log probability density estimated from training data. Since we employ an energy-based model (EBM) to represent the log density, our approach boils down to the joint training of a diffusion model and an EBM. Our IRL formulation, named Diffusion by Maximum Entropy IRL (DxMI), is a minimax problem that reaches equilibrium when both models converge to the data distribution. The entropy maximization plays a key role in DxMI, facilitating the exploration of the diffusion model and ensuring the convergence of the EBM. We also propose Diffusion by Dynamic Programming (DxDP), a novel reinforcement learning algorithm for diffusion models, as a subroutine in DxMI. DxDP makes the diffusion model update in DxMI efficient by transforming the original problem into an optimal control formulation where value functions replace back-propagation in time. Our empirical studies show that diffusion models fine-tuned using DxMI can generate high-quality samples in as few as 4 and 10 steps.  Additionally, DxMI enables the training of an EBM without MCMC, stabilizing EBM training dynamics and enhancing anomaly detection performance.",Oral Session 3D: Natural Language Processing,https://openreview.net/pdf?id=V0oJaLqY4E,https://openreview.net/forum?id=V0oJaLqY4E
"['Ioannis Kalogeropoulos', 'Giorgos Bouritsas', 'Yannis Panagakis']",NeurIPS,Scale Equivariant Graph Metanetworks,https://neurips.cc/virtual/2024/oral/97993,2024," This paper pertains to an emerging machine learning paradigm: learning higher- order functions, i.e. functions whose inputs are functions themselves, particularly when these inputs are Neural Networks (NNs). With the growing interest in architectures that process NNs, a recurring design principle has permeated the field: adhering to the permutation symmetries arising from the connectionist structure ofNNs. However, are these the sole symmetries present in NN parameterizations? Zooming into most practical activation functions (e.g. sine, ReLU, tanh) answers this question negatively and gives rise to intriguing new symmetries, which we collectively refer to as scaling symmetries, that is, non-zero scalar multiplications and divisions of weights and biases. In this work, we propose Scale Equivariant Graph MetaNetworks - ScaleGMNs, a framework that adapts the Graph Metanetwork (message-passing) paradigm by incorporating scaling symmetries and thus rendering neuron and edge representations equivariant to valid scalings. We introduce novel building blocks, of independent technical interest, that allow for equivariance or invariance with respect to individual scalar multipliers or their product and use them in all components of ScaleGMN. Furthermore, we prove that, under certain expressivity conditions, ScaleGMN can simulate the forward and backward pass of any input feedforward neural network. Experimental results demonstrate that our method advances the state-of-the-art performance for several datasets and activation functions, highlighting the power of scaling symmetries as an inductive bias for NN processing. The source code is publicly available at https://github.com/jkalogero/scalegmn.",Oral Session 5A: Graph Neural Networks,https://openreview.net/pdf?id=8Fxqn1tZM1,https://openreview.net/forum?id=8Fxqn1tZM1
"['Jiaqing Zhang', 'Mingxiang Cao', 'Weiying Xie', 'Jie Lei', 'Daixun Li', 'Wenbo Huang', 'Yunsong Li', 'Xue Yang']",NeurIPS,E2E-MFD_ Towards End-to-End Synchronous Multimodal Fusion Detection,https://neurips.cc/virtual/2024/oral/97999,2024," Multimodal image fusion and object detection are crucial for autonomous driving. While current methods have advanced the fusion of texture details and semantic information, their complex training processes hinder broader applications. Addressing this challenge, we introduce E2E-MFD, a novel end-to-end algorithm for multimodal fusion detection. E2E-MFD streamlines the process, achieving high performance with a single training phase. It employs synchronous joint optimization across components to avoid suboptimal solutions associated to individual tasks. Furthermore, it implements a comprehensive optimization strategy in the gradient matrix for shared parameters, ensuring convergence to an optimal fusion detection configuration. Our extensive testing on multiple public datasets reveals E2E-MFD's superior capabilities, showcasing not only visually appealing image fusion but also impressive detection outcomes, such as a 3.9\% and  2.0\% $\text{mAP}_{50}$ increase on horizontal object detection dataset M3FD and oriented object detection dataset DroneVehicle, respectively, compared to state-of-the-art approaches.",Oral Session 4D: Machine Vision,https://openreview.net/pdf?id=47loYmzxep,https://openreview.net/forum?id=47loYmzxep
"['Feng Xie', 'Zhen Yao', 'Lin Xie', 'Yan Zeng', 'Zhi Geng']",NeurIPS,Identification and Estimation of the Bi-Directional MR with Some Invalid Instruments,https://neurips.cc/virtual/2024/oral/97977,2024," We consider the challenging problem of estimating causal effects from purely observational data in the bi-directional Mendelian randomization (MR), where some invalid instruments, as well as unmeasured confounding, usually exist. To address this problem, most existing methods attempt to find proper valid instrumental variables (IVs) for the target causal effect by expert knowledge or by assuming that the causal model is a one-directional MR model. As such, in this paper, we first theoretically investigate the identification of the bi-directional MR from observational data. In particular, we provide necessary and sufficient conditions under which valid IV sets are correctly identified such that the bi-directional MR model is identifiable, including the causal directions of a pair of phenotypes (i.e., the treatment and outcome).Moreover, based on the identification theory, we develop a cluster fusion-like method to discover valid IV sets and estimate the causal effects of interest.We theoretically demonstrate the correctness of the proposed algorithm.Experimental results show the effectiveness of our method for estimating causal effects in both one-directional and bi-directional MR models.","Oral Session 5B: Graph Neural Networks, Causal Inference",https://openreview.net/pdf?id=S2P6KPLtm8,https://openreview.net/forum?id=S2P6KPLtm8
"['Peter Tong', 'Ellis Brown', 'Penghao Wu', 'Sanghyun Woo', 'Adithya Jairam Vedagiri IYER', 'Sai Charitha Akula', 'Shusheng Yang', 'Jihan Yang', 'Manoj Middepogu', 'Ziteng Wang', 'Xichen Pan', 'Rob Fergus', 'Yann LeCun', 'Saining Xie']",NeurIPS,"Cambrian-1_ A Fully Open, Vision-Centric Exploration of Multimodal LLMs",https://neurips.cc/virtual/2024/oral/97972,2024," We introduce Cambrian-1, a family of multimodal LLMs (MLLMs) designed with a vision-centric approach. While stronger language models can enhance multimodal capabilities, the design choices for vision components are often insufficiently explored and disconnected from visual representation learning research. This gap hinders accurate sensory grounding in real-world scenarios. Our study uses LLMs and visual instruction tuning as an interface to evaluate various visual representations, offering new insights into different models and architectures—self-supervised, strongly supervised, or combinations thereof—based on experiments with over 15 vision models. We critically examine existing MLLM benchmarks, addressing the difficulties involved in consolidating and interpreting results from various tasks. To further improve visual grounding, we propose spatial vision aggregator (SVA), a dynamic and spatially-aware connector that integrates vision features with LLMs while reducing the number of tokens. Additionally, we discuss the curation of high-quality visual instruction-tuning data from publicly available sources, emphasizing the importance of distribution balancing. Collectively, Cambrian-1 not only achieves state-of-the-art performances but also serves as a comprehensive, open cookbook for instruction-tuned MLLMs. We provide model weights, code, supporting tools, datasets, and detailed instruction-tuning and evaluation recipes. We hope our release will inspire and accelerate advancements in multimodal systems and visual representation learning.",Oral Session 5C: Machine Vision,https://openreview.net/pdf?id=Vi8AepAXGy,https://openreview.net/forum?id=Vi8AepAXGy
"['Gang Liu', 'Jiaxin Xu', 'Tengfei Luo', 'Meng Jiang']",NeurIPS,Graph Diffusion Transformers for Multi-Conditional Molecular Generation,https://neurips.cc/virtual/2024/oral/97964,2024," Inverse molecular design with diffusion models holds great potential for advancements in material and drug discovery. Despite success in unconditional molecule generation, integrating multiple properties such as synthetic score and gas permeability as condition constraints into diffusion models remains unexplored. We present the Graph Diffusion Transformer (Graph DiT) for multi-conditional molecular generation. Graph DiT has a condition encoder to learn the representation of numerical and categorical properties and utilizes a Transformer-based graph denoiser to achieve molecular graph denoising under conditions. Unlike previous graph diffusion models that add noise separately on the atoms and bonds in the forward diffusion process, we propose a graph-dependent noise model for training Graph DiT, designed to accurately estimate graph-related noise in molecules. We extensively validate the Graph DiT for multi-conditional polymer and small molecule generation. Results demonstrate our superiority across metrics from distribution learning to condition control for molecular properties. A polymer inverse design task for gas separation with feedback from domain experts further demonstrates its practical utility. The code is available at https://github.com/liugangcode/Graph-DiT.","Oral Session 6A: Machine Learning and Science, Safety",https://openreview.net/pdf?id=cfrDLD1wfO,https://openreview.net/forum?id=cfrDLD1wfO
"['Gabriel Poesia', 'David Broman', 'Nick Haber', 'Noah Goodman']",NeurIPS,Learning Formal Mathematics From Intrinsic Motivation,https://neurips.cc/virtual/2024/oral/97947,2024," How did humanity coax mathematics from the aether? We explore the Platonic view that mathematics can be discovered from its axioms---a game of conjecture and proof. We describe an agent that jointly learns to pose challenging problems for itself (conjecturing) and solve them (theorem proving). Given a mathematical domain axiomatized in dependent type theory, we first combine methods for constrained decoding and type-directed synthesis to sample valid conjectures from a language model. Our method guarantees well-formed conjectures by construction, even as we start with a randomly initialized model. We use the same model to represent a policy and value function for guiding proof search. Our agent targets generating hard but provable conjectures --- a moving target, since its own theorem proving ability also improves as it trains. We propose novel methods for hindsight relabeling on proof search trees to significantly improve the agent's sample efficiency in both tasks. Experiments on 3 axiomatic domains (propositional logic, arithmetic and group theory) demonstrate that our agent can bootstrap from only the axioms, self-improving in generating true and challenging conjectures and in finding proofs.",Oral Session 5D: Machine Learning and Science,https://openreview.net/pdf?id=uNKlTQ8mBD,https://openreview.net/forum?id=uNKlTQ8mBD
"['Hannah Rose Kirk', 'Alexander Whitefield', 'Paul Rottger', 'Andrew M. Bean', 'Katerina Margatina', 'Rafael Mosquera-Gomez', 'Juan Ciro', 'Max Bartolo', 'Adina Williams', 'He He', 'Bertie Vidgen', 'Scott Hale']",NeurIPS,"The PRISM Alignment Dataset_ What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models",https://neurips.cc/virtual/2024/oral/98025,2024," Human feedback is central to the alignment of Large Language Models (LLMs). However, open questions remain about the methods (how), domains (where), people (who) and objectives (to what end) of feedback processes. To navigate these questions, we introduce PRISM, a new dataset which maps the sociodemographics and stated preferences of 1,500 diverse participants from 75 countries, to their contextual preferences and fine-grained feedback in 8,011 live conversations with 21 LLMs. With PRISM, we contribute (i) wider geographic and demographic participation in feedback; (ii) census-representative samples for two countries (UK, US); and (iii) individualised ratings that link to detailed participant profiles, permitting personalisation and attribution of sample artefacts. We target subjective and multicultural perspectives on value-laden and controversial issues, where we expect interpersonal and cross-cultural disagreement. We use PRISM in three case studies to demonstrate the need for careful consideration of which humans provide alignment data.",Oral Session 1B: Human-AI Interaction,https://arxiv.org/pdf/2404.16019,
"['David Romero', 'Chenyang Lyu', 'Haryo Wibowo', 'Santiago Góngora', 'Aishik Mandal', 'Sukannya Purkayastha', 'Jesus-German Ortiz-Barajas', 'Emilio Cueva', 'Jinheon Baek', 'Soyeong Jeong', 'Injy Hamed', 'Yong Zheng-Xin', 'Zheng Wei Lim', 'Paula Silva', 'Jocelyn Dunstan', 'Mélanie Jouitteau', 'David LE MEUR', 'Joan Nwatu', 'Ganzorig Batnasan', 'Munkh-Erdene Otgonbold', 'Munkhjargal Gochoo', 'Guido Ivetta', 'Luciana Benotti', 'Laura Alonso Alemany', 'Hernán Maina', 'Jiahui Geng', 'Tiago Timponi Torrent', 'Frederico Belcavello', 'Marcelo Viridiano', 'Jan Christian Blaise Cruz', 'Dan John Velasco', 'Oana Ignat', 'Zara Burzo', 'Chenxi Whitehouse', 'Artem Abzaliev', 'Teresa Clifford', 'Gráinne Caulfield', 'Teresa Lynn', 'Christian Salamea-Palacios', 'Vladimir Araujo', 'Yova Kementchedjhieva', 'Mihail Mihaylov', 'Israel Azime', 'Henok Ademtew', 'Bontu Balcha', 'Naome A. Etori', 'David Adelani', 'Rada Mihalcea', 'Atnafu Lambebo Tonja', 'Maria Cabrera', 'Gisela Vallejo', 'Holy Lovenia', 'Ruochen Zhang', 'Marcos Estecha-Garitagoitia', 'Mario Rodríguez-Cantelar', 'Toqeer Ehsan', 'Rendi Chevi', 'Muhammad Adilazuarda', 'Ryandito Diandaru', 'Samuel Cahyawijaya', 'Fajri Koto', 'Tatsuki Kuribayashi', 'Haiyue Song', 'Aditya Khandavally', 'Thanmay Jayakumar', 'Raj Dabre', 'Mohamed Imam', 'Kumaranage Nagasinghe', 'Alina Dragonetti', 'Luis Fernando D&#x27;Haro', 'Niyomugisha Olivier', 'Jay Gala', 'Pranjal Chitale', 'Fauzan Farooqui', 'Thamar Solorio', 'Alham Aji']",NeurIPS,CVQA_ Culturally-diverse Multilingual Visual Question Answering Benchmark,https://neurips.cc/virtual/2024/oral/98024,2024," Visual Question Answering~(VQA) is an important task in multimodal AI, which requires models to understand and reason on knowledge present in visual and textual data. However, most of the current VQA datasets and models are primarily focused on English and a few major world languages, with images that are Western-centric. While recent efforts have tried to increase the number of languages covered on VQA datasets, they still lack diversity in low-resource languages. More importantly, some datasets extend the text to other languages, either via translation or some other approaches, but usually keep the same images, resulting in narrow cultural representation. To address these limitations, we create CVQA, a new Culturally-diverse Multilingual Visual Question Answering benchmark dataset, designed to cover a rich set of languages and regions, where we engage native speakers and cultural experts in the data collection process. CVQA includes culturally-driven images and questions from across 28 countries in four continents, covering 26 languages with 11 scripts, providing a total of 9k questions. We benchmark several Multimodal Large Language Models (MLLMs) on CVQA, and we show that the dataset is challenging for the current state-of-the-art models. This benchmark will serve as a probing evaluation suite for assessing the cultural bias of multimodal models and hopefully encourage more research efforts towards increasing cultural awareness and linguistic diversity in this field.",Oral Session 4A: Natural Language Processing,https://arxiv.org/pdf/2406.05967,
"['Shubham Toshniwal', 'Ivan Moshkov', 'Sean Narenthiran', 'Daria Gitman', 'Fei Jia', 'Igor Gitman']",NeurIPS,OpenMathInstruct-1_ A 1.8 Million Math Instruction Tuning Dataset,https://neurips.cc/virtual/2024/oral/98022,2024," Recent work has shown the immense potential of synthetically generated datasets for training large language models (LLMs), especially for acquiring targeted skills. Current large-scale math instruction tuning datasets such as MetaMathQA (Yu et al., 2024) and MAmmoTH (Yue et al., 2024) are constructed using outputs from closed-source LLMs with commercially restrictive licenses. A key reason limiting the use of open-source LLMs in these data generation pipelines has been the wide gap between the mathematical skills of the best closed-source LLMs, such as GPT-4, and the best open-source LLMs. Building on the recent progress in open-source LLMs, our proposed prompting novelty, and some brute-force scaling, we construct OpenMathInstruct-1, a math instruction tuning dataset with 1.8M problem-solution pairs. The dataset is constructed by synthesizing code-interpreter solutions for GSM8K and MATH, two popular math reasoning benchmarks, using the recently released and permissively licensed Mixtral model. Our best model, OpenMath-CodeLlama-70B, trained on a subset of OpenMathInstruct-1, achieves a score of 84.6% on GSM8K and 50.7% on MATH, which is competitive with the best gpt-distilled models. We will release our code, models, and the OpenMathInstruct-1 dataset under a commercially permissive license.","Oral Session 4C: Diffusion-based Models, Mathematics",https://arxiv.org/pdf/2402.10176,
"['Christopher Wang', 'Adam Yaari', 'Aaditya Singh', 'Vighnesh Subramaniam', 'Dana Rosenfarb', 'Jan DeWitt', 'Pranav Misra', 'Joseph Madsen', 'Scellig Stone', 'Gabriel Kreiman', 'Boris Katz', 'Ignacio Cases', 'Andrei Barbu']",NeurIPS,Brain Treebank_ Large-scale intracranial recordings from naturalistic language stimuli,https://neurips.cc/virtual/2024/oral/98023,2024," We present the Brain Treebank, a large-scale dataset of electrophysiological neural responses, recorded from intracranial probes while 10 subjects watched one or more Hollywood movies. Subjects watched on average 2.6 Hollywood movies, for an average viewing time of 4.3 hours, and a total of 43 hours. The audio track for each movie was transcribed with manual corrections. Word onsets were manually annotated on spectrograms of the audio track for each movie. Each transcript was automatically parsed and manually corrected into the universal dependencies (UD) formalism, assigning a part of speech to every word and a dependency parse to every sentence. In total, subjects heard over 38,000 sentences (223,000 words), while they had on average 168 electrodes implanted. This is the largest dataset of intracranial recordings featuring grounded naturalistic language, one of the largest English UD treebanks in general, and one of only a few UD treebanks aligned to multimodal features. We hope that this dataset serves as a bridge between linguistic concepts, perception, and their neural representations. To that end, we present an analysis of which electrodes are sensitive to language features while also mapping out a rough time course of language processing across these electrodes. The Brain Treebank is available at https://BrainTreebank.dev/",Oral Session 6C: New Data,https://arxiv.org/pdf/2411.08343,
"['Dora Zhao', 'Morgan Scheuerman', 'Pooja Chitre', 'Jerone Andrews', 'Georgia Panagiotidou', 'Shawn Walker', 'Kathleen Pine', 'Alice Xiang']",NeurIPS,A Taxonomy of Challenges to Curating Fair Datasets,https://neurips.cc/virtual/2024/oral/98019,2024," Despite extensive efforts to create fairer machine learning (ML) datasets, there remains a limited understanding of the practical aspects of dataset curation. Drawing from interviews with 30 ML dataset curators, we present a comprehensive taxonomy of the challenges and trade-offs encountered throughout the dataset curation lifecycle. Our findings underscore overarching issues within the broader fairness landscape that impact data curation. We conclude with recommendations aimed at fostering systemic changes to better facilitate fair dataset curation practices.","Oral Session 6B: Safety, New Data",nan,
"['YUHONG CHOU', 'Man Yao', 'Kexin Wang', 'Yuqi Pan', 'Rui-Jie Zhu', 'Jibin Wu', 'Yiran Zhong', 'Yu Qiao', 'Bo Xu', 'Guoqi Li']",NeurIPS,MetaLA_ Unified Optimal Linear Approximation to Softmax Attention Map,https://neurips.cc/virtual/2024/oral/97971,2024," Various linear complexity models, such as Linear Transformer (LinFormer), State Space Model (SSM), and Linear RNN (LinRNN), have been proposed to replace the conventional softmax attention in Transformer structures. However, the optimal design of these linear models is still an open question. In this work, we attempt to answer this question by finding the best linear approximation to softmax attention from a theoretical perspective. We start by unifying existing linear complexity models as the linear attention form and then identify three conditions for the optimal linear attention design: (1) Dynamic memory ability; (2) Static approximation ability; (3) Least parameter approximation. We find that none of the current linear models meet all three conditions, resulting in suboptimal performance. Instead, we propose Meta Linear Attention (MetaLA) as a solution that satisfies these conditions. Our experiments on Multi-Query Associative Recall (MQAR) task, language modeling, image classification, and Long-Range Arena (LRA) benchmark demonstrate that MetaLA is more effective than the existing linear models.","Oral Session 6D: Deep Learning Architecture, Infrastructure",https://openreview.net/pdf?id=Y8YVCOMEpz,https://openreview.net/forum?id=Y8YVCOMEpz
"['Andrew M. Bean', 'Simi Hellsten', 'Harry Mayne', 'Jabez Magomere', 'Ethan Chi', 'Ryan Chi', 'Scott Hale', 'Hannah Rose Kirk']",NeurIPS,LINGOLY_ A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in Low Resource and Extinct Languages,https://neurips.cc/virtual/2024/oral/98020,2024," In this paper, we present the LingOly benchmark, a novel benchmark for advanced reasoning abilities in large language models. Using challenging Linguistic Olympiad puzzles, we evaluate (i) capabilities for in-context identification and generalisation of linguistic patterns in very low-resource or extinct languages, and (ii) abilities to follow complex task instructions. The LingOly benchmark covers more than 90 mostly low-resource languages, minimising issues of data contamination, and contains 1,133 problems across 6 formats and 5 levels of human difficulty. We assess performance with both direct accuracy and comparison to a no-context baseline to penalise memorisation. Scores from 11 state-of-the-art LLMs demonstrate the benchmark to be challenging, and models perform poorly on the higher difficulty problems. On harder problems, even the top model only achieved 38.7% accuracy, a 24.7% improvement over the no-context baseline. Large closed models typically outperform open models, and in general, the higher resource the language, the better the scores. These results indicate, in absence of memorisation, true multi-step out-of-domain reasoning remains a challenge for current language models.",Oral Session 4A: Natural Language Processing,https://arxiv.org/pdf/2406.06196,
"['Ma Chang', 'Junlei Zhang', 'Zhihao Zhu', 'Cheng Yang', 'Yujiu Yang', 'Yaohui Jin', 'Zhenzhong Lan', 'Lingpeng Kong', 'Junxian He']",NeurIPS,AgentBoard_ An Analytical Evaluation Board of Multi-turn LLM Agents,https://neurips.cc/virtual/2024/oral/98026,2024," Evaluating large language models (LLMs) as general-purpose agents is essential for understanding their capabilities and facilitating their integration into practical applications. However, the evaluation process presents substantial challenges. A primary obstacle is the benchmarking of agent performance across diverse scenarios within a unified framework, especially in maintaining partially-observable environments and ensuring multi-round interactions. Moreover, current evaluation frameworks mostly focus on the final success rate, revealing few insights during the process and failing to provide a deep understanding of the model abilities. To address these challenges, we introduce AgentBoard, a pioneering comprehensive benchmark and accompanied open-source evaluation framework tailored to analytical evaluation of LLM agents. AgentBoard offers a fine-grained progress rate metric that captures incremental advancements as well as a comprehensive evaluation toolkit that features easy assessment of agents for multi-faceted analysis through interactive visualization. This not only sheds light on the capabilities and limitations of LLM agents but also propels the interpretability of their performance to the forefront. Ultimately, AgentBoard serves as a significant step towards demystifying agent behaviors and accelerating the development of stronger LLM agents.",Oral Session 2A: Agents,https://arxiv.org/pdf/2401.13178,
"['Juan Nathaniel', 'Yongquan Qu', 'Tung Nguyen', 'Sungduk Yu', 'Julius Busecke', 'Aditya Grover', 'Pierre Gentine']",NeurIPS,"ChaosBench_ A Multi-Channel, Physics-Based Benchmark for Subseasonal-to-Seasonal Climate Prediction",https://neurips.cc/virtual/2024/oral/98017,2024," Accurate prediction of climate in the subseasonal-to-seasonal scale is crucial for disaster preparedness and robust decision making amidst climate change. Yet, forecasting beyond the weather timescale is challenging because it deals with problems other than initial condition, including boundary interaction, butterfly effect, and our inherent lack of physical understanding. At present, existing benchmarks tend to have shorter forecasting range of up-to 15 days, do not include a wide range of operational baselines, and lack physics-based constraints for explainability. Thus, we propose ChaosBench, a challenging benchmark to extend the predictability range of data-driven weather emulators to S2S timescale. First, ChaosBench is comprised of variables beyond the typical surface-atmospheric ERA5 to also include ocean, ice, and land reanalysis products that span over 45 years to allow for full Earth system emulation that respects boundary conditions. We also propose physics-based, in addition to deterministic and probabilistic metrics, to ensure a physically-consistent ensemble that accounts for butterfly effect. Furthermore, we evaluate on a diverse set of physics-based forecasts from four national weather agencies as baselines to our data-driven counterpart such as ViT/ClimaX, PanguWeather, GraphCast, and FourCastNetV2. Overall, we find methods originally developed for weather-scale applications fail on S2S task: their performance simply collapse to an unskilled climatology. Nonetheless, we outline and demonstrate several strategies that can extend the predictability range of existing weather emulators, including the use of ensembles, robust control of error propagation, and the use of physics-informed models. Our benchmark, datasets, and instructions are available at https://leap-stc.github.io/ChaosBench.",Oral Session 6C: New Data,https://arxiv.org/pdf/2402.00712,
"['Jincheng Mei', 'Bo Dai', 'Alekh Agarwal', 'Mohammad Ghavamzadeh', 'Csaba Szepesvari', 'Dale Schuurmans']",NeurIPS,Ordering-based Conditions for Global Convergence of Policy Gradient Methods,https://neurips.cc/virtual/2023/oral/73818,2023," We prove that, for finite-arm bandits with linear function approximation, the global convergence of policy gradient (PG) methods depends on inter-related properties between the policy update and the representation. textcolor{blue}{First}, we establish a few key observations that frame the study: \textbf{(i)} Global convergence can be achieved under linear function approximation without policy or reward realizability, both for the standard Softmax PG and natural policy gradient (NPG). \textbf{(ii)} Approximation error is not a key quantity for characterizing global convergence in either algorithm. \textbf{(iii)} The conditions on the representation that imply global convergence are different between these two algorithms. Overall, these observations call into question approximation error as an appropriate quantity for characterizing the global convergence of PG methods under linear function approximation. \textcolor{blue}{Second}, motivated by these observations, we establish new general results: \textbf{(i)} NPG with linear function approximation achieves global convergence \emph{if and only if} the projection of the reward  onto the representable space preserves the optimal action's rank, a quantity that is not strongly related to approximation error. \textbf{(ii)} The global convergence of Softmax PG occurs if the representation satisfies a non-domination condition and can preserve the ranking of rewards, which goes well beyond policy or reward realizability. We provide experimental results to support these theoretical findings.",Oral 1A RL,https://openreview.net/pdf?id=sW8yGZ4uVJ,https://openreview.net/forum?id=sW8yGZ4uVJ
"['Kaiyue Wen', 'Zhiyuan Li', 'Tengyu Ma']",NeurIPS,Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization,https://neurips.cc/virtual/2023/oral/73867,2023," Despite extensive studies, the underlying reason as to why overparameterizedneural networks can generalize remains elusive. Existing theory shows that common stochastic optimizers prefer flatter minimizers of the training loss, and thusa natural potential explanation is that flatness implies generalization. This workcritically examines this explanation. Through theoretical and empirical investigation, we identify the following three scenarios for two-layer ReLU networks: (1)flatness provably implies generalization; (2) there exist non-generalizing flattestmodels and sharpness minimization algorithms fail to generalize poorly, and (3)perhaps most strikingly, there exist non-generalizing flattest models, but sharpnessminimization algorithms still generalize. Our results suggest that the relationshipbetween sharpness and generalization subtly depends on the data distributionsand the model architectures and sharpness minimization algorithms do not onlyminimize sharpness to achieve better generalization. This calls for the search forother explanations for the generalization of over-parameterized neural networks",Oral 1D DL Theory,https://openreview.net/pdf?id=Dkmpa6wCIx,https://openreview.net/forum?id=Dkmpa6wCIx
"['Lorenzo Loconte', 'Nicola Di Mauro', 'Robert Peharz', 'Antonio Vergari']",NeurIPS,How to Turn Your Knowledge Graph Embeddings into Generative Models,https://neurips.cc/virtual/2023/oral/73848,2023," Some of the most successful knowledge graph embedding (KGE) models for link prediction – CP, RESCAL, TuckER, ComplEx – can be interpreted as energy-based models. Under this perspective they are not amenable for exact maximum-likelihood estimation (MLE), sampling and struggle to integrate logical constraints. This work re-interprets the score functions of these KGEs as circuits – constrained computational graphs allowing efficient marginalisation. Then, we design two recipes to obtain efficient generative circuit models by either restricting their activations to be non-negative or squaring their outputs. Our interpretation comes with little or no loss of performance for link prediction, while the circuits framework unlocks exact learning by MLE, efficient sampling of new triples, and guarantee that logical constraints are satisfied by design. Furthermore, our models scale more gracefully than the original KGEs on graphs with millions of entities.",Oral 1C Tractable models,https://openreview.net/pdf?id=RSGNGiB1q4,https://openreview.net/forum?id=RSGNGiB1q4
"['Kaiyu Yang', 'Aidan Swope', 'Alex Gu', 'Rahul Chalamala', 'Peiyang Song', 'Shixing Yu', 'Saad Godil', 'Ryan J Prenger', 'Animashree Anandkumar']",NeurIPS,LeanDojo_ Theorem Proving with Retrieval-Augmented Language Models,https://neurips.cc/virtual/2023/oral/73738,2023," Large language models (LLMs) have shown promise in proving formal theorems using proof assistants such as Lean. However, existing methods are difficult to reproduce or build on, due to private code, data, and large compute requirements. This has created substantial barriers to research on machine learning methods for theorem proving. This paper removes these barriers by introducing LeanDojo: an open-source Lean playground consisting of toolkits, data, models, and benchmarks. LeanDojo extracts data from Lean and enables interaction with the proof environment programmatically. It contains fine-grained annotations of premises in proofs, providing valuable data for premise selection—a key bottleneck in theorem proving. Using this data, we develop ReProver (Retrieval-Augmented Prover): an LLM-based prover augmented with retrieval for selecting premises from a vast math library. It is inexpensive and needs only one GPU week of training. Our retriever leverages LeanDojo's program analysis capability to identify accessible premises and hard negative examples, which makes retrieval much more effective. Furthermore, we construct a new benchmark consisting of 98,734 theorems and proofs extracted from Lean's math library. It features challenging data split requiring the prover to generalize to theorems relying on novel premises that are never used in training. We use this benchmark for training and evaluation, and experimental results demonstrate the effectiveness of ReProver over non-retrieval baselines and GPT-4. We thus provide the first set of open-source LLM-based theorem provers without any proprietary datasets and release it under a permissive MIT license to facilitate further research.",Oral 1B Datasets & Benchmarks,https://openreview.net/pdf?id=g7OX2sOJtn,https://openreview.net/forum?id=g7OX2sOJtn
"['Dan Fu', 'Simran Arora', 'Jessica Grogan', 'Isys Johnson', 'Evan Sabri Eyuboglu', 'Armin Thomas', 'Benjamin Spector', 'Michael Poli', 'Atri Rudra', 'Christopher Ré']",NeurIPS,Monarch Mixer_ A Simple Sub-Quadratic GEMM-Based Architecture,https://neurips.cc/virtual/2023/oral/73841,2023," Machine learning models are increasingly being scaled in both sequence length and model dimension to reach longer contexts and better performance. However, existing architectures such as Transformers scale quadratically along both these axes. We ask: are there performant architectures that can scale sub-quadratically along sequence length and model dimension? We introduce Monarch Mixer (M2), a new architecture that uses the same sub-quadratic primitive along both sequence length and model dimension: Monarch matrices, a simple class of expressive structured matrices that captures many linear transforms, achieves high hardware efficiency on GPUs, and scales sub-quadratically. As a proof of concept, we explore the performance of M2 in three domains: non-causal BERT-style language modeling, ViT-style image classification, and causal GPT-style language modeling. For non-causal BERT-style modeling, M2 matches BERT-base and BERT-large in downstream GLUE quality with up to 27% fewer parameters, and achieves up to 9.1$\times$ higher throughput at sequence length 4K. On ImageNet, M2 outperforms ViT-b by 1% in accuracy, with only half the parameters. Causal GPT-style models introduce a technical challenge: enforcing causality via masking introduces a quadratic bottleneck. To alleviate this bottleneck, we develop a novel theoretical view of Monarch matrices based on multivariate polynomial evaluation and interpolation, which lets us parameterize M2 to be causal while remaining sub-quadratic. Using this parameterization, M2 matches GPT-style Transformers at 360M parameters in pretraining perplexity on The PILE—showing for the first time that it may be possible to match Transformer quality without attention or MLPs.",Oral 2A Efficient Learning,https://openreview.net/pdf?id=cB0BImqSS9,https://openreview.net/forum?id=cB0BImqSS9
"['Sindy Löwe', 'Phillip Lippe', 'Francesco Locatello', 'Max Welling']",NeurIPS,Rotating Features for Object Discovery,https://neurips.cc/virtual/2023/oral/73835,2023," The binding problem in human cognition, concerning how the brain represents and connects objects within a fixed network of neural connections, remains a subject of intense debate. Most machine learning efforts addressing this issue in an unsupervised setting have focused on slot-based methods, which may be limiting due to their discrete nature and difficulty to express uncertainty. Recently, the Complex AutoEncoder was proposed as an alternative that learns continuous and distributed object-centric representations. However, it is only applicable to simple toy data. In this paper, we present Rotating Features, a generalization of complex-valued features to higher dimensions, and a new evaluation procedure for extracting objects from distributed representations. Additionally, we show the applicability of our approach to pre-trained features. Together, these advancements enable us to scale distributed object-centric representations from simple toy to real-world data. We believe this work advances a new paradigm for addressing the binding problem in machine learning and has the potential to inspire further innovation in the field.",Oral 2B Objects/ Neuroscience/Vision,https://openreview.net/pdf?id=fg7iyNK81W,https://openreview.net/forum?id=fg7iyNK81W
"['Simon Buchholz', 'Goutham Rajendran', 'Elan Rosenfeld', 'Bryon Aragam', 'Bernhard Schölkopf', 'Pradeep Ravikumar']",NeurIPS,Learning Linear Causal Representations from Interventions under General Nonlinear Mixing,https://neurips.cc/virtual/2023/oral/73823,2023," We study the problem of learning causal representations from unknown, latent interventions in a general setting, where the latent distribution is Gaussian but the mixing function is completely general. We prove strong identifiability results given unknown single-node interventions, i.e., without having access to the intervention targets. This generalizes prior works which have focused on weaker classes, such as linear maps or paired counterfactual data. This is also the first instance of identifiability from non-paired interventions for deep neural network embeddings and general causal structures. Our proof relies on carefully uncovering the high-dimensional geometric structure present in the data distribution after a non-linear density transformation, which we capture by analyzing quadratic forms of precision matrices of the latent distributions. Finally, we propose a contrastive algorithm to identify the latent variables in practice and evaluate its performance on various tasks.",Oral 2C Causality,https://openreview.net/pdf?id=q131tA7HCT,https://openreview.net/forum?id=q131tA7HCT
"['Mina Dalirrooyfard', 'Slobodan Mitrovic', 'Yuriy Nevmyvaka']",NeurIPS,Nearly Tight Bounds For Differentially Private Multiway Cut,https://neurips.cc/virtual/2023/oral/73852,2023," Finding min $s$-$t$ cuts in graphs is a basic algorithmic tool, with applications in image segmentation, community detection, reinforcement learning, and data clustering. In this problem, we are given two nodes as terminals and the goal is to remove the smallest number of edges from the graph so that these two terminals are disconnected. We study the complexity of differential privacy for the min $s$-$t$ cut problem and show nearly tight lower and upper bounds where we achieve privacy at no cost for running time efficiency. We also develop a differentially private algorithm for the multiway $k$-cut problem, in which we are given $k$ nodes as terminals that we would like to disconnect.    As a function of $k$, we obtain privacy guarantees that are exponentially more efficient than applying the advanced composition theorem to known algorithms for multiway $k$-cut.    Finally, we empirically evaluate the approximation of our differentially private min $s$-$t$ cut algorithm and show that it almost matches the quality of the output of non-private ones.",Oral 2D Privacy,https://openreview.net/pdf?id=QDByreuQyk,https://openreview.net/forum?id=QDByreuQyk
"['Andrew Luo', 'Maggie Henderson', 'Leila Wehbe', 'Michael Tarr']",NeurIPS,Brain Diffusion for Visual Exploration_ Cortical Discovery using Large Scale Generative Models,https://neurips.cc/virtual/2023/oral/73872,2023," A long standing goal in neuroscience has been to elucidate the functional organization of the brain. Within higher visual cortex, functional accounts have remained relatively coarse, focusing on regions of interest (ROIs) and taking the form of selectivity for broad categories such as faces, places, bodies, food, or words. Because the identification of such ROIs has typically relied on manually assembled stimulus sets consisting of isolated objects in non-ecological contexts, exploring functional organization without robust a priori hypotheses has been challenging. To overcome these limitations, we introduce a data-driven approach in which we synthesize images predicted to activate a given brain region using paired natural images and fMRI recordings, bypassing the need for category-specific stimuli. Our approach -- Brain Diffusion for Visual Exploration (""BrainDiVE"") -- builds on recent generative methods by combining large-scale diffusion models with brain-guided image synthesis. Validating our method, we demonstrate the ability to synthesize preferred images with appropriate semantic specificity for well-characterized category-selective ROIs. We then show that BrainDiVE can characterize differences between ROIs selective for the same high-level category. Finally we identify novel functional subdivisions within these ROIs, validated with behavioral data. These  results advance our understanding of the fine-grained functional organization of human visual cortex, and provide well-specified constraints for further examination of cortical organization using hypothesis-driven methods.",Oral 3A Neuro,https://openreview.net/pdf?id=9VqMaSjf7U,https://openreview.net/forum?id=9VqMaSjf7U
"['Shibo Hao', 'Tianyang Liu', 'Zhen Wang', 'Zhiting Hu']",NeurIPS,ToolkenGPT_ Augmenting Frozen Language Models with Massive Tools via Tool Embeddings,https://neurips.cc/virtual/2023/oral/73868,2023," Integrating large language models (LLMs) with various tools has led to increased attention in the field. Existing approaches either involve fine-tuning the LLM, which is both computationally costly and limited to a fixed set of tools, or prompting LLMs by in-context tool demonstrations. Although the latter method offers adaptability to new tools, it struggles with the inherent context length constraint of LLMs when many new tools are presented, and mastering a new set of tools with few-shot examples remains challenging, resulting in suboptimal performance. To address these limitations, we propose a novel solution, named ToolkenGPT , wherein LLMs effectively learn to master tools as predicting tokens through tool embeddings for solving complex tasks. In this framework, each tool is transformed into vector embeddings and plugged into the language model head. Once the function is triggered during text generation, the LLM enters a special function mode to execute the tool calls. Our experiments show that function embeddings effectively help LLMs understand tool use and improve on several tasks, including numerical reasoning, knowledge-based question answering and embodied decision-making.",Oral 3B NLP/Tools,https://openreview.net/pdf?id=BHXsb69bSx,https://openreview.net/forum?id=BHXsb69bSx
"['Diederik Kingma', 'Ruiqi Gao']",NeurIPS,Understanding Diffusion Objectives as the ELBO with Simple Data Augmentation,https://neurips.cc/virtual/2023/oral/73857,2023," To achieve the highest perceptual quality, state-of-the-art diffusion models are optimized with objectives that typically look very different from the maximum likelihood and the Evidence Lower Bound (ELBO) objectives. In this work, we reveal that diffusion model objectives are actually closely related to the ELBO.Specifically, we show that all commonly used diffusion model objectives equate to a weighted integral of ELBOs over different noise levels, where the weighting depends on the specific objective used. Under the condition of monotonic weighting, the connection is even closer: the diffusion objective then equals the ELBO, combined with simple data augmentation, namely Gaussian noise perturbation. We show that this condition holds for a number of state-of-the-art diffusion models. In experiments, we explore new monotonic weightings and demonstrate their effectiveness, achieving state-of-the-art FID scores on the high-resolution ImageNet benchmark.",Oral 3C Diffusion Models,https://openreview.net/pdf?id=NnMEadcdyD,https://openreview.net/forum?id=NnMEadcdyD
"['Yuanyuan Liu', 'Fanhua Shang', 'Weixin An', 'Junhao Liu', 'Hongying Liu', 'Zhouchen Lin']",NeurIPS,A Single-Loop Accelerated Extra-Gradient Difference Algorithm with Improved Complexity Bounds for Constrained Minimax Optimization,https://neurips.cc/virtual/2023/oral/73815,2023," In this paper, we propose a novel extra-gradient difference acceleration algorithm for solving constrained nonconvex-nonconcave (NC-NC) minimax problems. In particular, we design a new extra-gradient difference step to obtain an important quasi-cocoercivity property, which plays a key role to significantly improve the convergence rate in the constrained NC-NC setting without additional structural assumption. Then momentum acceleration is also introduced into our dual accelerating update step. Moreover, we prove that, to find an $\epsilon$-stationary point of the function $f$, our algorithm attains the complexity $\mathcal{O}(\epsilon^{-2})$ in the constrained NC-NC setting, while the best-known complexity bound is $\widetilde{\mathcal{O}}(\epsilon^{-4})$, where $\widetilde{\mathcal{O}}(\cdot)$ hides logarithmic factors compared to $\mathcal{O}(\cdot)$. As the special cases of the constrained NC-NC setting, our algorithm can also obtain the same complexity $\mathcal{O}(\epsilon^{-2})$ for both the nonconvex-concave (NC-C) and convex-nonconcave (C-NC) cases, while the best-known complexity bounds are $\widetilde{\mathcal{O}}(\epsilon^{-2.5})$ for the NC-C case and $\widetilde{\mathcal{O}}(\epsilon^{-4})$ for the C-NC case. For fair comparison with existing algorithms, we also analyze the complexity bound to find $\epsilon$-stationary point of the primal function $\phi$ for the constrained NC-C problem, which shows that our algorithm can improve the complexity bound from $\widetilde{\mathcal{O}}(\epsilon^{-3})$ to $\mathcal{O}(\epsilon^{-2})$. To the best of our knowledge, this is the first time that the proposed algorithm improves the best-known complexity bounds from $\mathcal{O}(\epsilon^{-4})$ and $\widetilde{\mathcal{O}}(\epsilon^{-3})$ to $\mathcal{O}(\epsilon^{-2})$ in both the NC-NC and NC-C settings.",Oral 4A Optimization,https://openreview.net/pdf?id=wIlmx4bHrO,https://openreview.net/forum?id=wIlmx4bHrO
"['Spyridon Kondylatos', 'Ioannis Prapas', 'Gustau Camps-Valls', 'Ioannis Papoutsis']",NeurIPS,Mesogeos_ A multi-purpose dataset for data-driven wildfire modeling in the Mediterranean,https://neurips.cc/virtual/2023/oral/73742,2023," We introduce Mesogeos, a large-scale multi-purpose dataset for wildfire modeling in the Mediterranean. Mesogeos integrates variables representing wildfire drivers (meteorology, vegetation, human activity) and historical records of wildfire ignitions and burned areas for 17 years (2006-2022). It is designed as a cloud-friendly spatio-temporal dataset, namely a datacube, harmonizing all variables in a grid of 1km x 1km x 1-day resolution. The datacube structure offers opportunities to assess machine learning (ML) usage in various wildfire modeling tasks. We extract two ML-ready datasets that establish distinct tracks to demonstrate this potential: (1) short-term wildfire danger forecasting and (2) final burned area estimation given the point of ignition. We define appropriate metrics and baselines to evaluate the performance of models in each track. By publishing the datacube, along with the code to create the ML datasets and models, we encourage the community to foster the implementation of additional tracks for mitigating the increasing threat of wildfires in the Mediterranean.",Oral 4B Datasets & Benchmarks,https://openreview.net/pdf?id=VH1vxapUTs,https://openreview.net/forum?id=VH1vxapUTs
"['Matthew Jagielski', 'Milad Nasr', 'Katherine Lee', 'Christopher A. Choquette-Choo', 'Nicholas Carlini', 'Florian Tramer']",NeurIPS,Students Parrot Their Teachers_ Membership Inference on Model Distillation,https://neurips.cc/virtual/2023/oral/73842,2023," Model distillation is frequently proposed as a technique to reduce the privacy leakage of machine learning. These empirical privacy defenses rely on the intuition that distilled student'' models protect the privacy of training data, as they only interact with this data indirectly through a teacher'' model. In this work, we design membership inference attacks to systematically study the privacy provided by knowledge distillation to both the teacher and student training sets. Our new attacks show that distillation alone provides only limited privacy across a number of domains. We explain the success of our attacks on distillation by showing that membership inference attacks on a private dataset can succeed even if the target model is never queried on any actual training points, but only on inputs whose predictions are highly influenced by training data. Finally, we show that our attacks are strongest when student and teacher sets are similar, or when the attacker can poison the teacher set.",Oral 5B Privacy/Fairness,https://openreview.net/pdf?id=a2Yg9Za6Rb,https://openreview.net/forum?id=a2Yg9Za6Rb
"['Ben Prystawski', 'Michael Li', 'Noah Goodman']",NeurIPS,Why think step by step_ Reasoning emerges from the locality of experience,https://neurips.cc/virtual/2023/oral/73821,2023," Humans have a powerful and mysterious capacity to reason. Working through a set of mental steps enables us to make inferences we would not be capable of making directly even though we get no additional data from the world. Similarly, when large language models generate intermediate steps (a chain of thought) before answering a question, they often produce better answers than they would directly. We investigate why and how chain-of-thought reasoning is useful in language models, testing the hypothesis that reasoning is effective when training data consists of overlapping local clusters of variables that influence each other strongly. These training conditions enable the chaining of accurate local inferences to estimate relationships between variables that were not seen together in training. We prove that there will exist a ""reasoning gap"", where reasoning through intermediate variables reduces bias, for the simple case of an autoregressive density estimator trained on local samples from a chain-structured probabilistic model. We then test our hypothesis experimentally in more complex models, training an autoregressive language model on samples from Bayes nets but only including a subset of variables in each sample. We test language models’ ability to match conditional probabilities with and without intermediate reasoning steps, finding that intermediate steps are only helpful when the training data is locally structured with respect to dependencies between variables. The combination of locally structured observations and reasoning is much more data-efficient than training on all variables. Our results illustrate how the effectiveness of reasoning step by step is rooted in the local statistical structure of the training data.",Oral 4C COT/reasoning,https://openreview.net/pdf?id=rcXXNFVlEn,https://openreview.net/forum?id=rcXXNFVlEn
"['Johanna Immonen', 'Amauri Souza', 'Vikas Garg']",NeurIPS,Going beyond persistent homology using persistent homology,https://neurips.cc/virtual/2023/oral/73876,2023," Representational limits of message-passing graph neural networks (MP-GNNs), e.g., in terms of the Weisfeiler-Leman (WL) test for isomorphism, are well understood. Augmenting these graph models with topological features via persistent homology (PH) has gained prominence, but identifying the class of attributed graphs that PH can recognize remains open.  We introduce a novel concept of color-separating sets to provide a complete resolution to this important problem. Specifically, we establish the necessary and sufficient conditions for distinguishing graphs based on the persistence of their connected components, obtained from filter functions on vertex and edge colors. Our constructions expose the limits of vertex- and edge-level PH, proving that neither category subsumes the other. Leveraging these theoretical insights, we propose RePHINE for learning topological features on graphs. RePHINE efficiently combines vertex- and edge-level PH, achieving a scheme that is provably more powerful than both. Integrating RePHINE into MP-GNNs boosts their expressive power, resulting in gains over standard PH on several benchmarks for graph classification.",Oral 5A GNNs/Invariance,https://openreview.net/pdf?id=27TdrEvqLD,https://openreview.net/forum?id=27TdrEvqLD
"['Jihao Andreas Lin', 'Javier Antorán', 'Shreyas Padhy', 'David Janz', 'José Miguel Hernández-Lobato', 'Alexander Terenin']",NeurIPS,Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent,https://neurips.cc/virtual/2023/oral/73846,2023," Gaussian processes are a powerful framework for quantifying uncertainty and for sequential decision-making but are limited by the requirement of solving linear systems. In general, this has a cubic cost in dataset size and is sensitive to conditioning. We explore stochastic gradient algorithms as a computationally efficient method of approximately solving these linear systems: we develop low-variance optimization objectives for sampling from the posterior and extend these to inducing points. Counterintuitively, stochastic gradient descent often produces accurate predictions, even in cases where it does not converge quickly to the optimum. We explain this through a spectral characterization of the implicit bias from non-convergence. We show that stochastic gradient descent produces predictive distributions close to the true posterior both in regions with sufficient data coverage, and in regions sufficiently far away from the data. Experimentally, stochastic gradient descent achieves state-of-the-art performance on sufficiently large-scale or ill-conditioned regression tasks. Its uncertainty estimates match the performance of significantly more expensive baselines on a large-scale Bayesian~optimization~task.",Oral 5C Probability/Sampling,https://openreview.net/pdf?id=Sf9goJtTCE,https://openreview.net/forum?id=Sf9goJtTCE
"['Rylan Schaeffer', 'Brando Miranda', 'Sanmi Koyejo']",NeurIPS,Are Emergent Abilities of Large Language Models a Mirage_,https://neurips.cc/virtual/2023/oral/73863,2023," Recent work claims that large language models display \textit{emergent abilities}, abilities not present in smaller-scale models that are present in larger-scale models.What makes emergent abilities intriguing is two-fold: their \textit{sharpness}, transitioning seemingly instantaneously from not present to present, and their \textit{unpredictability}, appearing at seemingly unforeseeable model scales.Here, we present an alternative explanation for emergent abilities: that for a particular task and model family, when analyzing fixed model outputs, emergent abilities appear due the researcher’s choice of metric rather than due to fundamental changes in model behavior with scale. Specifically, nonlinear or discontinuous metrics produce apparent emergent abilities, whereas linear or continuous metrics produce smooth, continuous, predictable changes in model performance.We present our alternative explanation in a simple mathematical model, then test it in three complementary ways: we (1) make, test and confirm three predictions on the effect of metric choice using the InstructGPT/GPT-3 family on tasks with claimed emergent abilities, (2) make, test and confirm two predictions about metric choices in a meta-analysis of emergent abilities on BIG-Bench; and (3) show how to choose metrics to produce never-before-seen seemingly emergent abilities in multiple vision tasks across diverse deep networks.Via all three analyses, we provide evidence that alleged emergent abilities evaporate with different metrics or with better statistics, and may not be a fundamental property of scaling AI models.",Oral 6A LLMs,https://openreview.net/pdf?id=ITw9edRDlD,https://openreview.net/forum?id=ITw9edRDlD
"['Haotian Liu', 'Chunyuan Li', 'Qingyang Wu', 'Yong Jae Lee']",NeurIPS,Visual Instruction Tuning,https://neurips.cc/virtual/2023/oral/73817,2023," Instruction tuning large language models (LLMs) using machine-generated instruction-following data has been shown to improve zero-shot capabilities on new tasks, but the idea is less explored in the multimodal field. We present the first attempt to use language-only GPT-4 to generate multimodal language-image instruction-following data. By instruction tuning on such generated data, we introduce LLaVA: Large Language and Vision Assistant, an end-to-end trained large multimodal model that connects a vision encoder and an LLM for general-purpose visual and language understanding. To facilitate future research on visual instruction following, we construct two evaluation benchmarks with diverse and challenging application-oriented tasks. Our experiments show that LLaVA demonstrates impressive multimodal chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and yields a 85.1% relative score compared with GPT-4 on a synthetic multimodal instruction-following dataset. When fine-tuned on Science QA, the synergy of LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make GPT-4 generated visual instruction tuning data, our model, and code publicly available.",Oral 5D Vision,https://openreview.net/pdf?id=w0H2xGHlkw,https://openreview.net/forum?id=w0H2xGHlkw
"['Agrim Gupta', 'Jiajun Wu', 'Jia Deng', 'Fei-Fei Li']",NeurIPS,Siamese Masked Autoencoders,https://neurips.cc/virtual/2023/oral/73813,2023," Establishing correspondence between images or scenes is a significant challenge in computer vision, especially given occlusions, viewpoint changes, and varying object appearances. In this paper, we present Siamese Masked Autoencoders (SiamMAE), a simple extension of Masked Autoencoders (MAE) for learning visual correspondence from videos. SiamMAE operates on pairs of randomly sampled video frames and asymmetrically masks them. These frames are processed independently by an encoder network, and a decoder composed of a sequence of cross-attention layers is tasked with predicting the missing patches in the future frame. By masking a large fraction (95%) of patches in the future frame while leaving the past frame unchanged, SiamMAE encourages the network to focus on object motion and learn object-centric representations. Despite its conceptual simplicity, features learned via SiamMAE outperform state-of-the-art self-supervised methods on video object segmentation, pose keypoint propagation, and semantic part propagation tasks. SiamMAE achieves competitive results without relying on data augmentation, handcrafted tracking-based pretext tasks, or other techniques to prevent representational collapse.",Oral 6C Vision,https://openreview.net/pdf?id=yC3q7vInux,https://openreview.net/forum?id=yC3q7vInux
"['Tianwei Ni', 'Michel Ma', 'Benjamin Eysenbach', 'Pierre-Luc Bacon']",NeurIPS,When Do Transformers Shine in RL_ Decoupling Memory from Credit Assignment,https://neurips.cc/virtual/2023/oral/73869,2023," Reinforcement learning (RL) algorithms face two distinct challenges: learning effective representations of past and present observations, and determining how actions influence future returns. Both challenges involve modeling long-term dependencies. The Transformer architecture has been very successful to solve problems that involve long-term dependencies, including in the RL domain. However, the underlying reason for the strong performance of Transformer-based RL methods remains unclear: is it because they learn effective memory, or because they perform effective credit assignment? After introducing formal definitions of memory length and credit assignment length, we design simple configurable tasks to measure these distinct quantities. Our empirical results reveal that Transformers can enhance the memory capability of RL algorithms, scaling up to tasks that require memorizing observations $1500$ steps ago. However, Transformers do not improve long-term credit assignment. In summary, our results provide an explanation for the success of Transformers in RL, while also highlighting an important area for future research and benchmark design. Our code is open-sourced at https://github.com/twni2016/Memory-RL.",Oral 6B RL,https://openreview.net/pdf?id=APGXBNkt6h,https://openreview.net/forum?id=APGXBNkt6h
"['Siliang Zeng', 'Chenliang Li', 'Alfredo Garcia', 'Mingyi Hong']",NeurIPS,When Demonstrations meet Generative World Models_ A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning,https://neurips.cc/virtual/2023/oral/73824,2023," Offline inverse reinforcement learning (Offline IRL) aims to recover the structure of rewards and environment dynamics that underlie observed actions in a fixed, finite set of demonstrations from an expert agent. Accurate models of expertise in executing a task has applications in safety-sensitive applications such as clinical decision making and autonomous driving. However, the structure of an expert's preferences implicit in observed actions is closely linked to the expert's model of the environment dynamics (i.e. the ``world''). Thus, inaccurate models of the world obtained from finite data with limited coverage could compound inaccuracy in estimated rewards. To address this issue, we propose a bi-level optimization formulation of the estimation task wherein the upper level is likelihood maximization based upon a conservative model of the expert's policy (lower level). The policy model is conservative in that it maximizes reward subject to a penalty that is increasing in the uncertainty of the estimated model of the world. We propose a new algorithmic framework to solve the bi-level optimization problem formulation and provide statistical and computational guarantees of performance for the associated optimal reward estimator. Finally,  we demonstrate that the proposed algorithm outperforms the state-of-the-art offline IRL and imitation learning benchmarks by a large margin, over the continuous control tasks in MuJoCo and different datasets in the D4RL benchmark.",Oral 1A RL,https://openreview.net/pdf?id=oML3v2cFg2,https://openreview.net/forum?id=oML3v2cFg2
"['Idan Attias', 'Steve Hanneke', 'Alkis Kalavasis', 'Amin Karbasi', 'Grigoris Velegkas']",NeurIPS,Optimal Learners for Realizable Regression_ PAC Learning and Online Learning,https://neurips.cc/virtual/2023/oral/73816,2023," In this work, we aim to characterize the statistical complexity of realizable regression both in the PAC learning setting and the online learning setting. Previous work had established the sufficiency of finiteness of the fat shattering dimension for PAC learnability and the necessity of finiteness of the scaled Natarajan dimension, but little progress had been made towards a more complete characterization since  the work of Simon 1997 (SICOMP '97). To this end,  we first introduce a minimax instance optimal learner for realizable regression and propose a novel dimension that both qualitatively and quantitatively characterizes which classes of real-valued predictors are learnable.  We then identify a combinatorial dimension related to the graph dimension that characterizes ERM learnability in the realizable setting. Finally, we establish a necessary condition for learnability based on a combinatorial dimension related to the DS dimension, and conjecture that it may also be sufficient in this context. Additionally, in the context of online learning we provide a dimension that characterizes the minimax instance optimal cumulative loss up to a constant factor and design an optimal online learner for realizable regression, thus resolving an open question raised by Daskalakis and Golowich in STOC '22.",Oral 6D Theory,https://openreview.net/pdf?id=w116w62fxH,https://openreview.net/forum?id=w116w62fxH
"['Sibylle Marcotte', 'Remi Gribonval', 'Gabriel Peyré']",NeurIPS,Abide by the law and follow the flow_ conservation laws for gradient flows,https://neurips.cc/virtual/2023/oral/73829,2023," Understanding the geometric properties of gradient descent dynamics is a key ingredient in deciphering the recent success of very large machine learning models. A striking observation is that trained over-parameterized models retain some properties of the optimization initialization. This ""implicit bias"" is believed to be responsible for some favorable properties of the trained models and could explain their good generalization properties. The purpose of this article is threefold. First, we rigorously expose the definition and basic properties of ""conservation laws"", that define quantities conserved during gradient flows of a given model (e.g. of a ReLU network with a given architecture) with any training data and any loss. Then we explain how to find the maximal number of independent conservation lawsby performing finite-dimensional algebraic manipulations on the Lie algebra generated by the Jacobian of the model. Finally, we provide algorithms to: a) compute a family of polynomial laws; b) compute the maximal number of (not necessarily polynomial) independent conservation laws. We provide showcase examples that we fully work out theoretically. Besides, applying the two algorithms confirms for a number of ReLU network architectures that all known laws are recovered by the algorithm, and that there are no other independent laws. Such computational tools pave the way to understanding desirable properties of optimization initialization in large machine learning models.",Oral 1D DL Theory,https://openreview.net/pdf?id=kMueEV8Eyy,https://openreview.net/forum?id=kMueEV8Eyy
"['Fabian Zaiser', 'Andrzej Murawski', 'Chih-Hao Luke Ong']",NeurIPS,Exact Bayesian Inference on Discrete Models via Probability Generating Functions_ A Probabilistic Programming Approach,https://neurips.cc/virtual/2023/oral/73866,2023," We present an exact Bayesian inference method for discrete statistical models, which can find exact solutions to a large class of discrete inference problems, even with infinite support and continuous priors.To express such models, we introduce a probabilistic programming language that supports discrete and continuous sampling, discrete observations, affine functions, (stochastic) branching, and conditioning on discrete events.Our key tool is probability generating functions :they provide a compact closed-form representation of distributions that are definable by programs, thus enabling the exact computation of posterior probabilities, expectation, variance, and higher moments.Our inference method is provably correct and fully automated in a tool called Genfer , which uses automatic differentiation (specifically, Taylor polynomials), but does not require computer algebra.Our experiments show that Genfer is often faster than the existing exact inference tools PSI, Dice, and Prodigy.On a range of real-world inference problems that none of these exact tools can solve, Genfer's performance is competitive with approximate Monte Carlo methods, while avoiding approximation errors.",Oral 1C Tractable models,https://openreview.net/pdf?id=FtNruwFEs3,https://openreview.net/forum?id=FtNruwFEs3
"['Andreas Köpf', 'Yannic Kilcher', 'Dimitri von Rütte', 'Sotiris Anagnostidis', 'Zhi Rui Tam', 'Keith Stevens', 'Abdullah Barhoum', 'Duc Nguyen', 'Oliver Stanley', 'Richárd Nagyfi', 'Shahul ES', 'Sameer Suri', 'David Glushkov', 'Arnav Dantuluri', 'Andrew Maguire', 'Christoph Schuhmann', 'Huu Nguyen', 'Alexander Mattick']",NeurIPS,OpenAssistant Conversations - Democratizing Large Language Model Alignment,https://neurips.cc/virtual/2023/oral/73741,2023," Aligning large language models (LLMs) with human preferences has proven to drastically improve usability and has driven rapid adoption as demonstrated by ChatGPT.Alignment techniques such as supervised fine-tuning (\textit{SFT}) and  reinforcement learning from human feedback (\textit{RLHF}) greatly reduce the required skill and domain knowledge to effectively harness the capabilities of LLMs, increasing their accessibility and utility across various domains.However, state-of-the-art alignment techniques like \textit{RLHF} rely on high-quality human feedback data, which is expensive to create and often remains proprietary.In an effort to democratize research on large-scale alignment, we release OpenAssistant Conversations, a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 complete and fully annotated conversation trees.The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.Models trained on OpenAssistant Conversations show consistent improvements on standard benchmarks over respective base models.We release our code\footnote{\git} and data\footnote{\data} under a fully permissive licence.",Oral 1B Datasets & Benchmarks,https://openreview.net/pdf?id=VSJotgbPHF,https://openreview.net/forum?id=VSJotgbPHF
"['Tim Dettmers', 'Artidoro Pagnoni', 'Ari Holtzman', 'Luke Zettlemoyer']",NeurIPS,QLoRA_ Efficient Finetuning of Quantized LLMs,https://neurips.cc/virtual/2023/oral/73855,2023," We present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters~(LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information-theoretically optimal for normally distributed weights (b) Double Quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) Paged Optimziers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small, high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations, showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to ChatGPT. We release all of our models and code, including CUDA kernels for 4-bit training.",Oral 2A Efficient Learning,https://openreview.net/pdf?id=OUIFPHEgJU,https://openreview.net/forum?id=OUIFPHEgJU
"['Royi Rassin', 'Eran Hirsch', 'Daniel Glickman', 'Shauli Ravfogel', 'Yoav Goldberg', 'Gal Chechik']",NeurIPS,Linguistic Binding in Diffusion Models_ Enhancing Attribute Correspondence through Attention Map Alignment,https://neurips.cc/virtual/2023/oral/73870,2023," Text-conditioned image generation models often generate incorrect associations between entities and their visual attributes. This reflects an impaired mapping between linguistic binding of entities and modifiers in the prompt and visual binding of the corresponding elements in the generated image. As one example, a query like ``a pink sunflower and a yellow flamingo'' may incorrectly produce an image of a yellow sunflower and a pink flamingo. To remedy this issue, we propose SynGen, an approach which first syntactically analyses the prompt to identify entities and their modifiers, and then uses a novel loss function that encourages the cross-attention maps to agree with the linguistic binding reflected by the syntax. Specifically, we encourage large overlap between attention maps of entities and their modifiers, and small overlap with other entities and modifier words. The loss is optimized during inference, without retraining or fine-tuning the model. Human evaluation on three datasets, including one new and challenging set, demonstrate significant improvements of SynGen compared with current state of the art methods. This work highlights how making use of sentence structure during inference can efficiently and substantially improve the faithfulness of text-to-image generation.",Oral 2B Objects/ Neuroscience/Vision,https://openreview.net/pdf?id=AOKU4nRw1W,https://openreview.net/forum?id=AOKU4nRw1W
"['Thomas Steinke', 'Milad Nasr', 'Matthew Jagielski']",NeurIPS,Privacy Auditing with One (1) Training Run,https://neurips.cc/virtual/2023/oral/73837,2023," We propose a scheme for auditing differentially private machine learning systems with a single training run. This exploits the parallelism of being able to add or remove multiple training examples independently. We analyze this using the connection between differential privacy and statistical generalization, which avoids the cost of group privacy. Our auditing scheme requires minimal assumptions about the algorithm and can be applied in the black-box or white-box setting. We demonstrate the effectiveness of our framework by applying it to DP-SGD, where we can achieve meaningful empirical privacy lower bounds by training only one model. In contrast, standard methods would require training hundreds of models.",Oral 2D Privacy,https://openreview.net/pdf?id=f38EY21lBw,https://openreview.net/forum?id=f38EY21lBw
"['Junhyung Park', 'Simon Buchholz', 'Bernhard Schölkopf', 'Krikamol Muandet']",NeurIPS,A Measure-Theoretic Axiomatisation of Causality,https://neurips.cc/virtual/2023/oral/73819,2023," Causality is a central concept in a wide range of research areas, yet there is still no universally agreed axiomatisation of causality. We view causality both as an extension of probability theory and as a study of what happens when one intervenes on a system, and argue in favour of taking Kolmogorov's measure-theoretic axiomatisation of probability as the starting point towards an axiomatisation of causality. To that end, we propose the notion of a causal space, consisting of a probability space along with a collection of transition probability kernels, called causal kernels, that encode the causal information of the space. Our proposed framework is not only rigorously grounded in measure theory, but it also sheds light on long-standing limitations of existing frameworks including, for example, cycles, latent variables and stochastic processes.",Oral 2C Causality,https://openreview.net/pdf?id=sPLTQSf6GI,https://openreview.net/forum?id=sPLTQSf6GI
"['Zijiao Chen', 'Jiaxin Qing', 'Juan Helen Zhou']",NeurIPS,Cinematic Mindscapes_ High-quality Video Reconstruction from Brain Activity,https://neurips.cc/virtual/2023/oral/73833,2023," Reconstructing human vision from brain activities has been an appealing task that helps to understand our cognitive process. Even though recent research has seen great success in reconstructing static images from non-invasive brain recordings, work on recovering continuous visual experiences in the form of videos is limited. In this work, we propose Mind-Video that learns spatiotemporal information from continuous fMRI data of the cerebral cortex progressively through masked brain modeling, multimodal contrastive learning with spatiotemporal attention, and co-training with an augmented Stable Diffusion model that incorporates network temporal inflation. We show that high-quality videos of arbitrary frame rates can be reconstructed with Mind-Video using adversarial guidance. The recovered videos were evaluated with various semantic and pixel-level metrics. We achieved an average accuracy of 85% in semantic classification tasks and 0.19 in structural similarity index (SSIM), outperforming the previous state-of-the-art by 45%. We also show that our model is biologically plausible and interpretable, reflecting established physiological processes.",Oral 3A Neuro,https://openreview.net/pdf?id=i913TUOvTK,https://openreview.net/forum?id=i913TUOvTK
"['Timo Schick', 'Jane Dwivedi-Yu', 'Roberto Dessi', 'Roberta Raileanu', 'Maria Lomeli', 'Eric Hambro', 'Luke Zettlemoyer', 'Nicola Cancedda', 'Thomas Scialom']",NeurIPS,Toolformer_ Language Models Can Teach Themselves to Use Tools,https://neurips.cc/virtual/2023/oral/73843,2023," Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale. They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller specialized models excel. In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer , a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction. This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API. We incorporate a range of tools, including a calculator, a Q&A system, a search engine, a translation system, and a calendar. Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.",Oral 3B NLP/Tools,https://openreview.net/pdf?id=Yacmpz84TH,https://openreview.net/forum?id=Yacmpz84TH
"['Nikita Gushchin', 'Alexander Kolesov', 'Alexander Korotin', 'Dmitry Vetrov', 'Evgeny Burnaev']",NeurIPS,Entropic Neural Optimal Transport via Diffusion Processes,https://neurips.cc/virtual/2023/oral/73836,2023," We propose a novel neural algorithm for the fundamental problem of computing the entropic optimal transport (EOT) plan between probability distributions which are accessible by samples. Our algorithm is based on the saddle point reformulation of the dynamic version of EOT which is known as the Schrödinger Bridge problem. In contrast to the prior methods for large-scale EOT, our algorithm is end-to-end and consists of a single learning step, has fast inference procedure, and allows handling small values of the entropy regularization coefficient which is of particular importance in some applied problems. Empirically, we show the performance of the method on several large-scale EOT tasks. The code for the ENOT solver can be found at https://github.com/ngushchin/EntropicNeuralOptimalTransport",Oral 3C Diffusion Models,https://openreview.net/pdf?id=fHyLsfMDIs,https://openreview.net/forum?id=fHyLsfMDIs
"['Alex Damian', 'Eshaan Nichani', 'Rong Ge', 'Jason Lee']",NeurIPS,Smoothing the Landscape Boosts the Signal for SGD_ Optimal Sample Complexity for Learning Single Index Models,https://neurips.cc/virtual/2023/oral/73873,2023," We focus on the task of learning a single index model $\sigma(w^\star \cdot x)$ with respect to the isotropic Gaussian distribution in $d$ dimensions. Prior work has shown that the sample complexity of learning $w^\star$ is governed by the information exponent $k^\star$ of the link function $\sigma$, which is defined as the index of the first nonzero Hermite coefficient of $\sigma$. Ben Arous et al. (2021) showed that $n \gtrsim d^{k^\star-1}$ samples suffice for learning $w^\star$ and that this is tight for online SGD. However, the CSQ lower bound for gradient based methods only shows that $n \gtrsim d^{k^\star/2}$ samples are necessary. In this work, we close the gap between the upper and lower bounds by showing that online SGD on a smoothed loss learns $w^\star$ with $n \gtrsim d^{k^\star/2}$ samples. We also draw connections to statistical analyses of tensor PCA and to the implicit regularization effects of minibatch SGD on empirical losses.",Oral 4A Optimization,https://openreview.net/pdf?id=73XPopmbXH,https://openreview.net/forum?id=73XPopmbXH
"['Sungduk Yu', 'Walter Hannah', 'Liran Peng', 'Jerry Lin', 'Mohamed Aziz Bhouri', 'Ritwik Gupta', 'Björn Lütjens', 'Justus C. Will', 'Gunnar Behrens', 'Julius Busecke', 'Nora Loose', 'Charles Stern', 'Tom Beucler', 'Bryce Harrop', 'Benjamin Hillman', 'Andrea Jenney', 'Savannah L. Ferretti', 'Nana Liu', 'Animashree Anandkumar', 'Noah Brenowitz', 'Veronika Eyring', 'Nicholas Geneva', 'Pierre Gentine', 'Stephan Mandt', 'Jaideep Pathak', 'Akshay Subramaniam', 'Carl Vondrick', 'Rose Yu', 'Laure Zanna', 'Tian Zheng', 'Ryan Abernathey', 'Fiaz Ahmed', 'David Bader', 'Pierre Baldi', 'Elizabeth Barnes', 'Christopher Bretherton', 'Peter Caldwell', 'Wayne Chuang', 'Yilun Han', 'YU HUANG', 'Fernando Iglesias-Suarez', 'Sanket Jantre', 'Karthik Kashinath', 'Marat Khairoutdinov', 'Thorsten Kurth', 'Nicholas Lutsko', 'Po-Lun Ma', 'Griffin Mooers', 'J. David Neelin', 'David Randall', 'Sara Shamekh', 'Mark Taylor', 'Nathan Urban', 'Janni Yuval', 'Guang Zhang', 'Mike Pritchard']",NeurIPS,ClimSim_ A large multi-scale dataset for hybrid physics-ML climate emulation,https://neurips.cc/virtual/2023/oral/73740,2023," Modern climate projections lack adequate spatial and temporal resolution due to computational constraints. A consequence is inaccurate and imprecise predictions of critical processes such as storms. Hybrid methods that combine physics with machine learning (ML) have introduced a new generation of higher fidelity climate simulators that can sidestep Moore's Law by outsourcing compute-hungry, short, high-resolution simulations to ML emulators. However, this hybrid ML-physics simulation approach requires domain-specific treatment and has been inaccessible to ML experts because of lack of training data and relevant, easy-to-use workflows. We present ClimSim, the largest-ever dataset designed for hybrid ML-physics research. It comprises multi-scale climate simulations, developed by a consortium of climate scientists and ML researchers. It consists of 5.7 billion pairs of multivariate input and output vectors that isolate the influence of locally-nested, high-resolution, high-fidelity physics on a host climate simulator's macro-scale physical state.The dataset is global in coverage, spans multiple years at high sampling frequency, and is designed such that resulting emulators are compatible with downstream coupling into operational climate simulators. We implement a range of deterministic and stochastic regression baselines to highlight the ML challenges and their scoring. The data (https://huggingface.co/datasets/LEAP/ClimSim_high-res) and code (https://leap-stc.github.io/ClimSim) are released openly to support the development of hybrid ML-physics and high-fidelity climate simulations for the benefit of science and society.",Oral 4B Datasets & Benchmarks,https://openreview.net/pdf?id=W5If9P1xqO,https://openreview.net/forum?id=W5If9P1xqO
"['Samuel Dooley', 'Rhea Sukthanker', 'John Dickerson', 'Colin White', 'Frank Hutter', 'Micah Goldblum']",NeurIPS,Rethinking Bias Mitigation_ Fairer Architectures Make for Fairer Face Recognition,https://neurips.cc/virtual/2023/oral/73878,2023," Face recognition systems are widely deployed in safety-critical applications, including law enforcement, yet they exhibit bias across a range of socio-demographic dimensions, such as gender and race.  Conventional wisdom dictates that model biases arise from biased training data.  As a consequence, previous works on bias mitigation largely focused on pre-processing the training data, adding penalties to prevent bias from effecting the model during training, or post-processing predictions to debias them, yet these approaches have shown limited success on hard problems such as face recognition.  In our work, we discover that biases are actually inherent to neural network architectures themselves.  Following this reframing, we conduct the first neural architecture search for fairness, jointly with a search for hyperparameters. Our search outputs a suite of models which Pareto-dominate all other high-performance architectures and existing bias mitigation methods in terms of accuracy and fairness, often by large margins, on the two most widely used datasets for face identification, CelebA and VGGFace2. Furthermore, these models generalize to other datasets and sensitive attributes. We release our code, models and raw data files at https://github.com/dooleys/FR-NAS.",Oral 5B Privacy/Fairness,https://openreview.net/pdf?id=1vzF4zWQ1E,https://openreview.net/forum?id=1vzF4zWQ1E
"['Shunyu Yao', 'Dian Yu', 'Jeffrey Zhao', 'Izhak Shafran', 'Tom Griffiths', 'Yuan Cao', 'Karthik Narasimhan']",NeurIPS,Tree of Thoughts_ Deliberate Problem Solving with Large Language Models,https://neurips.cc/virtual/2023/oral/73874,2023," Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices.Our experiments show that ToT significantly enhances language models’ problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\% of tasks, our method achieved a success rate of 74\%. Code repo with all prompts: https://github.com/princeton-nlp/tree-of-thought-llm.",Oral 4C COT/reasoning,https://openreview.net/pdf?id=5Xc1ecxO1h,https://openreview.net/forum?id=5Xc1ecxO1h
"['Veit David Wild', 'Sahra Ghalebikesabi', 'Dino Sejdinovic', 'Jeremias Knoblauch']",NeurIPS,A Rigorous Link between Deep Ensembles and (Variational) Bayesian Methods,https://neurips.cc/virtual/2023/oral/73838,2023," We establish the first mathematically rigorous link between Bayesian, variational Bayesian, and ensemble methods. A key step towards this it to reformulate the non-convex optimisation problem typically encountered in deep learning as a convex optimisation in the space of probability measures. On a technical level, our contribution amounts to studying generalised variational inference through the lense of Wasserstein gradient flows. The result is a unified theory of various seemingly disconnected approaches that are commonly used for uncertainty quantification in deep learning---including deep ensembles and (variational) Bayesian methods. This offers a fresh perspective on the reasons behind the success of deep ensembles over procedures based on parameterised variational inference, and allows the derivation of new ensembling schemes with convergence guarantees. We showcase this by proposing a family of interacting deep ensembles with direct parallels to the interactions of particle systems in thermodynamics, and use our theory to prove the convergence of these algorithms to a well-defined global minimiser on the space of probability measures.",Oral 5C Probability/Sampling,https://openreview.net/pdf?id=eTHawKFT4h,https://openreview.net/forum?id=eTHawKFT4h
"['David Ruhe', 'Johannes Brandstetter', 'Patrick Forré']",NeurIPS,Clifford Group Equivariant Neural Networks,https://neurips.cc/virtual/2023/oral/73825,2023," We introduce Clifford Group Equivariant Neural Networks: a novel approach for constructing $\mathrm{O}(n)$- and $\mathrm{E}(n)$-equivariant models. We identify and study the *Clifford group*: a subgroup inside the Clifford algebra tailored to achieve several favorable properties. Primarily, the group's action forms an orthogonal automorphism that extends beyond the typical vector space to the entire Clifford algebra while respecting the multivector grading. This leads to several non-equivalent subrepresentations corresponding to the multivector decomposition. Furthermore, we prove that the action respects not just the vector space structure of the Clifford algebra but also its multiplicative structure, i.e., the geometric product. These findings imply that every polynomial in multivectors, including their grade projections, constitutes an equivariant map with respect to the Clifford group, allowing us to parameterize equivariant neural network layers. An advantage worth mentioning is that we obtain expressive layers that can elegantly generalize to inner-product spaces of any dimension. We demonstrate, notably from a single core implementation, state-of-the-art performance on several distinct tasks, including a three-dimensional $n$-body experiment, a four-dimensional Lorentz-equivariant high-energy physics experiment, and a five-dimensional convex hull experiment.",Oral 5A GNNs/Invariance,https://openreview.net/pdf?id=n84bzMrGUD,https://openreview.net/forum?id=n84bzMrGUD
"['Guillermo Ortiz-Jimenez', 'Alessandro Favero', 'Pascal Frossard']",NeurIPS,Task Arithmetic in the Tangent Space_ Improved Editing of Pre-Trained Models,https://neurips.cc/virtual/2023/oral/73879,2023," Task arithmetic has recently emerged as a cost-effective and scalable approach to edit pre-trained models directly in weight space: By adding the fine-tuned weights of different tasks, the model's performance can be improved on these tasks, while negating them leads to task forgetting. Yet, our understanding of the effectiveness of task arithmetic and its underlying principles remains limited. We present a comprehensive study of task arithmetic in vision-language models and show that weight disentanglement is the crucial factor that makes it effective. This property arises during pre-training and manifests when distinct directions in weight space govern separate, localized regions in function space associated with the tasks. Notably, we show that fine-tuning models in their tangent space by linearizing them amplifies weight disentanglement. This leads to substantial performance improvements across multiple task arithmetic benchmarks and diverse models. Building on these findings, we provide theoretical and empirical analyses of the neural tangent kernel (NTK) of these models and establish a compelling link between task arithmetic and the spatial localization of the NTK eigenfunctions. Overall, our work uncovers novel insights into the fundamental mechanisms of task arithmetic and offers a more reliable and effective approach to edit pre-trained models through the NTK linearization.",Oral 6A LLMs,https://openreview.net/pdf?id=0A9f2jZDGW,https://openreview.net/forum?id=0A9f2jZDGW
"['Tushar Nagarajan', 'Santhosh Kumar Ramakrishnan', 'Ruta Desai', 'James Hillis', 'Kristen Grauman']",NeurIPS,EgoEnv_ Human-centric environment representations from egocentric video,https://neurips.cc/virtual/2023/oral/73820,2023," First-person video highlights a camera-wearer's activities in the context of their persistent environment. However, current video understanding approaches reason over visual features from short video clips that are detached from the underlying physical space and  capture only what is immediately visible. To facilitate human-centric environment understanding, we present an approach that links egocentric video and the environment by learning representations that are predictive of the camera-wearer's (potentially unseen) local surroundings. We train such models using videos from agents in simulated 3D environments where the environment is fully observable, and test them on human-captured real-world videos from unseen environments. On two human-centric video tasks, we show that models equipped with our environment-aware features consistently outperform their counterparts with traditional clip features. Moreover, despite being trained exclusively on simulated videos, our approach successfully handles real-world videos from HouseTours and Ego4D, and achieves state-of-the-art results on the Ego4D NLQ challenge.",Oral 5D Vision,https://openreview.net/pdf?id=rybsHQ4DXy,https://openreview.net/forum?id=rybsHQ4DXy
"['Michael Tschannen', 'Manoj Kumar', 'Andreas Steiner', 'Andreas Steiner', 'Xiaohua Zhai', 'Neil Houlsby', 'Lucas Beyer']",NeurIPS,Image Captioners Are Scalable Vision Learners Too,https://neurips.cc/virtual/2023/oral/73871,2023," Contrastive pretraining on image-text pairs from the web is one of the most popular large-scale pretraining strategies for vision backbones, especially in the context of large multimodal models. At the same time, image captioning on this type of data is commonly considered an inferior pretraining strategy. In this paper, we perform a fair comparison of these two pretraining strategies, carefully matching training data, compute, and model capacity. Using a standard encoder-decoder transformer, we find that captioning alone is surprisingly effective: on classification tasks, captioning produces vision encoders competitive with contrastively pretrained encoders, while surpassing them on vision & language tasks. We further analyze the effect of the model architecture and scale, as well as the pretraining data on the representation quality, and find that captioning exhibits the same or better scaling behavior along these axes. Overall our results show that plain image captioning is a more powerful pretraining strategy than was previously believed. Code is available at https://github.com/google-research/big_vision .",Oral 6C Vision,https://openreview.net/pdf?id=A7feCufBhL,https://openreview.net/forum?id=A7feCufBhL
"['Cassidy Laidlaw', 'Stuart J Russell', 'Anca Dragan']",NeurIPS,Bridging RL Theory and Practice with the Effective Horizon,https://neurips.cc/virtual/2023/oral/73859,2023," Deep reinforcement learning (RL) works impressively in some environments and fails catastrophically in others. Ideally, RL theory should be able to provide an understanding of why this is, i.e. bounds predictive of practical performance. Unfortunately, current theory does not quite have this ability. We compare standard deep RL algorithms to prior sample complexity bounds by introducing a new dataset, BRIDGE. It consists of 155 MDPs from common deep RL benchmarks, along with their corresponding tabular representations, which enables us to exactly compute instance-dependent bounds. We find that prior bounds do not correlate well with when deep RL succeeds vs. fails, but discover a surprising property that does. When actions with the highest Q-values under the random policy also have the highest Q-values under the optimal policy—i.e., when it is optimal to act greedily with respect to the random's policy Q function—deep RL tends to succeed; when they don't, deep RL tends to fail. We generalize this property into a new complexity measure of an MDP that we call the effective horizon , which roughly corresponds to how many steps of lookahead search would be needed in that MDP in order to identify the next optimal action, when leaf nodes are evaluated with random rollouts. Using BRIDGE, we show that the effective horizon-based bounds are more closely reflective of the empirical performance of PPO and DQN than prior sample complexity bounds across four metrics. We also show that, unlike existing bounds, the effective horizon can predict the effects of using reward shaping or a pre-trained exploration policy. Our code and data are available at https://github.com/cassidylaidlaw/effective-horizon.",Oral 6B RL,https://openreview.net/pdf?id=Lr2swAfwff,https://openreview.net/forum?id=Lr2swAfwff
"['Gellert Weisz', 'András György', 'Csaba Szepesvari']",NeurIPS,Online RL in Linearly $q^_pi$-Realizable MDPs Is as Easy as in Linear MDPs If You Learn What to Ignore,https://neurips.cc/virtual/2023/oral/73864,2023," We consider online reinforcement learning (RL) in episodic Markov decision processes (MDPs) under the linear $q^\pi$-realizability assumption, where it is assumed that the action-values of all policies can be  expressed as linear functions of state-action features. This class is known to be more general than  linear MDPs, where the transition kernel and the reward function are assumed to be linear functions of the feature vectors. As our first contribution, we show that the difference between the two classes is the presence of states in linearly $q^\pi$-realizable MDPs where for any policy, all the actions have  approximately equal values, and skipping over these states by following an arbitrarily fixed policy in those states transforms the problem to a linear MDP. Based on this observation, we derive a novel (computationally inefficient) learning algorithm for linearly $q^\pi$-realizable MDPs that simultaneously learns what states should be skipped over and runs another learning algorithm on the linear MDP hidden in the problem. The method returns an $\epsilon$-optimal policy after $\text{polylog}(H, d)/\epsilon^2$ interactions with the MDP, where $H$ is the time horizon and $d$ is the dimension of the feature vectors, giving the first polynomial-sample-complexity online RL algorithm for this setting. The results are proved for the misspecified case, where the sample complexity is shown to degrade gracefully with the misspecification error.",Oral 1A RL,https://openreview.net/pdf?id=HV85SiyrsV,https://openreview.net/forum?id=HV85SiyrsV
"['Konstantin Makarychev', 'Liren Shan']",NeurIPS,Random Cuts are Optimal for Explainable k-Medians,https://neurips.cc/virtual/2023/oral/73858,2023," We show that the RandomCoordinateCut algorithm gives the optimal competitive ratio for explainable $k$-medians in $\ell_1$. The problem of explainable $k$-medians was introduced by Dasgupta, Frost, Moshkovitz, and Rashtchian in 2020. Several groups of authors independently proposed a simple polynomial-time randomized algorithm for the problem and showed that this algorithm is $O(\log k \log\log k)$ competitive.  We provide a tight analysis of the algorithm and prove that its competitive ratio is upper bounded by $2\ln k+2$. This bound matches the $\Omega(\log k)$ lower bound by Dasgupta et al (2020).",Oral 6D Theory,https://openreview.net/pdf?id=MFWgLCWgUB,https://openreview.net/forum?id=MFWgLCWgUB
"['Alicia Curth', 'Alan Jeffares', 'Mihaela van der Schaar']",NeurIPS,A U-turn on Double Descent_ Rethinking Parameter Counting in Statistical Learning,https://neurips.cc/virtual/2023/oral/73856,2023," Conventional statistical wisdom established a well-understood relationship between model complexity and prediction error, typically presented as a _U-shaped curve_ reflecting a transition between under- and overfitting regimes. However, motivated by the success of overparametrized neural networks, recent influential work has suggested this theory to be generally incomplete, introducing an additional regime that exhibits a second descent in test error as the parameter count $p$ grows past sample size $n$  -- a  phenomenon dubbed  _double descent_. While most attention has naturally been given to the deep-learning setting, double descent was shown to emerge more generally across non-neural models: known cases include _linear regression, trees, and boosting_. In this work, we take a closer look at the evidence surrounding these more classical statistical machine learning methods and challenge the claim that observed cases of  double descent truly extend the limits of a traditional U-shaped complexity-generalization curve therein. We show that once careful consideration is given to _what is being plotted_ on the x-axes of their double descent plots, it becomes apparent that there are implicitly multiple, distinct complexity axes along which the parameter count grows. We demonstrate that the second descent appears exactly (and _only_) when and where the transition between these underlying axes occurs, and that its location is thus _not_ inherently tied to the interpolation threshold $p=n$. We then gain further insight by adopting a classical nonparametric statistics perspective. We interpret the investigated methods as _smoothers_ and propose a generalized measure for the _effective_ number of parameters they use _on unseen examples_, using which we find that their apparent double descent curves do indeed fold back into more traditional convex shapes -- providing a resolution to the ostensible tension between double descent and traditional statistical intuition.",Oral 1D DL Theory,https://openreview.net/pdf?id=O0Lz8XZT2b,https://openreview.net/forum?id=O0Lz8XZT2b
"['Boxin Wang', 'Weixin Chen', 'Hengzhi Pei', 'Chulin Xie', 'Mintong Kang', 'Chenhui Zhang', 'Chejian Xu', 'Zidi Xiong', 'Ritik Dutta', 'Rylan Schaeffer', 'Sang Truong', 'Simran Arora', 'Mantas Mazeika', 'Dan Hendrycks', 'Zinan Lin', 'Yu Cheng', 'Sanmi Koyejo', 'Dawn Song', 'Bo Li']",NeurIPS,DecodingTrust_ A Comprehensive Assessment of Trustworthiness in GPT Models,https://neurips.cc/virtual/2023/oral/73736,2023," Generative Pre-trained Transformer (GPT) models have exhibited exciting progress in capabilities, capturing the interest of practitioners and the public alike. Yet, while the literature on the trustworthiness of GPT models remains limited, practitioners have proposed employing capable GPT models for sensitive applications to healthcare and finance – where mistakes can be costly. To this end, this work proposes a comprehensive trustworthiness evaluation for large language models with a focus on GPT-4 and GPT-3.5, considering diverse perspectives – including toxicity, stereotype bias, adversarial robustness, out-of-distribution robustness, robustness on adversarial demonstrations, privacy, machine ethics, and fairness. Based on our evaluations, we discover previously unpublished vulnerabilities to trustworthiness threats. For instance, we find that GPT models can be easily misled to generate toxic and biased outputs and leak private information in both training data and conversation history. We also find that although GPT-4 is usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more vulnerable given jailbreaking system or user prompts, potentially due to the reason that GPT-4 follows the (misleading) instructions more precisely. Our work illustrates a comprehensive trustworthiness evaluation of GPT models and sheds light on the trustworthiness gaps. Our benchmark is publicly available at https://decodingtrust.github.io/.",Oral 1B Datasets & Benchmarks,https://openreview.net/pdf?id=kaHpo8OZw2,https://openreview.net/forum?id=kaHpo8OZw2
"['Zhongjie Yu', 'Martin Trapp', 'Kristian Kersting']",NeurIPS,Characteristic Circuits,https://neurips.cc/virtual/2023/oral/73875,2023," In many real-world scenarios it is crucial to be able to reliably and efficiently reason under uncertainty while capturing complex relationships in data.  Probabilistic circuits (PCs), a prominent family of tractable probabilistic models, offer a remedy to this challenge by composing simple, tractable distributions into a high-dimensional probability distribution.   However, learning PCs on heterogeneous data is challenging and densities of some parametric distributions are not available in closed form, limiting their potential use.   We introduce characteristic circuits (CCs), a family of tractable probabilistic models providing a unified formalization of distributions over heterogeneous data in the spectral domain.  The one-to-one relationship between characteristic functions and probability measures enables us to learn high-dimensional distributions on heterogeneous data domains and facilitates efficient probabilistic inference even when no closed-form density function is available.   We show that the structure and parameters of CCs can be learned efficiently from the data and find that CCs outperform state-of-the-art density estimators for heterogeneous data domains on common benchmark data sets.",Oral 1C Tractable models,https://openreview.net/pdf?id=5W7cXno10k,https://openreview.net/forum?id=5W7cXno10k
"['Niklas Muennighoff', 'Alexander Rush', 'Boaz Barak', 'Teven Le Scao', 'Nouamane Tazi', 'Aleksandra Piktus', 'Sampo Pyysalo', 'Thomas Wolf', 'Colin Raffel']",NeurIPS,Scaling Data-Constrained Language Models,https://neurips.cc/virtual/2023/oral/73832,2023," The current trend of scaling language models involves increasing both parameter count and training dataset size. Extrapolating this trend suggests that training dataset size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity, including augmenting the training dataset with code data or removing commonly used filters. Models and datasets from our 400 training runs are freely available at https://github.com/huggingface/datablations.",Oral 2A Efficient Learning,https://openreview.net/pdf?id=j5BuTrEj35,https://openreview.net/forum?id=j5BuTrEj35
"['Sébastien Lachapelle', 'Divyat Mahajan', 'Ioannis Mitliagkas', 'Simon Lacoste-Julien']",NeurIPS,Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation,https://neurips.cc/virtual/2023/oral/73849,2023," We tackle the problems of latent variables identification and ""out-of-support'' image generation in representation learning. We show that both are possible for a class of decoders that we call additive, which are reminiscent of decoders used for object-centric representation learning (OCRL) and well suited for images that can be decomposed as a sum of object-specific images. We provide conditions under which exactly solving the reconstruction problem using an additive decoder is guaranteed to identify the blocks of latent variables up to permutation and block-wise invertible transformations. This guarantee relies only on very weak assumptions about the distribution of the latent factors, which might present statistical dependencies and have an almost arbitrarily shaped support. Our result provides a new setting where nonlinear independent component analysis (ICA) is possible and adds to our theoretical understanding of OCRL methods. We also show theoretically that additive decoders can generate novel images by recombining observed factors of variations in novel ways, an ability we refer to as Cartesian-product extrapolation. We show empirically that additivity is crucial for both identifiability and extrapolation on simulated data.",Oral 2B Objects/ Neuroscience/Vision,https://openreview.net/pdf?id=R6KJN1AUAR,https://openreview.net/forum?id=R6KJN1AUAR
"['Moni Naor', 'Kobbi Nissim', 'Uri Stemmer', 'Chao Yan']",NeurIPS,Private Everlasting Prediction,https://neurips.cc/virtual/2023/oral/73814,2023," A private learner is trained on a sample of labeled points and generates a hypothesis that can be used for predicting the labels of newly sampled points while protecting the privacy of the training set [Kasiviswannathan et al., FOCS 2008]. Past research uncovered that private learners may need to exhibit significantly higher sample complexity than non-private learners as is the case of learning of one-dimensional threshold functions [Bun et al., FOCS 2015, Alon et al., STOC 2019].We explore prediction as an alternative to learning. A predictor answers a stream of classification queries instead of outputting a hypothesis. Earlier work has considered a private prediction model with a single classification query [Dwork and Feldman, COLT 2018]. We observe that when answering a stream of queries, a predictor must modify the hypothesis it uses over time, and in a manner that  cannot rely solely on the training set.We introduce {\em private everlasting prediction} taking into account the privacy of both the training set {\em and} the (adaptively chosen) queries made to the predictor. We then present a generic construction of private everlasting predictors in the PAC model.The sample complexity of the initial training sample in our construction is quadratic (up to polylog factors) in the VC dimension of the concept class. Our construction allows prediction for all concept classes with finite VC dimension, and in particular threshold functions over infinite domains, for which (traditional) private learning is known to be impossible.",Oral 2D Privacy,https://openreview.net/pdf?id=y8UAQQHVTX,https://openreview.net/forum?id=y8UAQQHVTX
"['Ahmed Alaa', 'Zaid Ahmad', 'Mark van der Laan']",NeurIPS,Conformal Meta-learners for Predictive Inference of Individual Treatment Effects,https://neurips.cc/virtual/2023/oral/73862,2023," We investigate the problem of machine learning-based (ML) predictive inference on individual treatment effects (ITEs). Previous work has focused primarily on developing ML-based “meta-learners” that can provide point estimates of the conditional average treatment effect (CATE)—these are model-agnostic approaches for combining intermediate nuisance estimates to produce estimates of CATE. In this paper, we develop conformal meta-learners, a general framework for issuing predictive intervals for ITEs by applying the standard conformal prediction (CP) procedure on top of CATE meta-learners. We focus on a broad class of meta-learners based on two-stage pseudo-outcome regression and develop a stochastic ordering framework to study their validity. We show that inference with conformal meta-learners is marginally valid if their (pseudo-outcome) conformity scores stochastically dominate “oracle” conformity scores evaluated on the unobserved ITEs. Additionally, we prove that commonly used CATE meta-learners, such as the doubly-robust learner, satisfy a model- and distribution-free stochastic (or convex) dominance condition, making their conformal inferences valid for practically-relevant levels of target coverage. Whereas existing procedures conduct inference on nuisance parameters (i.e., potential outcomes) via weighted CP, conformal meta-learners enable direct inference on the target parameter (ITE). Numerical experiments show that conformal meta-learners provide valid intervals with competitive efficiency while retaining the favorable point estimation properties of CATE meta-learners.",Oral 2C Causality,https://openreview.net/pdf?id=IwnINorSZ5,https://openreview.net/forum?id=IwnINorSZ5
['Kevin Ellis'],NeurIPS,Human-like Few-Shot Learning via Bayesian Reasoning over Natural Language,https://neurips.cc/virtual/2023/oral/73840,2023," A core tension in models of concept learning is that the model must carefully balance the tractability of inference against the expressivity of the hypothesis class. Humans, however, can efficiently learn a broad range of concepts. We introduce a model of inductive learning that seeks to be human-like in that sense.It implements a Bayesian reasoning process where a language model first proposes candidate hypotheses expressed in natural language, which are then re-weighed by a prior and a likelihood.By estimating the prior from human data, we can predict human judgments on learning problems involving numbers and sets, spanning concepts that are generative, discriminative, propositional, and higher-order.",Oral 3A Neuro,https://openreview.net/pdf?id=dVnhdm9MIg,https://openreview.net/forum?id=dVnhdm9MIg
"['Dan Friedman', 'Alexander Wettig', 'Danqi Chen']",NeurIPS,Learning Transformer Programs,https://neurips.cc/virtual/2023/oral/73853,2023," Recent research in mechanistic interpretability has attempted to reverse-engineer Transformer models by carefully inspecting network weights and activations. However, these approaches require considerable manual effort and still fall short of providing complete, faithful descriptions of the underlying algorithms. In this work, we introduce a procedure for training Transformers that are mechanistically interpretable by design. We build on RASP [Weiss et al., 2021], a programming language that can be compiled into Transformer weights. Instead of compiling human-written programs into Transformers, we design a modified Transformer that can be trained using gradient-based optimization and then automatically converted into a discrete, human-readable program. We refer to these models as Transformer Programs. To validate our approach, we learn Transformer Programs for a variety of problems, including an in-context learning task, a suite of algorithmic problems (e.g. sorting, recognizing Dyck languages), and NLP tasks including named entity recognition and text classification. The Transformer Programs can automatically find reasonable solutions, performing on par with standard Transformers of comparable size; and, more importantly, they are easy to interpret. To demonstrate these advantages, we convert Transformers into Python programs and use off-the-shelf code analysis tools to debug model errors and identify the “circuits” used to solve different sub-problems. We hope that Transformer Programs open a new path toward the goal of intrinsically interpretable machine learning.",Oral 3B NLP/Tools,https://openreview.net/pdf?id=Pe9WxkN8Ff,https://openreview.net/forum?id=Pe9WxkN8Ff
"['Tsun-Hsuan Johnson Wang', 'Juntian Zheng', 'Pingchuan Ma', 'Yilun Du', 'Byungchul Kim', 'Andrew Spielberg', 'Josh Tenenbaum', 'Chuang Gan', 'Daniela Rus']",NeurIPS,DiffuseBot_ Breeding Soft Robots With Physics-Augmented Generative Diffusion Models,https://neurips.cc/virtual/2023/oral/73877,2023," Nature evolves creatures with a high complexity of morphological and behavioral intelligence, meanwhile computational methods lag in approaching that diversity and efficacy.  Co-optimization of artificial creatures' morphology and control in silico shows promise for applications in physical soft robotics and virtual character creation; such approaches, however, require developing new learning algorithms that can reason about function atop pure structure. In this paper, we present DiffuseBot, a physics-augmented diffusion model that generates soft robot morphologies capable of excelling in a wide spectrum of tasks. \name bridges the gap between virtually generated content and physical utility by (i) augmenting the diffusion process with a physical dynamical simulation which provides a certificate of performance, and (ii) introducing a co-design procedure that jointly optimizes physical design and control by leveraging information about physical sensitivities from differentiable simulation.  We showcase a range of simulated and fabricated robots along with their capabilities. Check our website: https://diffusebot.github.io/",Oral 3C Diffusion Models,https://openreview.net/pdf?id=1zo4iioUEs,https://openreview.net/forum?id=1zo4iioUEs
"['Wisdom Ikezogwo', 'Saygin Seyfioglu', 'Fatemeh Ghezloo', 'Dylan Geva', 'Fatwir Sheikh Mohammed', 'Pavan Kumar Anand', 'Ranjay Krishna', 'Linda Shapiro']",NeurIPS,Quilt-1M_ One Million Image-Text Pairs for Histopathology,https://neurips.cc/virtual/2023/oral/73744,2023," Recent accelerations in multi-modal applications have been made possible with the plethora of image and text data available online. However, the scarcity of analogous data in the medical field, specifically in histopathology, has slowed comparable progress. To enable similar representation learning for histopathology, we turn to YouTube, an untapped resource of videos, offering $1,087$ hours of valuable educational histopathology videos from expert clinicians.From YouTube, we curate QUILT: a large-scale vision-language dataset consisting of $802, 144$ image and text pairs.QUILT was automatically curated using a mixture of models, including large language models, handcrafted algorithms, human knowledge databases, and automatic speech recognition.In comparison, the most comprehensive datasets curated for histopathology amass only around $200$K samples.We combine QUILT with datasets from other sources, including Twitter, research papers, and the internet in general, to create an even larger dataset: QUILT-1M, with $1$M paired image-text samples, marking it as the largest vision-language histopathology dataset to date. We demonstrate the value of QUILT-1M by fine-tuning a pre-trained CLIP model. Our model outperforms state-of-the-art models on both zero-shot and linear probing tasks for classifying new histopathology images across $13$ diverse patch-level datasets of $8$ different sub-pathologies and cross-modal retrieval tasks.",Oral 4B Datasets & Benchmarks,https://openreview.net/pdf?id=OL2JQoO0kq,https://openreview.net/forum?id=OL2JQoO0kq
"['Yujia Zheng', 'Kun Zhang']",NeurIPS,Generalizing Nonlinear ICA Beyond Structural Sparsity,https://neurips.cc/virtual/2023/oral/73834,2023," Nonlinear independent component analysis (ICA) aims to uncover the true latent sources from their observable nonlinear mixtures. Despite its significance, the identifiability of nonlinear ICA is known to be impossible without additional assumptions. Recent advances have proposed conditions on the connective structure from sources to observed variables, known as Structural Sparsity, to achieve identifiability in an unsupervised manner. However, the sparsity constraint may not hold universally for all sources in practice. Furthermore, the assumptions of bijectivity of the mixing process and independence among all sources, which arise from the setting of ICA, may also be violated in many real-world scenarios. To address these limitations and generalize nonlinear ICA, we propose a set of new identifiability results in the general settings of undercompleteness, partial sparsity and source dependence, and flexible grouping structures. Specifically, we prove identifiability when there are more observed variables than sources (undercomplete), and when certain sparsity and/or source independence assumptions are not met for some changing sources. Moreover, we show that even in cases with flexible grouping structures (e.g., part of the sources can be divided into irreducible independent groups with various sizes), appropriate identifiability results can also be established. Theoretical claims are supported empirically on both synthetic and real-world datasets.",Oral 4A Optimization,https://openreview.net/pdf?id=gI1SOgW3kw,https://openreview.net/forum?id=gI1SOgW3kw
"['Jerone Andrews', 'Dora Zhao', 'William Thong', 'Apostolos Modas', 'Orestis Papakyriakopoulos', 'Alice Xiang']",NeurIPS,Ethical Considerations for Responsible Data Curation,https://neurips.cc/virtual/2023/oral/73743,2023," Human-centric computer vision (HCCV) data curation practices often neglect privacy and bias concerns, leading to dataset retractions and unfair models. HCCV datasets constructed through nonconsensual web scraping lack crucial metadata for comprehensive fairness and robustness evaluations. Current remedies are post hoc, lack persuasive justification for adoption, or fail to provide proper contextualization for appropriate application. Our research focuses on proactive, domain-specific recommendations, covering purpose, privacy and consent, and diversity, for curating HCCV evaluation datasets, addressing privacy and bias concerns. We adopt an ante hoc reflective perspective, drawing from current practices, guidelines, dataset withdrawals, and audits, to inform our considerations and recommendations.",Oral 5B Privacy/Fairness,https://openreview.net/pdf?id=Qf8uzIT1OK,https://openreview.net/forum?id=Qf8uzIT1OK
"['Constantine Caramanis', 'Dimitris Fotakis', 'Alkis Kalavasis', 'Vasilis Kontonis', 'Christos Tzamos']",NeurIPS,Optimizing Solution-Samplers for Combinatorial Problems_ The Landscape of Policy-Gradient Method,https://neurips.cc/virtual/2023/oral/73826,2023," Deep Neural Networks and Reinforcement Learning methods have empirically shown great promise in tackling challenging combinatorial problems. In those methods a deep neural network is used as a solution generator which is then trained by gradient-based methods (e.g., policy gradient) to successively obtain better solution distributions.In this work we introduce a novel theoretical framework for analyzing the effectiveness of such methods. We ask whether there exist generative models that (i) are expressive enough to generate approximately optimal solutions; (ii) have a tractable, i.e, polynomial in the size of the input, number of parameters; (iii) their optimization landscape is benign in the sense that it does not contain sub-optimal stationary points. Our main contribution is a positive answer to this question. Our result holds for a broad class of combinatorial problems including Max- and Min-Cut, Max-$k$-CSP, Maximum-Weight-Bipartite-Matching, and the Traveling Salesman Problem. As a byproduct of our analysis we introduce a novel regularization process over vanilla gradient descent and provide theoretical and experimental evidence that it helps address vanishing-gradient issues and escape bad stationary points.",Oral 5C Probability/Sampling,https://openreview.net/pdf?id=mmTy1iyU5G,https://openreview.net/forum?id=mmTy1iyU5G
"['Yu Bai', 'Fan Chen', 'Huan Wang', 'Caiming Xiong', 'Song Mei']",NeurIPS,Transformers as Statisticians_ Provable In-Context Learning with In-Context Algorithm Selection,https://neurips.cc/virtual/2023/oral/73828,2023," Neural sequence models based on the transformer architecture have demonstrated remarkable \emph{in-context learning} (ICL) abilities, where they can perform new tasks when prompted with training and test examples, without any parameter update to the model. This work first provides a comprehensive statistical theory for transformers to perform ICL. Concretely, we show that transformers can implement a broad class of standard machine learning algorithms in context, such as least squares, ridge regression, Lasso, learning generalized linear models, and gradient descent on two-layer neural networks, with near-optimal predictive power on various in-context data distributions. Using an efficient implementation of in-context gradient descent as the underlying mechanism, our transformer constructions admit mild size bounds, and can be learned with polynomially many pretraining sequences.    Building on these ``base'' ICL algorithms, intriguingly, we show that transformers can implement more complex ICL procedures involving \emph{in-context algorithm selection}, akin to what a statistician can do in real life---A \emph{single} transformer can adaptively select different base ICL algorithms---or even perform qualitatively different tasks---on different input sequences, without any explicit prompting of the right algorithm or task. We both establish this in theory by explicit constructions, and also observe this phenomenon experimentally. In theory, we construct two general mechanisms for algorithm selection with concrete examples: pre-ICL testing, and post-ICL validation. As an example, we use the post-ICL validation mechanism to construct a transformer that can perform nearly Bayes-optimal ICL on a challenging task---noisy linear models with mixed noise levels. Experimentally, we demonstrate the strong in-context algorithm selection capabilities of standard transformer architectures.",Oral 4C COT/reasoning,https://openreview.net/pdf?id=liMSqUuVg9,https://openreview.net/forum?id=liMSqUuVg9
"['Junfeng Fang', 'Wei Liu', 'Yuan Gao', 'Zemin Liu', 'An Zhang', 'Xiang Wang', 'Xiangnan He']",NeurIPS,Evaluating Post-hoc Explanations for Graph Neural Networks via Robustness Analysis,https://neurips.cc/virtual/2023/oral/73839,2023," This work studies the evaluation of explaining graph neural networks (GNNs), which is crucial to the credibility of post-hoc explainability in practical usage. Conventional evaluation metrics, and even explanation methods -- which mainly follow the paradigm of feeding the explanatory subgraph and measuring output difference -- always suffer from the notorious out-of-distribution (OOD) issue. In this work, we endeavor to confront the issue by introducing a novel evaluation metric, termed O OD-resistant A dversarial R obustness (OAR). Specifically, we draw inspiration from the notion of adversarial robustness and evaluate post-hoc explanation subgraphs by calculating their robustness under attack. On top of that, an elaborate OOD reweighting block is inserted into the pipeline to confine the evaluation process to the original data distribution. For applications involving large datasets, we further devise a Sim plified version of OAR (SimOAR), which achieves a significant improvement in computational efficiency at the cost of a small amount of performance. Extensive empirical studies validate the effectiveness of our OAR and SimOAR.",Oral 5A GNNs/Invariance,https://openreview.net/pdf?id=eD534mPhAg,https://openreview.net/forum?id=eD534mPhAg
"['Ziqian Zhong', 'Ziming Liu', 'Max Tegmark', 'Jacob Andreas']",NeurIPS,The Clock and the Pizza_ Two Stories in Mechanistic Explanation of Neural Networks,https://neurips.cc/virtual/2023/oral/73847,2023," Do neural networks, trained on well-understood algorithmic tasks, reliably rediscover known algorithms? Several recent studies, on tasks ranging from group operations to in-context linear regression, have suggested that the answer is yes. Using modular addition as a prototypical problem, we show that algorithm discovery in neural networks is sometimes more complex: small changes to model hyperparameters and initializations can induce discovery of qualitatively different algorithms from a fixed training set, and even learning of multiple different solutions in parallel. In modular addition, we specifically show that models learn a known Clock algorithm, a previously undescribed, less intuitive, but comprehensible procedure we term the Pizza algorithm, and a variety of even more complex procedures. Our results show that even simple learning problems can admit a surprising diversity of solutions, motivating the development of new tools for mechanistically characterizing the behavior of neural networks across the algorithmic phase space.",Oral 6A LLMs,https://openreview.net/pdf?id=S5wmbQc1We,https://openreview.net/forum?id=S5wmbQc1We
"['Samir Yitzhak Gadre', 'Gabriel Ilharco', 'Alex Fang', 'Jonathan Hayase', 'Georgios Smyrnis', 'Thao Nguyen', 'Ryan Marten', 'Mitchell Wortsman', 'Dhruba Ghosh', 'Jieyu Zhang', 'Eyal Orgad', 'Rahim Entezari', 'Giannis Daras', 'Sarah Pratt', 'Vivek Ramanujan', 'Yonatan Bitton', 'Kalyani Marathe', 'Stephen Mussmann', 'Richard Vencu', 'Mehdi Cherti', 'Ranjay Krishna', 'Pang Wei Koh', 'Olga Saukh', 'Alexander Ratner', 'Shuran Song', 'Hannaneh Hajishirzi', 'Ali Farhadi', 'Romain Beaumont', 'Sewoong Oh', 'Alex Dimakis', 'Jenia Jitsev', 'Yair Carmon', 'Vaishaal Shankar', 'Ludwig Schmidt']",NeurIPS,DataComp_ In search of the next generation of multimodal datasets,https://neurips.cc/virtual/2023/oral/73739,2023," Multimodal datasets are a critical component in recent breakthroughs such as CLIP, Stable Diffusion and GPT-4, yet their design does not receive the same research attention as model architectures or training algorithms. To address this shortcoming in the machine learning ecosystem, we introduce DataComp, a testbed for dataset experiments centered around a new candidate pool of 12.8 billion image-text pairs from Common Crawl. Participants in our benchmark design new filtering techniques or curate new data sources and then evaluate their new dataset by running our standardized CLIP training code and testing the resulting model on 38 downstream test sets. Our benchmark consists of multiple compute scales spanning four orders of magnitude, which enables the study of scaling trends and makes the benchmark accessible to researchers with varying resources. Our baseline experiments show that the DataComp workflow leads to better training sets. Our best baseline, DataComp-1B, enables training a CLIP ViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet, outperforming OpenAI's CLIP ViT-L/14 by 3.7 percentage points while using the same training procedure and compute. We release \datanet and all accompanying code at www.datacomp.ai.",Oral 5D Vision,https://openreview.net/pdf?id=dVaWCDMBof,https://openreview.net/forum?id=dVaWCDMBof
"['Saurabh Saxena', 'Charles Herrmann', 'Junhwa Hur', 'Abhishek Kar', 'Mohammad Norouzi', 'Deqing Sun', 'David Fleet']",NeurIPS,The Surprising Effectiveness of Diffusion Models for Optical Flow and Monocular Depth Estimation,https://neurips.cc/virtual/2023/oral/73830,2023," Denoising diffusion probabilistic models have transformed image generation with their impressive fidelity and diversity.We show that they also excel in estimating optical flow and monocular depth, surprisingly without task-specific architectures and loss functions that are predominant for these tasks. Compared to the point estimates of conventional regression-based methods, diffusion models also enable Monte Carlo inference, e.g., capturing uncertainty and ambiguity in flow and depth.With self-supervised pre-training, the combined use of synthetic and real data for supervised training, and technical innovations (infilling and step-unrolled denoising diffusion training) to handle noisy-incomplete training data, one can train state-of-the-art diffusion models for depth and optical flow estimation, with additional zero-shot coarse-to-fine refinement for high resolution estimates. Extensive experiments focus on quantitative performance against benchmarks, ablations, and the model's ability to capture uncertainty and multimodality, and impute missing values. Our model obtains a state-of-the-art relative depth error of 0.074 on the indoor NYU benchmark and an Fl-all score of 3.26\% on the KITTI  optical flow benchmark, about 25\% better than the best published method.",Oral 6C Vision,https://openreview.net/pdf?id=jDIlzSU8wJ,https://openreview.net/forum?id=jDIlzSU8wJ
"['Rafael Rafailov', 'Archit Sharma', 'Eric Mitchell', 'Christopher D Manning', 'Stefano Ermon', 'Chelsea Finn']",NeurIPS,Direct Preference Optimization_ Your Language Model is Secretly a Reward Model,https://neurips.cc/virtual/2023/oral/73865,2023," While large-scale unsupervised language models (LMs) learn broad world knowledge and some reasoning skills, achieving precise control of their behavior is difficult due to the completely unsupervised nature of their training. Existing methods for gaining such steerability collect human labels of the relative quality of model generations and fine-tune the unsupervised LM to align with these preferences, often with reinforcement learning from human feedback (RLHF). However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model. In this paper, we leverage a mapping between reward functions and optimal policies to show that this constrained reward maximization problem can be optimized exactly with a single stage of policy training, essentially solving a classification problem on the human preference data. The resulting algorithm, which we call Direct Preference Optimization (DPO), is stable, performant, and computationally lightweight, eliminating the need for fitting a reward model, sampling from the LM during fine-tuning, or performing significant hyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align with human preferences as well as or better than existing methods. Notably, fine-tuning with DPO exceeds RLHF's ability to control sentiment of generations and improves response quality in summarization and single-turn dialogue while being substantially simpler to implement and train.",Oral 6B RL,https://openreview.net/pdf?id=HPuSIXJaa9,https://openreview.net/forum?id=HPuSIXJaa9
"['Aravind Gollakota', 'Adam Klivans', 'Konstantinos Stavropoulos', 'Arsen Vasilyan']",NeurIPS,Tester-Learners for Halfspaces_ Universal Algorithms,https://neurips.cc/virtual/2023/oral/73861,2023," We give the first tester-learner for halfspaces that succeeds universally over a wide class of structured distributions. Our universal tester-learner runs in fully polynomial time and has the following guarantee: the learner achieves error $O(\mathrm{opt}) + \epsilon$ on any labeled distribution that the tester accepts, and moreover, the tester accepts whenever the marginal is any distribution that satisfies a Poincare inequality. In contrast to prior work on testable learning, our tester is not tailored to any single target distribution but rather succeeds for an entire target class of distributions. The class of Poincare distributions includes all strongly log-concave distributions, and, assuming the Kannan--Lovasz--Simonovits (KLS) conjecture, includes all log-concave distributions. In the special case where the label noise is known to be Massart, our tester-learner achieves error $\mathrm{opt} + \epsilon$ while accepting all log-concave distributions unconditionally (without assuming KLS).Our tests rely on checking hypercontractivity of the unknown distribution using a sum-of-squares (SOS) program, and crucially make use of the fact that Poincare distributions are certifiably hypercontractive in the SOS framework.",Oral 6D Theory,https://openreview.net/pdf?id=Kv8GJkV19S,https://openreview.net/forum?id=Kv8GJkV19S
"['Liyuan Liu', 'Chengyu Dong', 'Xiaodong Liu', 'Bin Yu', 'Jianfeng Gao']",NeurIPS,Bridging Discrete and Backpropagation_ Straight-Through and Beyond,https://neurips.cc/virtual/2023/oral/73827,2023," Backpropagation, the cornerstone of deep learning, is limited to computing gradients for continuous variables. This limitation poses challenges for problems involving discrete latent variables. To address this issue, we propose a novel approach to approximate the gradient of parameters involved in generating discrete latent variables. First, we examine the widely used Straight-Through (ST) heuristic and demonstrate that it works as a first-order approximation of the gradient. Guided by our findings, we propose ReinMax, which achieves second-order accuracy by integrating Heun’s method, a second-order numerical method for solving ODEs. ReinMax does not require Hessian or other second-order derivatives, thus having negligible computation overheads. Extensive experimental results on various tasks demonstrate the superiority of ReinMax over the state of the art.",Oral 2A Efficient Learning,https://openreview.net/pdf?id=mayAyPrhJI,https://openreview.net/forum?id=mayAyPrhJI
"['Tianqin Li', 'Ziqi Wen', 'Yangfan Li', 'Tai Sing Lee']",NeurIPS,Emergence of Shape Bias in Convolutional Neural Networks through Activation Sparsity,https://neurips.cc/virtual/2023/oral/73850,2023," Current deep-learning models for object recognition are known to be heavily biased toward texture. In contrast, human visual systems are known to be biased toward shape and structure. What could be the design principles in human visual systems that led to this difference? How could we introduce more shape bias into the deep learning models? In this paper, we report that sparse coding, a ubiquitous principle in the brain,  can in itself introduce shape bias into the network. We found that enforcing the sparse coding constraint using a non-differential Top-K operation  can lead to the emergence of structural encoding in neurons in convolutional neural networks,  resulting in a smooth decomposition of objects into parts and subparts and endowing the networks with shape bias.  We demonstrated this emergence of shape bias and its functional benefits for different network structures with various datasets. For object recognition convolutional neural networks, the shape bias leads to greater robustness against style and pattern change distraction. For the image synthesis generative adversary networks,  the emerged shape bias leads to more coherent and decomposable structures in the synthesized images. Ablation studies suggest that sparse codes tend to encode structures, whereas the more distributed codes tend to favor texture. Our code is host at the github repository: https://topk-shape-bias.github.io/",Oral 2B Objects/ Neuroscience/Vision,https://openreview.net/pdf?id=QzcZb3fWmW,https://openreview.net/forum?id=QzcZb3fWmW
"['Badih Ghazi', 'Pritish Kamath', 'Ravi Kumar', 'Pasin Manurangsi', 'Raghu Meka', 'Chiyuan Zhang']",NeurIPS,User-Level Differential Privacy With Few Examples Per User,https://neurips.cc/virtual/2023/oral/73854,2023," Previous work on user-level differential privacy (DP) [Ghazi et al. NeurIPS 2021, Bun et al. STOC 2023] obtained generic algorithms that work for various learning tasks. However, their focus was on the *example-rich* regime, where the users have so many examples that each user could themselves solve the problem. In this work we consider the *example-scarce* regime, where each user has only a few examples, and obtain the following results:* For approximate-DP, we give a generic transformation of any item-level DP algorithm to a user-level DP algorithm. Roughly speaking, the latter gives a (multiplicative) savings of $O_{\varepsilon,\delta}(\sqrt{m})$ in terms of the number of users required for achieving the same utility, where $m$ is the number of examples per user. This algorithm, while recovering most known bounds for specific problems, also gives new bounds, e.g., for PAC learning. * For pure-DP, we present a simple technique for adapting the exponential mechanism [McSherry & Talwar, FOCS 2007] to the user-level setting. This gives new bounds for a variety of tasks, such as private PAC learning, hypothesis selection, and distribution learning. For some of these problems, we show that our bounds are near-optimal.",Oral 2D Privacy,https://openreview.net/pdf?id=PITeSdYQkv,https://openreview.net/forum?id=PITeSdYQkv
"['Adrián Javaloy', 'Pablo Sanchez-Martin', 'Isabel Valera']",NeurIPS,Causal normalizing flows_ from theory to practice,https://neurips.cc/virtual/2023/oral/73851,2023," In this work, we deepen on the use of normalizing flows for causal reasoning. Specifically, we first leverage recent results on non-linear ICA to show that causal models are identifiable from observational data given a causal ordering, and thus can be recovered using autoregressive normalizing flows (NFs). Second, we analyze different design and learning choices for causal normalizing flows to capture the underlying causal data-generating process. Third, we describe how to implement the do-operator in causal NFs, and thus, how to answer interventional and counterfactual questions. Finally, in our experiments, we validate our design and training choices through a comprehensive ablation study; compare causal NFs to other approaches for approximating causal models; and empirically demonstrate that causal NFs can be used to address real-world problems—where the presence of mixed discrete-continuous data and partial knowledge on the causal graph is the norm. The code for this work can be found at https://github.com/psanch21/causal-flows.",Oral 2C Causality,https://openreview.net/pdf?id=QIFoCI7ca1,https://openreview.net/forum?id=QIFoCI7ca1
"['Stephanie Milani', 'Anssi Kanervisto', 'Karolis Ramanauskas', 'Sander Schulhoff', 'Brandon Houghton', 'Rohin Shah']",NeurIPS,BEDD_ The MineRL BASALT Evaluation and Demonstrations Dataset for Training and Benchmarking Agents that Solve Fuzzy Tasks,https://neurips.cc/virtual/2023/oral/73745,2023," The MineRL BASALT competition has served to catalyze advances in learning from human feedback through four hard-to-specify tasks in Minecraft, such as create and photograph a waterfall. Given the completion of two years of BASALT competitions, we offer to the community a formalized benchmark through the BASALT Evaluation and Demonstrations Dataset (BEDD), which serves as a resource for algorithm development and performance assessment. BEDD consists of a collection of 26 million image-action pairs from nearly 14,000 videos of human players completing the BASALT tasks in Minecraft. It also includes over 3,000 dense pairwise human evaluations of human and algorithmic agents. These comparisons serve as a fixed, preliminary leaderboard for evaluating newly-developed algorithms.  To enable this comparison, we present a streamlined codebase for benchmarking new algorithms against the leaderboard. In addition to presenting these datasets, we conduct a detailed analysis of the data from both datasets to guide algorithm development and evaluation. The released code and data are available at https://github.com/minerllabs/basalt-benchmark.",Oral 4B Datasets & Benchmarks,https://openreview.net/pdf?id=D1MOK2t2t2,https://openreview.net/forum?id=D1MOK2t2t2
"['Sadhika Malladi', 'Tianyu Gao', 'Eshaan Nichani', 'Alex Damian', 'Jason Lee', 'Danqi Chen', 'Sanjeev Arora']",NeurIPS,Fine-Tuning Language Models with Just Forward Passes,https://neurips.cc/virtual/2023/oral/73844,2023," Fine-tuning language models (LMs) has yielded success on diverse downstream tasks, but as LMs grow in size, backpropagation requires a prohibitively large amount of memory. Zeroth-order (ZO) methods can in principle estimate gradients using only two forward passes but are theorized to be catastrophically slow for optimizing large models. In this work, we propose a memory-efficient zerothorder optimizer (MeZO), adapting the classical ZO-SGD method to operate in-place, thereby fine-tuning LMs with the same memory footprint as inference. For example, with a single A100 80GB GPU, MeZO can train a 30-billion parameter model, whereas fine-tuning with backpropagation can train only a 2.7B LM with the same budget. We conduct comprehensive experiments across model types (masked and autoregressive LMs), model scales (up to 66B), and downstream tasks (classification, multiple-choice, and generation). Our results demonstrate that (1) MeZO significantly outperforms in-context learning and linear probing; (2) MeZO achieves comparable performance to fine-tuning with backpropagation across multiple tasks, with up to 12× memory reduction and up to 2× GPU-hour reduction in our implementation; (3) MeZO is compatible with both full-parameter and parameter-efficient tuning techniques such as LoRA and prefix tuning; (4) MeZO can effectively optimize non-differentiable objectives (e.g., maximizing accuracy or F1). We support our empirical findings with theoretical insights, highlighting how adequate pre-training and task prompts enable MeZO to fine-tune huge models, despite classical ZO analyses suggesting otherwise.",Oral 4A Optimization,https://openreview.net/pdf?id=Vota6rFhBQ,https://openreview.net/forum?id=Vota6rFhBQ
"['Guhao Feng', 'Bohang Zhang', 'Yuntian Gu', 'Haotian Ye', 'Di He', 'Liwei Wang']",NeurIPS,Towards Revealing the Mystery behind Chain of Thought_ A Theoretical Perspective,https://neurips.cc/virtual/2023/oral/73822,2023," Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the expressivity of LLMs with CoT in solving fundamental mathematical and decision-making problems. By using circuit complexity theory, we first give impossibility results showing that bounded-depth Transformers are unable to directly produce correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of constant size suffice to solve both tasks by generating CoT derivations using a commonly used math language format. Moreover, we show LLMs with CoT can handle a general class of decision-making problems known as Dynamic Programming, thus justifying their power in tackling complex real-world tasks. Finally, an extensive set of experiments show that, while Transformers always fail to directly predict the answers, they can consistently learn to generate correct solutions step-by-step given sufficient CoT demonstrations.",Oral 4C COT/reasoning,https://openreview.net/pdf?id=qHrADgAdYu,https://openreview.net/forum?id=qHrADgAdYu
"['Alexander Wei', 'Nika Haghtalab', 'Jacob Steinhardt']",NeurIPS,Jailbroken_ How Does LLM Safety Training Fail_,https://neurips.cc/virtual/2023/oral/73831,2023," Large language models trained for safety and harmlessness remain susceptible to adversarial misuse, as evidenced by the prevalence of “jailbreak” attacks on early releases of ChatGPT that elicit undesired behavior. Going beyond recognition of the issue, we investigate why such attacks succeed and how they can be created. We hypothesize two failure modes of safety training: competing objectives and mismatched generalization. Competing objectives arise when a model’s capabilities and safety goals conflict, while mismatched generalization occurs when safety training fails to generalize to a domain for which capabilities exist. We use these failure modes to guide jailbreak design and then evaluate state-of-the-art models, including OpenAI’s GPT-4 and Anthropic’s Claude v1.3, against both existing and newly designed attacks. We find that vulnerabilities persist despite the extensive red-teaming and safety-training efforts behind these models. Notably, new attacks utilizing our failure modes succeed on every prompt in a collection of unsafe requests from the models’ red-teaming evaluation sets and outperform existing ad hoc jailbreaks. Our analysis emphasizes the need for safety-capability parity—that safety mechanisms should be as sophisticated as the underlying model—and argues against the idea that scaling alone can resolve these safety failure modes.",Oral 6A LLMs,https://openreview.net/pdf?id=jA235JGM09,https://openreview.net/forum?id=jA235JGM09
"['Ajay Subramanian', 'Elena Sizikova', 'Najib Majaj', 'Denis Pelli']",NeurIPS,"Spatial-frequency channels, shape bias, and adversarial robustness",https://neurips.cc/virtual/2023/oral/73860,2023," What spatial frequency information do humans and neural networks use to recognize objects? In neuroscience, critical band masking is an established tool that can reveal the frequency-selective filters used for object recognition. Critical band masking measures the sensitivity of recognition performance to noise added at each spatial frequency. Existing critical band masking studies show that humans recognize periodic patterns (gratings) and letters by means of a spatial-frequency filter (or ""channel"") that has a frequency bandwidth of one octave (doubling of frequency). Here, we introduce critical band masking as a task for network-human comparison and test 14 humans and 76 neural networks on 16-way ImageNet categorization in the presence of narrowband noise. We find that humans recognize objects in natural images using the same one-octave-wide channel that they use for letters and gratings, making it a canonical feature of human object recognition. Unlike humans, the neural network channel is very broad, 2-4 times wider than the human channel. This means that the network channel extends to frequencies higher and lower than those that humans are sensitive to. Thus, noise at those frequencies will impair network performance and spare human performance. Adversarial and augmented-image training are commonly used to increase network robustness and shape bias. Does this training align network and human object recognition channels? Three network channel properties (bandwidth, center frequency, peak noise sensitivity) correlate strongly with shape bias (51% variance explained) and robustness of adversarially-trained networks (66% variance explained). Adversarial training increases robustness but expands the channel bandwidth even further beyond the human bandwidth. Thus, critical band masking reveals that the network channel is more than twice as wide as the human channel, and that adversarial training only makes it worse. Networks with narrower channels might be more robust.",Oral 6C Vision,https://openreview.net/pdf?id=KvPwXVcslY,https://openreview.net/forum?id=KvPwXVcslY
"['Zeyuan Ma', 'Hongshu Guo', 'Jiacheng Chen', 'Zhenrui Li', 'Guojun Peng', 'Yue-Jiao Gong', 'Yining Ma', 'Zhiguang Cao']",NeurIPS,MetaBox_ A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning,https://neurips.cc/virtual/2023/oral/73737,2023," Recently, Meta-Black-Box Optimization with Reinforcement Learning (MetaBBO-RL) has showcased the power of leveraging RL at the meta-level to mitigate manual fine-tuning of low-level black-box optimizers. However, this field is hindered by the lack of a unified benchmark. To fill this gap, we introduce MetaBox, the first benchmark platform expressly tailored for developing and evaluating MetaBBO-RL methods. MetaBox offers a flexible algorithmic template that allows users to effortlessly implement their unique designs within the platform. Moreover, it provides a broad spectrum of over 300 problem instances, collected from synthetic to realistic scenarios, and an extensive library of 19 baseline methods, including both traditional black-box optimizers and recent MetaBBO-RL methods. Besides, MetaBox introduces three standardized performance metrics, enabling a more thorough assessment of the methods. In a bid to illustrate the utility of MetaBox for facilitating rigorous evaluation and in-depth analysis, we carry out a wide-ranging benchmarking study on existing MetaBBO-RL methods. Our MetaBox is open-source and accessible at: https://github.com/GMC-DRL/MetaBox.",Oral 6B RL,https://openreview.net/pdf?id=j2wasUypqN,https://openreview.net/forum?id=j2wasUypqN
"['Hamish Flynn', 'David Reeb', 'Melih Kandemir', 'Jan Peters']",NeurIPS,Improved Algorithms for Stochastic Linear Bandits Using Tail Bounds for Martingale Mixtures,https://neurips.cc/virtual/2023/oral/73845,2023," We present improved algorithms with worst-case regret guarantees for the stochastic linear bandit problem. The widely used ""optimism in the face of uncertainty"" principle reduces a stochastic bandit problem to the construction of a confidence sequence for the unknown reward function. The performance of the resulting bandit algorithm depends on the size of the confidence sequence, with smaller confidence sets yielding better empirical performance and stronger regret guarantees. In this work, we use a novel tail bound for adaptive martingale mixtures to construct confidence sequences which are suitable for stochastic bandits. These confidence sequences allow for efficient action selection via convex programming. We prove that a linear bandit algorithm based on our confidence sequences is guaranteed to achieve competitive worst-case regret. We show that our confidence sequences are tighter than competitors, both empirically and theoretically. Finally, we demonstrate that our tighter confidence sequences give improved performance in several hyperparameter tuning tasks.",Oral 6D Theory,https://openreview.net/pdf?id=TXoZiUZywf,https://openreview.net/forum?id=TXoZiUZywf
